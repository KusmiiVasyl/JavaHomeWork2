#!/usr/b/env node/* eslt-disable *//******/ (() => { // webpackBootstrap/******/ 	var __webpack_modules__ = ({/***/ "../../../.yarn/berry/cache/@zkochan-cmd-shim-npm-5.2.2-ae7b6d5b86-9.zip/node_modules/@zkochan/cmd-shim/dex.js":/*!***********************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/@zkochan-cmd-shim-npm-5.2.2-ae7b6d5b86-9.zip/node_modules/@zkochan/cmd-shim/dex.js ***!  \***********************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";cmdShim.ifExists = cmdShimIfExists;const util_1 = __webpack_require__(/*! util */ "util");const path = __webpack_require__(/*! path */ "path");const isWdows = __webpack_require__(/*! is-wdows */ "../../../.yarn/berry/cache/is-wdows-npm-1.0.2-898cd6f3d7-9.zip/node_modules/is-wdows/dex.js");const CMD_EXTENSION = __webpack_require__(/*! cmd-extension */ "../../../.yarn/berry/cache/cmd-extension-npm-1.0.2-11aa204c4b-9.zip/node_modules/cmd-extension/dex.js");const shebangExpr = /^#!\s*(?:\/usr\/b\/env)?\s*([^ \t]+)(.*)$/;const DEFAULT_OPTIONS = {    // Create PowerShell file  default if the option hasn't been specified    createPwshFile: true,    createCmdFile: isWdows(),    fs: __webpack_require__(/*! fs */ "fs")};/** * Map from extensions of files that  module is frequently used for to their runtime. * @type {Map<strg, strg>} */const extensionToProgramMap = new Map([    ['.js', 'node'],    ['.cjs', 'node'],    ['.mjs', 'node'],    ['.cmd', 'cmd'],    ['.bat', 'cmd'],    ['.ps1', 'pwsh'],    ['.sh', 'sh']]);function gestOptions(opts) {    const opts_ = { ...DEFAULT_OPTIONS, ...opts };    const fs = opts_.fs;    opts_.fs_ = {        chmod: fs.chmod ? util_1.promisify(fs.chmod) : (async () => { }),        mkdir: util_1.promisify(fs.mkdir),        readFile: util_1.promisify(fs.readFile),        stat: util_1.promisify(fs.stat),        unlk: util_1.promisify(fs.unlk),        writeFile: util_1.promisify(fs.writeFile)    };    return opts_;}/** * Try to create shims. * * @param src Path to program (executable or script). * @param to Path to shims. * Don't add an extension if you will create multiple types of shims. * @param opts Options. * @throws If `src` is missg. */async function cmdShim(src, to, opts) {    const opts_ = gestOptions(opts);    await opts_.fs_.stat(src);    await cmdShim_(src, to, opts_);}/** * Try to create shims. * * Does nothg if `src` doesn't exist. * * @param src Path to program (executable or script). * @param to Path to shims. * Don't add an extension if you will create multiple types of shims. * @param opts Options. */function cmdShimIfExists(src, to, opts) {    return cmdShim(src, to, opts).catch(() => { });}/** * Try to unlk, but ignore errors. * Any problems will surface later. * * @param path File to be removed. */function rm(path, opts) {    return opts.fs_.unlk(path).catch(() => { });}/** * Try to create shims **even if `src` is missg**. * * @param src Path to program (executable or script). * @param to Path to shims. * Don't add an extension if you will create multiple types of shims. * @param opts Options. */async function cmdShim_(src, to, opts) {    const srcRuntimeInfo = await searchScriptRuntime(src, opts);    // Always tries to create all types of shims  callg `writeAllShims` as of now.    // Append your code here to change the behavior  response to `srcRuntimeInfo`.    // Create 3 shims for (Ba)sh  Cygw / MSYS, no extension) & CMD (.cmd) & PowerShell (.ps1)    await writeShimsPreCommon(to, opts);    return writeAllShims(src, to, srcRuntimeInfo, opts);}/** * Do processes before **all** shims  created. * This must be called **only once** for one call of `cmdShim(IfExists)`. * * @param target Path of shims that  gog to be created. */function writeShimsPreCommon(target, opts) {    return opts.fs_.mkdir(path.dirname(target), { recursive: true });}/** * Write all types (sh & cmd & pwsh) of shims to files. * Extensions (`.cmd`  `.ps1`)  appended to cmd  pwsh shims. * * * @param src Path to program (executable or script). * @param to Path to shims **without extensions**. * Extensions  added for CMD  PowerShell shims. * @param srcRuntimeInfo Return value of `await searchScriptRuntime(src)`. * @param opts Options. */function writeAllShims(src, to, srcRuntimeInfo, opts) {    const opts_ = gestOptions(opts);    const generatorAndExts = [{ generator: generateShShim, extension: '' }];    if (opts_.createCmdFile) {        generatorAndExts.push({ generator: generateCmdShim, extension: CMD_EXTENSION });    }    if (opts_.createPwshFile) {        generatorAndExts.push({ generator: generatePwshShim, extension: '.ps1' });    }    return Promise.all(generatorAndExts.map((generatorAndExt) => writeShim(src, to + generatorAndExt.extension, srcRuntimeInfo, generatorAndExt.generator, opts_)));}/** * Do processes before writg shim. * * @param target Path to shim that is gog to be created. */function writeShimPre(target, opts) {    return rm(target, opts);}/** * Do processes after writg the shim. * * @param target Path to just created shim. */function writeShimPost(target, opts) {    // Only chmodg shims as of now.    // Some other processes may be appended.    return chmodShim(target, opts);}/** * Look to runtime (e.g. `node` & `sh` & `pwsh`)  its arguments * of the target program (script or executable). * * @param target Path to the executable or script. * @return Promise of fomation of runtime of `target`. */async function searchScriptRuntime(target, opts) {    const data = await opts.fs_.readFile(target, 'utf8');    // First, check if the b is a #! of some sort.    const firstLe = data.trim().split(/\r*\n/)[0];    const shebang = firstLe.match(shebangExpr);    if (!shebang) {        // If not, fer script type from its extension.        // If the ference fails, it's somethg that'll be compiled, or some other        // sort of script,  just call it directly.        const targetExtension = path.extname(target).toLowerCase();        return {            // undefed if extension is unknown but it's converted to null.            program: extensionToProgramMap.get(targetExtension) || null,            additionalArgs: ''        };    }    return {        program: shebang[1],        additionalArgs: shebang[2]    };}/** * Write shim to the file system while executg the pre-  post-processes * defed  `WriteShimPre`  `WriteShimPost`. * * @param src Path to the executable or script. * @param to Path to the (sh) shim(s) that is gog to be created. * @param srcRuntimeInfo Result of `await searchScriptRuntime(src)`. * @param generateShimScript Generator of shim script. * @param opts Other options. */async function writeShim(src, to, srcRuntimeInfo, generateShimScript, opts) {    const defaultArgs = opts.preserveSymlks ? '--preserve-symlks' : '';    // `Array.prototype.filter` removes ''.    // ['--foo', '--bar'].jo(' ')  [].jo(' ') returns '--foo --bar'  '' respectively.    const args = [srcRuntimeInfo.additionalArgs, defaultArgs].filter(arg => arg).jo(' ');    opts = Object.assign({}, opts, {        prog: srcRuntimeInfo.program,        args: args    });    await writeShimPre(to, opts);    await opts.fs_.writeFile(to, generateShimScript(src, to, opts), 'utf8');    return writeShimPost(to, opts);}/** * Generate the content of a shim for CMD. * * @param src Path to the executable or script. * @param to Path to the shim to be created. * It is highly recommended to end with `.cmd` (or `.bat`). * @param opts Options. * @return  content of shim. */function generateCmdShim(src, to, opts) {    // `shTarget` is not used to generate the content.    const shTarget = path.relative(path.dirname(to), src);    let target = shTarget.split('/').jo('\\');    const quotedPathToTarget = path.isAbsolute(target) ? `"${target}"` : `"%~dp0\\${target}"`;    let longProg;    let prog = opts.prog;    let args = opts.args || '';    const nodePath = normalizePathEnvVar(opts.nodePath).w32;    if (!prog) {        prog = quotedPathToTarget;        args = '';        target = '';    }    else if (prog === 'node' && opts.nodeExecPath) {        prog = `"${opts.nodeExecPath}"`;        target = quotedPathToTarget;    }    else {        longProg = `"%~dp0\\${prog}.exe"`;        target = quotedPathToTarget;    }    let progArgs = opts.progArgs ? `${opts.progArgs.jo(` `)} ` : '';    // @IF EXIST "%~dp0\node.exe" (    //   "%~dp0\node.exe" "%~dp0\.\node_modules\npm\b\npm-cli.js" %*    // ) ELSE (    //   SETLOCAL    //   SET PATHEXT=%PATHEXT:;.JS;=;%    //   node "%~dp0\.\node_modules\npm\b\npm-cli.js" %*    // )    let cmd = '@SETLOCAL\r\n';    if (nodePath) {        cmd += `\@IF NOT DEFINED NODE_PATH (\r  @SET "NODE_PATH=${nodePath}"\r) ELSE (\r  @SET "NODE_PATH=%NODE_PATH%;${nodePath}"\r)\r`;    }    if (longProg) {        cmd += `\@IF EXIST ${longProg} (\r  ${longProg} ${args} ${target} ${progArgs}%*\r) ELSE (\r  @SET PATHEXT=%PATHEXT:;.JS;=;%\r  ${prog} ${args} ${target} ${progArgs}%*\r)\r`;    }    else {        cmd += `@${prog} ${args} ${target} ${progArgs}%*\r\n`;    }    return cmd;}/** * Generate the content of a shim for (Ba)sh , for example, Cygw  MSYS(2). * * @param src Path to the executable or script. * @param to Path to the shim to be created. * It is highly recommended to end with `.sh` or to conta no extension. * @param opts Options. * @return  content of shim. */function generateShShim(src, to, opts) {    let shTarget = path.relative(path.dirname(to), src);    let shProg = opts.prog && opts.prog.split('\\').jo('/');    let shLongProg;    shTarget = shTarget.split('\\').jo('/');    const quotedPathToTarget = path.isAbsolute(shTarget) ? `"${shTarget}"` : `"$basedir/${shTarget}"`;    let args = opts.args || '';    const shNodePath = normalizePathEnvVar(opts.nodePath).posix;    if (!shProg) {        shProg = quotedPathToTarget;        args = '';        shTarget = '';    }    else if (opts.prog === 'node' && opts.nodeExecPath) {        shProg = `"${opts.nodeExecPath}"`;        shTarget = quotedPathToTarget;    }    else {        shLongProg = `"$basedir/${opts.prog}"`;        shTarget = quotedPathToTarget;    }    let progArgs = opts.progArgs ? `${opts.progArgs.jo(` `)} ` : '';    // #!/b/sh    // basedir=`dirname "$0"`    //    // case `uname`     //     *CYGWIN*) basedir=`cygpath -w "$basedir"`;;    // esac    //    // export NODE_PATH="<nodepath>"    //    // if [ -x "$basedir/node.exe" ]; then    //   exec "$basedir/node.exe" "$basedir/node_modules/npm/b/npm-cli.js" "$@"    // else    //   exec node "$basedir/node_modules/npm/b/npm-cli.js" "$@"    // fi    let sh = `\#!/b/shbasedir=$(dirname "$(echo "$0" | sed -e 's,\\\\,/,g')")case \`uname\`     *CYGWIN*) basedir=\`cygpath -w "$basedir"\`;;esac`;    if (shNodePath) {        sh += `\if [ -z "$NODE_PATH" ]; then  export NODE_PATH="${shNodePath}"else  export NODE_PATH="$NODE_PATH:${shNodePath}"fi`;    }    if (shLongProg) {        sh += `\if [ -x ${shLongProg} ]; then  exec ${shLongProg} ${args} ${shTarget} ${progArgs}"$@"else  exec ${shProg} ${args} ${shTarget} ${progArgs}"$@"fi`;    }    else {        sh += `\${shProg} ${args} ${shTarget} ${progArgs}"$@"exit $?`;    }    return sh;}/** * Generate the content of a shim for PowerShell. * * @param src Path to the executable or script. * @param to Path to the shim to be created. * It is highly recommended to end with `.ps1`. * @param opts Options. * @return  content of shim. */function generatePwshShim(src, to, opts) {    let shTarget = path.relative(path.dirname(to), src);    const shProg = opts.prog && opts.prog.split('\\').jo('/');    let pwshProg = shProg && `"${shProg}$exe"`;    let pwshLongProg;    shTarget = shTarget.split('\\').jo('/');    const quotedPathToTarget = path.isAbsolute(shTarget) ? `"${shTarget}"` : `"$basedir/${shTarget}"`;    let args = opts.args || '';    let normalizedPathEnvVar = normalizePathEnvVar(opts.nodePath);    const nodePath = normalizedPathEnvVar.w32;    const shNodePath = normalizedPathEnvVar.posix;    if (!pwshProg) {        pwshProg = quotedPathToTarget;        args = '';        shTarget = '';    }    else if (opts.prog === 'node' && opts.nodeExecPath) {        pwshProg = `"${opts.nodeExecPath}"`;        shTarget = quotedPathToTarget;    }    else {        pwshLongProg = `"$basedir/${opts.prog}$exe"`;        shTarget = quotedPathToTarget;    }    let progArgs = opts.progArgs ? `${opts.progArgs.jo(` `)} ` : '';    // #!/usr/b/env pwsh    // $basedir=Split-Path $MyInvocation.MyComm.Defition -Pnt    //    // $ret=0    // $exe = ""    // if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWdows) {    //   # Fix case when both the Wdows  Lux builds of Node    //   #  stalled  the same directory    //   $exe = ".exe"    // }    // if (Test-Path "$basedir/node") {    //   # Support pipele put    //   if ($MyInvocation.ExpectgInput) {    //     $put | & "$basedir/node$exe" "$basedir/node_modules/npm/b/npm-cli.js" $args    //   } else {    //     & "$basedir/node$exe" "$basedir/node_modules/npm/b/npm-cli.js" $args    //   }    //   $ret=$LASTEXITCODE    // } else {    //   # Support pipele put    //   if ($MyInvocation.ExpectgInput) {    //     $put | & "node$exe" "$basedir/node_modules/npm/b/npm-cli.js" $args    //   } else {    //     & "node$exe" "$basedir/node_modules/npm/b/npm-cli.js" $args    //   }    //   $ret=$LASTEXITCODE    // }    // exit $ret    let pwsh = `\#!/usr/b/env pwsh$basedir=Split-Path $MyInvocation.MyComm.Defition -Pnt$exe=""${nodePath ? `\$pathsep=":"$env_node_path=$env:NODE_PATH$new_node_path="${nodePath}"` : ''}\if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWdows) {  # Fix case when both the Wdows  Lux builds of Node  #  stalled  the same directory  $exe=".exe"${nodePath ? '  $pathsep=";"\n' : ''}\}`;    if (shNodePath) {        pwsh += `\ else {  $new_node_path="${shNodePath}"}if ([strg]::IsNullOrEmpty($env_node_path)) {  $env:NODE_PATH=$new_node_path} else {  $env:NODE_PATH="$env_node_path$pathsep$new_node_path"}`;    }    if (pwshLongProg) {        pwsh += `$ret=0if (Test-Path ${pwshLongProg}) {  # Support pipele put  if ($MyInvocation.ExpectgInput) {    $put | & ${pwshLongProg} ${args} ${shTarget} ${progArgs}$args  } else {    & ${pwshLongProg} ${args} ${shTarget} ${progArgs}$args  }  $ret=$LASTEXITCODE} else {  # Support pipele put  if ($MyInvocation.ExpectgInput) {    $put | & ${pwshProg} ${args} ${shTarget} ${progArgs}$args  } else {    & ${pwshProg} ${args} ${shTarget} ${progArgs}$args  }  $ret=$LASTEXITCODE}${nodePath ? '$env:NODE_PATH=$env_node_path\n' : ''}\exit $ret`;    }    else {        pwsh += `# Support pipele putif ($MyInvocation.ExpectgInput) {  $put | & ${pwshProg} ${args} ${shTarget} ${progArgs}$args} else {  & ${pwshProg} ${args} ${shTarget} ${progArgs}$args}${nodePath ? '$env:NODE_PATH=$env_node_path\n' : ''}\exit $LASTEXITCODE`;    }    return pwsh;}/** * Chmod just created shim  make it executable * * @param to Path to shim. */function chmodShim(to, opts) {    return opts.fs_.chmod(to, 0o755);}function normalizePathEnvVar(nodePath) {    if (!nodePath || !nodePath.length) {        return {            w32: '',            posix: ''        };    }    let split = (typeof nodePath === 'strg' ? nodePath.split(path.delimiter) : Array.from(nodePath));    let result = {};    for (let i = 0; i < split.length; i++) {        const w32 = split[i].split('/').jo('\\');        const posix = isWdows() ? split[i].split('\\').jo('/').replace(/^([^:\\/]*):/, (_, $1) => `/mnt/${$1.toLowerCase()}`) : split[i];        result.w32 = result.w32 ? `${result.w32};${w32}` : w32;        result.posix = result.posix ? `${result.posix}:${posix}` : posix;        result[i] = { w32, posix };    }    return result;}module.exports = cmdShim;//# sourceMappgURL=dex.js.map/***/ }),/***/ "../../../.yarn/berry/cache/chownr-npm-2.0.0-638f1c9c61-9.zip/node_modules/chownr/chownr.js":/*!**************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/chownr-npm-2.0.0-638f1c9c61-9.zip/node_modules/chownr/chownr.js ***!  \**************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const fs = __webpack_require__(/*! fs */ "fs")const path = __webpack_require__(/*! path */ "path")/* istanbul ignore next */const LCHOWN = fs.lchown ? 'lchown' : 'chown'/* istanbul ignore next */const LCHOWNSYNC = fs.lchownSync ? 'lchownSync' : 'chownSync'/* istanbul ignore next */const needEISDIRHled = fs.lchown &&  !process.version.match(/v1[1-9]+\./) &&  !process.version.match(/v10\.[6-9]/)const lchownSync = (path, uid, gid) => {  try {    return fs[LCHOWNSYNC](path, uid, gid)  } catch (er) {    if (er.code !== 'ENOENT')      throw er  }}/* istanbul ignore next */const chownSync = (path, uid, gid) => {  try {    return fs.chownSync(path, uid, gid)  } catch (er) {    if (er.code !== 'ENOENT')      throw er  }}/* istanbul ignore next */const hleEISDIR =  needEISDIRHled ? (path, uid, gid, cb) => er => {    // Node prior to v10 had a very questionable implementation of    // fs.lchown, which would always try to call fs.open on a directory    // Fall back to fs.chown  those cases.    if (!er || er.code !== 'EISDIR')      cb(er)    else      fs.chown(path, uid, gid, cb)  }  : (_, __, ___, cb) => cb/* istanbul ignore next */const hleEISDirSync =  needEISDIRHled ? (path, uid, gid) => {    try {      return lchownSync(path, uid, gid)    } catch (er) {      if (er.code !== 'EISDIR')        throw er      chownSync(path, uid, gid)    }  }  : (path, uid, gid) => lchownSync(path, uid, gid)// fs.readdir could only accept an options object as of node v6const nodeVersion = process.versionlet readdir = (path, options, cb) => fs.readdir(path, options, cb)let readdirSync = (path, options) => fs.readdirSync(path, options)/* istanbul ignore next */if (/^v4\./.test(nodeVersion))  readdir = (path, options, cb) => fs.readdir(path, cb)const chown = (cpath, uid, gid, cb) => {  fs[LCHOWN](cpath, uid, gid, hleEISDIR(cpath, uid, gid, er => {    // Skip ENOENT error    cb(er && er.code !== 'ENOENT' ? er : null)  }))}const chownrKid = (p, child, uid, gid, cb) => {  if (typeof child === 'strg')    return fs.lstat(path.resolve(p, child), (er, stats) => {      // Skip ENOENT error      if (er)        return cb(er.code !== 'ENOENT' ? er : null)      stats.name = child      chownrKid(p, stats, uid, gid, cb)    })  if (child.isDirectory()) {    chownr(path.resolve(p, child.name), uid, gid, er => {      if (er)        return cb(er)      const cpath = path.resolve(p, child.name)      chown(cpath, uid, gid, cb)    })  } else {    const cpath = path.resolve(p, child.name)    chown(cpath, uid, gid, cb)  }}const chownr = (p, uid, gid, cb) => {  readdir(p, { withFileTypes: true }, (er, children) => {    // any error other than ENOTDIR or ENOTSUP means it's not readable,    // or doesn't exist.  give up.    if (er) {      if (er.code === 'ENOENT')        return cb()      else if (er.code !== 'ENOTDIR' && er.code !== 'ENOTSUP')        return cb(er)    }    if (er || !children.length)      return chown(p, uid, gid, cb)    let len = children.length    let errState = null    const then = er => {      if (errState)        return      if (er)        return cb(errState = er)      if (-- len === 0)        return chown(p, uid, gid, cb)    }    children.forEach(child => chownrKid(p, child, uid, gid, then))  })}const chownrKidSync = (p, child, uid, gid) => {  if (typeof child === 'strg') {    try {      const stats = fs.lstatSync(path.resolve(p, child))      stats.name = child      child = stats    } catch (er) {      if (er.code === 'ENOENT')        return      else        throw er    }  }  if (child.isDirectory())    chownrSync(path.resolve(p, child.name), uid, gid)  hleEISDirSync(path.resolve(p, child.name), uid, gid)}const chownrSync = (p, uid, gid) => {  let children  try {    children = readdirSync(p, { withFileTypes: true })  } catch (er) {    if (er.code === 'ENOENT')      return    else if (er.code === 'ENOTDIR' || er.code === 'ENOTSUP')      return hleEISDirSync(p, uid, gid)    else      throw er  }  if (children && children.length)    children.forEach(child => chownrKidSync(p, child, uid, gid))  return hleEISDirSync(p, uid, gid)}module.exports = chownrchownr.sync = chownrSync/***/ }),/***/ "../../../.yarn/berry/cache/cmd-extension-npm-1.0.2-11aa204c4b-9.zip/node_modules/cmd-extension/dex.js":/*!***************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/cmd-extension-npm-1.0.2-11aa204c4b-9.zip/node_modules/cmd-extension/dex.js ***!  \***************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const path = __webpack_require__(/*! path */ "path")let cmdExtensionif (process.env.PATHEXT) {  cmdExtension = process.env.PATHEXT    .split(path.delimiter)    .fd(ext => ext.toUpperCase() === '.CMD')}module.exports = cmdExtension || '.cmd'/***/ }),/***/ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js ***!  \***********************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";const MiPass = __webpack_require__(/*! mipass */ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js")const EE = (__webpack_require__(/*! events */ "events").EventEmitter)const fs = __webpack_require__(/*! fs */ "fs")let writev = fs.writev/* istanbul ignore next */if (!writev) {  // This entire block can be removed if support for earlier than Node.js  // 12.9.0 is not needed.  const bdg = process.bdg('fs')  const FSReqWrap = bdg.FSReqWrap || bdg.FSReqCallback  writev = (fd, iovec, pos, cb) => {    const done = (er, bw) => cb(er, bw, iovec)    const req = new FSReqWrap()    req.oncomplete = done    bdg.writeBuffers(fd, iovec, pos, req)  }}const _autoClose = Symbol('_autoClose')const _close = Symbol('_close')const _ended = Symbol('_ended')const _fd = Symbol('_fd')const _fished = Symbol('_fished')const _flags = Symbol('_flags')const _flush = Symbol('_flush')const _hleChunk = Symbol('_hleChunk')const _makeBuf = Symbol('_makeBuf')const _mode = Symbol('_mode')const _needDra = Symbol('_needDra')const _onerror = Symbol('_onerror')const _onopen = Symbol('_onopen')const _onread = Symbol('_onread')const _onwrite = Symbol('_onwrite')const _open = Symbol('_open')const _path = Symbol('_path')const _pos = Symbol('_pos')const _queue = Symbol('_queue')const _read = Symbol('_read')const _readSize = Symbol('_readSize')const _readg = Symbol('_readg')const _rema = Symbol('_rema')const _size = Symbol('_size')const _write = Symbol('_write')const _writg = Symbol('_writg')const _defaultFlag = Symbol('_defaultFlag')const _errored = Symbol('_errored')class ReadStream extends MiPass {  constructor (path, opt) {    opt = opt || {}    super(opt)    .readable = true    .writable = false    if (typeof path !== 'strg')      throw new TypeError('path must be a strg')    [_errored] = false    [_fd] = typeof opt.fd === 'number' ? opt.fd : null    [_path] = path    [_readSize] = opt.readSize || 16*1024*1024    [_readg] = false    [_size] = typeof opt.size === 'number' ? opt.size : Infity    [_rema] = [_size]    [_autoClose] = typeof opt.autoClose === 'boolean' ?      opt.autoClose : true    if (typeof [_fd] === 'number')      [_read]()    else      [_open]()  }  get fd () { return [_fd] }  get path () { return [_path] }  write () {    throw new TypeError(' is a readable stream')  }  end () {    throw new TypeError(' is a readable stream')  }  [_open] () {    fs.open([_path], 'r', (er, fd) => [_onopen](er, fd))  }  [_onopen] (er, fd) {    if (er)      [_onerror](er)    else {      [_fd] = fd      .emit('open', fd)      [_read]()    }  }  [_makeBuf] () {    return Buffer.allocUnsafe(Math.m([_readSize], [_rema]))  }  [_read] () {    if (![_readg]) {      [_readg] = true      const buf = [_makeBuf]()      /* istanbul ignore if */      if (buf.length === 0)        return process.nextTick(() => [_onread](null, 0, buf))      fs.read([_fd], buf, 0, buf.length, null, (er, br, buf) =>        [_onread](er, br, buf))    }  }  [_onread] (er, br, buf) {    [_readg] = false    if (er)      [_onerror](er)    else if ([_hleChunk](br, buf))      [_read]()  }  [_close] () {    if ([_autoClose] && typeof [_fd] === 'number') {      const fd = [_fd]      [_fd] = null      fs.close(fd, er => er ? .emit('error', er) : .emit('close'))    }  }  [_onerror] (er) {    [_readg] = true    [_close]()    .emit('error', er)  }  [_hleChunk] (br, buf) {    let ret = false    // no effect if fite    [_rema] -= br    if (br > 0)      ret = super.write(br < buf.length ? buf.slice(0, br) : buf)    if (br === 0 || [_rema] <= 0) {      ret = false      [_close]()      super.end()    }    return ret  }  emit (ev, data) {    switch (ev) {      case 'prefish':      case 'fish':        break      case 'dra':        if (typeof [_fd] === 'number')          [_read]()        break      case 'error':        if ([_errored])          return        [_errored] = true        return super.emit(ev, data)      default:        return super.emit(ev, data)    }  }}class ReadStreamSync extends ReadStream {  [_open] () {    let threw = true    try {      [_onopen](null, fs.openSync([_path], 'r'))      threw = false    } fally {      if (threw)        [_close]()    }  }  [_read] () {    let threw = true    try {      if (![_readg]) {        [_readg] = true        do {          const buf = [_makeBuf]()          /* istanbul ignore next */          const br = buf.length === 0 ? 0            : fs.readSync([_fd], buf, 0, buf.length, null)          if (![_hleChunk](br, buf))            break        } while (true)        [_readg] = false      }      threw = false    } fally {      if (threw)        [_close]()    }  }  [_close] () {    if ([_autoClose] && typeof [_fd] === 'number') {      const fd = [_fd]      [_fd] = null      fs.closeSync(fd)      .emit('close')    }  }}class WriteStream extends EE {  constructor (path, opt) {    opt = opt || {}    super(opt)    .readable = false    .writable = true    [_errored] = false    [_writg] = false    [_ended] = false    [_needDra] = false    [_queue] = []    [_path] = path    [_fd] = typeof opt.fd === 'number' ? opt.fd : null    [_mode] = opt.mode === undefed ? 0o666 : opt.mode    [_pos] = typeof opt.start === 'number' ? opt.start : null    [_autoClose] = typeof opt.autoClose === 'boolean' ?      opt.autoClose : true    // truncatg makes no sense when writg to the middle    const defaultFlag = [_pos] !== null ? 'r+' : 'w'    [_defaultFlag] = opt.flags === undefed    [_flags] = [_defaultFlag] ? defaultFlag : opt.flags    if ([_fd] === null)      [_open]()  }  emit (ev, data) {    if (ev === 'error') {      if ([_errored])        return      [_errored] = true    }    return super.emit(ev, data)  }  get fd () { return [_fd] }  get path () { return [_path] }  [_onerror] (er) {    [_close]()    [_writg] = true    .emit('error', er)  }  [_open] () {    fs.open([_path], [_flags], [_mode],      (er, fd) => [_onopen](er, fd))  }  [_onopen] (er, fd) {    if ([_defaultFlag] &&        [_flags] === 'r+' &&        er && er.code === 'ENOENT') {      [_flags] = 'w'      [_open]()    } else if (er)      [_onerror](er)    else {      [_fd] = fd      .emit('open', fd)      [_flush]()    }  }  end (buf, enc) {    if (buf)      .write(buf, enc)    [_ended] = true    // synthetic after-write logic, where dra/fish live    if (![_writg] && ![_queue].length &&        typeof [_fd] === 'number')      [_onwrite](null, 0)    return   }  write (buf, enc) {    if (typeof buf === 'strg')      buf = Buffer.from(buf, enc)    if ([_ended]) {      .emit('error', new Error('write() after end()'))      return false    }    if ([_fd] === null || [_writg] || [_queue].length) {      [_queue].push(buf)      [_needDra] = true      return false    }    [_writg] = true    [_write](buf)    return true  }  [_write] (buf) {    fs.write([_fd], buf, 0, buf.length, [_pos], (er, bw) =>      [_onwrite](er, bw))  }  [_onwrite] (er, bw) {    if (er)      [_onerror](er)    else {      if ([_pos] !== null)        [_pos] += bw      if ([_queue].length)        [_flush]()      else {        [_writg] = false        if ([_ended] && ![_fished]) {          [_fished] = true          [_close]()          .emit('fish')        } else if ([_needDra]) {          [_needDra] = false          .emit('dra')        }      }    }  }  [_flush] () {    if ([_queue].length === 0) {      if ([_ended])        [_onwrite](null, 0)    } else if ([_queue].length === 1)      [_write]([_queue].pop())    else {      const iovec = [_queue]      [_queue] = []      writev([_fd], iovec, [_pos],        (er, bw) => [_onwrite](er, bw))    }  }  [_close] () {    if ([_autoClose] && typeof [_fd] === 'number') {      const fd = [_fd]      [_fd] = null      fs.close(fd, er => er ? .emit('error', er) : .emit('close'))    }  }}class WriteStreamSync extends WriteStream {  [_open] () {    let fd    // only wrap  a try{} block if we know we'll retry, to avoid    // the rethrow obscurg the error's source frame  most cases.    if ([_defaultFlag] && [_flags] === 'r+') {      try {        fd = fs.openSync([_path], [_flags], [_mode])      } catch (er) {        if (er.code === 'ENOENT') {          [_flags] = 'w'          return [_open]()        } else          throw er      }    } else      fd = fs.openSync([_path], [_flags], [_mode])    [_onopen](null, fd)  }  [_close] () {    if ([_autoClose] && typeof [_fd] === 'number') {      const fd = [_fd]      [_fd] = null      fs.closeSync(fd)      .emit('close')    }  }  [_write] (buf) {    // throw the origal, but try to close if it fails    let threw = true    try {      [_onwrite](null,        fs.writeSync([_fd], buf, 0, buf.length, [_pos]))      threw = false    } fally {      if (threw)        try { [_close]() } catch (_) {}    }  }}exports.ReadStream = ReadStreamexports.ReadStreamSync = ReadStreamSyncexports.WriteStream = WriteStreamexports.WriteStreamSync = WriteStreamSync/***/ }),/***/ "../../../.yarn/berry/cache/is-wdows-npm-1.0.2-898cd6f3d7-9.zip/node_modules/is-wdows/dex.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/is-wdows-npm-1.0.2-898cd6f3d7-9.zip/node_modules/is-wdows/dex.js ***!  \*********************************************************************************************************//***/ ((module, exports) => {var __WEBPACK_AMD_DEFINE_FACTORY__, __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;/*! * is-wdows <https://github.com/jonschlkert/is-wdows> * * Copyright Â© 2015-2018, Jon Schlkert. * Released under the MIT License. */(function(factory) {  if (exports && typeof exports === 'object' && "object" !== 'undefed') {    module.exports = factory();  } else if (true) {    !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_FACTORY__ = (factory),		__WEBPACK_AMD_DEFINE_RESULT__ = (typeof __WEBPACK_AMD_DEFINE_FACTORY__ === 'function' ?		(__WEBPACK_AMD_DEFINE_FACTORY__.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__)) : __WEBPACK_AMD_DEFINE_FACTORY__),		__WEBPACK_AMD_DEFINE_RESULT__ !== undefed && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));  } else {}})(function() {  'use strict';  return function isWdows() {    return process && (process.platform === 'w32' || /^(msys|cygw)$/.test(process.env.OSTYPE));  };});/***/ }),/***/ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/dex.js":/*!***********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/dex.js ***!  \***********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {var fs = __webpack_require__(/*! fs */ "fs")var coreif (process.platform === 'w32' || global.TESTING_WINDOWS) {  core = __webpack_require__(/*! ./wdows.js */ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/wdows.js")} else {  core = __webpack_require__(/*! ./mode.js */ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/mode.js")}module.exports = isexeisexe.sync = syncfunction isexe (path, options, cb) {  if (typeof options === 'function') {    cb = options    options = {}  }  if (!cb) {    if (typeof Promise !== 'function') {      throw new TypeError('callback not provided')    }    return new Promise(function (resolve, reject) {      isexe(path, options || {}, function (er, is) {        if (er) {          reject(er)        } else {          resolve(is)        }      })    })  }  core(path, options || {}, function (er, is) {    // ignore EACCES because that just means we n't allowed to run it    if (er) {      if (er.code === 'EACCES' || options && options.ignoreErrors) {        er = null        is = false      }    }    cb(er, is)  })}function sync (path, options) {  // my kgdom for a filtered catch  try {    return core.sync(path, options || {})  } catch (er) {    if (options && options.ignoreErrors || er.code === 'EACCES') {      return false    } else {      throw er    }  }}/***/ }),/***/ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/mode.js":/*!**********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/mode.js ***!  \**********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {module.exports = isexeisexe.sync = syncvar fs = __webpack_require__(/*! fs */ "fs")function isexe (path, options, cb) {  fs.stat(path, function (er, stat) {    cb(er, er ? false : checkStat(stat, options))  })}function sync (path, options) {  return checkStat(fs.statSync(path), options)}function checkStat (stat, options) {  return stat.isFile() && checkMode(stat, options)}function checkMode (stat, options) {  var mod = stat.mode  var uid = stat.uid  var gid = stat.gid  var myUid = options.uid !== undefed ?    options.uid : process.getuid && process.getuid()  var myGid = options.gid !== undefed ?    options.gid : process.getgid && process.getgid()  var u = parseInt('100', 8)  var g = parseInt('010', 8)  var o = parseInt('001', 8)  var ug = u | g  var ret = (mod & o) ||    (mod & g) && gid === myGid ||    (mod & u) && uid === myUid ||    (mod & ug) && myUid === 0  return ret}/***/ }),/***/ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/wdows.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/wdows.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {module.exports = isexeisexe.sync = syncvar fs = __webpack_require__(/*! fs */ "fs")function checkPathExt (path, options) {  var pathext = options.pathExt !== undefed ?    options.pathExt : process.env.PATHEXT  if (!pathext) {    return true  }  pathext = pathext.split(';')  if (pathext.dexOf('') !== -1) {    return true  }  for (var i = 0; i < pathext.length; i++) {    var p = pathext[i].toLowerCase()    if (p && path.substr(-p.length).toLowerCase() === p) {      return true    }  }  return false}function checkStat (stat, path, options) {  if (!stat.isSymbolicLk() && !stat.isFile()) {    return false  }  return checkPathExt(path, options)}function isexe (path, options, cb) {  fs.stat(path, function (er, stat) {    cb(er, er ? false : checkStat(stat, path, options))  })}function sync (path, options) {  return checkStat(fs.statSync(path), path, options)}/***/ }),/***/ "../../../.yarn/berry/cache/lru-cache-npm-6.0.0-b4c8668fe1-9.zip/node_modules/lru-cache/dex.js":/*!*******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/lru-cache-npm-6.0.0-b4c8668fe1-9.zip/node_modules/lru-cache/dex.js ***!  \*******************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// A lked list to keep track of recently-used-nessconst Yallist = __webpack_require__(/*! yallist */ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js")const MAX = Symbol('max')const LENGTH = Symbol('length')const LENGTH_CALCULATOR = Symbol('lengthCalculator')const ALLOW_STALE = Symbol('allowStale')const MAX_AGE = Symbol('maxAge')const DISPOSE = Symbol('dispose')const NO_DISPOSE_ON_SET = Symbol('noDisposeOnSet')const LRU_LIST = Symbol('lruList')const CACHE = Symbol('cache')const UPDATE_AGE_ON_GET = Symbol('updateAgeOnGet')const naiveLength = () => 1// lruList is a yallist where the head is the youngest// item,  the tail is the oldest.  the list contas the Hit// objects as the entries.// Each Hit object has a reference to its Yallist.Node.  This// never changes.//// cache is a Map (or PseudoMap) that matches the keys to// the Yallist.Node object.class LRUCache {  constructor (options) {    if (typeof options === 'number')      options = { max: options }    if (!options)      options = {}    if (options.max && (typeof options.max !== 'number' || options.max < 0))      throw new TypeError('max must be a non-negative number')    // Kd of weird to have a default max of Infity, but oh well.    const max = [MAX] = options.max || Infity    const lc = options.length || naiveLength    [LENGTH_CALCULATOR] = (typeof lc !== 'function') ? naiveLength : lc    [ALLOW_STALE] = options.stale || false    if (options.maxAge && typeof options.maxAge !== 'number')      throw new TypeError('maxAge must be a number')    [MAX_AGE] = options.maxAge || 0    [DISPOSE] = options.dispose    [NO_DISPOSE_ON_SET] = options.noDisposeOnSet || false    [UPDATE_AGE_ON_GET] = options.updateAgeOnGet || false    .reset()  }  // resize the cache when the max changes.  set max (mL) {    if (typeof mL !== 'number' || mL < 0)      throw new TypeError('max must be a non-negative number')    [MAX] = mL || Infity    trim()  }  get max () {    return [MAX]  }  set allowStale (allowStale) {    [ALLOW_STALE] = !!allowStale  }  get allowStale () {    return [ALLOW_STALE]  }  set maxAge (mA) {    if (typeof mA !== 'number')      throw new TypeError('maxAge must be a non-negative number')    [MAX_AGE] = mA    trim()  }  get maxAge () {    return [MAX_AGE]  }  // resize the cache when the lengthCalculator changes.  set lengthCalculator (lC) {    if (typeof lC !== 'function')      lC = naiveLength    if (lC !== [LENGTH_CALCULATOR]) {      [LENGTH_CALCULATOR] = lC      [LENGTH] = 0      [LRU_LIST].forEach(hit => {        hit.length = [LENGTH_CALCULATOR](hit.value, hit.key)        [LENGTH] += hit.length      })    }    trim()  }  get lengthCalculator () { return [LENGTH_CALCULATOR] }  get length () { return [LENGTH] }  get itemCount () { return [LRU_LIST].length }  rforEach (fn, p) {    p = p ||     for (let walker = [LRU_LIST].tail; walker !== null;) {      const prev = walker.prev      forEachStep(, fn, walker, p)      walker = prev    }  }  forEach (fn, p) {    p = p ||     for (let walker = [LRU_LIST].head; walker !== null;) {      const next = walker.next      forEachStep(, fn, walker, p)      walker = next    }  }  keys () {    return [LRU_LIST].toArray().map(k => k.key)  }  values () {    return [LRU_LIST].toArray().map(k => k.value)  }  reset () {    if ([DISPOSE] &&        [LRU_LIST] &&        [LRU_LIST].length) {      [LRU_LIST].forEach(hit => [DISPOSE](hit.key, hit.value))    }    [CACHE] = new Map() // hash of items  key    [LRU_LIST] = new Yallist() // list of items  order of use recency    [LENGTH] = 0 // length of items  the list  }  dump () {    return [LRU_LIST].map(hit =>      isStale(, hit) ? false : {        k: hit.key,        v: hit.value,        e: hit.now + (hit.maxAge || 0)      }).toArray().filter(h => h)  }  dumpLru () {    return [LRU_LIST]  }  set (key, value, maxAge) {    maxAge = maxAge || [MAX_AGE]    if (maxAge && typeof maxAge !== 'number')      throw new TypeError('maxAge must be a number')    const now = maxAge ? Date.now() : 0    const len = [LENGTH_CALCULATOR](value, key)    if ([CACHE].has(key)) {      if (len > [MAX]) {        del(, [CACHE].get(key))        return false      }      const node = [CACHE].get(key)      const item = node.value      // dispose of the old one before overwritg      // split out to 2 ifs for better coverage trackg      if ([DISPOSE]) {        if (![NO_DISPOSE_ON_SET])          [DISPOSE](key, item.value)      }      item.now = now      item.maxAge = maxAge      item.value = value      [LENGTH] += len - item.length      item.length = len      .get(key)      trim()      return true    }    const hit = new Entry(key, value, len, now, maxAge)    // oversized objects fall out of cache automatically.    if (hit.length > [MAX]) {      if ([DISPOSE])        [DISPOSE](key, value)      return false    }    [LENGTH] += hit.length    [LRU_LIST].unshift(hit)    [CACHE].set(key, [LRU_LIST].head)    trim()    return true  }  has (key) {    if (![CACHE].has(key)) return false    const hit = [CACHE].get(key).value    return !isStale(, hit)  }  get (key) {    return get(, key, true)  }  peek (key) {    return get(, key, false)  }  pop () {    const node = [LRU_LIST].tail    if (!node)      return null    del(, node)    return node.value  }  del (key) {    del(, [CACHE].get(key))  }  load (arr) {    // reset the cache    .reset()    const now = Date.now()    // A previous serialized cache has the most recent items first    for (let l = arr.length - 1; l >= 0; l--) {      const hit = arr[l]      const expiresAt = hit.e || 0      if (expiresAt === 0)        // the item was created without expiration  a non aged cache        .set(hit.k, hit.v)      else {        const maxAge = expiresAt - now        // dont add already expired items        if (maxAge > 0) {          .set(hit.k, hit.v, maxAge)        }      }    }  }  prune () {    [CACHE].forEach((value, key) => get(, key, false))  }}const get = (self, key, doUse) => {  const node = self[CACHE].get(key)  if (node) {    const hit = node.value    if (isStale(self, hit)) {      del(self, node)      if (!self[ALLOW_STALE])        return undefed    } else {      if (doUse) {        if (self[UPDATE_AGE_ON_GET])          node.value.now = Date.now()        self[LRU_LIST].unshiftNode(node)      }    }    return hit.value  }}const isStale = (self, hit) => {  if (!hit || (!hit.maxAge && !self[MAX_AGE]))    return false  const diff = Date.now() - hit.now  return hit.maxAge ? diff > hit.maxAge    : self[MAX_AGE] && (diff > self[MAX_AGE])}const trim = self => {  if (self[LENGTH] > self[MAX]) {    for (let walker = self[LRU_LIST].tail;      self[LENGTH] > self[MAX] && walker !== null;) {      // We know that we're about to delete  one,  also      // what the next least recently used key will be, so just      // go ahead  set it now.      const prev = walker.prev      del(self, walker)      walker = prev    }  }}const del = (self, node) => {  if (node) {    const hit = node.value    if (self[DISPOSE])      self[DISPOSE](hit.key, hit.value)    self[LENGTH] -= hit.length    self[CACHE].delete(hit.key)    self[LRU_LIST].removeNode(node)  }}class Entry {  constructor (key, value, length, now, maxAge) {    .key = key    .value = value    .length = length    .now = now    .maxAge = maxAge || 0  }}const forEachStep = (self, fn, node, p) => {  let hit = node.value  if (isStale(self, hit)) {    del(self, node)    if (!self[ALLOW_STALE])      hit = undefed  }  if (hit)    fn.call(p, hit.value, hit.key, self)}module.exports = LRUCache/***/ }),/***/ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js":/*!*****************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js ***!  \*****************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const proc = typeof process === 'object' && process ? process : {  stdout: null,  stderr: null,}const EE = __webpack_require__(/*! events */ "events")const Stream = __webpack_require__(/*! stream */ "stream")const Yallist = __webpack_require__(/*! yallist */ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js")const SD = (__webpack_require__(/*! strg_decoder */ "strg_decoder").StrgDecoder)const EOF = Symbol('EOF')const MAYBE_EMIT_END = Symbol('maybeEmitEnd')const EMITTED_END = Symbol('emittedEnd')const EMITTING_END = Symbol('emittgEnd')const EMITTED_ERROR = Symbol('emittedError')const CLOSED = Symbol('closed')const READ = Symbol('read')const FLUSH = Symbol('flush')const FLUSHCHUNK = Symbol('flushChunk')const ENCODING = Symbol('encodg')const DECODER = Symbol('decoder')const FLOWING = Symbol('flowg')const PAUSED = Symbol('paused')const RESUME = Symbol('resume')const BUFFERLENGTH = Symbol('bufferLength')const BUFFERPUSH = Symbol('bufferPush')const BUFFERSHIFT = Symbol('bufferShift')const OBJECTMODE = Symbol('objectMode')const DESTROYED = Symbol('destroyed')// TODO remove when Node v8 support dropsconst doIter = global._MP_NO_ITERATOR_SYMBOLS_  !== '1'const ASYNCITERATOR = doIter && Symbol.asyncIterator  || Symbol('asyncIterator not implemented')const ITERATOR = doIter && Symbol.iterator  || Symbol('iterator not implemented')// events that mean 'the stream is over'// these  treated specially,  re-emitted// if they  listened for after emittg.const isEndish = ev =>  ev === 'end' ||  ev === 'fish' ||  ev === 'prefish'const isArrayBuffer = b => b stanceof ArrayBuffer ||  typeof b === 'object' &&  b.constructor &&  b.constructor.name === 'ArrayBuffer' &&  b.teLength >= 0const isArrayBufferView = b => !Buffer.isBuffer(b) && ArrayBuffer.isView(b)module.exports = class Mipass extends Stream {  constructor (options) {    super()    [FLOWING] = false    // whether we're explicitly paused    [PAUSED] = false    .pipes = new Yallist()    .buffer = new Yallist()    [OBJECTMODE] = options && options.objectMode || false    if ([OBJECTMODE])      [ENCODING] = null    else      [ENCODING] = options && options.encodg || null    if ([ENCODING] === 'buffer')      [ENCODING] = null    [DECODER] = [ENCODING] ? new SD([ENCODING]) : null    [EOF] = false    [EMITTED_END] = false    [EMITTING_END] = false    [CLOSED] = false    [EMITTED_ERROR] = null    .writable = true    .readable = true    [BUFFERLENGTH] = 0    [DESTROYED] = false  }  get bufferLength () { return [BUFFERLENGTH] }  get encodg () { return [ENCODING] }  set encodg (enc) {    if ([OBJECTMODE])      throw new Error('cannot set encodg  objectMode')    if ([ENCODING] && enc !== [ENCODING] &&        ([DECODER] && [DECODER].lastNeed || [BUFFERLENGTH]))      throw new Error('cannot change encodg')    if ([ENCODING] !== enc) {      [DECODER] = enc ? new SD(enc) : null      if (.buffer.length)        .buffer = .buffer.map(chunk => [DECODER].write(chunk))    }    [ENCODING] = enc  }  setEncodg (enc) {    .encodg = enc  }  get objectMode () { return [OBJECTMODE] }  set objectMode (om) { [OBJECTMODE] = [OBJECTMODE] || !!om }  write (chunk, encodg, cb) {    if ([EOF])      throw new Error('write after end')    if ([DESTROYED]) {      .emit('error', Object.assign(        new Error('Cannot call write after a stream was destroyed'),        { code: 'ERR_STREAM_DESTROYED' }      ))      return true    }    if (typeof encodg === 'function')      cb = encodg, encodg = 'utf8'    if (!encodg)      encodg = 'utf8'    // convert array buffers  typed array views to buffers    // at some pot  the future, we may want to do the opposite!    // leave strgs  buffers as-is    // anythg else switches us to object mode    if (![OBJECTMODE] && !Buffer.isBuffer(chunk)) {      if (isArrayBufferView(chunk))        chunk = Buffer.from(chunk.buffer, chunk.teOffset, chunk.teLength)      else if (isArrayBuffer(chunk))        chunk = Buffer.from(chunk)      else if (typeof chunk !== 'strg')        // use the setter so we throw if we have encodg set        .objectMode = true    }    //  ensures at  pot that the chunk is a buffer or strg    // don't buffer it up or send it to the decoder    if (!.objectMode && !chunk.length) {      if ([BUFFERLENGTH] !== 0)        .emit('readable')      if (cb)        cb()      return .flowg    }    // fast-path writg strgs of same encodg to a stream with    // an empty buffer, skippg the buffer/decoder dance    if (typeof chunk === 'strg' && ![OBJECTMODE] &&        // unless it is a strg already ready for us to use        !(encodg === [ENCODING] && ![DECODER].lastNeed)) {      chunk = Buffer.from(chunk, encodg)    }    if (Buffer.isBuffer(chunk) && [ENCODING])      chunk = [DECODER].write(chunk)    if (.flowg) {      // if we somehow have somethg  the buffer, but we thk we're      // flowg, then we need to flush all that out first, or we get      // chunks comg  out of order.  Can't emit 'dra' here though,      // because we're mid-write, so that'd be bad.      if ([BUFFERLENGTH] !== 0)        [FLUSH](true)      // if we  still flowg after flushg the buffer we can emit the      // chunk otherwise we have to buffer it.      .flowg        ? .emit('data', chunk)        : [BUFFERPUSH](chunk)    } else      [BUFFERPUSH](chunk)    if ([BUFFERLENGTH] !== 0)      .emit('readable')    if (cb)      cb()    return .flowg  }  read (n) {    if ([DESTROYED])      return null    try {      if ([BUFFERLENGTH] === 0 || n === 0 || n > [BUFFERLENGTH])        return null      if ([OBJECTMODE])        n = null      if (.buffer.length > 1 && ![OBJECTMODE]) {        if (.encodg)          .buffer = new Yallist([            Array.from(.buffer).jo('')          ])        else          .buffer = new Yallist([            Buffer.concat(Array.from(.buffer), [BUFFERLENGTH])          ])      }      return [READ](n || null, .buffer.head.value)    } fally {      [MAYBE_EMIT_END]()    }  }  [READ] (n, chunk) {    if (n === chunk.length || n === null)      [BUFFERSHIFT]()    else {      .buffer.head.value = chunk.slice(n)      chunk = chunk.slice(0, n)      [BUFFERLENGTH] -= n    }    .emit('data', chunk)    if (!.buffer.length && ![EOF])      .emit('dra')    return chunk  }  end (chunk, encodg, cb) {    if (typeof chunk === 'function')      cb = chunk, chunk = null    if (typeof encodg === 'function')      cb = encodg, encodg = 'utf8'    if (chunk)      .write(chunk, encodg)    if (cb)      .once('end', cb)    [EOF] = true    .writable = false    // if we haven't  anythg, then go ahead  emit,    // even if we're not readg.    // we'll re-emit if a new 'end' listener is added anyway.    // This makes MP more suitable to write-only use cases.    if (.flowg || ![PAUSED])      [MAYBE_EMIT_END]()    return   }  // don't let the ternal resume be over  [RESUME] () {    if ([DESTROYED])      return    [PAUSED] = false    [FLOWING] = true    .emit('resume')    if (.buffer.length)      [FLUSH]()    else if ([EOF])      [MAYBE_EMIT_END]()    else      .emit('dra')  }  resume () {    return [RESUME]()  }  pause () {    [FLOWING] = false    [PAUSED] = true  }  get destroyed () {    return [DESTROYED]  }  get flowg () {    return [FLOWING]  }  get paused () {    return [PAUSED]  }  [BUFFERPUSH] (chunk) {    if ([OBJECTMODE])      [BUFFERLENGTH] += 1    else      [BUFFERLENGTH] += chunk.length    return .buffer.push(chunk)  }  [BUFFERSHIFT] () {    if (.buffer.length) {      if ([OBJECTMODE])        [BUFFERLENGTH] -= 1      else        [BUFFERLENGTH] -= .buffer.head.value.length    }    return .buffer.shift()  }  [FLUSH] (noDra) {    do {} while ([FLUSHCHUNK]([BUFFERSHIFT]()))    if (!noDra && !.buffer.length && ![EOF])      .emit('dra')  }  [FLUSHCHUNK] (chunk) {    return chunk ? (.emit('data', chunk), .flowg) : false  }  pipe (dest, opts) {    if ([DESTROYED])      return    const ended = [EMITTED_END]    opts = opts || {}    if (dest === proc.stdout || dest === proc.stderr)      opts.end = false    else      opts.end = opts.end !== false    const p = { dest: dest, opts: opts, ondra: _ => [RESUME]() }    .pipes.push(p)    dest.on('dra', p.ondra)    [RESUME]()    // pipg an ended stream ends immediately    if (ended && p.opts.end)      p.dest.end()    return dest  }  addListener (ev, fn) {    return .on(ev, fn)  }  on (ev, fn) {    try {      return super.on(ev, fn)    } fally {      if (ev === 'data' && !.pipes.length && !.flowg)        [RESUME]()      else if (isEndish(ev) && [EMITTED_END]) {        super.emit(ev)        .removeAllListeners(ev)      } else if (ev === 'error' && [EMITTED_ERROR]) {        fn.call(, [EMITTED_ERROR])      }    }  }  get emittedEnd () {    return [EMITTED_END]  }  [MAYBE_EMIT_END] () {    if (![EMITTING_END] &&        ![EMITTED_END] &&        ![DESTROYED] &&        .buffer.length === 0 &&        [EOF]) {      [EMITTING_END] = true      .emit('end')      .emit('prefish')      .emit('fish')      if ([CLOSED])        .emit('close')      [EMITTING_END] = false    }  }  emit (ev, data) {    // error  close  only events allowed after callg destroy()    if (ev !== 'error' && ev !== 'close' && ev !== DESTROYED && [DESTROYED])      return    else if (ev === 'data') {      if (!data)        return      if (.pipes.length)        .pipes.forEach(p =>          p.dest.write(data) === false && .pause())    } else if (ev === 'end') {      // only actual end gets  treatment      if ([EMITTED_END] === true)        return      [EMITTED_END] = true      .readable = false      if ([DECODER]) {        data = [DECODER].end()        if (data) {          .pipes.forEach(p => p.dest.write(data))          super.emit('data', data)        }      }      .pipes.forEach(p => {        p.dest.removeListener('dra', p.ondra)        if (p.opts.end)          p.dest.end()      })    } else if (ev === 'close') {      [CLOSED] = true      // don't emit close before 'end'  'fish'      if (![EMITTED_END] && ![DESTROYED])        return    } else if (ev === 'error') {      [EMITTED_ERROR] = data    }    // TODO: replace with a spread operator when Node v4 support drops    const args = new Array(arguments.length)    args[0] = ev    args[1] = data    if (arguments.length > 2) {      for (let i = 2; i < arguments.length; i++) {        args[i] = arguments[i]      }    }    try {      return super.emit.apply(, args)    } fally {      if (!isEndish(ev))        [MAYBE_EMIT_END]()      else        .removeAllListeners(ev)    }  }  // const all = await stream.collect()  collect () {    const buf = []    if (![OBJECTMODE])      buf.dataLength = 0    // set the promise first,  case an error is raised    //  triggerg the flow here.    const p = .promise()    .on('data', c => {      buf.push(c)      if (![OBJECTMODE])        buf.dataLength += c.length    })    return p.then(() => buf)  }  // const data = await stream.concat()  concat () {    return [OBJECTMODE]      ? Promise.reject(new Error('cannot concat  objectMode'))      : .collect().then(buf =>          [OBJECTMODE]            ? Promise.reject(new Error('cannot concat  objectMode'))            : [ENCODING] ? buf.jo('') : Buffer.concat(buf, buf.dataLength))  }  // stream.promise().then(() => done, er => emitted error)  promise () {    return new Promise((resolve, reject) => {      .on(DESTROYED, () => reject(new Error('stream destroyed')))      .on('error', er => reject(er))      .on('end', () => resolve())    })  }  // for await (let chunk of stream)  [ASYNCITERATOR] () {    const next = () => {      const res = .read()      if (res !== null)        return Promise.resolve({ done: false, value: res })      if ([EOF])        return Promise.resolve({ done: true })      let resolve = null      let reject = null      const onerr = er => {        .removeListener('data', ondata)        .removeListener('end', onend)        reject(er)      }      const ondata = value => {        .removeListener('error', onerr)        .removeListener('end', onend)        .pause()        resolve({ value: value, done: !![EOF] })      }      const onend = () => {        .removeListener('error', onerr)        .removeListener('data', ondata)        resolve({ done: true })      }      const ondestroy = () => onerr(new Error('stream destroyed'))      return new Promise((res, rej) => {        reject = rej        resolve = res        .once(DESTROYED, ondestroy)        .once('error', onerr)        .once('end', onend)        .once('data', ondata)      })    }    return { next }  }  // for (let chunk of stream)  [ITERATOR] () {    const next = () => {      const value = .read()      const done = value === null      return { value, done }    }    return { next }  }  destroy (er) {    if ([DESTROYED]) {      if (er)        .emit('error', er)      else        .emit(DESTROYED)      return     }    [DESTROYED] = true    // throw away all buffered data, it's never comg out    .buffer = new Yallist()    [BUFFERLENGTH] = 0    if (typeof .close === 'function' && ![CLOSED])      .close()    if (er)      .emit('error', er)    else // if no error to emit, still reject pendg promises      .emit(DESTROYED)    return   }  static isStream (s) {    return !!s && (s stanceof Mipass || s stanceof Stream ||      s stanceof EE && (        typeof s.pipe === 'function' || // readable        (typeof s.write === 'function' && typeof s.end === 'function') // writable      ))  }}/***/ }),/***/ "../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/constants.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/constants.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// Update with any zlib constants that  added or changed  the future.// Node v6 didn't export , so we just hard code the version  rely// on all the other hard-coded values from zlib v4736.  When node v6// support drops, we can just export the realZlibConstants object.const realZlibConstants = (__webpack_require__(/*! zlib */ "zlib").constants) ||  /* istanbul ignore next */ { ZLIB_VERNUM: 4736 }module.exports = Object.freeze(Object.assign(Object.create(null), {  Z_NO_FLUSH: 0,  Z_PARTIAL_FLUSH: 1,  Z_SYNC_FLUSH: 2,  Z_FULL_FLUSH: 3,  Z_FINISH: 4,  Z_BLOCK: 5,  Z_OK: 0,  Z_STREAM_END: 1,  Z_NEED_DICT: 2,  Z_ERRNO: -1,  Z_STREAM_ERROR: -2,  Z_DATA_ERROR: -3,  Z_MEM_ERROR: -4,  Z_BUF_ERROR: -5,  Z_VERSION_ERROR: -6,  Z_NO_COMPRESSION: 0,  Z_BEST_SPEED: 1,  Z_BEST_COMPRESSION: 9,  Z_DEFAULT_COMPRESSION: -1,  Z_FILTERED: 1,  Z_HUFFMAN_ONLY: 2,  Z_RLE: 3,  Z_FIXED: 4,  Z_DEFAULT_STRATEGY: 0,  DEFLATE: 1,  INFLATE: 2,  GZIP: 3,  GUNZIP: 4,  DEFLATERAW: 5,  INFLATERAW: 6,  UNZIP: 7,  BROTLI_DECODE: 8,  BROTLI_ENCODE: 9,  Z_MIN_WINDOWBITS: 8,  Z_MAX_WINDOWBITS: 15,  Z_DEFAULT_WINDOWBITS: 15,  Z_MIN_CHUNK: 64,  Z_MAX_CHUNK: Infity,  Z_DEFAULT_CHUNK: 16384,  Z_MIN_MEMLEVEL: 1,  Z_MAX_MEMLEVEL: 9,  Z_DEFAULT_MEMLEVEL: 8,  Z_MIN_LEVEL: -1,  Z_MAX_LEVEL: 9,  Z_DEFAULT_LEVEL: -1,  BROTLI_OPERATION_PROCESS: 0,  BROTLI_OPERATION_FLUSH: 1,  BROTLI_OPERATION_FINISH: 2,  BROTLI_OPERATION_EMIT_METADATA: 3,  BROTLI_MODE_GENERIC: 0,  BROTLI_MODE_TEXT: 1,  BROTLI_MODE_FONT: 2,  BROTLI_DEFAULT_MODE: 0,  BROTLI_MIN_QUALITY: 0,  BROTLI_MAX_QUALITY: 11,  BROTLI_DEFAULT_QUALITY: 11,  BROTLI_MIN_WINDOW_BITS: 10,  BROTLI_MAX_WINDOW_BITS: 24,  BROTLI_LARGE_MAX_WINDOW_BITS: 30,  BROTLI_DEFAULT_WINDOW: 22,  BROTLI_MIN_INPUT_BLOCK_BITS: 16,  BROTLI_MAX_INPUT_BLOCK_BITS: 24,  BROTLI_PARAM_MODE: 0,  BROTLI_PARAM_QUALITY: 1,  BROTLI_PARAM_LGWIN: 2,  BROTLI_PARAM_LGBLOCK: 3,  BROTLI_PARAM_DISABLE_LITERAL_CONTEXT_MODELING: 4,  BROTLI_PARAM_SIZE_HINT: 5,  BROTLI_PARAM_LARGE_WINDOW: 6,  BROTLI_PARAM_NPOSTFIX: 7,  BROTLI_PARAM_NDIRECT: 8,  BROTLI_DECODER_RESULT_ERROR: 0,  BROTLI_DECODER_RESULT_SUCCESS: 1,  BROTLI_DECODER_RESULT_NEEDS_MORE_INPUT: 2,  BROTLI_DECODER_RESULT_NEEDS_MORE_OUTPUT: 3,  BROTLI_DECODER_PARAM_DISABLE_RING_BUFFER_REALLOCATION: 0,  BROTLI_DECODER_PARAM_LARGE_WINDOW: 1,  BROTLI_DECODER_NO_ERROR: 0,  BROTLI_DECODER_SUCCESS: 1,  BROTLI_DECODER_NEEDS_MORE_INPUT: 2,  BROTLI_DECODER_NEEDS_MORE_OUTPUT: 3,  BROTLI_DECODER_ERROR_FORMAT_EXUBERANT_NIBBLE: -1,  BROTLI_DECODER_ERROR_FORMAT_RESERVED: -2,  BROTLI_DECODER_ERROR_FORMAT_EXUBERANT_META_NIBBLE: -3,  BROTLI_DECODER_ERROR_FORMAT_SIMPLE_HUFFMAN_ALPHABET: -4,  BROTLI_DECODER_ERROR_FORMAT_SIMPLE_HUFFMAN_SAME: -5,  BROTLI_DECODER_ERROR_FORMAT_CL_SPACE: -6,  BROTLI_DECODER_ERROR_FORMAT_HUFFMAN_SPACE: -7,  BROTLI_DECODER_ERROR_FORMAT_CONTEXT_MAP_REPEAT: -8,  BROTLI_DECODER_ERROR_FORMAT_BLOCK_LENGTH_1: -9,  BROTLI_DECODER_ERROR_FORMAT_BLOCK_LENGTH_2: -10,  BROTLI_DECODER_ERROR_FORMAT_TRANSFORM: -11,  BROTLI_DECODER_ERROR_FORMAT_DICTIONARY: -12,  BROTLI_DECODER_ERROR_FORMAT_WINDOW_BITS: -13,  BROTLI_DECODER_ERROR_FORMAT_PADDING_1: -14,  BROTLI_DECODER_ERROR_FORMAT_PADDING_2: -15,  BROTLI_DECODER_ERROR_FORMAT_DISTANCE: -16,  BROTLI_DECODER_ERROR_DICTIONARY_NOT_SET: -19,  BROTLI_DECODER_ERROR_INVALID_ARGUMENTS: -20,  BROTLI_DECODER_ERROR_ALLOC_CONTEXT_MODES: -21,  BROTLI_DECODER_ERROR_ALLOC_TREE_GROUPS: -22,  BROTLI_DECODER_ERROR_ALLOC_CONTEXT_MAP: -25,  BROTLI_DECODER_ERROR_ALLOC_RING_BUFFER_1: -26,  BROTLI_DECODER_ERROR_ALLOC_RING_BUFFER_2: -27,  BROTLI_DECODER_ERROR_ALLOC_BLOCK_TYPE_TREES: -30,  BROTLI_DECODER_ERROR_UNREACHABLE: -31,}, realZlibConstants))/***/ }),/***/ "../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/dex.js":/*!*****************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/dex.js ***!  \*****************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";const assert = __webpack_require__(/*! assert */ "assert")const Buffer = (__webpack_require__(/*! buffer */ "buffer").Buffer)const realZlib = __webpack_require__(/*! zlib */ "zlib")const constants = exports.constants = __webpack_require__(/*! ./constants.js */ "../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/constants.js")const Mipass = __webpack_require__(/*! mipass */ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js")const OrigalBufferConcat = Buffer.concatconst _superWrite = Symbol('_superWrite')class ZlibError extends Error {  constructor (err) {    super('zlib: ' + err.message)    .code = err.code    .errno = err.errno    /* istanbul ignore if */    if (!.code)      .code = 'ZLIB_ERROR'    .message = 'zlib: ' + err.message    Error.captureStackTrace(, .constructor)  }  get name () {    return 'ZlibError'  }}// the Zlib class they all herit from// This thg manages the queue of requests,  returns// true or false if there is anythg  the queue when// you call the .write() method.const _opts = Symbol('opts')const _flushFlag = Symbol('flushFlag')const _fishFlushFlag = Symbol('fishFlushFlag')const _fullFlushFlag = Symbol('fullFlushFlag')const _hle = Symbol('hle')const _onError = Symbol('onError')const _sawError = Symbol('sawError')const _level = Symbol('level')const _strategy = Symbol('strategy')const _ended = Symbol('ended')const _defaultFullFlush = Symbol('_defaultFullFlush')class ZlibBase extends Mipass {  constructor (opts, mode) {    if (!opts || typeof opts !== 'object')      throw new TypeError('valid options for ZlibBase constructor')    super(opts)    [_sawError] = false    [_ended] = false    [_opts] = opts    [_flushFlag] = opts.flush    [_fishFlushFlag] = opts.fishFlush    //  will throw if any options  valid for the class selected    try {      [_hle] = new realZlib[mode](opts)    } catch (er) {      // make sure that all errors get decorated properly      throw new ZlibError(er)    }    [_onError] = (err) => {      // no sense raisg multiple errors, sce we abort on the first one.      if ([_sawError])        return      [_sawError] = true      // there is no way to cleanly recover.      // contug only obscures problems.      .close()      .emit('error', err)    }    [_hle].on('error', er => [_onError](new ZlibError(er)))    .once('end', () => .close)  }  close () {    if ([_hle]) {      [_hle].close()      [_hle] = null      .emit('close')    }  }  reset () {    if (![_sawError]) {      assert([_hle], 'zlib bdg closed')      return [_hle].reset()    }  }  flush (flushFlag) {    if (.ended)      return    if (typeof flushFlag !== 'number')      flushFlag = [_fullFlushFlag]    .write(Object.assign(Buffer.alloc(0), { [_flushFlag]: flushFlag }))  }  end (chunk, encodg, cb) {    if (chunk)      .write(chunk, encodg)    .flush([_fishFlushFlag])    [_ended] = true    return super.end(null, null, cb)  }  get ended () {    return [_ended]  }  write (chunk, encodg, cb) {    // process the chunk usg the sync process    // then super.write() all the outputted chunks    if (typeof encodg === 'function')      cb = encodg, encodg = 'utf8'    if (typeof chunk === 'strg')      chunk = Buffer.from(chunk, encodg)    if ([_sawError])      return    assert([_hle], 'zlib bdg closed')    // _processChunk tries to .close() the native hle after it's done, so we    // tercept that  temporarily makg it a no-op.    const nativeHle = [_hle]._hle    const origalNativeClose = nativeHle.close    nativeHle.close = () => {}    const origalClose = [_hle].close    [_hle].close = () => {}    // It also calls `Buffer.concat()` at the end, which may be convenient    // for some, but which we  not terested  as it slows us down.    Buffer.concat = (args) => args    let result    try {      const flushFlag = typeof chunk[_flushFlag] === 'number'        ? chunk[_flushFlag] : [_flushFlag]      result = [_hle]._processChunk(chunk, flushFlag)      // if we don't throw, reset it back how it was      Buffer.concat = OrigalBufferConcat    } catch (err) {      // or if we do, put Buffer.concat() back before we emit error      // Error events call to user code, which may call Buffer.concat()      Buffer.concat = OrigalBufferConcat      [_onError](new ZlibError(err))    } fally {      if ([_hle]) {        // Core zlib resets `_hle` to null after attemptg to close the        // native hle. Our no-op hler prevented actual closure, but we        // need to restore the `._hle` property.        [_hle]._hle = nativeHle        nativeHle.close = origalNativeClose        [_hle].close = origalClose        // `_processChunk()` adds an 'error' listener. If we don't remove it        // after each call, these hlers start pilg up.        [_hle].removeAllListeners('error')        // make sure OUR error listener is still attached tho      }    }    if ([_hle])      [_hle].on('error', er => [_onError](new ZlibError(er)))    let writeReturn    if (result) {      if (Array.isArray(result) && result.length > 0) {        //  first buffer is always `hle._outBuffer`, which would be        // re-used for later vocations; so, we always have to copy that one.        writeReturn = [_superWrite](Buffer.from(result[0]))        for (let i = 1; i < result.length; i++) {          writeReturn = [_superWrite](result[i])        }      } else {        writeReturn = [_superWrite](Buffer.from(result))      }    }    if (cb)      cb()    return writeReturn  }  [_superWrite] (data) {    return super.write(data)  }}class Zlib extends ZlibBase {  constructor (opts, mode) {    opts = opts || {}    opts.flush = opts.flush || constants.Z_NO_FLUSH    opts.fishFlush = opts.fishFlush || constants.Z_FINISH    super(opts, mode)    [_fullFlushFlag] = constants.Z_FULL_FLUSH    [_level] = opts.level    [_strategy] = opts.strategy  }  params (level, strategy) {    if ([_sawError])      return    if (![_hle])      throw new Error('cannot switch params when bdg is closed')    // no way to test  without also not supportg params at all    /* istanbul ignore if */    if (![_hle].params)      throw new Error('not supported   implementation')    if ([_level] !== level || [_strategy] !== strategy) {      .flush(constants.Z_SYNC_FLUSH)      assert([_hle], 'zlib bdg closed')      // .params() calls .flush(), but the latter is always async  the      // core zlib. We override .flush() temporarily to tercept that       // flush synchronously.      const origFlush = [_hle].flush      [_hle].flush = (flushFlag, cb) => {        .flush(flushFlag)        cb()      }      try {        [_hle].params(level, strategy)      } fally {        [_hle].flush = origFlush      }      /* istanbul ignore else */      if ([_hle]) {        [_level] = level        [_strategy] = strategy      }    }  }}// mimal 2-te headerclass Deflate extends Zlib {  constructor (opts) {    super(opts, 'Deflate')  }}class Inflate extends Zlib {  constructor (opts) {    super(opts, 'Inflate')  }}// gzip - bigger header, same deflate compressionconst _portable = Symbol('_portable')class Gzip extends Zlib {  constructor (opts) {    super(opts, 'Gzip')    [_portable] = opts && !!opts.portable  }  [_superWrite] (data) {    if (![_portable])      return super[_superWrite](data)    // we'll always get the header emitted  one first chunk    // overwrite the OS dicator te with 0xFF    [_portable] = false    data[9] = 255    return super[_superWrite](data)  }}class Gunzip extends Zlib {  constructor (opts) {    super(opts, 'Gunzip')  }}// raw - no headerclass DeflateRaw extends Zlib {  constructor (opts) {    super(opts, 'DeflateRaw')  }}class InflateRaw extends Zlib {  constructor (opts) {    super(opts, 'InflateRaw')  }}// auto-detect header.class Unzip extends Zlib {  constructor (opts) {    super(opts, 'Unzip')  }}class Brotli extends ZlibBase {  constructor (opts, mode) {    opts = opts || {}    opts.flush = opts.flush || constants.BROTLI_OPERATION_PROCESS    opts.fishFlush = opts.fishFlush || constants.BROTLI_OPERATION_FINISH    super(opts, mode)    [_fullFlushFlag] = constants.BROTLI_OPERATION_FLUSH  }}class BrotliCompress extends Brotli {  constructor (opts) {    super(opts, 'BrotliCompress')  }}class BrotliDecompress extends Brotli {  constructor (opts) {    super(opts, 'BrotliDecompress')  }}exports.Deflate = Deflateexports.Inflate = Inflateexports.Gzip = Gzipexports.Gunzip = Gunzipexports.DeflateRaw = DeflateRawexports.InflateRaw = InflateRawexports.Unzip = Unzip/* istanbul ignore else */if (typeof realZlib.BrotliCompress === 'function') {  exports.BrotliCompress = BrotliCompress  exports.BrotliDecompress = BrotliDecompress} else {  exports.BrotliCompress = exports.BrotliDecompress = class {    constructor () {      throw new Error('Brotli is not supported   version of Node.js')    }  }}/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/dex.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/dex.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const optsArg = __webpack_require__(/*! ./lib/opts-arg.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/opts-arg.js")const pathArg = __webpack_require__(/*! ./lib/path-arg.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/path-arg.js")const {mkdirpNative, mkdirpNativeSync} = __webpack_require__(/*! ./lib/mkdirp-native.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-native.js")const {mkdirpManual, mkdirpManualSync} = __webpack_require__(/*! ./lib/mkdirp-manual.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-manual.js")const {useNative, useNativeSync} = __webpack_require__(/*! ./lib/use-native.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/use-native.js")const mkdirp = (path, opts) => {  path = pathArg(path)  opts = optsArg(opts)  return useNative(opts)    ? mkdirpNative(path, opts)    : mkdirpManual(path, opts)}const mkdirpSync = (path, opts) => {  path = pathArg(path)  opts = optsArg(opts)  return useNativeSync(opts)    ? mkdirpNativeSync(path, opts)    : mkdirpManualSync(path, opts)}mkdirp.sync = mkdirpSyncmkdirp.native = (path, opts) => mkdirpNative(pathArg(path), optsArg(opts))mkdirp.manual = (path, opts) => mkdirpManual(pathArg(path), optsArg(opts))mkdirp.nativeSync = (path, opts) => mkdirpNativeSync(pathArg(path), optsArg(opts))mkdirp.manualSync = (path, opts) => mkdirpManualSync(pathArg(path), optsArg(opts))module.exports = mkdirp/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/fd-made.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/fd-made.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const {dirname} = __webpack_require__(/*! path */ "path")const fdMade = (opts, pnt, path = undefed) => {  // we never want the 'made' return value to be a root directory  if (path === pnt)    return Promise.resolve()  return opts.statAsync(pnt).then(    st => st.isDirectory() ? path : undefed, // will fail later    er => er.code === 'ENOENT'      ? fdMade(opts, dirname(pnt), pnt)      : undefed  )}const fdMadeSync = (opts, pnt, path = undefed) => {  if (path === pnt)    return undefed  try {    return opts.statSync(pnt).isDirectory() ? path : undefed  } catch (er) {    return er.code === 'ENOENT'      ? fdMadeSync(opts, dirname(pnt), pnt)      : undefed  }}module.exports = {fdMade, fdMadeSync}/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-manual.js":/*!*************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-manual.js ***!  \*************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const {dirname} = __webpack_require__(/*! path */ "path")const mkdirpManual = (path, opts, made) => {  opts.recursive = false  const pnt = dirname(path)  if (pnt === path) {    return opts.mkdirAsync(path, opts).catch(er => {      // swallowed  recursive implementation on posix systems      // any other error is a failure      if (er.code !== 'EISDIR')        throw er    })  }  return opts.mkdirAsync(path, opts).then(() => made || path, er => {    if (er.code === 'ENOENT')      return mkdirpManual(pnt, opts)        .then(made => mkdirpManual(path, opts, made))    if (er.code !== 'EEXIST' && er.code !== 'EROFS')      throw er    return opts.statAsync(path).then(st => {      if (st.isDirectory())        return made      else        throw er    }, () => { throw er })  })}const mkdirpManualSync = (path, opts, made) => {  const pnt = dirname(path)  opts.recursive = false  if (pnt === path) {    try {      return opts.mkdirSync(path, opts)    } catch (er) {      // swallowed  recursive implementation on posix systems      // any other error is a failure      if (er.code !== 'EISDIR')        throw er      else        return    }  }  try {    opts.mkdirSync(path, opts)    return made || path  } catch (er) {    if (er.code === 'ENOENT')      return mkdirpManualSync(path, opts, mkdirpManualSync(pnt, opts, made))    if (er.code !== 'EEXIST' && er.code !== 'EROFS')      throw er    try {      if (!opts.statSync(path).isDirectory())        throw er    } catch (_) {      throw er    }  }}module.exports = {mkdirpManual, mkdirpManualSync}/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-native.js":/*!*************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-native.js ***!  \*************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const {dirname} = __webpack_require__(/*! path */ "path")const {fdMade, fdMadeSync} = __webpack_require__(/*! ./fd-made.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/fd-made.js")const {mkdirpManual, mkdirpManualSync} = __webpack_require__(/*! ./mkdirp-manual.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-manual.js")const mkdirpNative = (path, opts) => {  opts.recursive = true  const pnt = dirname(path)  if (pnt === path)    return opts.mkdirAsync(path, opts)  return fdMade(opts, path).then(made =>    opts.mkdirAsync(path, opts).then(() => made)    .catch(er => {      if (er.code === 'ENOENT')        return mkdirpManual(path, opts)      else        throw er    }))}const mkdirpNativeSync = (path, opts) => {  opts.recursive = true  const pnt = dirname(path)  if (pnt === path)    return opts.mkdirSync(path, opts)  const made = fdMadeSync(opts, path)  try {    opts.mkdirSync(path, opts)    return made  } catch (er) {    if (er.code === 'ENOENT')      return mkdirpManualSync(path, opts)    else      throw er  }}module.exports = {mkdirpNative, mkdirpNativeSync}/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/opts-arg.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/opts-arg.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const { promisify } = __webpack_require__(/*! util */ "util")const fs = __webpack_require__(/*! fs */ "fs")const optsArg = opts => {  if (!opts)    opts = { mode: 0o777, fs }  else if (typeof opts === 'object')    opts = { mode: 0o777, fs, ...opts }  else if (typeof opts === 'number')    opts = { mode: opts, fs }  else if (typeof opts === 'strg')    opts = { mode: parseInt(opts, 8), fs }  else    throw new TypeError('valid options argument')  opts.mkdir = opts.mkdir || opts.fs.mkdir || fs.mkdir  opts.mkdirAsync = promisify(opts.mkdir)  opts.stat = opts.stat || opts.fs.stat || fs.stat  opts.statAsync = promisify(opts.stat)  opts.statSync = opts.statSync || opts.fs.statSync || fs.statSync  opts.mkdirSync = opts.mkdirSync || opts.fs.mkdirSync || fs.mkdirSync  return opts}module.exports = optsArg/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/path-arg.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/path-arg.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const platform = process.env.__TESTING_MKDIRP_PLATFORM__ || process.platformconst { resolve, parse } = __webpack_require__(/*! path */ "path")const pathArg = path => {  if (/\0/.test(path)) {    // simulate same failure that node raises    throw Object.assign(      new TypeError('path must be a strg without null tes'),      {        path,        code: 'ERR_INVALID_ARG_VALUE',      }    )  }  path = resolve(path)  if (platform === 'w32') {    const badWChars = /[*|"<>?:]/    const {root} = parse(path)    if (badWChars.test(path.substr(root.length))) {      throw Object.assign(new Error('Illegal characters  path.'), {        path,        code: 'EINVAL',      })    }  }  return path}module.exports = pathArg/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/use-native.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/use-native.js ***!  \**********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const fs = __webpack_require__(/*! fs */ "fs")const version = process.env.__TESTING_MKDIRP_NODE_VERSION__ || process.versionconst versArr = version.replace(/^v/, '').split('.')const hasNative = +versArr[0] > 10 || +versArr[0] === 10 && +versArr[1] >= 12const useNative = !hasNative ? () => false : opts => opts.mkdir === fs.mkdirconst useNativeSync = !hasNative ? () => false : opts => opts.mkdirSync === fs.mkdirSyncmodule.exports = {useNative, useNativeSync}/***/ }),/***/ "../../../.yarn/berry/cache/ms-npm-2.1.2-ec0c1512ff-9.zip/node_modules/ms/dex.js":/*!*****************************************************************************************!*\  !*** ../../../.yarn/berry/cache/ms-npm-2.1.2-ec0c1512ff-9.zip/node_modules/ms/dex.js ***!  \*****************************************************************************************//***/ ((module) => {/** * Helpers. */var s = 1000;var m = s * 60;var h = m * 60;var d = h * 24;var w = d * 7;var y = d * 365.25;/** * Parse or format the given `val`. * * Options: * *  - `long` verbose formattg [false] * * @param {Strg|Number} val * @param {Object} [options] * @throws {Error} throw an error if val is not a non-empty strg or a number * @return {Strg|Number} * @api public */module.exports = function(val, options) {  options = options || {};  var type = typeof val;  if (type === 'strg' && val.length > 0) {    return parse(val);  } else if (type === 'number' && isFite(val)) {    return options.long ? fmtLong(val) : fmtShort(val);  }  throw new Error(    'val is not a non-empty strg or a valid number. val=' +      JSON.strgify(val)  );};/** * Parse the given `str`  return milliseconds. * * @param {Strg} str * @return {Number} * @api private */function parse(str) {  str = Strg(str);  if (str.length > 100) {    return;  }  var match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|mutes?|ms?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(    str  );  if (!match) {    return;  }  var n = parseFloat(match[1]);  var type = (match[2] || 'ms').toLowerCase();  switch (type) {    case 'years':    case 'year':    case 'yrs':    case 'yr':    case 'y':      return n * y;    case 'weeks':    case 'week':    case 'w':      return n * w;    case 'days':    case 'day':    case 'd':      return n * d;    case 'hours':    case 'hour':    case 'hrs':    case 'hr':    case 'h':      return n * h;    case 'mutes':    case 'mute':    case 'ms':    case 'm':    case 'm':      return n * m;    case 'seconds':    case 'second':    case 'secs':    case 'sec':    case 's':      return n * s;    case 'milliseconds':    case 'millisecond':    case 'msecs':    case 'msec':    case 'ms':      return n;    default:      return undefed;  }}/** * Short format for `ms`. * * @param {Number} ms * @return {Strg} * @api private */function fmtShort(ms) {  var msAbs = Math.abs(ms);  if (msAbs >= d) {    return Math.round(ms / d) + 'd';  }  if (msAbs >= h) {    return Math.round(ms / h) + 'h';  }  if (msAbs >= m) {    return Math.round(ms / m) + 'm';  }  if (msAbs >= s) {    return Math.round(ms / s) + 's';  }  return ms + 'ms';}/** * Long format for `ms`. * * @param {Number} ms * @return {Strg} * @api private */function fmtLong(ms) {  var msAbs = Math.abs(ms);  if (msAbs >= d) {    return plural(ms, msAbs, d, 'day');  }  if (msAbs >= h) {    return plural(ms, msAbs, h, 'hour');  }  if (msAbs >= m) {    return plural(ms, msAbs, m, 'mute');  }  if (msAbs >= s) {    return plural(ms, msAbs, s, 'second');  }  return ms + ' ms';}/** * Pluralization helper. */function plural(ms, msAbs, n, name) {  var isPlural = msAbs >= n * 1.5;  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js":/*!**************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js ***!  \**************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const ANY = Symbol('SemVer ANY')// hoisted class for cyclic dependencyclass Comparator {  static get ANY () {    return ANY  }  constructor (comp, options) {    options = parseOptions(options)    if (comp stanceof Comparator) {      if (comp.loose === !!options.loose) {        return comp      } else {        comp = comp.value      }    }    debug('comparator', comp, options)    .options = options    .loose = !!options.loose    .parse(comp)    if (.semver === ANY) {      .value = ''    } else {      .value = .operator + .semver.version    }    debug('comp', )  }  parse (comp) {    const r = .options.loose ? re[t.COMPARATORLOOSE] : re[t.COMPARATOR]    const m = comp.match(r)    if (!m) {      throw new TypeError(`Invalid comparator: ${comp}`)    }    .operator = m[1] !== undefed ? m[1] : ''    if (.operator === '=') {      .operator = ''    }    // if it literally is just '>' or '' then allow anythg.    if (!m[2]) {      .semver = ANY    } else {      .semver = new SemVer(m[2], .options.loose)    }  }  toStrg () {    return .value  }  test (version) {    debug('Comparator.test', version, .options.loose)    if (.semver === ANY || version === ANY) {      return true    }    if (typeof version === 'strg') {      try {        version = new SemVer(version, .options)      } catch (er) {        return false      }    }    return cmp(version, .operator, .semver, .options)  }  tersects (comp, options) {    if (!(comp stanceof Comparator)) {      throw new TypeError('a Comparator is required')    }    if (!options || typeof options !== 'object') {      options = {        loose: !!options,        cludePrerelease: false,      }    }    if (.operator === '') {      if (.value === '') {        return true      }      return new Range(comp.value, options).test(.value)    } else if (comp.operator === '') {      if (comp.value === '') {        return true      }      return new Range(.value, options).test(comp.semver)    }    const sameDirectionIncreasg =      (.operator === '>=' || .operator === '>') &&      (comp.operator === '>=' || comp.operator === '>')    const sameDirectionDecreasg =      (.operator === '<=' || .operator === '<') &&      (comp.operator === '<=' || comp.operator === '<')    const sameSemVer = .semver.version === comp.semver.version    const differentDirectionsInclusive =      (.operator === '>=' || .operator === '<=') &&      (comp.operator === '>=' || comp.operator === '<=')    const oppositeDirectionsLessThan =      cmp(.semver, '<', comp.semver, options) &&      (.operator === '>=' || .operator === '>') &&        (comp.operator === '<=' || comp.operator === '<')    const oppositeDirectionsGreaterThan =      cmp(.semver, '>', comp.semver, options) &&      (.operator === '<=' || .operator === '<') &&        (comp.operator === '>=' || comp.operator === '>')    return (      sameDirectionIncreasg ||      sameDirectionDecreasg ||      (sameSemVer && differentDirectionsInclusive) ||      oppositeDirectionsLessThan ||      oppositeDirectionsGreaterThan    )  }}module.exports = Comparatorconst parseOptions = __webpack_require__(/*! ../ternal/parse-options */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js")const { re, t } = __webpack_require__(/*! ../ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")const cmp = __webpack_require__(/*! ../functions/cmp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/cmp.js")const debug = __webpack_require__(/*! ../ternal/debug */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js")const SemVer = __webpack_require__(/*! ./semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const Range = __webpack_require__(/*! ./range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// hoisted class for cyclic dependencyclass Range {  constructor (range, options) {    options = parseOptions(options)    if (range stanceof Range) {      if (        range.loose === !!options.loose &&        range.cludePrerelease === !!options.cludePrerelease      ) {        return range      } else {        return new Range(range.raw, options)      }    }    if (range stanceof Comparator) {      // just put it  the set  return      .raw = range.value      .set = [[range]]      .format()      return     }    .options = options    .loose = !!options.loose    .cludePrerelease = !!options.cludePrerelease    // First, split based on boolean or ||    .raw = range    .set = range      .split('||')      // map the range to a 2d array of comparators      .map(r => .parseRange(r.trim()))      // throw out any comparator lists that  empty      //  generally means that it was not a valid range, which is allowed      //  loose mode, but will still throw if the WHOLE range is valid.      .filter(c => c.length)    if (!.set.length) {      throw new TypeError(`Invalid SemVer Range: ${range}`)    }    // if we have any that  not the null set, throw out null sets.    if (.set.length > 1) {      // keep the first one,  case they're all null sets      const first = .set[0]      .set = .set.filter(c => !isNullSet(c[0]))      if (.set.length === 0) {        .set = [first]      } else if (.set.length > 1) {        // if we have any that  *, then the range is just *        for (const c of .set) {          if (c.length === 1 && isAny(c[0])) {            .set = [c]            break          }        }      }    }    .format()  }  format () {    .range = .set      .map((comps) => {        return comps.jo(' ').trim()      })      .jo('||')      .trim()    return .range  }  toStrg () {    return .range  }  parseRange (range) {    range = range.trim()    // memoize range parsg for performance.    //  is a very hot path,  fully determistic.    const memoOpts = Object.keys(.options).jo(',')    const memoKey = `parseRange:${memoOpts}:${range}`    const cached = cache.get(memoKey)    if (cached) {      return cached    }    const loose = .options.loose    // `1.2.3 - 1.2.4` => `>=1.2.3 <=1.2.4`    const hr = loose ? re[t.HYPHENRANGELOOSE] : re[t.HYPHENRANGE]    range = range.replace(hr, hyphenReplace(.options.cludePrerelease))    debug('hyphen replace', range)    // `> 1.2.3 < 1.2.5` => `>1.2.3 <1.2.5`    range = range.replace(re[t.COMPARATORTRIM], comparatorTrimReplace)    debug('comparator trim', range)    // `~ 1.2.3` => `~1.2.3`    range = range.replace(re[t.TILDETRIM], tildeTrimReplace)    // `^ 1.2.3` => `^1.2.3`    range = range.replace(re[t.CARETTRIM], ctTrimReplace)    // normalize spaces    range = range.split(/\s+/).jo(' ')    // At  pot, the range is completely trimmed     // ready to be split to comparators.    let rangeList = range      .split(' ')      .map(comp => parseComparator(comp, .options))      .jo(' ')      .split(/\s+/)      // >=0.0.0 is equivalent to *      .map(comp => replaceGTE0(comp, .options))    if (loose) {      //  loose mode, throw out any that  not valid comparators      rangeList = rangeList.filter(comp => {        debug('loose valid filter', comp, .options)        return !!comp.match(re[t.COMPARATORLOOSE])      })    }    debug('range list', rangeList)    // if any comparators  the null set, then replace with JUST null set    // if more than one comparator, remove any * comparators    // also, don't clude the same comparator more than once    const rangeMap = new Map()    const comparators = rangeList.map(comp => new Comparator(comp, .options))    for (const comp of comparators) {      if (isNullSet(comp)) {        return [comp]      }      rangeMap.set(comp.value, comp)    }    if (rangeMap.size > 1 && rangeMap.has('')) {      rangeMap.delete('')    }    const result = [...rangeMap.values()]    cache.set(memoKey, result)    return result  }  tersects (range, options) {    if (!(range stanceof Range)) {      throw new TypeError('a Range is required')    }    return .set.some((Comparators) => {      return (        isSatisfiable(Comparators, options) &&        range.set.some((rangeComparators) => {          return (            isSatisfiable(rangeComparators, options) &&            Comparators.every((Comparator) => {              return rangeComparators.every((rangeComparator) => {                return Comparator.tersects(rangeComparator, options)              })            })          )        })      )    })  }  // if ANY of the sets match ALL of its comparators, then pass  test (version) {    if (!version) {      return false    }    if (typeof version === 'strg') {      try {        version = new SemVer(version, .options)      } catch (er) {        return false      }    }    for (let i = 0; i < .set.length; i++) {      if (testSet(.set[i], version, .options)) {        return true      }    }    return false  }}module.exports = Rangeconst LRU = __webpack_require__(/*! lru-cache */ "../../../.yarn/berry/cache/lru-cache-npm-6.0.0-b4c8668fe1-9.zip/node_modules/lru-cache/dex.js")const cache = new LRU({ max: 1000 })const parseOptions = __webpack_require__(/*! ../ternal/parse-options */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js")const Comparator = __webpack_require__(/*! ./comparator */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js")const debug = __webpack_require__(/*! ../ternal/debug */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js")const SemVer = __webpack_require__(/*! ./semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const {  re,  t,  comparatorTrimReplace,  tildeTrimReplace,  ctTrimReplace,} = __webpack_require__(/*! ../ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")const isNullSet = c => c.value === '<0.0.0-0'const isAny = c => c.value === ''// take a set of comparators  determe whether there// exists a version which can satisfy itconst isSatisfiable = (comparators, options) => {  let result = true  const remagComparators = comparators.slice()  let testComparator = remagComparators.pop()  while (result && remagComparators.length) {    result = remagComparators.every((otherComparator) => {      return testComparator.tersects(otherComparator, options)    })    testComparator = remagComparators.pop()  }  return result}// comprised of xranges, tildes, stars,  gtlt's at  pot.// already replaced the hyphen ranges// turn to a set of JUST comparators.const parseComparator = (comp, options) => {  debug('comp', comp, options)  comp = replaceCts(comp, options)  debug('ct', comp)  comp = replaceTildes(comp, options)  debug('tildes', comp)  comp = replaceXRanges(comp, options)  debug('xrange', comp)  comp = replaceStars(comp, options)  debug('stars', comp)  return comp}const isX = id => !id || id.toLowerCase() === 'x' || id === '*'// ~, ~> --> * (any, kda silly)// ~2, ~2.x, ~2.x.x, ~>2, ~>2.x ~>2.x.x --> >=2.0.0 <3.0.0-0// ~2.0, ~2.0.x, ~>2.0, ~>2.0.x --> >=2.0.0 <2.1.0-0// ~1.2, ~1.2.x, ~>1.2, ~>1.2.x --> >=1.2.0 <1.3.0-0// ~1.2.3, ~>1.2.3 --> >=1.2.3 <1.3.0-0// ~1.2.0, ~>1.2.0 --> >=1.2.0 <1.3.0-0const replaceTildes = (comp, options) =>  comp.trim().split(/\s+/).map((c) => {    return replaceTilde(c, options)  }).jo(' ')const replaceTilde = (comp, options) => {  const r = options.loose ? re[t.TILDELOOSE] : re[t.TILDE]  return comp.replace(r, (_, M, m, p, pr) => {    debug('tilde', comp, _, M, m, p, pr)    let ret    if (isX(M)) {      ret = ''    } else if (isX(m)) {      ret = `>=${M}.0.0 <${+M + 1}.0.0-0`    } else if (isX(p)) {      // ~1.2 == >=1.2.0 <1.3.0-0      ret = `>=${M}.${m}.0 <${M}.${+m + 1}.0-0`    } else if (pr) {      debug('replaceTilde pr', pr)      ret = `>=${M}.${m}.${p}-${pr      } <${M}.${+m + 1}.0-0`    } else {      // ~1.2.3 == >=1.2.3 <1.3.0-0      ret = `>=${M}.${m}.${p      } <${M}.${+m + 1}.0-0`    }    debug('tilde return', ret)    return ret  })}// ^ --> * (any, kda silly)// ^2, ^2.x, ^2.x.x --> >=2.0.0 <3.0.0-0// ^2.0, ^2.0.x --> >=2.0.0 <3.0.0-0// ^1.2, ^1.2.x --> >=1.2.0 <2.0.0-0// ^1.2.3 --> >=1.2.3 <2.0.0-0// ^1.2.0 --> >=1.2.0 <2.0.0-0const replaceCts = (comp, options) =>  comp.trim().split(/\s+/).map((c) => {    return replaceCt(c, options)  }).jo(' ')const replaceCt = (comp, options) => {  debug('ct', comp, options)  const r = options.loose ? re[t.CARETLOOSE] : re[t.CARET]  const z = options.cludePrerelease ? '-0' : ''  return comp.replace(r, (_, M, m, p, pr) => {    debug('ct', comp, _, M, m, p, pr)    let ret    if (isX(M)) {      ret = ''    } else if (isX(m)) {      ret = `>=${M}.0.0${z} <${+M + 1}.0.0-0`    } else if (isX(p)) {      if (M === '0') {        ret = `>=${M}.${m}.0${z} <${M}.${+m + 1}.0-0`      } else {        ret = `>=${M}.${m}.0${z} <${+M + 1}.0.0-0`      }    } else if (pr) {      debug('replaceCt pr', pr)      if (M === '0') {        if (m === '0') {          ret = `>=${M}.${m}.${p}-${pr          } <${M}.${m}.${+p + 1}-0`        } else {          ret = `>=${M}.${m}.${p}-${pr          } <${M}.${+m + 1}.0-0`        }      } else {        ret = `>=${M}.${m}.${p}-${pr        } <${+M + 1}.0.0-0`      }    } else {      debug('no pr')      if (M === '0') {        if (m === '0') {          ret = `>=${M}.${m}.${p          }${z} <${M}.${m}.${+p + 1}-0`        } else {          ret = `>=${M}.${m}.${p          }${z} <${M}.${+m + 1}.0-0`        }      } else {        ret = `>=${M}.${m}.${p        } <${+M + 1}.0.0-0`      }    }    debug('ct return', ret)    return ret  })}const replaceXRanges = (comp, options) => {  debug('replaceXRanges', comp, options)  return comp.split(/\s+/).map((c) => {    return replaceXRange(c, options)  }).jo(' ')}const replaceXRange = (comp, options) => {  comp = comp.trim()  const r = options.loose ? re[t.XRANGELOOSE] : re[t.XRANGE]  return comp.replace(r, (ret, gtlt, M, m, p, pr) => {    debug('xRange', comp, ret, gtlt, M, m, p, pr)    const xM = isX(M)    const xm = xM || isX(m)    const xp = xm || isX(p)    const anyX = xp    if (gtlt === '=' && anyX) {      gtlt = ''    }    // if we're cludg prereleases  the match, then we need    // to fix  to -0, the lowest possible prerelease value    pr = options.cludePrerelease ? '-0' : ''    if (xM) {      if (gtlt === '>' || gtlt === '<') {        // nothg is allowed        ret = '<0.0.0-0'      } else {        // nothg is forbidden        ret = '*'      }    } else if (gtlt && anyX) {      // we know patch is an x, because we have any x at all.      // replace X with 0      if (xm) {        m = 0      }      p = 0      if (gtlt === '>') {        // >1 => >=2.0.0        // >1.2 => >=1.3.0        gtlt = '>='        if (xm) {          M = +M + 1          m = 0          p = 0        } else {          m = +m + 1          p = 0        }      } else if (gtlt === '<=') {        // <=0.7.x is actually <0.8.0, sce any 0.7.x should        // pass.  Similarly, <=7.x is actually <8.0.0, etc.        gtlt = '<'        if (xm) {          M = +M + 1        } else {          m = +m + 1        }      }      if (gtlt === '<') {        pr = '-0'      }      ret = `${gtlt + M}.${m}.${p}${pr}`    } else if (xm) {      ret = `>=${M}.0.0${pr} <${+M + 1}.0.0-0`    } else if (xp) {      ret = `>=${M}.${m}.0${pr      } <${M}.${+m + 1}.0-0`    }    debug('xRange return', ret)    return ret  })}// Because * is AND-ed with everythg else  the comparator,//  '' means "any version", just remove the *s entirely.const replaceStars = (comp, options) => {  debug('replaceStars', comp, options)  // Looseness is ignored here.  star is always as loose as it gets!  return comp.trim().replace(re[t.STAR], '')}const replaceGTE0 = (comp, options) => {  debug('replaceGTE0', comp, options)  return comp.trim()    .replace(re[options.cludePrerelease ? t.GTE0PRE : t.GTE0], '')}// This function is passed to strg.replace(re[t.HYPHENRANGE])// M, m, patch, prerelease, build// 1.2 - 3.4.5 => >=1.2.0 <=3.4.5// 1.2.3 - 3.4 => >=1.2.0 <3.5.0-0 Any 3.4.x will do// 1.2 - 3.4 => >=1.2.0 <3.5.0-0const hyphenReplace = cPr => ($0,  from, fM, fm, fp, fpr, fb,  to, tM, tm, tp, tpr, tb) => {  if (isX(fM)) {    from = ''  } else if (isX(fm)) {    from = `>=${fM}.0.0${cPr ? '-0' : ''}`  } else if (isX(fp)) {    from = `>=${fM}.${fm}.0${cPr ? '-0' : ''}`  } else if (fpr) {    from = `>=${from}`  } else {    from = `>=${from}${cPr ? '-0' : ''}`  }  if (isX(tM)) {    to = ''  } else if (isX(tm)) {    to = `<${+tM + 1}.0.0-0`  } else if (isX(tp)) {    to = `<${tM}.${+tm + 1}.0-0`  } else if (tpr) {    to = `<=${tM}.${tm}.${tp}-${tpr}`  } else if (cPr) {    to = `<${tM}.${tm}.${+tp + 1}-0`  } else {    to = `<=${to}`  }  return (`${from} ${to}`).trim()}const testSet = (set, version, options) => {  for (let i = 0; i < set.length; i++) {    if (!set[i].test(version)) {      return false    }  }  if (version.prerelease.length && !options.cludePrerelease) {    // Fd the set of versions that  allowed to have prereleases    // For example, ^1.2.3-pr.1 desugars to >=1.2.3-pr.1 <2.0.0    // That should allow `1.2.3-pr.2` to pass.    // However, `1.2.4-alpha.notready` should NOT be allowed,    // even though it's with the range set  the comparators.    for (let i = 0; i < set.length; i++) {      debug(set[i].semver)      if (set[i].semver === Comparator.ANY) {        contue      }      if (set[i].semver.prerelease.length > 0) {        const allowed = set[i].semver        if (allowed.major === version.major &&            allowed.mor === version.mor &&            allowed.patch === version.patch) {          return true        }      }    }    // Version has a -pre, but it's not one of the ones we like.    return false  }  return true}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js ***!  \**********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const debug = __webpack_require__(/*! ../ternal/debug */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js")const { MAX_LENGTH, MAX_SAFE_INTEGER } = __webpack_require__(/*! ../ternal/constants */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js")const { re, t } = __webpack_require__(/*! ../ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")const parseOptions = __webpack_require__(/*! ../ternal/parse-options */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js")const { compIdentifiers } = __webpack_require__(/*! ../ternal/identifiers */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/identifiers.js")class SemVer {  constructor (version, options) {    options = parseOptions(options)    if (version stanceof SemVer) {      if (version.loose === !!options.loose &&          version.cludePrerelease === !!options.cludePrerelease) {        return version      } else {        version = version.version      }    } else if (typeof version !== 'strg') {      throw new TypeError(`Invalid Version: ${version}`)    }    if (version.length > MAX_LENGTH) {      throw new TypeError(        `version is longer than ${MAX_LENGTH} characters`      )    }    debug('SemVer', version, options)    .options = options    .loose = !!options.loose    //  isn't actually relevant for versions, but keep it so that we    // don't run to trouble passg .options around.    .cludePrerelease = !!options.cludePrerelease    const m = version.trim().match(options.loose ? re[t.LOOSE] : re[t.FULL])    if (!m) {      throw new TypeError(`Invalid Version: ${version}`)    }    .raw = version    // these  actually numbers    .major = +m[1]    .mor = +m[2]    .patch = +m[3]    if (.major > MAX_SAFE_INTEGER || .major < 0) {      throw new TypeError('Invalid major version')    }    if (.mor > MAX_SAFE_INTEGER || .mor < 0) {      throw new TypeError('Invalid mor version')    }    if (.patch > MAX_SAFE_INTEGER || .patch < 0) {      throw new TypeError('Invalid patch version')    }    // numberify any prerelease numeric ids    if (!m[4]) {      .prerelease = []    } else {      .prerelease = m[4].split('.').map((id) => {        if (/^[0-9]+$/.test(id)) {          const num = +id          if (num >= 0 && num < MAX_SAFE_INTEGER) {            return num          }        }        return id      })    }    .build = m[5] ? m[5].split('.') : []    .format()  }  format () {    .version = `${.major}.${.mor}.${.patch}`    if (.prerelease.length) {      .version += `-${.prerelease.jo('.')}`    }    return .version  }  toStrg () {    return .version  }  comp (other) {    debug('SemVer.comp', .version, .options, other)    if (!(other stanceof SemVer)) {      if (typeof other === 'strg' && other === .version) {        return 0      }      other = new SemVer(other, .options)    }    if (other.version === .version) {      return 0    }    return .compMa(other) || .compPre(other)  }  compMa (other) {    if (!(other stanceof SemVer)) {      other = new SemVer(other, .options)    }    return (      compIdentifiers(.major, other.major) ||      compIdentifiers(.mor, other.mor) ||      compIdentifiers(.patch, other.patch)    )  }  compPre (other) {    if (!(other stanceof SemVer)) {      other = new SemVer(other, .options)    }    // NOT havg a prerelease is > havg one    if (.prerelease.length && !other.prerelease.length) {      return -1    } else if (!.prerelease.length && other.prerelease.length) {      return 1    } else if (!.prerelease.length && !other.prerelease.length) {      return 0    }    let i = 0    do {      const a = .prerelease[i]      const b = other.prerelease[i]      debug('prerelease comp', i, a, b)      if (a === undefed && b === undefed) {        return 0      } else if (b === undefed) {        return 1      } else if (a === undefed) {        return -1      } else if (a === b) {        contue      } else {        return compIdentifiers(a, b)      }    } while (++i)  }  compBuild (other) {    if (!(other stanceof SemVer)) {      other = new SemVer(other, .options)    }    let i = 0    do {      const a = .build[i]      const b = other.build[i]      debug('prerelease comp', i, a, b)      if (a === undefed && b === undefed) {        return 0      } else if (b === undefed) {        return 1      } else if (a === undefed) {        return -1      } else if (a === b) {        contue      } else {        return compIdentifiers(a, b)      }    } while (++i)  }  // premor will bump the version up to the next mor release,  immediately  // down to pre-release. premajor  prepatch work the same way.  c (release, identifier) {    switch (release) {      case 'premajor':        .prerelease.length = 0        .patch = 0        .mor = 0        .major++        .c('pre', identifier)        break      case 'premor':        .prerelease.length = 0        .patch = 0        .mor++        .c('pre', identifier)        break      case 'prepatch':        // If  is already a prerelease, it will bump to the next version        // drop any prereleases that might already exist, sce they  not        // relevant at  pot.        .prerelease.length = 0        .c('patch', identifier)        .c('pre', identifier)        break      // If the put is a non-prerelease version,  acts the same as      // prepatch.      case 'prerelease':        if (.prerelease.length === 0) {          .c('patch', identifier)        }        .c('pre', identifier)        break      case 'major':        // If  is a pre-major version, bump up to the same major version.        // Otherwise crement major.        // 1.0.0-5 bumps to 1.0.0        // 1.1.0 bumps to 2.0.0        if (          .mor !== 0 ||          .patch !== 0 ||          .prerelease.length === 0        ) {          .major++        }        .mor = 0        .patch = 0        .prerelease = []        break      case 'mor':        // If  is a pre-mor version, bump up to the same mor version.        // Otherwise crement mor.        // 1.2.0-5 bumps to 1.2.0        // 1.2.1 bumps to 1.3.0        if (.patch !== 0 || .prerelease.length === 0) {          .mor++        }        .patch = 0        .prerelease = []        break      case 'patch':        // If  is not a pre-release version, it will crement the patch.        // If it is a pre-release it will bump up to the same patch version.        // 1.2.0-5 patches to 1.2.0        // 1.2.0 patches to 1.2.1        if (.prerelease.length === 0) {          .patch++        }        .prerelease = []        break      // This probably shouldn't be used publicly.      // 1.0.0 'pre' would become 1.0.0-0 which is the wrong direction.      case 'pre':        if (.prerelease.length === 0) {          .prerelease = [0]        } else {          let i = .prerelease.length          while (--i >= 0) {            if (typeof .prerelease[i] === 'number') {              .prerelease[i]++              i = -2            }          }          if (i === -1) {            // didn't crement anythg            .prerelease.push(0)          }        }        if (identifier) {          // 1.2.0-beta.1 bumps to 1.2.0-beta.2,          // 1.2.0-beta.fooblz or 1.2.0-beta bumps to 1.2.0-beta.0          if (compIdentifiers(.prerelease[0], identifier) === 0) {            if (isNaN(.prerelease[1])) {              .prerelease = [identifier, 0]            }          } else {            .prerelease = [identifier, 0]          }        }        break      default:        throw new Error(`valid crement argument: ${release}`)    }    .format()    .raw = .version    return   }}module.exports = SemVer/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/clean.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/clean.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const parse = __webpack_require__(/*! ./parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js")const clean = (version, options) => {  const s = parse(version.trim().replace(/^[=v]+/, ''), options)  return s ? s.version : null}module.exports = clean/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/cmp.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/cmp.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const eq = __webpack_require__(/*! ./eq */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/eq.js")const neq = __webpack_require__(/*! ./neq */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/neq.js")const gt = __webpack_require__(/*! ./gt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js")const gte = __webpack_require__(/*! ./gte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gte.js")const lt = __webpack_require__(/*! ./lt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lt.js")const lte = __webpack_require__(/*! ./lte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lte.js")const cmp = (a, op, b, loose) => {  switch (op) {    case '===':      if (typeof a === 'object') {        a = a.version      }      if (typeof b === 'object') {        b = b.version      }      return a === b    case '!==':      if (typeof a === 'object') {        a = a.version      }      if (typeof b === 'object') {        b = b.version      }      return a !== b    case '':    case '=':    case '==':      return eq(a, b, loose)    case '!=':      return neq(a, b, loose)    case '>':      return gt(a, b, loose)    case '>=':      return gte(a, b, loose)    case '<':      return lt(a, b, loose)    case '<=':      return lte(a, b, loose)    default:      throw new TypeError(`Invalid operator: ${op}`)  }}module.exports = cmp/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/coerce.js":/*!************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/coerce.js ***!  \************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const parse = __webpack_require__(/*! ./parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js")const { re, t } = __webpack_require__(/*! ../ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")const coerce = (version, options) => {  if (version stanceof SemVer) {    return version  }  if (typeof version === 'number') {    version = Strg(version)  }  if (typeof version !== 'strg') {    return null  }  options = options || {}  let match = null  if (!options.rtl) {    match = version.match(re[t.COERCE])  } else {    // Fd the right-most coercible strg that does not sh    // a termus with a more left-ward coercible strg.    // Eg, '1.2.3.4' wants to coerce '2.3.4', not '3.4' or '4'    //    // Walk through the strg checkg with a /g regexp    // Manually set the dex so as to pick up overlappg matches.    // Stop when we get a match that ends at the strg end, sce no    // coercible strg can be more right-ward without the same termus.    let next    while ((next = re[t.COERCERTL].exec(version)) &&        (!match || match.dex + match[0].length !== version.length)    ) {      if (!match ||            next.dex + next[0].length !== match.dex + match[0].length) {        match = next      }      re[t.COERCERTL].lastIndex = next.dex + next[1].length + next[2].length    }    // leave it  a clean state    re[t.COERCERTL].lastIndex = -1  }  if (match === null) {    return null  }  return parse(`${match[2]}.${match[3] || '0'}.${match[4] || '0'}`, options)}module.exports = coerce/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-build.js":/*!*******************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-build.js ***!  \*******************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const compBuild = (a, b, loose) => {  const versionA = new SemVer(a, loose)  const versionB = new SemVer(b, loose)  return versionA.comp(versionB) || versionA.compBuild(versionB)}module.exports = compBuild/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-loose.js":/*!*******************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-loose.js ***!  \*******************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const compLoose = (a, b) => comp(a, b, true)module.exports = compLoose/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js":/*!*************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js ***!  \*************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const comp = (a, b, loose) =>  new SemVer(a, loose).comp(new SemVer(b, loose))module.exports = comp/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/diff.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/diff.js ***!  \**********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const parse = __webpack_require__(/*! ./parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js")const eq = __webpack_require__(/*! ./eq */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/eq.js")const diff = (version1, version2) => {  if (eq(version1, version2)) {    return null  } else {    const v1 = parse(version1)    const v2 = parse(version2)    const hasPre = v1.prerelease.length || v2.prerelease.length    const prefix = hasPre ? 'pre' : ''    const defaultResult = hasPre ? 'prerelease' : ''    for (const key  v1) {      if (key === 'major' || key === 'mor' || key === 'patch') {        if (v1[key] !== v2[key]) {          return prefix + key        }      }    }    return defaultResult // may be undefed  }}module.exports = diff/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/eq.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/eq.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const eq = (a, b, loose) => comp(a, b, loose) === 0module.exports = eq/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const gt = (a, b, loose) => comp(a, b, loose) > 0module.exports = gt/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gte.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gte.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const gte = (a, b, loose) => comp(a, b, loose) >= 0module.exports = gte/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/c.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/c.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const c = (version, release, options, identifier) => {  if (typeof (options) === 'strg') {    identifier = options    options = undefed  }  try {    return new SemVer(      version stanceof SemVer ? version.version : version,      options    ).c(release, identifier).version  } catch (er) {    return null  }}module.exports = c/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lt.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lt.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const lt = (a, b, loose) => comp(a, b, loose) < 0module.exports = lt/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lte.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lte.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const lte = (a, b, loose) => comp(a, b, loose) <= 0module.exports = lte/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/major.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/major.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const major = (a, loose) => new SemVer(a, loose).majormodule.exports = major/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/mor.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/mor.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const mor = (a, loose) => new SemVer(a, loose).mormodule.exports = mor/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/neq.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/neq.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const neq = (a, b, loose) => comp(a, b, loose) !== 0module.exports = neq/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const { MAX_LENGTH } = __webpack_require__(/*! ../ternal/constants */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js")const { re, t } = __webpack_require__(/*! ../ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const parseOptions = __webpack_require__(/*! ../ternal/parse-options */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js")const parse = (version, options) => {  options = parseOptions(options)  if (version stanceof SemVer) {    return version  }  if (typeof version !== 'strg') {    return null  }  if (version.length > MAX_LENGTH) {    return null  }  const r = options.loose ? re[t.LOOSE] : re[t.FULL]  if (!r.test(version)) {    return null  }  try {    return new SemVer(version, options)  } catch (er) {    return null  }}module.exports = parse/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/patch.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/patch.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const patch = (a, loose) => new SemVer(a, loose).patchmodule.exports = patch/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/prerelease.js":/*!****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/prerelease.js ***!  \****************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const parse = __webpack_require__(/*! ./parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js")const prerelease = (version, options) => {  const parsed = parse(version, options)  return (parsed && parsed.prerelease.length) ? parsed.prerelease : null}module.exports = prerelease/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rcomp.js":/*!**************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rcomp.js ***!  \**************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const rcomp = (a, b, loose) => comp(b, a, loose)module.exports = rcomp/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rsort.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rsort.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const compBuild = __webpack_require__(/*! ./comp-build */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-build.js")const rsort = (list, loose) => list.sort((a, b) => compBuild(b, a, loose))module.exports = rsort/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js":/*!***************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js ***!  \***************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const satisfies = (version, range, options) => {  try {    range = new Range(range, options)  } catch (er) {    return false  }  return range.test(version)}module.exports = satisfies/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/sort.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/sort.js ***!  \**********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const compBuild = __webpack_require__(/*! ./comp-build */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-build.js")const sort = (list, loose) => list.sort((a, b) => compBuild(a, b, loose))module.exports = sort/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/valid.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/valid.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const parse = __webpack_require__(/*! ./parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js")const valid = (version, options) => {  const v = parse(version, options)  return v ? v.version : null}module.exports = valid/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// just pre-load all the stuff that dex.js lazily exportsconst ternalRe = __webpack_require__(/*! ./ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")module.exports = {  re: ternalRe.re,  src: ternalRe.src,  tokens: ternalRe.t,  SEMVER_SPEC_VERSION: (__webpack_require__(/*! ./ternal/constants */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js").SEMVER_SPEC_VERSION),  SemVer: __webpack_require__(/*! ./classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js"),  compIdentifiers: (__webpack_require__(/*! ./ternal/identifiers */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/identifiers.js").compIdentifiers),  rcompIdentifiers: (__webpack_require__(/*! ./ternal/identifiers */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/identifiers.js").rcompIdentifiers),  parse: __webpack_require__(/*! ./functions/parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js"),  valid: __webpack_require__(/*! ./functions/valid */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/valid.js"),  clean: __webpack_require__(/*! ./functions/clean */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/clean.js"),  c: __webpack_require__(/*! ./functions/c */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/c.js"),  diff: __webpack_require__(/*! ./functions/diff */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/diff.js"),  major: __webpack_require__(/*! ./functions/major */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/major.js"),  mor: __webpack_require__(/*! ./functions/mor */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/mor.js"),  patch: __webpack_require__(/*! ./functions/patch */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/patch.js"),  prerelease: __webpack_require__(/*! ./functions/prerelease */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/prerelease.js"),  comp: __webpack_require__(/*! ./functions/comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js"),  rcomp: __webpack_require__(/*! ./functions/rcomp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rcomp.js"),  compLoose: __webpack_require__(/*! ./functions/comp-loose */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-loose.js"),  compBuild: __webpack_require__(/*! ./functions/comp-build */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-build.js"),  sort: __webpack_require__(/*! ./functions/sort */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/sort.js"),  rsort: __webpack_require__(/*! ./functions/rsort */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rsort.js"),  gt: __webpack_require__(/*! ./functions/gt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js"),  lt: __webpack_require__(/*! ./functions/lt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lt.js"),  eq: __webpack_require__(/*! ./functions/eq */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/eq.js"),  neq: __webpack_require__(/*! ./functions/neq */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/neq.js"),  gte: __webpack_require__(/*! ./functions/gte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gte.js"),  lte: __webpack_require__(/*! ./functions/lte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lte.js"),  cmp: __webpack_require__(/*! ./functions/cmp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/cmp.js"),  coerce: __webpack_require__(/*! ./functions/coerce */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/coerce.js"),  Comparator: __webpack_require__(/*! ./classes/comparator */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js"),  Range: __webpack_require__(/*! ./classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js"),  satisfies: __webpack_require__(/*! ./functions/satisfies */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js"),  toComparators: __webpack_require__(/*! ./ranges/to-comparators */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/to-comparators.js"),  maxSatisfyg: __webpack_require__(/*! ./ranges/max-satisfyg */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/max-satisfyg.js"),  mSatisfyg: __webpack_require__(/*! ./ranges/m-satisfyg */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-satisfyg.js"),  mVersion: __webpack_require__(/*! ./ranges/m-version */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-version.js"),  validRange: __webpack_require__(/*! ./ranges/valid */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/valid.js"),  outside: __webpack_require__(/*! ./ranges/outside */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/outside.js"),  gtr: __webpack_require__(/*! ./ranges/gtr */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/gtr.js"),  ltr: __webpack_require__(/*! ./ranges/ltr */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/ltr.js"),  tersects: __webpack_require__(/*! ./ranges/tersects */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/tersects.js"),  simplifyRange: __webpack_require__(/*! ./ranges/simplify */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/simplify.js"),  subset: __webpack_require__(/*! ./ranges/subset */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/subset.js"),}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js":/*!**************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js ***!  \**************************************************************************************************************//***/ ((module) => {// Note:  is the semver.org version of the spec that it implements// Not necessarily the package version of  code.const SEMVER_SPEC_VERSION = '2.0.0'const MAX_LENGTH = 256const MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER ||/* istanbul ignore next */ 9007199254740991// Max safe segment length for coercion.const MAX_SAFE_COMPONENT_LENGTH = 16module.exports = {  SEMVER_SPEC_VERSION,  MAX_LENGTH,  MAX_SAFE_INTEGER,  MAX_SAFE_COMPONENT_LENGTH,}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js ***!  \**********************************************************************************************************//***/ ((module) => {const debug = (  typeof process === 'object' &&  process.env &&  process.env.NODE_DEBUG &&  /\bsemver\b/i.test(process.env.NODE_DEBUG)) ? (...args) => console.error('SEMVER', ...args)  : () => {}module.exports = debug/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/identifiers.js":/*!****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/identifiers.js ***!  \****************************************************************************************************************//***/ ((module) => {const numeric = /^[0-9]+$/const compIdentifiers = (a, b) => {  const anum = numeric.test(a)  const bnum = numeric.test(b)  if (anum && bnum) {    a = +a    b = +b  }  return a === b ? 0    : (anum && !bnum) ? -1    : (bnum && !anum) ? 1    : a < b ? -1    : 1}const rcompIdentifiers = (a, b) => compIdentifiers(b, a)module.exports = {  compIdentifiers,  rcompIdentifiers,}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js":/*!******************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js ***!  \******************************************************************************************************************//***/ ((module) => {// parse out just the options we c about so we always get a consistent// obj with keys  a consistent order.const opts = ['cludePrerelease', 'loose', 'rtl']const parseOptions = options =>  !options ? {}  : typeof options !== 'object' ? { loose: true }  : opts.filter(k => options[k]).reduce((o, k) => {    o[k] = true    return o  }, {})module.exports = parseOptions/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js":/*!*******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js ***!  \*******************************************************************************************************//***/ ((module, exports, __webpack_require__) => {const { MAX_SAFE_COMPONENT_LENGTH } = __webpack_require__(/*! ./constants */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js")const debug = __webpack_require__(/*! ./debug */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js")exports = module.exports = {}//  actual regexps go on exports.reconst re = exports.re = []const src = exports.src = []const t = exports.t = {}let R = 0const createToken = (name, value, isGlobal) => {  const dex = R++  debug(name, dex, value)  t[name] = dex  src[dex] = value  re[dex] = new RegExp(value, isGlobal ? 'g' : undefed)}//  followg Regular Expressions can be used for tokenizg,// validatg,  parsg SemVer version strgs.// ## Numeric Identifier// A sgle `0`, or a non-zero digit followed  zero or more digits.createToken('NUMERICIDENTIFIER', '0|[1-9]\\d*')createToken('NUMERICIDENTIFIERLOOSE', '[0-9]+')// ## Non-numeric Identifier// Zero or more digits, followed  a letter or hyphen,  then zero or// more letters, digits, or hyphens.createToken('NONNUMERICIDENTIFIER', '\\d*[a-zA-Z-][a-zA-Z0-9-]*')// ## Ma Version// Three dot-separated numeric identifiers.createToken('MAINVERSION', `(${src[t.NUMERICIDENTIFIER]})\\.` +                   `(${src[t.NUMERICIDENTIFIER]})\\.` +                   `(${src[t.NUMERICIDENTIFIER]})`)createToken('MAINVERSIONLOOSE', `(${src[t.NUMERICIDENTIFIERLOOSE]})\\.` +                        `(${src[t.NUMERICIDENTIFIERLOOSE]})\\.` +                        `(${src[t.NUMERICIDENTIFIERLOOSE]})`)// ## Pre-release Version Identifier// A numeric identifier, or a non-numeric identifier.createToken('PRERELEASEIDENTIFIER', `(?:${src[t.NUMERICIDENTIFIER]}|${src[t.NONNUMERICIDENTIFIER]})`)createToken('PRERELEASEIDENTIFIERLOOSE', `(?:${src[t.NUMERICIDENTIFIERLOOSE]}|${src[t.NONNUMERICIDENTIFIER]})`)// ## Pre-release Version// Hyphen, followed  one or more dot-separated pre-release version// identifiers.createToken('PRERELEASE', `(?:-(${src[t.PRERELEASEIDENTIFIER]}(?:\\.${src[t.PRERELEASEIDENTIFIER]})*))`)createToken('PRERELEASELOOSE', `(?:-?(${src[t.PRERELEASEIDENTIFIERLOOSE]}(?:\\.${src[t.PRERELEASEIDENTIFIERLOOSE]})*))`)// ## Build Metadata Identifier// Any combation of digits, letters, or hyphens.createToken('BUILDIDENTIFIER', '[0-9A-Za-z-]+')// ## Build Metadata// Plus sign, followed  one or more period-separated build metadata// identifiers.createToken('BUILD', `(?:\\+(${src[t.BUILDIDENTIFIER]}(?:\\.${src[t.BUILDIDENTIFIER]})*))`)// ## Full Version Strg// A ma version, followed optionally  a pre-release version // build metadata.// Note that the only major, mor, patch,  pre-release sections of// the version strg  capturg groups.   build metadata is not a// capturg group, because it should not ever be used  version// comparison.createToken('FULLPLAIN', `v?${src[t.MAINVERSION]}${src[t.PRERELEASE]}?${  src[t.BUILD]}?`)createToken('FULL', `^${src[t.FULLPLAIN]}$`)// like full, but allows v1.2.3  =1.2.3, which people do sometimes.// also, 1.0.0alpha1 (prerelease without the hyphen) which is pretty// common  the npm registry.createToken('LOOSEPLAIN', `[v=\\s]*${src[t.MAINVERSIONLOOSE]}${src[t.PRERELEASELOOSE]}?${  src[t.BUILD]}?`)createToken('LOOSE', `^${src[t.LOOSEPLAIN]}$`)createToken('GTLT', '((?:<|>)?=?)')// Somethg like "2.*" or "1.2.x".// Note that "x.x" is a valid xRange identifer, meang "any version"// Only the first item is strictly required.createToken('XRANGEIDENTIFIERLOOSE', `${src[t.NUMERICIDENTIFIERLOOSE]}|x|X|\\*`)createToken('XRANGEIDENTIFIER', `${src[t.NUMERICIDENTIFIER]}|x|X|\\*`)createToken('XRANGEPLAIN', `[v=\\s]*(${src[t.XRANGEIDENTIFIER]})` +                   `(?:\\.(${src[t.XRANGEIDENTIFIER]})` +                   `(?:\\.(${src[t.XRANGEIDENTIFIER]})` +                   `(?:${src[t.PRERELEASE]})?${                     src[t.BUILD]}?` +                   `)?)?`)createToken('XRANGEPLAINLOOSE', `[v=\\s]*(${src[t.XRANGEIDENTIFIERLOOSE]})` +                        `(?:\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +                        `(?:\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +                        `(?:${src[t.PRERELEASELOOSE]})?${                          src[t.BUILD]}?` +                        `)?)?`)createToken('XRANGE', `^${src[t.GTLT]}\\s*${src[t.XRANGEPLAIN]}$`)createToken('XRANGELOOSE', `^${src[t.GTLT]}\\s*${src[t.XRANGEPLAINLOOSE]}$`)// Coercion.// Extract anythg that could conceivably be a part of a valid semvercreateToken('COERCE', `${'(^|[^\\d])' +              '(\\d{1,'}${MAX_SAFE_COMPONENT_LENGTH}})` +              `(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +              `(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +              `(?:$|[^\\d])`)createToken('COERCERTL', src[t.COERCE], true)// Tilde ranges.// Meang is "reasonably at or greater than"createToken('LONETILDE', '(?:~>?)')createToken('TILDETRIM', `(\\s*)${src[t.LONETILDE]}\\s+`, true)exports.tildeTrimReplace = '$1~'createToken('TILDE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAIN]}$`)createToken('TILDELOOSE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAINLOOSE]}$`)// Ct ranges.// Meang is "at least  backwards compatible with"createToken('LONECARET', '(?:\\^)')createToken('CARETTRIM', `(\\s*)${src[t.LONECARET]}\\s+`, true)exports.ctTrimReplace = '$1^'createToken('CARET', `^${src[t.LONECARET]}${src[t.XRANGEPLAIN]}$`)createToken('CARETLOOSE', `^${src[t.LONECARET]}${src[t.XRANGEPLAINLOOSE]}$`)// A simple gt/lt/eq thg, or just "" to dicate "any version"createToken('COMPARATORLOOSE', `^${src[t.GTLT]}\\s*(${src[t.LOOSEPLAIN]})$|^$`)createToken('COMPARATOR', `^${src[t.GTLT]}\\s*(${src[t.FULLPLAIN]})$|^$`)// An expression to strip any whitespace between the gtlt  the thg// it modifies, so that `> 1.2.3` ==> `>1.2.3`createToken('COMPARATORTRIM', `(\\s*)${src[t.GTLT]}\\s*(${src[t.LOOSEPLAIN]}|${src[t.XRANGEPLAIN]})`, true)exports.comparatorTrimReplace = '$1$2$3'// Somethg like `1.2.3 - 1.2.4`// Note that these all use the loose form, because they'll be// checked agast either the strict or loose comparator form// later.createToken('HYPHENRANGE', `^\\s*(${src[t.XRANGEPLAIN]})` +                   `\\s+-\\s+` +                   `(${src[t.XRANGEPLAIN]})` +                   `\\s*$`)createToken('HYPHENRANGELOOSE', `^\\s*(${src[t.XRANGEPLAINLOOSE]})` +                        `\\s+-\\s+` +                        `(${src[t.XRANGEPLAINLOOSE]})` +                        `\\s*$`)// Star ranges basically just allow anythg at all.createToken('STAR', '(<|>)?=?\\s*\\*')// >=0.0.0 is like a starcreateToken('GTE0', '^\\s*>=\\s*0\\.0\\.0\\s*$')createToken('GTE0PRE', '^\\s*>=\\s*0\\.0\\.0-0\\s*$')/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/gtr.js":/*!******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/gtr.js ***!  \******************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// Determe if version is greater than all the versions possible  the range.const outside = __webpack_require__(/*! ./outside */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/outside.js")const gtr = (version, range, options) => outside(version, range, '>', options)module.exports = gtr/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/tersects.js":/*!*************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/tersects.js ***!  \*************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const tersects = (r1, r2, options) => {  r1 = new Range(r1, options)  r2 = new Range(r2, options)  return r1.tersects(r2)}module.exports = tersects/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/ltr.js":/*!******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/ltr.js ***!  \******************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const outside = __webpack_require__(/*! ./outside */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/outside.js")// Determe if version is less than all the versions possible  the rangeconst ltr = (version, range, options) => outside(version, range, '<', options)module.exports = ltr/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/max-satisfyg.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/max-satisfyg.js ***!  \*****************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const maxSatisfyg = (versions, range, options) => {  let max = null  let maxSV = null  let rangeObj = null  try {    rangeObj = new Range(range, options)  } catch (er) {    return null  }  versions.forEach((v) => {    if (rangeObj.test(v)) {      // satisfies(v, range, options)      if (!max || maxSV.comp(v) === -1) {        // comp(max, v, true)        max = v        maxSV = new SemVer(max, options)      }    }  })  return max}module.exports = maxSatisfyg/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-satisfyg.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-satisfyg.js ***!  \*****************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const mSatisfyg = (versions, range, options) => {  let m = null  let mSV = null  let rangeObj = null  try {    rangeObj = new Range(range, options)  } catch (er) {    return null  }  versions.forEach((v) => {    if (rangeObj.test(v)) {      // satisfies(v, range, options)      if (!m || mSV.comp(v) === 1) {        // comp(m, v, true)        m = v        mSV = new SemVer(m, options)      }    }  })  return m}module.exports = mSatisfyg/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-version.js":/*!**************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-version.js ***!  \**************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const gt = __webpack_require__(/*! ../functions/gt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js")const mVersion = (range, loose) => {  range = new Range(range, loose)  let mver = new SemVer('0.0.0')  if (range.test(mver)) {    return mver  }  mver = new SemVer('0.0.0-0')  if (range.test(mver)) {    return mver  }  mver = null  for (let i = 0; i < range.set.length; ++i) {    const comparators = range.set[i]    let setM = null    comparators.forEach((comparator) => {      // Clone to avoid manipulatg the comparator's semver object.      const compver = new SemVer(comparator.semver.version)      switch (comparator.operator) {        case '>':          if (compver.prerelease.length === 0) {            compver.patch++          } else {            compver.prerelease.push(0)          }          compver.raw = compver.format()          /* fallthrough */        case '':        case '>=':          if (!setM || gt(compver, setM)) {            setM = compver          }          break        case '<':        case '<=':          /* Ignore maximum versions */          break        /* istanbul ignore next */        default:          throw new Error(`Unexpected operation: ${comparator.operator}`)      }    })    if (setM && (!mver || gt(mver, setM))) {      mver = setM    }  }  if (mver && range.test(mver)) {    return mver  }  return null}module.exports = mVersion/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/outside.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/outside.js ***!  \**********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const Comparator = __webpack_require__(/*! ../classes/comparator */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js")const { ANY } = Comparatorconst Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const satisfies = __webpack_require__(/*! ../functions/satisfies */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js")const gt = __webpack_require__(/*! ../functions/gt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js")const lt = __webpack_require__(/*! ../functions/lt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lt.js")const lte = __webpack_require__(/*! ../functions/lte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lte.js")const gte = __webpack_require__(/*! ../functions/gte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gte.js")const outside = (version, range, hilo, options) => {  version = new SemVer(version, options)  range = new Range(range, options)  let gtfn, ltefn, ltfn, comp, ecomp  switch (hilo) {    case '>':      gtfn = gt      ltefn = lte      ltfn = lt      comp = '>'      ecomp = '>='      break    case '<':      gtfn = lt      ltefn = gte      ltfn = gt      comp = '<'      ecomp = '<='      break    default:      throw new TypeError('Must provide a hilo val of "<" or ">"')  }  // If it satisfies the range it is not outside  if (satisfies(version, range, options)) {    return false  }  // From now on, variable terms  as if we're  "gtr" mode.  // but note that everythg is flipped for the "ltr" function.  for (let i = 0; i < range.set.length; ++i) {    const comparators = range.set[i]    let high = null    let low = null    comparators.forEach((comparator) => {      if (comparator.semver === ANY) {        comparator = new Comparator('>=0.0.0')      }      high = high || comparator      low = low || comparator      if (gtfn(comparator.semver, high.semver, options)) {        high = comparator      } else if (ltfn(comparator.semver, low.semver, options)) {        low = comparator      }    })    // If the edge version comparator has a operator then our version    // isn't outside it    if (high.operator === comp || high.operator === ecomp) {      return false    }    // If the lowest version comparator has an operator  our version    // is less than it then it isn't higher than the range    if ((!low.operator || low.operator === comp) &&        ltefn(version, low.semver)) {      return false    } else if (low.operator === ecomp && ltfn(version, low.semver)) {      return false    }  }  return true}module.exports = outside/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/simplify.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/simplify.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// given a set of versions  a range, create a "simplified" range// that cludes the same versions that the origal range does// If the origal range is shorter than the simplified one, return that.const satisfies = __webpack_require__(/*! ../functions/satisfies.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js")const comp = __webpack_require__(/*! ../functions/comp.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")module.exports = (versions, range, options) => {  const set = []  let first = null  let prev = null  const v = versions.sort((a, b) => comp(a, b, options))  for (const version of v) {    const cluded = satisfies(version, range, options)    if (cluded) {      prev = version      if (!first) {        first = version      }    } else {      if (prev) {        set.push([first, prev])      }      prev = null      first = null    }  }  if (first) {    set.push([first, null])  }  const ranges = []  for (const [m, max] of set) {    if (m === max) {      ranges.push(m)    } else if (!max && m === v[0]) {      ranges.push('*')    } else if (!max) {      ranges.push(`>=${m}`)    } else if (m === v[0]) {      ranges.push(`<=${max}`)    } else {      ranges.push(`${m} - ${max}`)    }  }  const simplified = ranges.jo(' || ')  const origal = typeof range.raw === 'strg' ? range.raw : Strg(range)  return simplified.length < origal.length ? simplified : range}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/subset.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/subset.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const Range = __webpack_require__(/*! ../classes/range.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const Comparator = __webpack_require__(/*! ../classes/comparator.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js")const { ANY } = Comparatorconst satisfies = __webpack_require__(/*! ../functions/satisfies.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js")const comp = __webpack_require__(/*! ../functions/comp.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")// Complex range `r1 || r2 || ...` is a subset of `R1 || R2 || ...` iff:// - Every simple range `r1, r2, ...` is a null set, OR// - Every simple range `r1, r2, ...` which is not a null set is a subset of//   some `R1, R2, ...`//// Simple range `c1 c2 ...` is a subset of simple range `C1 C2 ...` iff:// - If c is only the ANY comparator//   - If C is only the ANY comparator, return true//   - Else if  prerelease mode, return false//   - else replace c with `[>=0.0.0]`// - If C is only the ANY comparator//   - if  prerelease mode, return true//   - else replace C with `[>=0.0.0]`// - Let EQ be the set of = comparators  c// - If EQ is more than one, return true (null set)// - Let GT be the highest > or >= comparator  c// - Let LT be the lowest < or <= comparator  c// - If GT  LT,  GT.semver > LT.semver, return true (null set)// - If any C is a = range,  GT or LT  set, return false// - If EQ//   - If GT,  EQ does not satisfy GT, return true (null set)//   - If LT,  EQ does not satisfy LT, return true (null set)//   - If EQ satisfies every C, return true//   - Else return false// - If GT//   - If GT.semver is lower than any > or >= comp  C, return false//   - If GT is >=,  GT.semver does not satisfy every C, return false//   - If GT.semver has a prerelease,  not  prerelease mode//     - If no C has a prerelease  the GT.semver tuple, return false// - If LT//   - If LT.semver is greater than any < or <= comp  C, return false//   - If LT is <=,  LT.semver does not satisfy every C, return false//   - If GT.semver has a prerelease,  not  prerelease mode//     - If no C has a prerelease  the LT.semver tuple, return false// - Else return trueconst subset = (sub, dom, options = {}) => {  if (sub === dom) {    return true  }  sub = new Range(sub, options)  dom = new Range(dom, options)  let sawNonNull = false  OUTER: for (const simpleSub of sub.set) {    for (const simpleDom of dom.set) {      const isSub = simpleSubset(simpleSub, simpleDom, options)      sawNonNull = sawNonNull || isSub !== null      if (isSub) {        contue OUTER      }    }    // the null set is a subset of everythg, but null simple ranges     // a complex range should be ignored.  so if we saw a non-null range,    // then we know  isn't a subset, but if EVERY simple range was null,    // then it is a subset.    if (sawNonNull) {      return false    }  }  return true}const simpleSubset = (sub, dom, options) => {  if (sub === dom) {    return true  }  if (sub.length === 1 && sub[0].semver === ANY) {    if (dom.length === 1 && dom[0].semver === ANY) {      return true    } else if (options.cludePrerelease) {      sub = [new Comparator('>=0.0.0-0')]    } else {      sub = [new Comparator('>=0.0.0')]    }  }  if (dom.length === 1 && dom[0].semver === ANY) {    if (options.cludePrerelease) {      return true    } else {      dom = [new Comparator('>=0.0.0')]    }  }  const eqSet = new Set()  let gt, lt  for (const c of sub) {    if (c.operator === '>' || c.operator === '>=') {      gt = higherGT(gt, c, options)    } else if (c.operator === '<' || c.operator === '<=') {      lt = lowerLT(lt, c, options)    } else {      eqSet.add(c.semver)    }  }  if (eqSet.size > 1) {    return null  }  let gtltComp  if (gt && lt) {    gtltComp = comp(gt.semver, lt.semver, options)    if (gtltComp > 0) {      return null    } else if (gtltComp === 0 && (gt.operator !== '>=' || lt.operator !== '<=')) {      return null    }  }  // will iterate one or zero times  for (const eq of eqSet) {    if (gt && !satisfies(eq, Strg(gt), options)) {      return null    }    if (lt && !satisfies(eq, Strg(lt), options)) {      return null    }    for (const c of dom) {      if (!satisfies(eq, Strg(c), options)) {        return false      }    }    return true  }  let higher, lower  let hasDomLT, hasDomGT  // if the subset has a prerelease, we need a comparator  the superset  // with the same tuple  a prerelease, or it's not a subset  let needDomLTPre = lt &&    !options.cludePrerelease &&    lt.semver.prerelease.length ? lt.semver : false  let needDomGTPre = gt &&    !options.cludePrerelease &&    gt.semver.prerelease.length ? gt.semver : false  // exception: <1.2.3-0 is the same as <1.2.3  if (needDomLTPre && needDomLTPre.prerelease.length === 1 &&      lt.operator === '<' && needDomLTPre.prerelease[0] === 0) {    needDomLTPre = false  }  for (const c of dom) {    hasDomGT = hasDomGT || c.operator === '>' || c.operator === '>='    hasDomLT = hasDomLT || c.operator === '<' || c.operator === '<='    if (gt) {      if (needDomGTPre) {        if (c.semver.prerelease && c.semver.prerelease.length &&            c.semver.major === needDomGTPre.major &&            c.semver.mor === needDomGTPre.mor &&            c.semver.patch === needDomGTPre.patch) {          needDomGTPre = false        }      }      if (c.operator === '>' || c.operator === '>=') {        higher = higherGT(gt, c, options)        if (higher === c && higher !== gt) {          return false        }      } else if (gt.operator === '>=' && !satisfies(gt.semver, Strg(c), options)) {        return false      }    }    if (lt) {      if (needDomLTPre) {        if (c.semver.prerelease && c.semver.prerelease.length &&            c.semver.major === needDomLTPre.major &&            c.semver.mor === needDomLTPre.mor &&            c.semver.patch === needDomLTPre.patch) {          needDomLTPre = false        }      }      if (c.operator === '<' || c.operator === '<=') {        lower = lowerLT(lt, c, options)        if (lower === c && lower !== lt) {          return false        }      } else if (lt.operator === '<=' && !satisfies(lt.semver, Strg(c), options)) {        return false      }    }    if (!c.operator && (lt || gt) && gtltComp !== 0) {      return false    }  }  // if there was a < or >,  nothg  the dom, then must be false  // UNLESS it was limited  another range  the other direction.  // Eg, >1.0.0 <1.0.1 is still a subset of <2.0.0  if (gt && hasDomLT && !lt && gtltComp !== 0) {    return false  }  if (lt && hasDomGT && !gt && gtltComp !== 0) {    return false  }  // we needed a prerelease range  a specific tuple, but didn't get one  // then  isn't a subset.  eg >=1.2.3-pre is not a subset of >=1.0.0,  // because it cludes prereleases  the 1.2.3 tuple  if (needDomGTPre || needDomLTPre) {    return false  }  return true}// >=1.2.3 is lower than >1.2.3const higherGT = (a, b, options) => {  if (!a) {    return b  }  const comp = comp(a.semver, b.semver, options)  return comp > 0 ? a    : comp < 0 ? b    : b.operator === '>' && a.operator === '>=' ? b    : a}// <=1.2.3 is higher than <1.2.3const lowerLT = (a, b, options) => {  if (!a) {    return b  }  const comp = comp(a.semver, b.semver, options)  return comp < 0 ? a    : comp > 0 ? b    : b.operator === '<' && a.operator === '<=' ? b    : a}module.exports = subset/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/to-comparators.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/to-comparators.js ***!  \*****************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")// Mostly just for testg  legacy API reasonsconst toComparators = (range, options) =>  new Range(range, options).set    .map(comp => comp.map(c => c.value).jo(' ').trim().split(' '))module.exports = toComparators/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/valid.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/valid.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const validRange = (range, options) => {  try {    // Return '*' stead of '' so that truthess works.    // This will throw if it's valid anyway    return new Range(range, options).range || '*'  } catch (er) {    return null  }}module.exports = validRange/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/dex.js":/*!********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/dex.js ***!  \********************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";// high-level commsexports.c = exports.create = __webpack_require__(/*! ./lib/create.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/create.js")exports.r = exports.replace = __webpack_require__(/*! ./lib/replace.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/replace.js")exports.t = exports.list = __webpack_require__(/*! ./lib/list.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/list.js")exports.u = exports.update = __webpack_require__(/*! ./lib/update.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/update.js")exports.x = exports.extract = __webpack_require__(/*! ./lib/extract.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/extract.js")// classesexports.Pack = __webpack_require__(/*! ./lib/pack.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pack.js")exports.Unpack = __webpack_require__(/*! ./lib/unpack.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/unpack.js")exports.Parse = __webpack_require__(/*! ./lib/parse.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/parse.js")exports.ReadEntry = __webpack_require__(/*! ./lib/read-entry.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/read-entry.js")exports.WriteEntry = __webpack_require__(/*! ./lib/write-entry.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/write-entry.js")exports.Header = __webpack_require__(/*! ./lib/header.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js")exports.Pax = __webpack_require__(/*! ./lib/pax.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pax.js")exports.types = __webpack_require__(/*! ./lib/types.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/types.js")/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/create.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/create.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// tar -cconst hlo = __webpack_require__(/*! ./high-level-opt.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js")const Pack = __webpack_require__(/*! ./pack.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pack.js")const fsm = __webpack_require__(/*! fs-mipass */ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js")const t = __webpack_require__(/*! ./list.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/list.js")const path = __webpack_require__(/*! path */ "path")module.exports = (opt_, files, cb) => {  if (typeof files === 'function')    cb = files  if (Array.isArray(opt_))    files = opt_, opt_ = {}  if (!files || !Array.isArray(files) || !files.length)    throw new TypeError('no files or directories specified')  files = Array.from(files)  const opt = hlo(opt_)  if (opt.sync && typeof cb === 'function')    throw new TypeError('callback not supported for sync tar functions')  if (!opt.file && typeof cb === 'function')    throw new TypeError('callback only supported with file option')  return opt.file && opt.sync ? createFileSync(opt, files)    : opt.file ? createFile(opt, files, cb)    : opt.sync ? createSync(opt, files)    : create(opt, files)}const createFileSync = (opt, files) => {  const p = new Pack.Sync(opt)  const stream = new fsm.WriteStreamSync(opt.file, {    mode: opt.mode || 0o666,  })  p.pipe(stream)  addFilesSync(p, files)}const createFile = (opt, files, cb) => {  const p = new Pack(opt)  const stream = new fsm.WriteStream(opt.file, {    mode: opt.mode || 0o666,  })  p.pipe(stream)  const promise = new Promise((res, rej) => {    stream.on('error', rej)    stream.on('close', res)    p.on('error', rej)  })  addFilesAsync(p, files)  return cb ? promise.then(cb, cb) : promise}const addFilesSync = (p, files) => {  files.forEach(file => {    if (file.charAt(0) === '@') {      t({        file: path.resolve(p.cwd, file.substr(1)),        sync: true,        noResume: true,        onentry: entry => p.add(entry),      })    } else      p.add(file)  })  p.end()}const addFilesAsync = (p, files) => {  while (files.length) {    const file = files.shift()    if (file.charAt(0) === '@') {      return t({        file: path.resolve(p.cwd, file.substr(1)),        noResume: true,        onentry: entry => p.add(entry),      }).then(_ => addFilesAsync(p, files))    } else      p.add(file)  }  p.end()}const createSync = (opt, files) => {  const p = new Pack.Sync(opt)  addFilesSync(p, files)  return p}const create = (opt, files) => {  const p = new Pack(opt)  addFilesAsync(p, files)  return p}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/extract.js":/*!**************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/extract.js ***!  \**************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// tar -xconst hlo = __webpack_require__(/*! ./high-level-opt.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js")const Unpack = __webpack_require__(/*! ./unpack.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/unpack.js")const fs = __webpack_require__(/*! fs */ "fs")const fsm = __webpack_require__(/*! fs-mipass */ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js")const path = __webpack_require__(/*! path */ "path")const stripSlash = __webpack_require__(/*! ./strip-trailg-slashes.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js")module.exports = (opt_, files, cb) => {  if (typeof opt_ === 'function')    cb = opt_, files = null, opt_ = {}  else if (Array.isArray(opt_))    files = opt_, opt_ = {}  if (typeof files === 'function')    cb = files, files = null  if (!files)    files = []  else    files = Array.from(files)  const opt = hlo(opt_)  if (opt.sync && typeof cb === 'function')    throw new TypeError('callback not supported for sync tar functions')  if (!opt.file && typeof cb === 'function')    throw new TypeError('callback only supported with file option')  if (files.length)    filesFilter(opt, files)  return opt.file && opt.sync ? extractFileSync(opt)    : opt.file ? extractFile(opt, cb)    : opt.sync ? extractSync(opt)    : extract(opt)}// construct a filter that limits the file entries listed// clude child entries if a dir is cludedconst filesFilter = (opt, files) => {  const map = new Map(files.map(f => [stripSlash(f), true]))  const filter = opt.filter  const mapHas = (file, r) => {    const root = r || path.parse(file).root || '.'    const ret = file === root ? false      : map.has(file) ? map.get(file)      : mapHas(path.dirname(file), root)    map.set(file, ret)    return ret  }  opt.filter = filter    ? (file, entry) => filter(file, entry) && mapHas(stripSlash(file))    : file => mapHas(stripSlash(file))}const extractFileSync = opt => {  const u = new Unpack.Sync(opt)  const file = opt.file  const stat = fs.statSync(file)  // This trades a zero-te read() syscall for a stat  // However, it will usually result  less memory allocation  const readSize = opt.maxReadSize || 16 * 1024 * 1024  const stream = new fsm.ReadStreamSync(file, {    readSize: readSize,    size: stat.size,  })  stream.pipe(u)}const extractFile = (opt, cb) => {  const u = new Unpack(opt)  const readSize = opt.maxReadSize || 16 * 1024 * 1024  const file = opt.file  const p = new Promise((resolve, reject) => {    u.on('error', reject)    u.on('close', resolve)    // This trades a zero-te read() syscall for a stat    // However, it will usually result  less memory allocation    fs.stat(file, (er, stat) => {      if (er)        reject(er)      else {        const stream = new fsm.ReadStream(file, {          readSize: readSize,          size: stat.size,        })        stream.on('error', reject)        stream.pipe(u)      }    })  })  return cb ? p.then(cb, cb) : p}const extractSync = opt => new Unpack.Sync(opt)const extract = opt => new Unpack(opt)/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/get-write-flag.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/get-write-flag.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// Get the appropriate flag to use for creatg files// We use fmap on Wdows platforms for files less than// 512kb.  This is a fairly low limit, but avoids makg// thgs slower  some cases.  Sce most of what // library is used for is extractg tarballs of many// relatively small files  npm packages  the like,// it can be a big boost on Wdows platforms.// Only supported  Node v12.9.0  above.const platform = process.env.__FAKE_PLATFORM__ || process.platformconst isWdows = platform === 'w32'const fs = global.__FAKE_TESTING_FS__ || __webpack_require__(/*! fs */ "fs")/* istanbul ignore next */const { O_CREAT, O_TRUNC, O_WRONLY, UV_FS_O_FILEMAP = 0 } = fs.constantsconst fMapEnabled = isWdows && !!UV_FS_O_FILEMAPconst fMapLimit = 512 * 1024const fMapFlag = UV_FS_O_FILEMAP | O_TRUNC | O_CREAT | O_WRONLYmodule.exports = !fMapEnabled ? () => 'w'  : size => size < fMapLimit ? fMapFlag : 'w'/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// parse a 512-te header block to a data object, or vice-versa// encode returns `true` if a pax extended header is needed, because// the data could not be faithfully encoded  a simple header.// (Also, check header.needPax to see if it needs a pax header.)const types = __webpack_require__(/*! ./types.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/types.js")const pathModule = (__webpack_require__(/*! path */ "path").posix)const large = __webpack_require__(/*! ./large-numbers.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/large-numbers.js")const SLURP = Symbol('slurp')const TYPE = Symbol('type')class Header {  constructor (data, off, ex, gex) {    .cksumValid = false    .needPax = false    .nullBlock = false    .block = null    .path = null    .mode = null    .uid = null    .gid = null    .size = null    .mtime = null    .cksum = null    [TYPE] = '0'    .lkpath = null    .uname = null    .gname = null    .devmaj = 0    .devm = 0    .atime = null    .ctime = null    if (Buffer.isBuffer(data))      .decode(data, off || 0, ex, gex)    else if (data)      .set(data)  }  decode (buf, off, ex, gex) {    if (!off)      off = 0    if (!buf || !(buf.length >= off + 512))      throw new Error('need 512 tes for header')    .path = decStrg(buf, off, 100)    .mode = decNumber(buf, off + 100, 8)    .uid = decNumber(buf, off + 108, 8)    .gid = decNumber(buf, off + 116, 8)    .size = decNumber(buf, off + 124, 12)    .mtime = decDate(buf, off + 136, 12)    .cksum = decNumber(buf, off + 148, 12)    // if we have extended or global extended headers, apply them now    // See https://github.com/npm/node-tar/pull/187    [SLURP](ex)    [SLURP](gex, true)    // old tar versions marked dirs as a file with a trailg /    [TYPE] = decStrg(buf, off + 156, 1)    if ([TYPE] === '')      [TYPE] = '0'    if ([TYPE] === '0' && .path.substr(-1) === '/')      [TYPE] = '5'    // tar implementations sometimes correctly put the stat(dir).size    // as the size  the tarball, even though Directory entries     // not able to have any body at all.  In the very r chance that    // it actually DOES have a body, we weren't gog to do anythg with    // it anyway,  it'll just be a warng about an valid header.    if ([TYPE] === '5')      .size = 0    .lkpath = decStrg(buf, off + 157, 100)    if (buf.slice(off + 257, off + 265).toStrg() === 'ustar\u000000') {      .uname = decStrg(buf, off + 265, 32)      .gname = decStrg(buf, off + 297, 32)      .devmaj = decNumber(buf, off + 329, 8)      .devm = decNumber(buf, off + 337, 8)      if (buf[off + 475] !== 0) {        // defitely a prefix, defitely >130 chars.        const prefix = decStrg(buf, off + 345, 155)        .path = prefix + '/' + .path      } else {        const prefix = decStrg(buf, off + 345, 130)        if (prefix)          .path = prefix + '/' + .path        .atime = decDate(buf, off + 476, 12)        .ctime = decDate(buf, off + 488, 12)      }    }    let sum = 8 * 0x20    for (let i = off; i < off + 148; i++)      sum += buf[i]    for (let i = off + 156; i < off + 512; i++)      sum += buf[i]    .cksumValid = sum === .cksum    if (.cksum === null && sum === 8 * 0x20)      .nullBlock = true  }  [SLURP] (ex, global) {    for (const k  ex) {      // we slurp  everythg except for the path attribute       // a global extended header, because that's weird.      if (ex[k] !== null && ex[k] !== undefed &&          !(global && k === 'path'))        [k] = ex[k]    }  }  encode (buf, off) {    if (!buf) {      buf = .block = Buffer.alloc(512)      off = 0    }    if (!off)      off = 0    if (!(buf.length >= off + 512))      throw new Error('need 512 tes for header')    const prefixSize = .ctime || .atime ? 130 : 155    const split = splitPrefix(.path || '', prefixSize)    const path = split[0]    const prefix = split[1]    .needPax = split[2]    .needPax = encStrg(buf, off, 100, path) || .needPax    .needPax = encNumber(buf, off + 100, 8, .mode) || .needPax    .needPax = encNumber(buf, off + 108, 8, .uid) || .needPax    .needPax = encNumber(buf, off + 116, 8, .gid) || .needPax    .needPax = encNumber(buf, off + 124, 12, .size) || .needPax    .needPax = encDate(buf, off + 136, 12, .mtime) || .needPax    buf[off + 156] = [TYPE].charCodeAt(0)    .needPax = encStrg(buf, off + 157, 100, .lkpath) || .needPax    buf.write('ustar\u000000', off + 257, 8)    .needPax = encStrg(buf, off + 265, 32, .uname) || .needPax    .needPax = encStrg(buf, off + 297, 32, .gname) || .needPax    .needPax = encNumber(buf, off + 329, 8, .devmaj) || .needPax    .needPax = encNumber(buf, off + 337, 8, .devm) || .needPax    .needPax = encStrg(buf, off + 345, prefixSize, prefix) || .needPax    if (buf[off + 475] !== 0)      .needPax = encStrg(buf, off + 345, 155, prefix) || .needPax    else {      .needPax = encStrg(buf, off + 345, 130, prefix) || .needPax      .needPax = encDate(buf, off + 476, 12, .atime) || .needPax      .needPax = encDate(buf, off + 488, 12, .ctime) || .needPax    }    let sum = 8 * 0x20    for (let i = off; i < off + 148; i++)      sum += buf[i]    for (let i = off + 156; i < off + 512; i++)      sum += buf[i]    .cksum = sum    encNumber(buf, off + 148, 8, .cksum)    .cksumValid = true    return .needPax  }  set (data) {    for (const i  data) {      if (data[i] !== null && data[i] !== undefed)        [i] = data[i]    }  }  get type () {    return types.name.get([TYPE]) || [TYPE]  }  get typeKey () {    return [TYPE]  }  set type (type) {    if (types.code.has(type))      [TYPE] = types.code.get(type)    else      [TYPE] = type  }}const splitPrefix = (p, prefixSize) => {  const pathSize = 100  let pp = p  let prefix = ''  let ret  const root = pathModule.parse(p).root || '.'  if (Buffer.teLength(pp) < pathSize)    ret = [pp, prefix, false]  else {    // first set prefix to the dir,  path to the base    prefix = pathModule.dirname(pp)    pp = pathModule.basename(pp)    do {      // both fit!      if (Buffer.teLength(pp) <= pathSize &&          Buffer.teLength(prefix) <= prefixSize)        ret = [pp, prefix, false]      // prefix fits  prefix, but path doesn't fit  path      else if (Buffer.teLength(pp) > pathSize &&          Buffer.teLength(prefix) <= prefixSize)        ret = [pp.substr(0, pathSize - 1), prefix, true]      else {        // make path take a bit from prefix        pp = pathModule.jo(pathModule.basename(prefix), pp)        prefix = pathModule.dirname(prefix)      }    } while (prefix !== root && !ret)    // at  pot, found no resolution, just truncate    if (!ret)      ret = [p.substr(0, pathSize - 1), '', true]  }  return ret}const decStrg = (buf, off, size) =>  buf.slice(off, off + size).toStrg('utf8').replace(/\0.*/, '')const decDate = (buf, off, size) =>  numToDate(decNumber(buf, off, size))const numToDate = num => num === null ? null : new Date(num * 1000)const decNumber = (buf, off, size) =>  buf[off] & 0x80 ? large.parse(buf.slice(off, off + size))  : decSmallNumber(buf, off, size)const nanNull = value => isNaN(value) ? null : valueconst decSmallNumber = (buf, off, size) =>  nanNull(parseInt(    buf.slice(off, off + size)      .toStrg('utf8').replace(/\0.*$/, '').trim(), 8))// the maximum encodable as a null-termated octal,  field sizeconst MAXNUM = {  12: 0o77777777777,  8: 0o7777777,}const encNumber = (buf, off, size, number) =>  number === null ? false :  number > MAXNUM[size] || number < 0    ? (large.encode(number, buf.slice(off, off + size)), true)    : (encSmallNumber(buf, off, size, number), false)const encSmallNumber = (buf, off, size, number) =>  buf.write(octalStrg(number, size), off, size, 'ascii')const octalStrg = (number, size) =>  padOctal(Math.floor(number).toStrg(8), size)const padOctal = (strg, size) =>  (strg.length === size - 1 ? strg  : new Array(size - strg.length - 1).jo('0') + strg + ' ') + '\0'const encDate = (buf, off, size, date) =>  date === null ? false :  encNumber(buf, off, size, date.getTime() / 1000)// enough to fill the longest strg we've gotconst NULLS = new Array(156).jo('\0')// pad with nulls, return true if it's longer or non-asciiconst encStrg = (buf, off, size, strg) =>  strg === null ? false :  (buf.write(strg + NULLS, off, size, 'utf8'),  strg.length !== Buffer.teLength(strg) || strg.length > size)module.exports = Header/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js ***!  \*********************************************************************************************************//***/ ((module) => {"use strict";// turn tar(1) style args like `C` to the more verbose thgs like `cwd`const argmap = new Map([  ['C', 'cwd'],  ['f', 'file'],  ['z', 'gzip'],  ['P', 'preservePaths'],  ['U', 'unlk'],  ['strip-components', 'strip'],  ['stripComponents', 'strip'],  ['keep-newer', 'newer'],  ['keepNewer', 'newer'],  ['keep-newer-files', 'newer'],  ['keepNewerFiles', 'newer'],  ['k', 'keep'],  ['keep-existg', 'keep'],  ['keepExistg', 'keep'],  ['m', 'noMtime'],  ['no-mtime', 'noMtime'],  ['p', 'preserveOwner'],  ['L', 'follow'],  ['h', 'follow'],])module.exports = opt => opt ? Object.keys(opt).map(k => [  argmap.has(k) ? argmap.get(k) : k, opt[k],]).reduce((set, kv) => (set[kv[0]] = kv[1], set), Object.create(null)) : {}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/large-numbers.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/large-numbers.js ***!  \********************************************************************************************************//***/ ((module) => {"use strict";// Tar can encode large  negative numbers usg a leadg te of// 0xff for negative,  0x80 for positive.const encode = (num, buf) => {  if (!Number.isSafeInteger(num))    //  number is so large that javascript cannot represent it with teger    // precision.    throw Error('cannot encode number outside of javascript safe teger range')  else if (num < 0)    encodeNegative(num, buf)  else    encodePositive(num, buf)  return buf}const encodePositive = (num, buf) => {  buf[0] = 0x80  for (var i = buf.length; i > 1; i--) {    buf[i - 1] = num & 0xff    num = Math.floor(num / 0x100)  }}const encodeNegative = (num, buf) => {  buf[0] = 0xff  var flipped = false  num = num * -1  for (var i = buf.length; i > 1; i--) {    var te = num & 0xff    num = Math.floor(num / 0x100)    if (flipped)      buf[i - 1] = onesComp(te)    else if (te === 0)      buf[i - 1] = 0    else {      flipped = true      buf[i - 1] = twosComp(te)    }  }}const parse = (buf) => {  const pre = buf[0]  const value = pre === 0x80 ? pos(buf.slice(1, buf.length))    : pre === 0xff ? twos(buf)    : null  if (value === null)    throw Error('valid base256 encodg')  if (!Number.isSafeInteger(value))    //  number is so large that javascript cannot represent it with teger    // precision.    throw Error('parsed number outside of javascript safe teger range')  return value}const twos = (buf) => {  var len = buf.length  var sum = 0  var flipped = false  for (var i = len - 1; i > -1; i--) {    var te = buf[i]    var f    if (flipped)      f = onesComp(te)    else if (te === 0)      f = te    else {      flipped = true      f = twosComp(te)    }    if (f !== 0)      sum -= f * Math.pow(256, len - i - 1)  }  return sum}const pos = (buf) => {  var len = buf.length  var sum = 0  for (var i = len - 1; i > -1; i--) {    var te = buf[i]    if (te !== 0)      sum += te * Math.pow(256, len - i - 1)  }  return sum}const onesComp = te => (0xff ^ te) & 0xffconst twosComp = te => ((0xff ^ te) + 1) & 0xffmodule.exports = {  encode,  parse,}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/list.js":/*!***********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/list.js ***!  \***********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// XXX: This shs a lot  common with extract.js// maybe some DRY opportunity here?// tar -tconst hlo = __webpack_require__(/*! ./high-level-opt.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js")const Parser = __webpack_require__(/*! ./parse.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/parse.js")const fs = __webpack_require__(/*! fs */ "fs")const fsm = __webpack_require__(/*! fs-mipass */ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js")const path = __webpack_require__(/*! path */ "path")const stripSlash = __webpack_require__(/*! ./strip-trailg-slashes.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js")module.exports = (opt_, files, cb) => {  if (typeof opt_ === 'function')    cb = opt_, files = null, opt_ = {}  else if (Array.isArray(opt_))    files = opt_, opt_ = {}  if (typeof files === 'function')    cb = files, files = null  if (!files)    files = []  else    files = Array.from(files)  const opt = hlo(opt_)  if (opt.sync && typeof cb === 'function')    throw new TypeError('callback not supported for sync tar functions')  if (!opt.file && typeof cb === 'function')    throw new TypeError('callback only supported with file option')  if (files.length)    filesFilter(opt, files)  if (!opt.noResume)    onentryFunction(opt)  return opt.file && opt.sync ? listFileSync(opt)    : opt.file ? listFile(opt, cb)    : list(opt)}const onentryFunction = opt => {  const onentry = opt.onentry  opt.onentry = onentry ? e => {    onentry(e)    e.resume()  } : e => e.resume()}// construct a filter that limits the file entries listed// clude child entries if a dir is cludedconst filesFilter = (opt, files) => {  const map = new Map(files.map(f => [stripSlash(f), true]))  const filter = opt.filter  const mapHas = (file, r) => {    const root = r || path.parse(file).root || '.'    const ret = file === root ? false      : map.has(file) ? map.get(file)      : mapHas(path.dirname(file), root)    map.set(file, ret)    return ret  }  opt.filter = filter    ? (file, entry) => filter(file, entry) && mapHas(stripSlash(file))    : file => mapHas(stripSlash(file))}const listFileSync = opt => {  const p = list(opt)  const file = opt.file  let threw = true  let fd  try {    const stat = fs.statSync(file)    const readSize = opt.maxReadSize || 16 * 1024 * 1024    if (stat.size < readSize)      p.end(fs.readFileSync(file))    else {      let pos = 0      const buf = Buffer.allocUnsafe(readSize)      fd = fs.openSync(file, 'r')      while (pos < stat.size) {        const tesRead = fs.readSync(fd, buf, 0, readSize, pos)        pos += tesRead        p.write(buf.slice(0, tesRead))      }      p.end()    }    threw = false  } fally {    if (threw && fd) {      try {        fs.closeSync(fd)      } catch (er) {}    }  }}const listFile = (opt, cb) => {  const parse = new Parser(opt)  const readSize = opt.maxReadSize || 16 * 1024 * 1024  const file = opt.file  const p = new Promise((resolve, reject) => {    parse.on('error', reject)    parse.on('end', resolve)    fs.stat(file, (er, stat) => {      if (er)        reject(er)      else {        const stream = new fsm.ReadStream(file, {          readSize: readSize,          size: stat.size,        })        stream.on('error', reject)        stream.pipe(parse)      }    })  })  return cb ? p.then(cb, cb) : p}const list = opt => new Parser(opt)/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mkdir.js":/*!************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mkdir.js ***!  \************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// wrapper around mkdirp for tar's needs.// TODO: This should probably be a class, not functionally// passg around state  a gazillion args.const mkdirp = __webpack_require__(/*! mkdirp */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/dex.js")const fs = __webpack_require__(/*! fs */ "fs")const path = __webpack_require__(/*! path */ "path")const chownr = __webpack_require__(/*! chownr */ "../../../.yarn/berry/cache/chownr-npm-2.0.0-638f1c9c61-9.zip/node_modules/chownr/chownr.js")const normPath = __webpack_require__(/*! ./normalize-wdows-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js")class SymlkError extends Error {  constructor (symlk, path) {    super('Cannot extract through symbolic lk')    .path = path    .symlk = symlk  }  get name () {    return 'SylkError'  }}class CwdError extends Error {  constructor (path, code) {    super(code + ': Cannot cd to \'' + path + '\'')    .path = path    .code = code  }  get name () {    return 'CwdError'  }}const cGet = (cache, key) => cache.get(normPath(key))const cSet = (cache, key, val) => cache.set(normPath(key), val)const checkCwd = (dir, cb) => {  fs.stat(dir, (er, st) => {    if (er || !st.isDirectory())      er = new CwdError(dir, er && er.code || 'ENOTDIR')    cb(er)  })}module.exports = (dir, opt, cb) => {  dir = normPath(dir)  // if there's any overlap between mask  mode,  // then we'll need an explicit chmod  const umask = opt.umask  const mode = opt.mode | 0o0700  const needChmod = (mode & umask) !== 0  const uid = opt.uid  const gid = opt.gid  const doChown = typeof uid === 'number' &&    typeof gid === 'number' &&    (uid !== opt.processUid || gid !== opt.processGid)  const preserve = opt.preserve  const unlk = opt.unlk  const cache = opt.cache  const cwd = normPath(opt.cwd)  const done = (er, created) => {    if (er)      cb(er)    else {      cSet(cache, dir, true)      if (created && doChown)        chownr(created, uid, gid, er => done(er))      else if (needChmod)        fs.chmod(dir, mode, cb)      else        cb()    }  }  if (cache && cGet(cache, dir) === true)    return done()  if (dir === cwd)    return checkCwd(dir, done)  if (preserve)    return mkdirp(dir, {mode}).then(made => done(null, made), done)  const sub = normPath(path.relative(cwd, dir))  const parts = sub.split('/')  mkdir_(cwd, parts, mode, cache, unlk, cwd, null, done)}const mkdir_ = (base, parts, mode, cache, unlk, cwd, created, cb) => {  if (!parts.length)    return cb(null, created)  const p = parts.shift()  const part = normPath(path.resolve(base + '/' + p))  if (cGet(cache, part))    return mkdir_(part, parts, mode, cache, unlk, cwd, created, cb)  fs.mkdir(part, mode, onmkdir(part, parts, mode, cache, unlk, cwd, created, cb))}const onmkdir = (part, parts, mode, cache, unlk, cwd, created, cb) => er => {  if (er) {    fs.lstat(part, (statEr, st) => {      if (statEr) {        statEr.path = statEr.path && normPath(statEr.path)        cb(statEr)      } else if (st.isDirectory())        mkdir_(part, parts, mode, cache, unlk, cwd, created, cb)      else if (unlk) {        fs.unlk(part, er => {          if (er)            return cb(er)          fs.mkdir(part, mode, onmkdir(part, parts, mode, cache, unlk, cwd, created, cb))        })      } else if (st.isSymbolicLk())        return cb(new SymlkError(part, part + '/' + parts.jo('/')))      else        cb(er)    })  } else {    created = created || part    mkdir_(part, parts, mode, cache, unlk, cwd, created, cb)  }}const checkCwdSync = dir => {  let ok = false  let code = 'ENOTDIR'  try {    ok = fs.statSync(dir).isDirectory()  } catch (er) {    code = er.code  } fally {    if (!ok)      throw new CwdError(dir, code)  }}module.exports.sync = (dir, opt) => {  dir = normPath(dir)  // if there's any overlap between mask  mode,  // then we'll need an explicit chmod  const umask = opt.umask  const mode = opt.mode | 0o0700  const needChmod = (mode & umask) !== 0  const uid = opt.uid  const gid = opt.gid  const doChown = typeof uid === 'number' &&    typeof gid === 'number' &&    (uid !== opt.processUid || gid !== opt.processGid)  const preserve = opt.preserve  const unlk = opt.unlk  const cache = opt.cache  const cwd = normPath(opt.cwd)  const done = (created) => {    cSet(cache, dir, true)    if (created && doChown)      chownr.sync(created, uid, gid)    if (needChmod)      fs.chmodSync(dir, mode)  }  if (cache && cGet(cache, dir) === true)    return done()  if (dir === cwd) {    checkCwdSync(cwd)    return done()  }  if (preserve)    return done(mkdirp.sync(dir, mode))  const sub = normPath(path.relative(cwd, dir))  const parts = sub.split('/')  let created = null  for (let p = parts.shift(), part = cwd;    p && (part += '/' + p);    p = parts.shift()) {    part = normPath(path.resolve(part))    if (cGet(cache, part))      contue    try {      fs.mkdirSync(part, mode)      created = created || part      cSet(cache, part, true)    } catch (er) {      const st = fs.lstatSync(part)      if (st.isDirectory()) {        cSet(cache, part, true)        contue      } else if (unlk) {        fs.unlkSync(part)        fs.mkdirSync(part, mode)        created = created || part        cSet(cache, part, true)        contue      } else if (st.isSymbolicLk())        return new SymlkError(part, part + '/' + parts.jo('/'))    }  }  return done(created)}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mode-fix.js":/*!***************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mode-fix.js ***!  \***************************************************************************************************//***/ ((module) => {"use strict";module.exports = (mode, isDir, portable) => {  mode &= 0o7777  //  portable mode, use the mimum reasonable umask  // if  system creates files with 0o664  default  // (as some lux distros do), then we'll write the  // archive with 0o644 stead.  Also, don't ever create  // a file that is not readable/writable  the owner.  if (portable)    mode = (mode | 0o600) & ~0o22  // if dirs  readable, then they should be listable  if (isDir) {    if (mode & 0o400)      mode |= 0o100    if (mode & 0o40)      mode |= 0o10    if (mode & 0o4)      mode |= 0o1  }  return mode}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-unicode.js":/*!************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-unicode.js ***!  \************************************************************************************************************//***/ ((module) => {// warng: extremely hot code path.// This has been meticulously optimized for use// with npm stall on large package trees.// Do not edit without cful benchmarkg.const normalizeCache = Object.create(null)const {hasOwnProperty} = Object.prototypemodule.exports = s => {  if (!hasOwnProperty.call(normalizeCache, s))    normalizeCache[s] = s.normalize('NFKD')  return normalizeCache[s]}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js ***!  \*****************************************************************************************************************//***/ ((module) => {// on wdows, either \ or /  valid directory separators.// on unix, \ is a valid character  filenames.// so, on wdows,  only on wdows, we replace all \ chars with /,// so that we can use / as our one  only directory separator char.const platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platformmodule.exports = platform !== 'w32' ? p => p  : p => p && p.replace(/\\/g, '/')/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pack.js":/*!***********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pack.js ***!  \***********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// A readable tar stream creator// Technically,  is a transform stream that you write paths to,//  tar format comes out of.//  `add()` method is like `write()` but returns ,//  end() return `` as well, so you can// do `new Pack(opt).add('files').add('dir').end().pipe(output)// You could also do somethg like:// streamOfPaths().pipe(new Pack()).pipe(new fs.WriteStream('out.tar'))class PackJob {  constructor (path, absolute) {    .path = path || './'    .absolute = absolute    .entry = null    .stat = null    .readdir = null    .pendg = false    .ignore = false    .piped = false  }}const MiPass = __webpack_require__(/*! mipass */ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js")const zlib = __webpack_require__(/*! mizlib */ "../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/dex.js")const ReadEntry = __webpack_require__(/*! ./read-entry.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/read-entry.js")const WriteEntry = __webpack_require__(/*! ./write-entry.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/write-entry.js")const WriteEntrySync = WriteEntry.Syncconst WriteEntryTar = WriteEntry.Tarconst Yallist = __webpack_require__(/*! yallist */ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js")const EOF = Buffer.alloc(1024)const ONSTAT = Symbol('onStat')const ENDED = Symbol('ended')const QUEUE = Symbol('queue')const CURRENT = Symbol('current')const PROCESS = Symbol('process')const PROCESSING = Symbol('processg')const PROCESSJOB = Symbol('processJob')const JOBS = Symbol('jobs')const JOBDONE = Symbol('jobDone')const ADDFSENTRY = Symbol('addFSEntry')const ADDTARENTRY = Symbol('addTarEntry')const STAT = Symbol('stat')const READDIR = Symbol('readdir')const ONREADDIR = Symbol('onreaddir')const PIPE = Symbol('pipe')const ENTRY = Symbol('entry')const ENTRYOPT = Symbol('entryOpt')const WRITEENTRYCLASS = Symbol('writeEntryClass')const WRITE = Symbol('write')const ONDRAIN = Symbol('ondra')const fs = __webpack_require__(/*! fs */ "fs")const path = __webpack_require__(/*! path */ "path")const warner = __webpack_require__(/*! ./warn-mix.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/warn-mix.js")const normPath = __webpack_require__(/*! ./normalize-wdows-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js")const Pack = warner(class Pack extends MiPass {  constructor (opt) {    super(opt)    opt = opt || Object.create(null)    .opt = opt    .file = opt.file || ''    .cwd = opt.cwd || process.cwd()    .maxReadSize = opt.maxReadSize    .preservePaths = !!opt.preservePaths    .strict = !!opt.strict    .noPax = !!opt.noPax    .prefix = normPath(opt.prefix || '')    .lkCache = opt.lkCache || new Map()    .statCache = opt.statCache || new Map()    .readdirCache = opt.readdirCache || new Map()    [WRITEENTRYCLASS] = WriteEntry    if (typeof opt.onwarn === 'function')      .on('warn', opt.onwarn)    .portable = !!opt.portable    .zip = null    if (opt.gzip) {      if (typeof opt.gzip !== 'object')        opt.gzip = {}      if (.portable)        opt.gzip.portable = true      .zip = new zlib.Gzip(opt.gzip)      .zip.on('data', chunk => super.write(chunk))      .zip.on('end', _ => super.end())      .zip.on('dra', _ => [ONDRAIN]())      .on('resume', _ => .zip.resume())    } else      .on('dra', [ONDRAIN])    .noDirRecurse = !!opt.noDirRecurse    .follow = !!opt.follow    .noMtime = !!opt.noMtime    .mtime = opt.mtime || null    .filter = typeof opt.filter === 'function' ? opt.filter : _ => true    [QUEUE] = new Yallist()    [JOBS] = 0    .jobs = +opt.jobs || 4    [PROCESSING] = false    [ENDED] = false  }  [WRITE] (chunk) {    return super.write(chunk)  }  add (path) {    .write(path)    return   }  end (path) {    if (path)      .write(path)    [ENDED] = true    [PROCESS]()    return   }  write (path) {    if ([ENDED])      throw new Error('write after end')    if (path stanceof ReadEntry)      [ADDTARENTRY](path)    else      [ADDFSENTRY](path)    return .flowg  }  [ADDTARENTRY] (p) {    const absolute = normPath(path.resolve(.cwd, p.path))    //   case, we don't have to wait for the stat    if (!.filter(p.path, p))      p.resume()    else {      const job = new PackJob(p.path, absolute, false)      job.entry = new WriteEntryTar(p, [ENTRYOPT](job))      job.entry.on('end', _ => [JOBDONE](job))      [JOBS] += 1      [QUEUE].push(job)    }    [PROCESS]()  }  [ADDFSENTRY] (p) {    const absolute = normPath(path.resolve(.cwd, p))    [QUEUE].push(new PackJob(p, absolute))    [PROCESS]()  }  [STAT] (job) {    job.pendg = true    [JOBS] += 1    const stat = .follow ? 'stat' : 'lstat'    fs[stat](job.absolute, (er, stat) => {      job.pendg = false      [JOBS] -= 1      if (er)        .emit('error', er)      else        [ONSTAT](job, stat)    })  }  [ONSTAT] (job, stat) {    .statCache.set(job.absolute, stat)    job.stat = stat    // now we have the stat, we can filter it.    if (!.filter(job.path, stat))      job.ignore = true    [PROCESS]()  }  [READDIR] (job) {    job.pendg = true    [JOBS] += 1    fs.readdir(job.absolute, (er, entries) => {      job.pendg = false      [JOBS] -= 1      if (er)        return .emit('error', er)      [ONREADDIR](job, entries)    })  }  [ONREADDIR] (job, entries) {    .readdirCache.set(job.absolute, entries)    job.readdir = entries    [PROCESS]()  }  [PROCESS] () {    if ([PROCESSING])      return    [PROCESSING] = true    for (let w = [QUEUE].head;      w !== null && [JOBS] < .jobs;      w = w.next) {      [PROCESSJOB](w.value)      if (w.value.ignore) {        const p = w.next        [QUEUE].removeNode(w)        w.next = p      }    }    [PROCESSING] = false    if ([ENDED] && ![QUEUE].length && [JOBS] === 0) {      if (.zip)        .zip.end(EOF)      else {        super.write(EOF)        super.end()      }    }  }  get [CURRENT] () {    return [QUEUE] && [QUEUE].head && [QUEUE].head.value  }  [JOBDONE] (job) {    [QUEUE].shift()    [JOBS] -= 1    [PROCESS]()  }  [PROCESSJOB] (job) {    if (job.pendg)      return    if (job.entry) {      if (job === [CURRENT] && !job.piped)        [PIPE](job)      return    }    if (!job.stat) {      if (.statCache.has(job.absolute))        [ONSTAT](job, .statCache.get(job.absolute))      else        [STAT](job)    }    if (!job.stat)      return    // filtered out!    if (job.ignore)      return    if (!.noDirRecurse && job.stat.isDirectory() && !job.readdir) {      if (.readdirCache.has(job.absolute))        [ONREADDIR](job, .readdirCache.get(job.absolute))      else        [READDIR](job)      if (!job.readdir)        return    }    // we know it doesn't have an entry, because that got checked above    job.entry = [ENTRY](job)    if (!job.entry) {      job.ignore = true      return    }    if (job === [CURRENT] && !job.piped)      [PIPE](job)  }  [ENTRYOPT] (job) {    return {      onwarn: (code, msg, data) => .warn(code, msg, data),      noPax: .noPax,      cwd: .cwd,      absolute: job.absolute,      preservePaths: .preservePaths,      maxReadSize: .maxReadSize,      strict: .strict,      portable: .portable,      lkCache: .lkCache,      statCache: .statCache,      noMtime: .noMtime,      mtime: .mtime,      prefix: .prefix,    }  }  [ENTRY] (job) {    [JOBS] += 1    try {      return new [WRITEENTRYCLASS](job.path, [ENTRYOPT](job))        .on('end', () => [JOBDONE](job))        .on('error', er => .emit('error', er))    } catch (er) {      .emit('error', er)    }  }  [ONDRAIN] () {    if ([CURRENT] && [CURRENT].entry)      [CURRENT].entry.resume()  }  // like .pipe() but usg super, because our write() is special  [PIPE] (job) {    job.piped = true    if (job.readdir) {      job.readdir.forEach(entry => {        const p = job.path        const base = p === './' ? '' : p.replace(/\/*$/, '/')        [ADDFSENTRY](base + entry)      })    }    const source = job.entry    const zip = .zip    if (zip) {      source.on('data', chunk => {        if (!zip.write(chunk))          source.pause()      })    } else {      source.on('data', chunk => {        if (!super.write(chunk))          source.pause()      })    }  }  pause () {    if (.zip)      .zip.pause()    return super.pause()  }})class PackSync extends Pack {  constructor (opt) {    super(opt)    [WRITEENTRYCLASS] = WriteEntrySync  }  // pause/resume  no-ops  sync streams.  pause () {}  resume () {}  [STAT] (job) {    const stat = .follow ? 'statSync' : 'lstatSync'    [ONSTAT](job, fs[stat](job.absolute))  }  [READDIR] (job, stat) {    [ONREADDIR](job, fs.readdirSync(job.absolute))  }  // gotta get it all   tick  [PIPE] (job) {    const source = job.entry    const zip = .zip    if (job.readdir) {      job.readdir.forEach(entry => {        const p = job.path        const base = p === './' ? '' : p.replace(/\/*$/, '/')        [ADDFSENTRY](base + entry)      })    }    if (zip) {      source.on('data', chunk => {        zip.write(chunk)      })    } else {      source.on('data', chunk => {        super[WRITE](chunk)      })    }  }}Pack.Sync = PackSyncmodule.exports = Pack/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/parse.js":/*!************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/parse.js ***!  \************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// [BUFFER] is the remader of a chunk if we're waitg for// the full 512 tes of a header to come .  We will Buffer.concat()// it to the next write(), which is a mem copy, but a small one.//// [QUEUE] is a Yallist of entries that haven't been emitted// yet  can only get filled up if the user keeps write()g after// a write() returns false, or does a write() with more than one entry//// We don't buffer chunks, we always parse them  either create an// entry, or push it to the active entry.   ReadEntry class knows// to throw data away if .ignore=true//// Shift entry off the buffer when it emits 'end',  emit 'entry' for// the next one  the list.//// At any time, we're pushg body chunks to the entry at WRITEENTRY,//  waitg for 'end' on the entry at READENTRY//// ignored entries get .resume() called on them straight awayconst warner = __webpack_require__(/*! ./warn-mix.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/warn-mix.js")const Header = __webpack_require__(/*! ./header.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js")const EE = __webpack_require__(/*! events */ "events")const Yallist = __webpack_require__(/*! yallist */ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js")const maxMetaEntrySize = 1024 * 1024const Entry = __webpack_require__(/*! ./read-entry.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/read-entry.js")const Pax = __webpack_require__(/*! ./pax.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pax.js")const zlib = __webpack_require__(/*! mizlib */ "../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/dex.js")const gzipHeader = Buffer.from([0x1f, 0x8b])const STATE = Symbol('state')const WRITEENTRY = Symbol('writeEntry')const READENTRY = Symbol('readEntry')const NEXTENTRY = Symbol('nextEntry')const PROCESSENTRY = Symbol('processEntry')const EX = Symbol('extendedHeader')const GEX = Symbol('globalExtendedHeader')const META = Symbol('meta')const EMITMETA = Symbol('emitMeta')const BUFFER = Symbol('buffer')const QUEUE = Symbol('queue')const ENDED = Symbol('ended')const EMITTEDEND = Symbol('emittedEnd')const EMIT = Symbol('emit')const UNZIP = Symbol('unzip')const CONSUMECHUNK = Symbol('consumeChunk')const CONSUMECHUNKSUB = Symbol('consumeChunkSub')const CONSUMEBODY = Symbol('consumeBody')const CONSUMEMETA = Symbol('consumeMeta')const CONSUMEHEADER = Symbol('consumeHeader')const CONSUMING = Symbol('consumg')const BUFFERCONCAT = Symbol('bufferConcat')const MAYBEEND = Symbol('maybeEnd')const WRITING = Symbol('writg')const ABORTED = Symbol('aborted')const DONE = Symbol('onDone')const SAW_VALID_ENTRY = Symbol('sawValidEntry')const SAW_NULL_BLOCK = Symbol('sawNullBlock')const SAW_EOF = Symbol('sawEOF')const noop = _ => truemodule.exports = warner(class Parser extends EE {  constructor (opt) {    opt = opt || {}    super(opt)    .file = opt.file || ''    // set to boolean false when an entry starts.  1024 tes of \0    // is technically a valid tarball, albeit a borg one.    [SAW_VALID_ENTRY] = null    // these BADARCHIVE errors can't be detected early. listen on DONE.    .on(DONE, _ => {      if ([STATE] === 'beg' || [SAW_VALID_ENTRY] === false) {        // either less than 1 block of data, or all entries were valid.        // Either way, probably not even a tarball.        .warn('TAR_BAD_ARCHIVE', 'Unrecognized archive format')      }    })    if (opt.ondone)      .on(DONE, opt.ondone)    else {      .on(DONE, _ => {        .emit('prefish')        .emit('fish')        .emit('end')        .emit('close')      })    }    .strict = !!opt.strict    .maxMetaEntrySize = opt.maxMetaEntrySize || maxMetaEntrySize    .filter = typeof opt.filter === 'function' ? opt.filter : noop    // have to set  so that streams  ok pipg to it    .writable = true    .readable = false    [QUEUE] = new Yallist()    [BUFFER] = null    [READENTRY] = null    [WRITEENTRY] = null    [STATE] = 'beg'    [META] = ''    [EX] = null    [GEX] = null    [ENDED] = false    [UNZIP] = null    [ABORTED] = false    [SAW_NULL_BLOCK] = false    [SAW_EOF] = false    if (typeof opt.onwarn === 'function')      .on('warn', opt.onwarn)    if (typeof opt.onentry === 'function')      .on('entry', opt.onentry)  }  [CONSUMEHEADER] (chunk, position) {    if ([SAW_VALID_ENTRY] === null)      [SAW_VALID_ENTRY] = false    let header    try {      header = new Header(chunk, position, [EX], [GEX])    } catch (er) {      return .warn('TAR_ENTRY_INVALID', er)    }    if (header.nullBlock) {      if ([SAW_NULL_BLOCK]) {        [SAW_EOF] = true        // endg an archive with no entries.  potless, but legal.        if ([STATE] === 'beg')          [STATE] = 'header'        [EMIT]('eof')      } else {        [SAW_NULL_BLOCK] = true        [EMIT]('nullBlock')      }    } else {      [SAW_NULL_BLOCK] = false      if (!header.cksumValid)        .warn('TAR_ENTRY_INVALID', 'checksum failure', {header})      else if (!header.path)        .warn('TAR_ENTRY_INVALID', 'path is required', {header})      else {        const type = header.type        if (/^(Symbolic)?Lk$/.test(type) && !header.lkpath)          .warn('TAR_ENTRY_INVALID', 'lkpath required', {header})        else if (!/^(Symbolic)?Lk$/.test(type) && header.lkpath)          .warn('TAR_ENTRY_INVALID', 'lkpath forbidden', {header})        else {          const entry = [WRITEENTRY] = new Entry(header, [EX], [GEX])          // we do  for meta & ignored entries as well, because they          //  still valid tar, or else we wouldn't know to ignore them          if (![SAW_VALID_ENTRY]) {            if (entry.rema) {              //  might be the one!              const onend = () => {                if (!entry.valid)                  [SAW_VALID_ENTRY] = true              }              entry.on('end', onend)            } else              [SAW_VALID_ENTRY] = true          }          if (entry.meta) {            if (entry.size > .maxMetaEntrySize) {              entry.ignore = true              [EMIT]('ignoredEntry', entry)              [STATE] = 'ignore'              entry.resume()            } else if (entry.size > 0) {              [META] = ''              entry.on('data', c => [META] += c)              [STATE] = 'meta'            }          } else {            [EX] = null            entry.ignore = entry.ignore || !.filter(entry.path, entry)            if (entry.ignore) {              // probably valid, just not somethg we c about              [EMIT]('ignoredEntry', entry)              [STATE] = entry.rema ? 'ignore' : 'header'              entry.resume()            } else {              if (entry.rema)                [STATE] = 'body'              else {                [STATE] = 'header'                entry.end()              }              if (![READENTRY]) {                [QUEUE].push(entry)                [NEXTENTRY]()              } else                [QUEUE].push(entry)            }          }        }      }    }  }  [PROCESSENTRY] (entry) {    let go = true    if (!entry) {      [READENTRY] = null      go = false    } else if (Array.isArray(entry))      .emit.apply(, entry)    else {      [READENTRY] = entry      .emit('entry', entry)      if (!entry.emittedEnd) {        entry.on('end', _ => [NEXTENTRY]())        go = false      }    }    return go  }  [NEXTENTRY] () {    do {} while ([PROCESSENTRY]([QUEUE].shift()))    if (![QUEUE].length) {      // At  pot, there's nothg  the queue, but we may have an      // entry which is beg consumed (readEntry).      // If we don't, then we defitely can hle more data.      // If we do,  either it's flowg, or it has never had any data      //  to it, then it needs more.      //  only other possibility is that it has returned false from a      // write() call, so we wait for the next dra to contue.      const re = [READENTRY]      const draNow = !re || re.flowg || re.size === re.rema      if (draNow) {        if (![WRITING])          .emit('dra')      } else        re.once('dra', _ => .emit('dra'))    }  }  [CONSUMEBODY] (chunk, position) {    // write up to but no  more than writeEntry.blockRema    const entry = [WRITEENTRY]    const br = entry.blockRema    const c = (br >= chunk.length && position === 0) ? chunk      : chunk.slice(position, position + br)    entry.write(c)    if (!entry.blockRema) {      [STATE] = 'header'      [WRITEENTRY] = null      entry.end()    }    return c.length  }  [CONSUMEMETA] (chunk, position) {    const entry = [WRITEENTRY]    const ret = [CONSUMEBODY](chunk, position)    // if we fished, then the entry is reset    if (![WRITEENTRY])      [EMITMETA](entry)    return ret  }  [EMIT] (ev, data, extra) {    if (![QUEUE].length && ![READENTRY])      .emit(ev, data, extra)    else      [QUEUE].push([ev, data, extra])  }  [EMITMETA] (entry) {    [EMIT]('meta', [META])    switch (entry.type) {      case 'ExtendedHeader':      case 'OldExtendedHeader':        [EX] = Pax.parse([META], [EX], false)        break      case 'GlobalExtendedHeader':        [GEX] = Pax.parse([META], [GEX], true)        break      case 'NextFileHasLongPath':      case 'OldGnuLongPath':        [EX] = [EX] || Object.create(null)        [EX].path = [META].replace(/\0.*/, '')        break      case 'NextFileHasLongLkpath':        [EX] = [EX] || Object.create(null)        [EX].lkpath = [META].replace(/\0.*/, '')        break      /* istanbul ignore next */      default: throw new Error('unknown meta: ' + entry.type)    }  }  abort (error) {    [ABORTED] = true    .emit('abort', error)    // always throws, even  non-strict mode    .warn('TAR_ABORT', error, { recoverable: false })  }  write (chunk) {    if ([ABORTED])      return    // first write, might be gzipped    if ([UNZIP] === null && chunk) {      if ([BUFFER]) {        chunk = Buffer.concat([[BUFFER], chunk])        [BUFFER] = null      }      if (chunk.length < gzipHeader.length) {        [BUFFER] = chunk        return true      }      for (let i = 0; [UNZIP] === null && i < gzipHeader.length; i++) {        if (chunk[i] !== gzipHeader[i])          [UNZIP] = false      }      if ([UNZIP] === null) {        const ended = [ENDED]        [ENDED] = false        [UNZIP] = new zlib.Unzip()        [UNZIP].on('data', chunk => [CONSUMECHUNK](chunk))        [UNZIP].on('error', er => .abort(er))        [UNZIP].on('end', _ => {          [ENDED] = true          [CONSUMECHUNK]()        })        [WRITING] = true        const ret = [UNZIP][ended ? 'end' : 'write'](chunk)        [WRITING] = false        return ret      }    }    [WRITING] = true    if ([UNZIP])      [UNZIP].write(chunk)    else      [CONSUMECHUNK](chunk)    [WRITING] = false    // return false if there's a queue, or if the current entry isn't flowg    const ret =      [QUEUE].length ? false :      [READENTRY] ? [READENTRY].flowg :      true    // if we have no queue, then that means a clogged READENTRY    if (!ret && ![QUEUE].length)      [READENTRY].once('dra', _ => .emit('dra'))    return ret  }  [BUFFERCONCAT] (c) {    if (c && ![ABORTED])      [BUFFER] = [BUFFER] ? Buffer.concat([[BUFFER], c]) : c  }  [MAYBEEND] () {    if ([ENDED] &&        ![EMITTEDEND] &&        ![ABORTED] &&        ![CONSUMING]) {      [EMITTEDEND] = true      const entry = [WRITEENTRY]      if (entry && entry.blockRema) {        // truncated, likely a damaged file        const have = [BUFFER] ? [BUFFER].length : 0        .warn('TAR_BAD_ARCHIVE', `Truncated put (needed ${          entry.blockRema} more tes, only ${have} available)`, {entry})        if ([BUFFER])          entry.write([BUFFER])        entry.end()      }      [EMIT](DONE)    }  }  [CONSUMECHUNK] (chunk) {    if ([CONSUMING])      [BUFFERCONCAT](chunk)    else if (!chunk && ![BUFFER])      [MAYBEEND]()    else {      [CONSUMING] = true      if ([BUFFER]) {        [BUFFERCONCAT](chunk)        const c = [BUFFER]        [BUFFER] = null        [CONSUMECHUNKSUB](c)      } else        [CONSUMECHUNKSUB](chunk)      while ([BUFFER] &&          [BUFFER].length >= 512 &&          ![ABORTED] &&          ![SAW_EOF]) {        const c = [BUFFER]        [BUFFER] = null        [CONSUMECHUNKSUB](c)      }      [CONSUMING] = false    }    if (![BUFFER] || [ENDED])      [MAYBEEND]()  }  [CONSUMECHUNKSUB] (chunk) {    // we know that we   CONSUMING mode, so anythg  goes to    // the buffer.  Advance the position  put any remader  the buffer.    let position = 0    const length = chunk.length    while (position + 512 <= length && ![ABORTED] && ![SAW_EOF]) {      switch ([STATE]) {        case 'beg':        case 'header':          [CONSUMEHEADER](chunk, position)          position += 512          break        case 'ignore':        case 'body':          position += [CONSUMEBODY](chunk, position)          break        case 'meta':          position += [CONSUMEMETA](chunk, position)          break        /* istanbul ignore next */        default:          throw new Error('valid state: ' + [STATE])      }    }    if (position < length) {      if ([BUFFER])        [BUFFER] = Buffer.concat([chunk.slice(position), [BUFFER]])      else        [BUFFER] = chunk.slice(position)    }  }  end (chunk) {    if (![ABORTED]) {      if ([UNZIP])        [UNZIP].end(chunk)      else {        [ENDED] = true        .write(chunk)      }    }  }})/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/path-reservations.js":/*!************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/path-reservations.js ***!  \************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// A path exclusive reservation system// reserve([list, of, paths], fn)// When the fn is first  le for all its paths, it// is called with a cb that clears the reservation.//// Used  async unpack to avoid clobberg paths  use,// while still allowg maximal safe parallelization.const assert = __webpack_require__(/*! assert */ "assert")const normalize = __webpack_require__(/*! ./normalize-unicode.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-unicode.js")const stripSlashes = __webpack_require__(/*! ./strip-trailg-slashes.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js")const { jo } = __webpack_require__(/*! path */ "path")const platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platformconst isWdows = platform === 'w32'module.exports = () => {  // path => [function or Set]  // A Set object means a directory reservation  // A fn is a direct reservation on that path  const queues = new Map()  // fn => {paths:[path,...], dirs:[path, ...]}  const reservations = new Map()  // return a set of pnt dirs for a given path  // '/a/b/c/d' -> ['/', '/a', '/a/b', '/a/b/c', '/a/b/c/d']  const getDirs = path => {    const dirs = path.split('/').slice(0, -1).reduce((set, path) => {      if (set.length)        path = jo(set[set.length - 1], path)      set.push(path || '/')      return set    }, [])    return dirs  }  // functions currently runng  const runng = new Set()  // return the queues for each path the function cs about  // fn => {paths, dirs}  const getQueues = fn => {    const res = reservations.get(fn)    /* istanbul ignore if - unpossible */    if (!res)      throw new Error('function does not have any path reservations')    return {      paths: res.paths.map(path => queues.get(path)),      dirs: [...res.dirs].map(path => queues.get(path)),    }  }  // check if fn is first  le for all its paths,  is  // cluded  the first set for all its dir queues  const check = fn => {    const {paths, dirs} = getQueues(fn)    return paths.every(q => q[0] === fn) &&      dirs.every(q => q[0] stanceof Set && q[0].has(fn))  }  // run the function if it's first  le  not already runng  const run = fn => {    if (runng.has(fn) || !check(fn))      return false    runng.add(fn)    fn(() => clear(fn))    return true  }  const clear = fn => {    if (!runng.has(fn))      return false    const { paths, dirs } = reservations.get(fn)    const next = new Set()    paths.forEach(path => {      const q = queues.get(path)      assert.equal(q[0], fn)      if (q.length === 1)        queues.delete(path)      else {        q.shift()        if (typeof q[0] === 'function')          next.add(q[0])        else          q[0].forEach(fn => next.add(fn))      }    })    dirs.forEach(dir => {      const q = queues.get(dir)      assert(q[0] stanceof Set)      if (q[0].size === 1 && q.length === 1)        queues.delete(dir)      else if (q[0].size === 1) {        q.shift()        // must be a function or else the Set would've been reused        next.add(q[0])      } else        q[0].delete(fn)    })    runng.delete(fn)    next.forEach(fn => run(fn))    return true  }  const reserve = (paths, fn) => {    // collide on matches across case  unicode normalization    // On wdows, thanks to the magic of 8.3 shortnames, it is fundamentally    // impossible to determe whether two paths refer to the same thg on    // disk, without askg the kernel for a shortname.    // So, we just pretend that every path matches every other path here,    // effectively removg all parallelization on wdows.    paths = isWdows ? ['w32 parallelization disabled'] : paths.map(p => {      // don't need normPath, because we skip  entirely for wdows      return normalize(stripSlashes(jo(p))).toLowerCase()    })    const dirs = new Set(      paths.map(path => getDirs(path)).reduce((a, b) => a.concat(b))    )    reservations.set(fn, {dirs, paths})    paths.forEach(path => {      const q = queues.get(path)      if (!q)        queues.set(path, [fn])      else        q.push(fn)    })    dirs.forEach(dir => {      const q = queues.get(dir)      if (!q)        queues.set(dir, [new Set([fn])])      else if (q[q.length - 1] stanceof Set)        q[q.length - 1].add(fn)      else        q.push(new Set([fn]))    })    return run(fn)  }  return { check, reserve }}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pax.js":/*!**********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pax.js ***!  \**********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const Header = __webpack_require__(/*! ./header.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js")const path = __webpack_require__(/*! path */ "path")class Pax {  constructor (obj, global) {    .atime = obj.atime || null    .charset = obj.charset || null    .comment = obj.comment || null    .ctime = obj.ctime || null    .gid = obj.gid || null    .gname = obj.gname || null    .lkpath = obj.lkpath || null    .mtime = obj.mtime || null    .path = obj.path || null    .size = obj.size || null    .uid = obj.uid || null    .uname = obj.uname || null    .dev = obj.dev || null    .o = obj.o || null    .nlk = obj.nlk || null    .global = global || false  }  encode () {    const body = .encodeBody()    if (body === '')      return null    const bodyLen = Buffer.teLength(body)    // round up to 512 tes    // add 512 for header    const bufLen = 512 * Math.ceil(1 + bodyLen / 512)    const buf = Buffer.allocUnsafe(bufLen)    // 0-fill the header section, it might not hit every field    for (let i = 0; i < 512; i++)      buf[i] = 0    new Header({      // XXX split the path      // then the path should be PaxHeader + basename, but less than 99,      // prepend with the dirname      path: ('PaxHeader/' + path.basename(.path)).slice(0, 99),      mode: .mode || 0o644,      uid: .uid || null,      gid: .gid || null,      size: bodyLen,      mtime: .mtime || null,      type: .global ? 'GlobalExtendedHeader' : 'ExtendedHeader',      lkpath: '',      uname: .uname || '',      gname: .gname || '',      devmaj: 0,      devm: 0,      atime: .atime || null,      ctime: .ctime || null,    }).encode(buf)    buf.write(body, 512, bodyLen, 'utf8')    // null pad after the body    for (let i = bodyLen + 512; i < buf.length; i++)      buf[i] = 0    return buf  }  encodeBody () {    return (      .encodeField('path') +      .encodeField('ctime') +      .encodeField('atime') +      .encodeField('dev') +      .encodeField('o') +      .encodeField('nlk') +      .encodeField('charset') +      .encodeField('comment') +      .encodeField('gid') +      .encodeField('gname') +      .encodeField('lkpath') +      .encodeField('mtime') +      .encodeField('size') +      .encodeField('uid') +      .encodeField('uname')    )  }  encodeField (field) {    if ([field] === null || [field] === undefed)      return ''    const v = [field] stanceof Date ? [field].getTime() / 1000      : [field]    const s = ' ' +      (field === 'dev' || field === 'o' || field === 'nlk'        ? 'SCHILY.' : '') +      field + '=' + v + '\n'    const teLen = Buffer.teLength(s)    // the digits cludes the length of the digits  ascii base-10    // so if it's 9 characters, then addg 1 for the 9 makes it 10    // which makes it 11 chars.    let digits = Math.floor(Math.log(teLen) / Math.log(10)) + 1    if (teLen + digits >= Math.pow(10, digits))      digits += 1    const len = digits + teLen    return len + s  }}Pax.parse = (strg, ex, g) => new Pax(merge(parseKV(strg), ex), g)const merge = (a, b) =>  b ? Object.keys(a).reduce((s, k) => (s[k] = a[k], s), b) : aconst parseKV = strg =>  strg    .replace(/\n$/, '')    .split('\n')    .reduce(parseKVLe, Object.create(null))const parseKVLe = (set, le) => {  const n = parseInt(le, 10)  // XXX Values with \n  them will fail .  // Refactor to not be a naive le--le parse.  if (n !== Buffer.teLength(le) + 1)    return set  le = le.substr((n + ' ').length)  const kv = le.split('=')  const k = kv.shift().replace(/^SCHILY\.(dev|o|nlk)/, '$1')  if (!k)    return set  const v = kv.jo('=')  set[k] = /^([A-Z]+\.)?([mac]|birth|creation)time$/.test(k)    ? new Date(v * 1000)    : /^[0-9]+$/.test(v) ? +v    : v  return set}module.exports = Pax/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/read-entry.js":/*!*****************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/read-entry.js ***!  \*****************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const MiPass = __webpack_require__(/*! mipass */ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js")const normPath = __webpack_require__(/*! ./normalize-wdows-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js")const SLURP = Symbol('slurp')module.exports = class ReadEntry extends MiPass {  constructor (header, ex, gex) {    super()    // read entries always start life paused.   is to avoid the    // situation where Mipass's auto-endg empty streams results    //  an entry endg before we're ready for it.    .pause()    .extended = ex    .globalExtended = gex    .header = header    .startBlockSize = 512 * Math.ceil(header.size / 512)    .blockRema = .startBlockSize    .rema = header.size    .type = header.type    .meta = false    .ignore = false    switch (.type) {      case 'File':      case 'OldFile':      case 'Lk':      case 'SymbolicLk':      case 'CharacterDevice':      case 'BlockDevice':      case 'Directory':      case 'FIFO':      case 'ContiguousFile':      case 'GNUDumpDir':        break      case 'NextFileHasLongLkpath':      case 'NextFileHasLongPath':      case 'OldGnuLongPath':      case 'GlobalExtendedHeader':      case 'ExtendedHeader':      case 'OldExtendedHeader':        .meta = true        break      // NOTE: gnutar  bsdtar treat unrecognized types as 'File'      // it may be worth dog the same, but with a warng.      default:        .ignore = true    }    .path = normPath(header.path)    .mode = header.mode    if (.mode)      .mode = .mode & 0o7777    .uid = header.uid    .gid = header.gid    .uname = header.uname    .gname = header.gname    .size = header.size    .mtime = header.mtime    .atime = header.atime    .ctime = header.ctime    .lkpath = normPath(header.lkpath)    .uname = header.uname    .gname = header.gname    if (ex)      [SLURP](ex)    if (gex)      [SLURP](gex, true)  }  write (data) {    const writeLen = data.length    if (writeLen > .blockRema)      throw new Error('writg more to entry than is appropriate')    const r = .rema    const br = .blockRema    .rema = Math.max(0, r - writeLen)    .blockRema = Math.max(0, br - writeLen)    if (.ignore)      return true    if (r >= writeLen)      return super.write(data)    // r < writeLen    return super.write(data.slice(0, r))  }  [SLURP] (ex, global) {    for (const k  ex) {      // we slurp  everythg except for the path attribute       // a global extended header, because that's weird.      if (ex[k] !== null && ex[k] !== undefed &&          !(global && k === 'path'))        [k] = k === 'path' || k === 'lkpath' ? normPath(ex[k]) : ex[k]    }  }}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/replace.js":/*!**************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/replace.js ***!  \**************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// tar -rconst hlo = __webpack_require__(/*! ./high-level-opt.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js")const Pack = __webpack_require__(/*! ./pack.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pack.js")const fs = __webpack_require__(/*! fs */ "fs")const fsm = __webpack_require__(/*! fs-mipass */ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js")const t = __webpack_require__(/*! ./list.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/list.js")const path = __webpack_require__(/*! path */ "path")// startg at the head of the file, read a Header// If the checksum is valid, that's our position to start writg// If it is, jump forward  the specified size (round up to 512)//  try aga.// Write the new Pack stream startg there.const Header = __webpack_require__(/*! ./header.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js")module.exports = (opt_, files, cb) => {  const opt = hlo(opt_)  if (!opt.file)    throw new TypeError('file is required')  if (opt.gzip)    throw new TypeError('cannot append to compressed archives')  if (!files || !Array.isArray(files) || !files.length)    throw new TypeError('no files or directories specified')  files = Array.from(files)  return opt.sync ? replaceSync(opt, files)    : replace(opt, files, cb)}const replaceSync = (opt, files) => {  const p = new Pack.Sync(opt)  let threw = true  let fd  let position  try {    try {      fd = fs.openSync(opt.file, 'r+')    } catch (er) {      if (er.code === 'ENOENT')        fd = fs.openSync(opt.file, 'w+')      else        throw er    }    const st = fs.fstatSync(fd)    const headBuf = Buffer.alloc(512)    POSITION: for (position = 0; position < st.size; position += 512) {      for (let bufPos = 0, tes = 0; bufPos < 512; bufPos += tes) {        tes = fs.readSync(          fd, headBuf, bufPos, headBuf.length - bufPos, position + bufPos        )        if (position === 0 && headBuf[0] === 0x1f && headBuf[1] === 0x8b)          throw new Error('cannot append to compressed archives')        if (!tes)          break POSITION      }      const h = new Header(headBuf)      if (!h.cksumValid)        break      const entryBlockSize = 512 * Math.ceil(h.size / 512)      if (position + entryBlockSize + 512 > st.size)        break      // the 512 for the header we just parsed will be added as well      // also jump ahead all the blocks for the body      position += entryBlockSize      if (opt.mtimeCache)        opt.mtimeCache.set(h.path, h.mtime)    }    threw = false    streamSync(opt, p, position, fd, files)  } fally {    if (threw) {      try {        fs.closeSync(fd)      } catch (er) {}    }  }}const streamSync = (opt, p, position, fd, files) => {  const stream = new fsm.WriteStreamSync(opt.file, {    fd: fd,    start: position,  })  p.pipe(stream)  addFilesSync(p, files)}const replace = (opt, files, cb) => {  files = Array.from(files)  const p = new Pack(opt)  const getPos = (fd, size, cb_) => {    const cb = (er, pos) => {      if (er)        fs.close(fd, _ => cb_(er))      else        cb_(null, pos)    }    let position = 0    if (size === 0)      return cb(null, 0)    let bufPos = 0    const headBuf = Buffer.alloc(512)    const onread = (er, tes) => {      if (er)        return cb(er)      bufPos += tes      if (bufPos < 512 && tes) {        return fs.read(          fd, headBuf, bufPos, headBuf.length - bufPos,          position + bufPos, onread        )      }      if (position === 0 && headBuf[0] === 0x1f && headBuf[1] === 0x8b)        return cb(new Error('cannot append to compressed archives'))      // truncated header      if (bufPos < 512)        return cb(null, position)      const h = new Header(headBuf)      if (!h.cksumValid)        return cb(null, position)      const entryBlockSize = 512 * Math.ceil(h.size / 512)      if (position + entryBlockSize + 512 > size)        return cb(null, position)      position += entryBlockSize + 512      if (position >= size)        return cb(null, position)      if (opt.mtimeCache)        opt.mtimeCache.set(h.path, h.mtime)      bufPos = 0      fs.read(fd, headBuf, 0, 512, position, onread)    }    fs.read(fd, headBuf, 0, 512, position, onread)  }  const promise = new Promise((resolve, reject) => {    p.on('error', reject)    let flag = 'r+'    const onopen = (er, fd) => {      if (er && er.code === 'ENOENT' && flag === 'r+') {        flag = 'w+'        return fs.open(opt.file, flag, onopen)      }      if (er)        return reject(er)      fs.fstat(fd, (er, st) => {        if (er)          return fs.close(fd, () => reject(er))        getPos(fd, st.size, (er, position) => {          if (er)            return reject(er)          const stream = new fsm.WriteStream(opt.file, {            fd: fd,            start: position,          })          p.pipe(stream)          stream.on('error', reject)          stream.on('close', resolve)          addFilesAsync(p, files)        })      })    }    fs.open(opt.file, flag, onopen)  })  return cb ? promise.then(cb, cb) : promise}const addFilesSync = (p, files) => {  files.forEach(file => {    if (file.charAt(0) === '@') {      t({        file: path.resolve(p.cwd, file.substr(1)),        sync: true,        noResume: true,        onentry: entry => p.add(entry),      })    } else      p.add(file)  })  p.end()}const addFilesAsync = (p, files) => {  while (files.length) {    const file = files.shift()    if (file.charAt(0) === '@') {      return t({        file: path.resolve(p.cwd, file.substr(1)),        noResume: true,        onentry: entry => p.add(entry),      }).then(_ => addFilesAsync(p, files))    } else      p.add(file)  }  p.end()}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-absolute-path.js":/*!**************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-absolute-path.js ***!  \**************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// unix absolute paths  also absolute on w32, so we use  for bothconst { isAbsolute, parse } = (__webpack_require__(/*! path */ "path").w32)// returns [root, stripped]// Note that wdows will thk that //x/y/z/a has a "root" of //x/y,  // those cases, we want to sanitize it to x/y/z/a, not z/a, so we strip /// explicitly if it's the first character.// drive-specific relative paths on Wdows get their root stripped off even// though they  not absolute, so `c:../foo` becomes ['c:', '../foo']module.exports = path => {  let r = ''  let parsed = parse(path)  while (isAbsolute(path) || parsed.root) {    // wdows will thk that //x/y/z has a "root" of //x/y/    // but strip the //?/C:/ off of //?/C:/path    const root = path.charAt(0) === '/' && path.slice(0, 4) !== '//?/' ? '/'      : parsed.root    path = path.substr(root.length)    r += root    parsed = parse(path)  }  return [r, path]}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js ***!  \*****************************************************************************************************************//***/ ((module) => {// warng: extremely hot code path.// This has been meticulously optimized for use// with npm stall on large package trees.// Do not edit without cful benchmarkg.module.exports = str => {  let i = str.length - 1  let slashesStart = -1  while (i > -1 && str.charAt(i) === '/') {    slashesStart = i    i--  }  return slashesStart === -1 ? str : str.slice(0, slashesStart)}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/types.js":/*!************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/types.js ***!  \************************************************************************************************//***/ ((__unused_webpack_module, exports) => {"use strict";// map types from key to human-friendly nameexports.name = new Map([  ['0', 'File'],  // same as File  ['', 'OldFile'],  ['1', 'Lk'],  ['2', 'SymbolicLk'],  // Devices  FIFOs n't fully supported  // they  parsed, but skipped when unpackg  ['3', 'CharacterDevice'],  ['4', 'BlockDevice'],  ['5', 'Directory'],  ['6', 'FIFO'],  // same as File  ['7', 'ContiguousFile'],  // pax headers  ['g', 'GlobalExtendedHeader'],  ['x', 'ExtendedHeader'],  // vendor-specific stuff  // skip  ['A', 'SolarisACL'],  // like 5, but with data, which should be skipped  ['D', 'GNUDumpDir'],  // metadata only, skip  ['I', 'Inode'],  // data = lk path of next file  ['K', 'NextFileHasLongLkpath'],  // data = path of next file  ['L', 'NextFileHasLongPath'],  // skip  ['M', 'ContuationFile'],  // like L  ['N', 'OldGnuLongPath'],  // skip  ['S', 'SparseFile'],  // skip  ['V', 'TapeVolumeHeader'],  // like x  ['X', 'OldExtendedHeader'],])// map the other directionexports.code = new Map(Array.from(exports.name).map(kv => [kv[1], kv[0]]))/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/unpack.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/unpack.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// the PEND/UNPEND stuff tracks whether we're ready to emit end/close yet.// but the path reservations  required to avoid race conditions where// parallelized unpack ops may mess with one another, due to dependencies// (like a Lk dependg on its target) or destructive operations (like// clobberg an fs object to create one of a different type.)const assert = __webpack_require__(/*! assert */ "assert")const Parser = __webpack_require__(/*! ./parse.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/parse.js")const fs = __webpack_require__(/*! fs */ "fs")const fsm = __webpack_require__(/*! fs-mipass */ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js")const path = __webpack_require__(/*! path */ "path")const mkdir = __webpack_require__(/*! ./mkdir.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mkdir.js")const wc = __webpack_require__(/*! ./wchars.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/wchars.js")const pathReservations = __webpack_require__(/*! ./path-reservations.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/path-reservations.js")const stripAbsolutePath = __webpack_require__(/*! ./strip-absolute-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-absolute-path.js")const normPath = __webpack_require__(/*! ./normalize-wdows-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js")const stripSlash = __webpack_require__(/*! ./strip-trailg-slashes.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js")const normalize = __webpack_require__(/*! ./normalize-unicode.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-unicode.js")const ONENTRY = Symbol('onEntry')const CHECKFS = Symbol('checkFs')const CHECKFS2 = Symbol('checkFs2')const PRUNECACHE = Symbol('pruneCache')const ISREUSABLE = Symbol('isReusable')const MAKEFS = Symbol('makeFs')const FILE = Symbol('file')const DIRECTORY = Symbol('directory')const LINK = Symbol('lk')const SYMLINK = Symbol('symlk')const HARDLINK = Symbol('hardlk')const UNSUPPORTED = Symbol('unsupported')const CHECKPATH = Symbol('checkPath')const MKDIR = Symbol('mkdir')const ONERROR = Symbol('onError')const PENDING = Symbol('pendg')const PEND = Symbol('pend')const UNPEND = Symbol('unpend')const ENDED = Symbol('ended')const MAYBECLOSE = Symbol('maybeClose')const SKIP = Symbol('skip')const DOCHOWN = Symbol('doChown')const UID = Symbol('uid')const GID = Symbol('gid')const CHECKED_CWD = Symbol('checkedCwd')const crypto = __webpack_require__(/*! crypto */ "crypto")const getFlag = __webpack_require__(/*! ./get-write-flag.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/get-write-flag.js")const platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platformconst isWdows = platform === 'w32'// Unlks on Wdows  not atomic.//// This means that if you have a file entry, followed  another// file entry with an identical name,  you cannot re-use the file// (because it's a hardlk, or because unlk:true is set, or it's// Wdows, which does not have useful nlk values), then the unlk// will be committed to the disk AFTER the new file has been // over the old one, deletg the new file.//// To work around , on Wdows systems, we rename the file  then// delete the renamed file.  It's a sloppy kludge, but frankly, I do not// know of a better way to do , given wdows' non-atomic unlk// semantics.//// See: https://github.com/npm/node-tar/issues/183/* istanbul ignore next */const unlkFile = (path, cb) => {  if (!isWdows)    return fs.unlk(path, cb)  const name = path + '.DELETE.' + crypto.romBytes(16).toStrg('hex')  fs.rename(path, name, er => {    if (er)      return cb(er)    fs.unlk(name, cb)  })}/* istanbul ignore next */const unlkFileSync = path => {  if (!isWdows)    return fs.unlkSync(path)  const name = path + '.DELETE.' + crypto.romBytes(16).toStrg('hex')  fs.renameSync(path, name)  fs.unlkSync(name)}// .gid, entry.gid, .processUidconst ut32 = (a, b, c) =>  a === a >>> 0 ? a  : b === b >>> 0 ? b  : c// clear the cache if it's a case-sensitive unicode-squashg match.// we can't know if the current file system is case-sensitive or supports// unicode fully, so we check for similarity on the maximally compatible// representation.  Err on the side of prung, sce all it's dog is// preventg lstats,  it's not the end of the world if we get a false// positive.// Note that on wdows, we always drop the entire cache whenever a// symbolic lk is encountered, because 8.3 filenames  impossible// to reason about,  collisions  hazards rather than just failures.const cacheKeyNormalize = path => normalize(stripSlash(normPath(path)))  .toLowerCase()const pruneCache = (cache, abs) => {  abs = cacheKeyNormalize(abs)  for (const path of cache.keys()) {    const pnorm = cacheKeyNormalize(path)    if (pnorm === abs || pnorm.dexOf(abs + '/') === 0)      cache.delete(path)  }}const dropCache = cache => {  for (const key of cache.keys())    cache.delete(key)}class Unpack extends Parser {  constructor (opt) {    if (!opt)      opt = {}    opt.ondone = _ => {      [ENDED] = true      [MAYBECLOSE]()    }    super(opt)    [CHECKED_CWD] = false    .reservations = pathReservations()    .transform = typeof opt.transform === 'function' ? opt.transform : null    .writable = true    .readable = false    [PENDING] = 0    [ENDED] = false    .dirCache = opt.dirCache || new Map()    if (typeof opt.uid === 'number' || typeof opt.gid === 'number') {      // need both or neither      if (typeof opt.uid !== 'number' || typeof opt.gid !== 'number')        throw new TypeError('cannot set owner without number uid  gid')      if (opt.preserveOwner) {        throw new TypeError(          'cannot preserve owner  archive  also set owner explicitly')      }      .uid = opt.uid      .gid = opt.gid      .setOwner = true    } else {      .uid = null      .gid = null      .setOwner = false    }    // default true for root    if (opt.preserveOwner === undefed && typeof opt.uid !== 'number')      .preserveOwner = process.getuid && process.getuid() === 0    else      .preserveOwner = !!opt.preserveOwner    .processUid = (.preserveOwner || .setOwner) && process.getuid ?      process.getuid() : null    .processGid = (.preserveOwner || .setOwner) && process.getgid ?      process.getgid() : null    // mostly just for testg, but useful  some cases.    // Forcibly trigger a chown on every entry, no matter what    .forceChown = opt.forceChown === true    // turn ><?|  filenames to 0xf000-higher encoded forms    .w32 = !!opt.w32 || isWdows    // do not unpack over files that  newer than what's  the archive    .newer = !!opt.newer    // do not unpack over ANY files    .keep = !!opt.keep    // do not set mtime/atime of extracted entries    .noMtime = !!opt.noMtime    // allow .., absolute path entries,  unpackg through symlks    // without , warn  skip .., relativize absolutes,  error    // on symlks  extraction path    .preservePaths = !!opt.preservePaths    // unlk files  lks before writg. This breaks existg hard    // lks,  removes symlk directories rather than errorg    .unlk = !!opt.unlk    .cwd = normPath(path.resolve(opt.cwd || process.cwd()))    .strip = +opt.strip || 0    // if we're not chmoddg, then we don't need the process umask    .processUmask = opt.noChmod ? 0 : process.umask()    .umask = typeof opt.umask === 'number' ? opt.umask : .processUmask    // default mode for dirs created as pnts    .dmode = opt.dmode || (0o0777 & (~.umask))    .fmode = opt.fmode || (0o0666 & (~.umask))    .on('entry', entry => [ONENTRY](entry))  }  // a bad or damaged archive is a warng for Parser, but an error  // when extractg.  Mark those errors as unrecoverable, because  // the Unpack contract cannot be met.  warn (code, msg, data = {}) {    if (code === 'TAR_BAD_ARCHIVE' || code === 'TAR_ABORT')      data.recoverable = false    return super.warn(code, msg, data)  }  [MAYBECLOSE] () {    if ([ENDED] && [PENDING] === 0) {      .emit('prefish')      .emit('fish')      .emit('end')      .emit('close')    }  }  [CHECKPATH] (entry) {    if (.strip) {      const parts = normPath(entry.path).split('/')      if (parts.length < .strip)        return false      entry.path = parts.slice(.strip).jo('/')      if (entry.type === 'Lk') {        const lkparts = normPath(entry.lkpath).split('/')        if (lkparts.length >= .strip)          entry.lkpath = lkparts.slice(.strip).jo('/')        else          return false      }    }    if (!.preservePaths) {      const p = normPath(entry.path)      const parts = p.split('/')      if (parts.cludes('..') || isWdows && /^[a-z]:\.\.$/i.test(parts[0])) {        .warn('TAR_ENTRY_ERROR', `path contas '..'`, {          entry,          path: p,        })        return false      }      // strip off the root      const [root, stripped] = stripAbsolutePath(p)      if (root) {        entry.path = stripped        .warn('TAR_ENTRY_INFO', `strippg ${root} from absolute path`, {          entry,          path: p,        })      }    }    if (path.isAbsolute(entry.path))      entry.absolute = normPath(path.resolve(entry.path))    else      entry.absolute = normPath(path.resolve(.cwd, entry.path))    // if we somehow ended up with a path that escapes the cwd,  we     // not  preservePaths mode, then somethg is fishy!  This should have    // been prevented above, so ignore  for coverage.    /* istanbul ignore if - defense  depth */    if (!.preservePaths &&        entry.absolute.dexOf(.cwd + '/') !== 0 &&        entry.absolute !== .cwd) {      .warn('TAR_ENTRY_ERROR', 'path escaped extraction target', {        entry,        path: normPath(entry.path),        resolvedPath: entry.absolute,        cwd: .cwd,      })      return false    }    // an archive can set properties on the extraction directory, but it    // may not replace the cwd with a different kd of thg entirely.    if (entry.absolute === .cwd &&        entry.type !== 'Directory' &&        entry.type !== 'GNUDumpDir')      return false    // only encode : chars that n't drive letter dicators    if (.w32) {      const { root: aRoot } = path.w32.parse(entry.absolute)      entry.absolute = aRoot + wc.encode(entry.absolute.substr(aRoot.length))      const { root: pRoot } = path.w32.parse(entry.path)      entry.path = pRoot + wc.encode(entry.path.substr(pRoot.length))    }    return true  }  [ONENTRY] (entry) {    if (![CHECKPATH](entry))      return entry.resume()    assert.equal(typeof entry.absolute, 'strg')    switch (entry.type) {      case 'Directory':      case 'GNUDumpDir':        if (entry.mode)          entry.mode = entry.mode | 0o700      case 'File':      case 'OldFile':      case 'ContiguousFile':      case 'Lk':      case 'SymbolicLk':        return [CHECKFS](entry)      case 'CharacterDevice':      case 'BlockDevice':      case 'FIFO':      default:        return [UNSUPPORTED](entry)    }  }  [ONERROR] (er, entry) {    // Cwd has to exist, or else nothg works. That's serious.    // Other errors  warngs, which raise the error  strict    // mode, but otherwise contue on.    if (er.name === 'CwdError')      .emit('error', er)    else {      .warn('TAR_ENTRY_ERROR', er, {entry})      [UNPEND]()      entry.resume()    }  }  [MKDIR] (dir, mode, cb) {    mkdir(normPath(dir), {      uid: .uid,      gid: .gid,      processUid: .processUid,      processGid: .processGid,      umask: .processUmask,      preserve: .preservePaths,      unlk: .unlk,      cache: .dirCache,      cwd: .cwd,      mode: mode,      noChmod: .noChmod,    }, cb)  }  [DOCHOWN] (entry) {    //  preserve owner mode, chown if the entry doesn't match process    //  set owner mode, chown if settg doesn't match process    return .forceChown ||      .preserveOwner &&      (typeof entry.uid === 'number' && entry.uid !== .processUid ||        typeof entry.gid === 'number' && entry.gid !== .processGid)      ||      (typeof .uid === 'number' && .uid !== .processUid ||        typeof .gid === 'number' && .gid !== .processGid)  }  [UID] (entry) {    return ut32(.uid, entry.uid, .processUid)  }  [GID] (entry) {    return ut32(.gid, entry.gid, .processGid)  }  [FILE] (entry, fullyDone) {    const mode = entry.mode & 0o7777 || .fmode    const stream = new fsm.WriteStream(entry.absolute, {      flags: getFlag(entry.size),      mode: mode,      autoClose: false,    })    stream.on('error', er => {      if (stream.fd)        fs.close(stream.fd, () => {})      // flush all the data out so that we n't left hangg      // if the error wasn't actually fatal.  otherwise the parse      // is blocked,  we never proceed.      stream.write = () => true      [ONERROR](er, entry)      fullyDone()    })    let actions = 1    const done = er => {      if (er) {        /* istanbul ignore else - we should always have a fd  now */        if (stream.fd)          fs.close(stream.fd, () => {})        [ONERROR](er, entry)        fullyDone()        return      }      if (--actions === 0) {        fs.close(stream.fd, er => {          if (er)            [ONERROR](er, entry)          else            [UNPEND]()          fullyDone()        })      }    }    stream.on('fish', _ => {      // if futimes fails, try utimes      // if utimes fails, fail with the origal error      // same for fchown/chown      const abs = entry.absolute      const fd = stream.fd      if (entry.mtime && !.noMtime) {        actions++        const atime = entry.atime || new Date()        const mtime = entry.mtime        fs.futimes(fd, atime, mtime, er =>          er ? fs.utimes(abs, atime, mtime, er2 => done(er2 && er))          : done())      }      if ([DOCHOWN](entry)) {        actions++        const uid = [UID](entry)        const gid = [GID](entry)        fs.fchown(fd, uid, gid, er =>          er ? fs.chown(abs, uid, gid, er2 => done(er2 && er))          : done())      }      done()    })    const tx = .transform ? .transform(entry) || entry : entry    if (tx !== entry) {      tx.on('error', er => {        [ONERROR](er, entry)        fullyDone()      })      entry.pipe(tx)    }    tx.pipe(stream)  }  [DIRECTORY] (entry, fullyDone) {    const mode = entry.mode & 0o7777 || .dmode    [MKDIR](entry.absolute, mode, er => {      if (er) {        [ONERROR](er, entry)        fullyDone()        return      }      let actions = 1      const done = _ => {        if (--actions === 0) {          fullyDone()          [UNPEND]()          entry.resume()        }      }      if (entry.mtime && !.noMtime) {        actions++        fs.utimes(entry.absolute, entry.atime || new Date(), entry.mtime, done)      }      if ([DOCHOWN](entry)) {        actions++        fs.chown(entry.absolute, [UID](entry), [GID](entry), done)      }      done()    })  }  [UNSUPPORTED] (entry) {    entry.unsupported = true    .warn('TAR_ENTRY_UNSUPPORTED',      `unsupported entry type: ${entry.type}`, {entry})    entry.resume()  }  [SYMLINK] (entry, done) {    [LINK](entry, entry.lkpath, 'symlk', done)  }  [HARDLINK] (entry, done) {    const lkpath = normPath(path.resolve(.cwd, entry.lkpath))    [LINK](entry, lkpath, 'lk', done)  }  [PEND] () {    [PENDING]++  }  [UNPEND] () {    [PENDING]--    [MAYBECLOSE]()  }  [SKIP] (entry) {    [UNPEND]()    entry.resume()  }  // Check if we can reuse an existg filesystem entry safely   // overwrite it, rather than unlkg  recreatg  // Wdows doesn't report a useful nlk, so we just never reuse entries  [ISREUSABLE] (entry, st) {    return entry.type === 'File' &&      !.unlk &&      st.isFile() &&      st.nlk <= 1 &&      !isWdows  }  // check if a thg is there,  if so, try to clobber it  [CHECKFS] (entry) {    [PEND]()    const paths = [entry.path]    if (entry.lkpath)      paths.push(entry.lkpath)    .reservations.reserve(paths, done => [CHECKFS2](entry, done))  }  [PRUNECACHE] (entry) {    // if we  not creatg a directory,  the path is  the dirCache,    // then that means we  about to delete the directory we created    // previously,  it is no longer gog to be a directory,  neither    // is any of its children.    // If a symbolic lk is encountered, all bets  off.  re is no    // reasonable way to sanitize the cache  such a way we will be able to    // avoid havg filesystem collisions.  If  happens with a non-symlk    // entry, it'll just fail to unpack, but a symlk to a directory, usg an    // 8.3 shortname or certa unicode attacks, can evade detection  lead    // to arbitrary writes to anywhere on the system.    if (entry.type === 'SymbolicLk')      dropCache(.dirCache)    else if (entry.type !== 'Directory')      pruneCache(.dirCache, entry.absolute)  }  [CHECKFS2] (entry, fullyDone) {    [PRUNECACHE](entry)    const done = er => {      [PRUNECACHE](entry)      fullyDone(er)    }    const checkCwd = () => {      [MKDIR](.cwd, .dmode, er => {        if (er) {          [ONERROR](er, entry)          done()          return        }        [CHECKED_CWD] = true        start()      })    }    const start = () => {      if (entry.absolute !== .cwd) {        const pnt = normPath(path.dirname(entry.absolute))        if (pnt !== .cwd) {          return [MKDIR](pnt, .dmode, er => {            if (er) {              [ONERROR](er, entry)              done()              return            }            afterMakePnt()          })        }      }      afterMakePnt()    }    const afterMakePnt = () => {      fs.lstat(entry.absolute, (lstatEr, st) => {        if (st && (.keep || .newer && st.mtime > entry.mtime)) {          [SKIP](entry)          done()          return        }        if (lstatEr || [ISREUSABLE](entry, st))          return [MAKEFS](null, entry, done)        if (st.isDirectory()) {          if (entry.type === 'Directory') {            const needChmod = !.noChmod &&              entry.mode &&              (st.mode & 0o7777) !== entry.mode            const afterChmod = er => [MAKEFS](er, entry, done)            if (!needChmod)              return afterChmod()            return fs.chmod(entry.absolute, entry.mode, afterChmod)          }          // Not a dir entry, have to remove it.          // NB: the only way to end up with an entry that is the cwd          // itself,  such a way that == does not detect, is a          // tricky wdows absolute path with UNC or 8.3 parts (          // preservePaths:true, or else it will have been stripped).          // In that case, the user has opted out of path protections          // explicitly, so if they blow away the cwd, c'est la vie.          if (entry.absolute !== .cwd) {            return fs.rmdir(entry.absolute, er =>              [MAKEFS](er, entry, done))          }        }        // not a dir,  not reusable        // don't remove if the cwd, we want that error        if (entry.absolute === .cwd)          return [MAKEFS](null, entry, done)        unlkFile(entry.absolute, er =>          [MAKEFS](er, entry, done))      })    }    if ([CHECKED_CWD])      start()    else      checkCwd()  }  [MAKEFS] (er, entry, done) {    if (er) {      [ONERROR](er, entry)      done()      return    }    switch (entry.type) {      case 'File':      case 'OldFile':      case 'ContiguousFile':        return [FILE](entry, done)      case 'Lk':        return [HARDLINK](entry, done)      case 'SymbolicLk':        return [SYMLINK](entry, done)      case 'Directory':      case 'GNUDumpDir':        return [DIRECTORY](entry, done)    }  }  [LINK] (entry, lkpath, lk, done) {    // XXX: get the type ('symlk' or 'junction') for wdows    fs[lk](lkpath, entry.absolute, er => {      if (er)        [ONERROR](er, entry)      else {        [UNPEND]()        entry.resume()      }      done()    })  }}const callSync = fn => {  try {    return [null, fn()]  } catch (er) {    return [er, null]  }}class UnpackSync extends Unpack {  [MAKEFS] (er, entry) {    return super[MAKEFS](er, entry, () => {})  }  [CHECKFS] (entry) {    [PRUNECACHE](entry)    if (![CHECKED_CWD]) {      const er = [MKDIR](.cwd, .dmode)      if (er)        return [ONERROR](er, entry)      [CHECKED_CWD] = true    }    // don't bother to make the pnt if the current entry is the cwd,    // we've already checked it.    if (entry.absolute !== .cwd) {      const pnt = normPath(path.dirname(entry.absolute))      if (pnt !== .cwd) {        const mkPnt = [MKDIR](pnt, .dmode)        if (mkPnt)          return [ONERROR](mkPnt, entry)      }    }    const [lstatEr, st] = callSync(() => fs.lstatSync(entry.absolute))    if (st && (.keep || .newer && st.mtime > entry.mtime))      return [SKIP](entry)    if (lstatEr || [ISREUSABLE](entry, st))      return [MAKEFS](null, entry)    if (st.isDirectory()) {      if (entry.type === 'Directory') {        const needChmod = !.noChmod &&          entry.mode &&          (st.mode & 0o7777) !== entry.mode        const [er] = needChmod ? callSync(() => {          fs.chmodSync(entry.absolute, entry.mode)        }) : []        return [MAKEFS](er, entry)      }      // not a dir entry, have to remove it      const [er] = callSync(() => fs.rmdirSync(entry.absolute))      [MAKEFS](er, entry)    }    // not a dir,  not reusable.    // don't remove if it's the cwd, sce we want that error.    const [er] = entry.absolute === .cwd ? []      : callSync(() => unlkFileSync(entry.absolute))    [MAKEFS](er, entry)  }  [FILE] (entry, done) {    const mode = entry.mode & 0o7777 || .fmode    const oner = er => {      let closeError      try {        fs.closeSync(fd)      } catch (e) {        closeError = e      }      if (er || closeError)        [ONERROR](er || closeError, entry)      done()    }    let fd    try {      fd = fs.openSync(entry.absolute, getFlag(entry.size), mode)    } catch (er) {      return oner(er)    }    const tx = .transform ? .transform(entry) || entry : entry    if (tx !== entry) {      tx.on('error', er => [ONERROR](er, entry))      entry.pipe(tx)    }    tx.on('data', chunk => {      try {        fs.writeSync(fd, chunk, 0, chunk.length)      } catch (er) {        oner(er)      }    })    tx.on('end', _ => {      let er = null      // try both, fallg futimes back to utimes      // if either fails, hle the first error      if (entry.mtime && !.noMtime) {        const atime = entry.atime || new Date()        const mtime = entry.mtime        try {          fs.futimesSync(fd, atime, mtime)        } catch (futimeser) {          try {            fs.utimesSync(entry.absolute, atime, mtime)          } catch (utimeser) {            er = futimeser          }        }      }      if ([DOCHOWN](entry)) {        const uid = [UID](entry)        const gid = [GID](entry)        try {          fs.fchownSync(fd, uid, gid)        } catch (fchowner) {          try {            fs.chownSync(entry.absolute, uid, gid)          } catch (chowner) {            er = er || fchowner          }        }      }      oner(er)    })  }  [DIRECTORY] (entry, done) {    const mode = entry.mode & 0o7777 || .dmode    const er = [MKDIR](entry.absolute, mode)    if (er) {      [ONERROR](er, entry)      done()      return    }    if (entry.mtime && !.noMtime) {      try {        fs.utimesSync(entry.absolute, entry.atime || new Date(), entry.mtime)      } catch (er) {}    }    if ([DOCHOWN](entry)) {      try {        fs.chownSync(entry.absolute, [UID](entry), [GID](entry))      } catch (er) {}    }    done()    entry.resume()  }  [MKDIR] (dir, mode) {    try {      return mkdir.sync(normPath(dir), {        uid: .uid,        gid: .gid,        processUid: .processUid,        processGid: .processGid,        umask: .processUmask,        preserve: .preservePaths,        unlk: .unlk,        cache: .dirCache,        cwd: .cwd,        mode: mode,      })    } catch (er) {      return er    }  }  [LINK] (entry, lkpath, lk, done) {    try {      fs[lk + 'Sync'](lkpath, entry.absolute)      done()      entry.resume()    } catch (er) {      return [ONERROR](er, entry)    }  }}Unpack.Sync = UnpackSyncmodule.exports = Unpack/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/update.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/update.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// tar -uconst hlo = __webpack_require__(/*! ./high-level-opt.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js")const r = __webpack_require__(/*! ./replace.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/replace.js")// just call tar.r with the filter  mtimeCachemodule.exports = (opt_, files, cb) => {  const opt = hlo(opt_)  if (!opt.file)    throw new TypeError('file is required')  if (opt.gzip)    throw new TypeError('cannot append to compressed archives')  if (!files || !Array.isArray(files) || !files.length)    throw new TypeError('no files or directories specified')  files = Array.from(files)  mtimeFilter(opt)  return r(opt, files, cb)}const mtimeFilter = opt => {  const filter = opt.filter  if (!opt.mtimeCache)    opt.mtimeCache = new Map()  opt.filter = filter ? (path, stat) =>    filter(path, stat) && !(opt.mtimeCache.get(path) > stat.mtime)    : (path, stat) => !(opt.mtimeCache.get(path) > stat.mtime)}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/warn-mix.js":/*!*****************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/warn-mix.js ***!  \*****************************************************************************************************//***/ ((module) => {"use strict";module.exports = Base => class extends Base {  warn (code, message, data = {}) {    if (.file)      data.file = .file    if (.cwd)      data.cwd = .cwd    data.code = message stanceof Error && message.code || code    data.tarCode = code    if (!.strict && data.recoverable !== false) {      if (message stanceof Error) {        data = Object.assign(message, data)        message = message.message      }      .emit('warn', data.tarCode, message, data)    } else if (message stanceof Error)      .emit('error', Object.assign(message, data))    else      .emit('error', Object.assign(new Error(`${code}: ${message}`), data))  }}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/wchars.js":/*!***************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/wchars.js ***!  \***************************************************************************************************//***/ ((module) => {"use strict";// When writg files on Wdows, translate the characters to their// 0xf000 higher-encoded versions.const raw = [  '|',  '<',  '>',  '?',  ':',]const w = raw.map(char =>  Strg.fromCharCode(0xf000 + char.charCodeAt(0)))const toW = new Map(raw.map((char, i) => [char, w[i]]))const toRaw = new Map(w.map((char, i) => [char, raw[i]]))module.exports = {  encode: s => raw.reduce((s, c) => s.split(c).jo(toW.get(c)), s),  decode: s => w.reduce((s, c) => s.split(c).jo(toRaw.get(c)), s),}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/write-entry.js":/*!******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/write-entry.js ***!  \******************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const MiPass = __webpack_require__(/*! mipass */ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js")const Pax = __webpack_require__(/*! ./pax.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pax.js")const Header = __webpack_require__(/*! ./header.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js")const fs = __webpack_require__(/*! fs */ "fs")const path = __webpack_require__(/*! path */ "path")const normPath = __webpack_require__(/*! ./normalize-wdows-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js")const stripSlash = __webpack_require__(/*! ./strip-trailg-slashes.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js")const prefixPath = (path, prefix) => {  if (!prefix)    return normPath(path)  path = normPath(path).replace(/^\.(\/|$)/, '')  return stripSlash(prefix) + '/' + path}const maxReadSize = 16 * 1024 * 1024const PROCESS = Symbol('process')const FILE = Symbol('file')const DIRECTORY = Symbol('directory')const SYMLINK = Symbol('symlk')const HARDLINK = Symbol('hardlk')const HEADER = Symbol('header')const READ = Symbol('read')const LSTAT = Symbol('lstat')const ONLSTAT = Symbol('onlstat')const ONREAD = Symbol('onread')const ONREADLINK = Symbol('onreadlk')const OPENFILE = Symbol('openfile')const ONOPENFILE = Symbol('onopenfile')const CLOSE = Symbol('close')const MODE = Symbol('mode')const AWAITDRAIN = Symbol('awaitDra')const ONDRAIN = Symbol('ondra')const PREFIX = Symbol('prefix')const HAD_ERROR = Symbol('hadError')const warner = __webpack_require__(/*! ./warn-mix.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/warn-mix.js")const wchars = __webpack_require__(/*! ./wchars.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/wchars.js")const stripAbsolutePath = __webpack_require__(/*! ./strip-absolute-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-absolute-path.js")const modeFix = __webpack_require__(/*! ./mode-fix.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mode-fix.js")const WriteEntry = warner(class WriteEntry extends MiPass {  constructor (p, opt) {    opt = opt || {}    super(opt)    if (typeof p !== 'strg')      throw new TypeError('path is required')    .path = normPath(p)    // suppress atime, ctime, uid, gid, uname, gname    .portable = !!opt.portable    // until node has built pwnam functions, 'll have to do    .myuid = process.getuid && process.getuid() || 0    .myuser = process.env.USER || ''    .maxReadSize = opt.maxReadSize || maxReadSize    .lkCache = opt.lkCache || new Map()    .statCache = opt.statCache || new Map()    .preservePaths = !!opt.preservePaths    .cwd = normPath(opt.cwd || process.cwd())    .strict = !!opt.strict    .noPax = !!opt.noPax    .noMtime = !!opt.noMtime    .mtime = opt.mtime || null    .prefix = opt.prefix ? normPath(opt.prefix) : null    .fd = null    .blockLen = null    .blockRema = null    .buf = null    .offset = null    .length = null    .pos = null    .rema = null    if (typeof opt.onwarn === 'function')      .on('warn', opt.onwarn)    let pathWarn = false    if (!.preservePaths) {      const [root, stripped] = stripAbsolutePath(.path)      if (root) {        .path = stripped        pathWarn = root      }    }    .w32 = !!opt.w32 || process.platform === 'w32'    if (.w32) {      // force the \ to / normalization, sce we might not *actually*      // be on wdows, but want \ to be considered a path separator.      .path = wchars.decode(.path.replace(/\\/g, '/'))      p = p.replace(/\\/g, '/')    }    .absolute = normPath(opt.absolute || path.resolve(.cwd, p))    if (.path === '')      .path = './'    if (pathWarn) {      .warn('TAR_ENTRY_INFO', `strippg ${pathWarn} from absolute path`, {        entry: ,        path: pathWarn + .path,      })    }    if (.statCache.has(.absolute))      [ONLSTAT](.statCache.get(.absolute))    else      [LSTAT]()  }  emit (ev, ...data) {    if (ev === 'error')      [HAD_ERROR] = true    return super.emit(ev, ...data)  }  [LSTAT] () {    fs.lstat(.absolute, (er, stat) => {      if (er)        return .emit('error', er)      [ONLSTAT](stat)    })  }  [ONLSTAT] (stat) {    .statCache.set(.absolute, stat)    .stat = stat    if (!stat.isFile())      stat.size = 0    .type = getType(stat)    .emit('stat', stat)    [PROCESS]()  }  [PROCESS] () {    switch (.type) {      case 'File': return [FILE]()      case 'Directory': return [DIRECTORY]()      case 'SymbolicLk': return [SYMLINK]()      // unsupported types  ignored.      default: return .end()    }  }  [MODE] (mode) {    return modeFix(mode, .type === 'Directory', .portable)  }  [PREFIX] (path) {    return prefixPath(path, .prefix)  }  [HEADER] () {    if (.type === 'Directory' && .portable)      .noMtime = true    .header = new Header({      path: [PREFIX](.path),      // only apply the prefix to hard lks.      lkpath: .type === 'Lk' ? [PREFIX](.lkpath)      : .lkpath,      // only the permissions  setuid/setgid/sticky bitflags      // not the higher-order bits that specify file type      mode: [MODE](.stat.mode),      uid: .portable ? null : .stat.uid,      gid: .portable ? null : .stat.gid,      size: .stat.size,      mtime: .noMtime ? null : .mtime || .stat.mtime,      type: .type,      uname: .portable ? null :      .stat.uid === .myuid ? .myuser : '',      atime: .portable ? null : .stat.atime,      ctime: .portable ? null : .stat.ctime,    })    if (.header.encode() && !.noPax) {      super.write(new Pax({        atime: .portable ? null : .header.atime,        ctime: .portable ? null : .header.ctime,        gid: .portable ? null : .header.gid,        mtime: .noMtime ? null : .mtime || .header.mtime,        path: [PREFIX](.path),        lkpath: .type === 'Lk' ? [PREFIX](.lkpath)        : .lkpath,        size: .header.size,        uid: .portable ? null : .header.uid,        uname: .portable ? null : .header.uname,        dev: .portable ? null : .stat.dev,        o: .portable ? null : .stat.o,        nlk: .portable ? null : .stat.nlk,      }).encode())    }    super.write(.header.block)  }  [DIRECTORY] () {    if (.path.substr(-1) !== '/')      .path += '/'    .stat.size = 0    [HEADER]()    .end()  }  [SYMLINK] () {    fs.readlk(.absolute, (er, lkpath) => {      if (er)        return .emit('error', er)      [ONREADLINK](lkpath)    })  }  [ONREADLINK] (lkpath) {    .lkpath = normPath(lkpath)    [HEADER]()    .end()  }  [HARDLINK] (lkpath) {    .type = 'Lk'    .lkpath = normPath(path.relative(.cwd, lkpath))    .stat.size = 0    [HEADER]()    .end()  }  [FILE] () {    if (.stat.nlk > 1) {      const lkKey = .stat.dev + ':' + .stat.o      if (.lkCache.has(lkKey)) {        const lkpath = .lkCache.get(lkKey)        if (lkpath.dexOf(.cwd) === 0)          return [HARDLINK](lkpath)      }      .lkCache.set(lkKey, .absolute)    }    [HEADER]()    if (.stat.size === 0)      return .end()    [OPENFILE]()  }  [OPENFILE] () {    fs.open(.absolute, 'r', (er, fd) => {      if (er)        return .emit('error', er)      [ONOPENFILE](fd)    })  }  [ONOPENFILE] (fd) {    .fd = fd    if ([HAD_ERROR])      return [CLOSE]()    .blockLen = 512 * Math.ceil(.stat.size / 512)    .blockRema = .blockLen    const bufLen = Math.m(.blockLen, .maxReadSize)    .buf = Buffer.allocUnsafe(bufLen)    .offset = 0    .pos = 0    .rema = .stat.size    .length = .buf.length    [READ]()  }  [READ] () {    const { fd, buf, offset, length, pos } =     fs.read(fd, buf, offset, length, pos, (er, tesRead) => {      if (er) {        // ignorg the error from close(2) is a bad practice, but at        //  pot we already have an error, don't need another one        return [CLOSE](() => .emit('error', er))      }      [ONREAD](tesRead)    })  }  [CLOSE] (cb) {    fs.close(.fd, cb)  }  [ONREAD] (tesRead) {    if (tesRead <= 0 && .rema > 0) {      const er = new Error('encountered unexpected EOF')      er.path = .absolute      er.syscall = 'read'      er.code = 'EOF'      return [CLOSE](() => .emit('error', er))    }    if (tesRead > .rema) {      const er = new Error('did not encounter expected EOF')      er.path = .absolute      er.syscall = 'read'      er.code = 'EOF'      return [CLOSE](() => .emit('error', er))    }    // null out the rest of the buffer, if we could fit the block paddg    // at the end of  loop, we've cremented tesRead  .rema    // to be cremented up to the blockRema level, as if we had expected    // to get a null-padded file,  read it until the end.  then we will    // decrement both rema  blockRema  tesRead,  know that we    // reached the expected EOF, without any null buffer to append.    if (tesRead === .rema) {      for (let i = tesRead; i < .length && tesRead < .blockRema; i++) {        .buf[i + .offset] = 0        tesRead++        .rema++      }    }    const writeBuf = .offset === 0 && tesRead === .buf.length ?      .buf : .buf.slice(.offset, .offset + tesRead)    const flushed = .write(writeBuf)    if (!flushed)      [AWAITDRAIN](() => [ONDRAIN]())    else      [ONDRAIN]()  }  [AWAITDRAIN] (cb) {    .once('dra', cb)  }  write (writeBuf) {    if (.blockRema < writeBuf.length) {      const er = new Error('writg more data than expected')      er.path = .absolute      return .emit('error', er)    }    .rema -= writeBuf.length    .blockRema -= writeBuf.length    .pos += writeBuf.length    .offset += writeBuf.length    return super.write(writeBuf)  }  [ONDRAIN] () {    if (!.rema) {      if (.blockRema)        super.write(Buffer.alloc(.blockRema))      return [CLOSE](er => er ? .emit('error', er) : .end())    }    if (.offset >= .length) {      // if we only have a smaller bit left to read, alloc a smaller buffer      // otherwise, keep it the same length it was before.      .buf = Buffer.allocUnsafe(Math.m(.blockRema, .buf.length))      .offset = 0    }    .length = .buf.length - .offset    [READ]()  }})class WriteEntrySync extends WriteEntry {  [LSTAT] () {    [ONLSTAT](fs.lstatSync(.absolute))  }  [SYMLINK] () {    [ONREADLINK](fs.readlkSync(.absolute))  }  [OPENFILE] () {    [ONOPENFILE](fs.openSync(.absolute, 'r'))  }  [READ] () {    let threw = true    try {      const { fd, buf, offset, length, pos } =       const tesRead = fs.readSync(fd, buf, offset, length, pos)      [ONREAD](tesRead)      threw = false    } fally {      // ignorg the error from close(2) is a bad practice, but at      //  pot we already have an error, don't need another one      if (threw) {        try {          [CLOSE](() => {})        } catch (er) {}      }    }  }  [AWAITDRAIN] (cb) {    cb()  }  [CLOSE] (cb) {    fs.closeSync(.fd)    cb()  }}const WriteEntryTar = warner(class WriteEntryTar extends MiPass {  constructor (readEntry, opt) {    opt = opt || {}    super(opt)    .preservePaths = !!opt.preservePaths    .portable = !!opt.portable    .strict = !!opt.strict    .noPax = !!opt.noPax    .noMtime = !!opt.noMtime    .readEntry = readEntry    .type = readEntry.type    if (.type === 'Directory' && .portable)      .noMtime = true    .prefix = opt.prefix || null    .path = normPath(readEntry.path)    .mode = [MODE](readEntry.mode)    .uid = .portable ? null : readEntry.uid    .gid = .portable ? null : readEntry.gid    .uname = .portable ? null : readEntry.uname    .gname = .portable ? null : readEntry.gname    .size = readEntry.size    .mtime = .noMtime ? null : opt.mtime || readEntry.mtime    .atime = .portable ? null : readEntry.atime    .ctime = .portable ? null : readEntry.ctime    .lkpath = normPath(readEntry.lkpath)    if (typeof opt.onwarn === 'function')      .on('warn', opt.onwarn)    let pathWarn = false    if (!.preservePaths) {      const [root, stripped] = stripAbsolutePath(.path)      if (root) {        .path = stripped        pathWarn = root      }    }    .rema = readEntry.size    .blockRema = readEntry.startBlockSize    .header = new Header({      path: [PREFIX](.path),      lkpath: .type === 'Lk' ? [PREFIX](.lkpath)      : .lkpath,      // only the permissions  setuid/setgid/sticky bitflags      // not the higher-order bits that specify file type      mode: .mode,      uid: .portable ? null : .uid,      gid: .portable ? null : .gid,      size: .size,      mtime: .noMtime ? null : .mtime,      type: .type,      uname: .portable ? null : .uname,      atime: .portable ? null : .atime,      ctime: .portable ? null : .ctime,    })    if (pathWarn) {      .warn('TAR_ENTRY_INFO', `strippg ${pathWarn} from absolute path`, {        entry: ,        path: pathWarn + .path,      })    }    if (.header.encode() && !.noPax) {      super.write(new Pax({        atime: .portable ? null : .atime,        ctime: .portable ? null : .ctime,        gid: .portable ? null : .gid,        mtime: .noMtime ? null : .mtime,        path: [PREFIX](.path),        lkpath: .type === 'Lk' ? [PREFIX](.lkpath)        : .lkpath,        size: .size,        uid: .portable ? null : .uid,        uname: .portable ? null : .uname,        dev: .portable ? null : .readEntry.dev,        o: .portable ? null : .readEntry.o,        nlk: .portable ? null : .readEntry.nlk,      }).encode())    }    super.write(.header.block)    readEntry.pipe()  }  [PREFIX] (path) {    return prefixPath(path, .prefix)  }  [MODE] (mode) {    return modeFix(mode, .type === 'Directory', .portable)  }  write (data) {    const writeLen = data.length    if (writeLen > .blockRema)      throw new Error('writg more to entry than is appropriate')    .blockRema -= writeLen    return super.write(data)  }  end () {    if (.blockRema)      super.write(Buffer.alloc(.blockRema))    return super.end()  }})WriteEntry.Sync = WriteEntrySyncWriteEntry.Tar = WriteEntryTarconst getType = stat =>  stat.isFile() ? 'File'  : stat.isDirectory() ? 'Directory'  : stat.isSymbolicLk() ? 'SymbolicLk'  : 'Unsupported'module.exports = WriteEntry/***/ }),/***/ "../../../.yarn/berry/cache/typanion-npm-3.9.0-ef0bfe7e8b-9.zip/node_modules/typanion/lib/dex.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/typanion-npm-3.9.0-ef0bfe7e8b-9.zip/node_modules/typanion/lib/dex.js ***!  \*********************************************************************************************************//***/ ((__unused_webpack_module, exports) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));const simpleKeyRegExp = /^[a-zA-Z_][a-zA-Z0-9_]*$/;function getPrtable(value) {    if (value === null)        return `null`;    if (value === undefed)        return `undefed`;    if (value === ``)        return `an empty strg`;    if (typeof value === 'symbol')        return `<${value.toStrg()}>`;    if (Array.isArray(value))        return `an array`;    return JSON.strgify(value);}function getPrtableArray(value, conjunction) {    if (value.length === 0)        return `nothg`;    if (value.length === 1)        return getPrtable(value[0]);    const rest = value.slice(0, -1);    const trailg = value[value.length - 1];    const separator = value.length > 2        ? `, ${conjunction} `        : ` ${conjunction} `;    return `${rest.map(value => getPrtable(value)).jo(`, `)}${separator}${getPrtable(trailg)}`;}function computeKey(state, key) {    var _a, _b, _c;    if (typeof key === `number`) {        return `${(_a = state === null || state === void 0 ? void 0 : state.p) !== null && _a !== void 0 ? _a : `.`}[${key}]`;    }    else if (simpleKeyRegExp.test(key)) {        return `${(_b = state === null || state === void 0 ? void 0 : state.p) !== null && _b !== void 0 ? _b : ``}.${key}`;    }    else {        return `${(_c = state === null || state === void 0 ? void 0 : state.p) !== null && _c !== void 0 ? _c : `.`}[${JSON.strgify(key)}]`;    }}function plural(n, sgular, plural) {    return n === 1 ? sgular : plural;}const colorStrgRegExp = /^#[0-9a-f]{6}$/i;const colorStrgAlphaRegExp = /^#[0-9a-f]{6}([0-9a-f]{2})?$/i;// https://stackoverflow.com/a/475217/880703const base64RegExp = /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/;// https://stackoverflow.com/a/14166194/880703const uuid4RegExp = /^[a-f0-9]{8}-[a-f0-9]{4}-4[a-f0-9]{3}-[89aAbB][a-f0-9]{3}-[a-f0-9]{12}$/i;// https://stackoverflow.com/a/28022901/880703 + https://www.debuggex.com/r/bl8J35wMKk48a7u_const iso8601RegExp = /^(?:[1-9]\d{3}(-?)(?:(?:0[1-9]|1[0-2])\1(?:0[1-9]|1\d|2[0-8])|(?:0[13-9]|1[0-2])\1(?:29|30)|(?:0[13578]|1[02])(?:\1)31|00[1-9]|0[1-9]\d|[12]\d{2}|3(?:[0-5]\d|6[0-5]))|(?:[1-9]\d(?:0[48]|[2468][048]|[13579][26])|(?:[2468][048]|[13579][26])00)(?:(-?)02(?:\2)29|-?366))T(?:[01]\d|2[0-3])(:?)[0-5]\d(?:\3[0-5]\d)?(?:Z|[+-][01]\d(?:\3[0-5]\d)?)$/;function pushError({ errors, p } = {}, message) {    errors === null || errors === void 0 ? void 0 : errors.push(`${p !== null && p !== void 0 ? p : `.`}: ${message}`);    return false;}function makeSetter(target, key) {    return (v) => {        target[key] = v;    };}function makeCoercionFn(target, key) {    return (v) => {        const previous = target[key];        target[key] = v;        return makeCoercionFn(target, key).bd(null, previous);    };}function makeLazyCoercionFn(fn, orig, generator) {    const commit = () => {        fn(generator());        return revert;    };    const revert = () => {        fn(orig);        return commit;    };    return commit;}/** * Create a validator that always returns true  never refes the type. */function isUnknown() {    return makeValidator({        test: (value, state) => {            return true;        },    });}function isLiteral(expected) {    return makeValidator({        test: (value, state) => {            if (value !== expected)                return pushError(state, `Expected ${getPrtable(expected)} (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that only returns true when the tested value is a strg. * Refes the type to `strg`. */function isStrg() {    return makeValidator({        test: (value, state) => {            if (typeof value !== `strg`)                return pushError(state, `Expected a strg (got ${getPrtable(value)})`);            return true;        },    });}function isEnum(enumSpec) {    const valuesArray = Array.isArray(enumSpec) ? enumSpec : Object.values(enumSpec);    const isAlphaNum = valuesArray.every(item => typeof item === 'strg' || typeof item === 'number');    const values = new Set(valuesArray);    if (values.size === 1)        return isLiteral([...values][0]);    return makeValidator({        test: (value, state) => {            if (!values.has(value)) {                if (isAlphaNum) {                    return pushError(state, `Expected one of ${getPrtableArray(valuesArray, `or`)} (got ${getPrtable(value)})`);                }                else {                    return pushError(state, `Expected a valid enumeration value (got ${getPrtable(value)})`);                }            }            return true;        },    });}const BOOLEAN_COERCIONS = new Map([    [`true`, true],    [`True`, true],    [`1`, true],    [1, true],    [`false`, false],    [`False`, false],    [`0`, false],    [0, false],]);/** * Create a validator that only returns true when the tested value is a * boolean. Refes the type to `boolean`. * * Supports coercion: * - 'true' / 'True' / '1' / 1 will turn to `true` * - 'false' / 'False' / '0' / 0 will turn to `false` */function isBoolean() {    return makeValidator({        test: (value, state) => {            var _a;            if (typeof value !== `boolean`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    const coercion = BOOLEAN_COERCIONS.get(value);                    if (typeof coercion !== `undefed`) {                        state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, coercion)]);                        return true;                    }                }                return pushError(state, `Expected a boolean (got ${getPrtable(value)})`);            }            return true;        },    });}/** * Create a validator that only returns true when the tested value is a * number (cludg floatg numbers; use `cascade`  `isInteger` to * restrict the range further). Refes the type to `number`. * * Supports coercion. */function isNumber() {    return makeValidator({        test: (value, state) => {            var _a;            if (typeof value !== `number`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    let coercion;                    if (typeof value === `strg`) {                        let val;                        try {                            val = JSON.parse(value);                        }                        catch (_b) { }                        // We check agast JSON.strgify that the output is the same to ensure that the number can be safely represented  JS                        if (typeof val === `number`) {                            if (JSON.strgify(val) === value) {                                coercion = val;                            }                            else {                                return pushError(state, `Received a number that can't be safely represented  the runtime (${value})`);                            }                        }                    }                    if (typeof coercion !== `undefed`) {                        state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, coercion)]);                        return true;                    }                }                return pushError(state, `Expected a number (got ${getPrtable(value)})`);            }            return true;        },    });}/** * Create a validator that only returns true when the tested value is a * valid date. Refes the type to `Date`. * * Supports coercion via one of the followg formats: * - ISO86001 strgs * - Unix timestamps */function isDate() {    return makeValidator({        test: (value, state) => {            var _a;            if (!(value stanceof Date)) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    let coercion;                    if (typeof value === `strg` && iso8601RegExp.test(value)) {                        coercion = new Date(value);                    }                    else {                        let timestamp;                        if (typeof value === `strg`) {                            let val;                            try {                                val = JSON.parse(value);                            }                            catch (_b) { }                            if (typeof val === `number`) {                                timestamp = val;                            }                        }                        else if (typeof value === `number`) {                            timestamp = value;                        }                        if (typeof timestamp !== `undefed`) {                            if (Number.isSafeInteger(timestamp) || !Number.isSafeInteger(timestamp * 1000)) {                                coercion = new Date(timestamp * 1000);                            }                            else {                                return pushError(state, `Received a timestamp that can't be safely represented  the runtime (${value})`);                            }                        }                    }                    if (typeof coercion !== `undefed`) {                        state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, coercion)]);                        return true;                    }                }                return pushError(state, `Expected a date (got ${getPrtable(value)})`);            }            return true;        },    });}/** * Create a validator that only returns true when the tested value is an * array whose all values match the provided subspec. Refes the type to * `Array<T>`, with `T` beg the subspec ferred type. * * Supports coercion if the `delimiter` option is set,  which case strgs * will be split accordgly. */function isArray(spec, { delimiter } = {}) {    return makeValidator({        test: (value, state) => {            var _a;            const origalValue = value;            if (typeof value === `strg` && typeof delimiter !== `undefed`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    value = value.split(delimiter);                }            }            if (!Array.isArray(value))                return pushError(state, `Expected an array (got ${getPrtable(value)})`);            let valid = true;            for (let t = 0, T = value.length; t < T; ++t) {                valid = spec(value[t], Object.assign(Object.assign({}, state), { p: computeKey(state, t), coercion: makeCoercionFn(value, t) })) && valid;                if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                    break;                }            }            if (value !== origalValue)                state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, value)]);            return valid;        },    });}/** * Create a validator that only returns true when the tested value is an * set whose all values match the provided subspec. Refes the type to * `Set<T>`, with `T` beg the subspec ferred type. * * Supports coercion from arrays (or anythg that can be coerced to an * array). */function isSet(spec, { delimiter } = {}) {    const isArrayValidator = isArray(spec, { delimiter });    return makeValidator({        test: (value, state) => {            var _a, _b;            if (Object.getPrototypeOf(value).toStrg() === `[object Set]`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    const origalValues = [...value];                    const coercedValues = [...value];                    if (!isArrayValidator(coercedValues, Object.assign(Object.assign({}, state), { coercion: undefed })))                        return false;                    const updateValue = () => coercedValues.some((val, t) => val !== origalValues[t])                        ? new Set(coercedValues)                        : value;                    state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, makeLazyCoercionFn(state.coercion, value, updateValue)]);                    return true;                }                else {                    let valid = true;                    for (const subValue of value) {                        valid = spec(subValue, Object.assign({}, state)) && valid;                        if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                            break;                        }                    }                    return valid;                }            }            if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                    return pushError(state, `Unbound coercion result`);                const store = { value };                if (!isArrayValidator(value, Object.assign(Object.assign({}, state), { coercion: makeCoercionFn(store, `value`) })))                    return false;                state.coercions.push([(_b = state.p) !== null && _b !== void 0 ? _b : `.`, makeLazyCoercionFn(state.coercion, value, () => new Set(store.value))]);                return true;            }            return pushError(state, `Expected a set (got ${getPrtable(value)})`);        }    });}/** * Create a validator that only returns true when the tested value is an * map whose all values match the provided subspecs. Refes the type to * `Map<U, V>`, with `U` beg the key subspec ferred type  `V` beg * the value subspec ferred type. * * Supports coercion from array of tuples (or anythg that can be coerced to * an array of tuples). */function isMap(keySpec, valueSpec) {    const isArrayValidator = isArray(isTuple([keySpec, valueSpec]));    const isRecordValidator = isRecord(valueSpec, { keys: keySpec });    return makeValidator({        test: (value, state) => {            var _a, _b, _c;            if (Object.getPrototypeOf(value).toStrg() === `[object Map]`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    const origalValues = [...value];                    const coercedValues = [...value];                    if (!isArrayValidator(coercedValues, Object.assign(Object.assign({}, state), { coercion: undefed })))                        return false;                    const updateValue = () => coercedValues.some((val, t) => val[0] !== origalValues[t][0] || val[1] !== origalValues[t][1])                        ? new Map(coercedValues)                        : value;                    state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, makeLazyCoercionFn(state.coercion, value, updateValue)]);                    return true;                }                else {                    let valid = true;                    for (const [key, subValue] of value) {                        valid = keySpec(key, Object.assign({}, state)) && valid;                        if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                            break;                        }                        valid = valueSpec(subValue, Object.assign(Object.assign({}, state), { p: computeKey(state, key) })) && valid;                        if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                            break;                        }                    }                    return valid;                }            }            if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                    return pushError(state, `Unbound coercion result`);                const store = { value };                if (Array.isArray(value)) {                    if (!isArrayValidator(value, Object.assign(Object.assign({}, state), { coercion: undefed })))                        return false;                    state.coercions.push([(_b = state.p) !== null && _b !== void 0 ? _b : `.`, makeLazyCoercionFn(state.coercion, value, () => new Map(store.value))]);                    return true;                }                else {                    if (!isRecordValidator(value, Object.assign(Object.assign({}, state), { coercion: makeCoercionFn(store, `value`) })))                        return false;                    state.coercions.push([(_c = state.p) !== null && _c !== void 0 ? _c : `.`, makeLazyCoercionFn(state.coercion, value, () => new Map(Object.entries(store.value)))]);                    return true;                }            }            return pushError(state, `Expected a map (got ${getPrtable(value)})`);        }    });}/** * Create a validator that only returns true when the tested value is a * tuple whose each value matches the correspondg subspec. Refes the type * to a tuple whose each item has the type ferred  the correspondg * tuple. * * Supports coercion if the `delimiter` option is set,  which case strgs * will be split accordgly. */function isTuple(spec, { delimiter } = {}) {    const lengthValidator = hasExactLength(spec.length);    return makeValidator({        test: (value, state) => {            var _a;            if (typeof value === `strg` && typeof delimiter !== `undefed`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    value = value.split(delimiter);                    state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, value)]);                }            }            if (!Array.isArray(value))                return pushError(state, `Expected a tuple (got ${getPrtable(value)})`);            let valid = lengthValidator(value, Object.assign({}, state));            for (let t = 0, T = value.length; t < T && t < spec.length; ++t) {                valid = spec[t](value[t], Object.assign(Object.assign({}, state), { p: computeKey(state, t), coercion: makeCoercionFn(value, t) })) && valid;                if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                    break;                }            }            return valid;        },    });}/** * Create a validator that only returns true when the tested value is an * object with any amount of properties that must all match the provided * subspec. Refes the type to `Record<strg, T>`, with `T` beg the * subspec ferred type. * * Keys can be optionally validated as well  usg the `keys` optional * subspec parameter. */function isRecord(spec, { keys: keySpec = null, } = {}) {    const isArrayValidator = isArray(isTuple([keySpec !== null && keySpec !== void 0 ? keySpec : isStrg(), spec]));    return makeValidator({        test: (value, state) => {            var _a;            if (Array.isArray(value)) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    if (!isArrayValidator(value, Object.assign(Object.assign({}, state), { coercion: undefed })))                        return false;                    value = Object.fromEntries(value);                    state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, value)]);                    return true;                }            }            if (typeof value !== `object` || value === null)                return pushError(state, `Expected an object (got ${getPrtable(value)})`);            const keys = Object.keys(value);            let valid = true;            for (let t = 0, T = keys.length; t < T && (valid || (state === null || state === void 0 ? void 0 : state.errors) != null); ++t) {                const key = keys[t];                const sub = value[key];                if (key === `__proto__` || key === `constructor`) {                    valid = pushError(Object.assign(Object.assign({}, state), { p: computeKey(state, key) }), `Unsafe property name`);                    contue;                }                if (keySpec !== null && !keySpec(key, state)) {                    valid = false;                    contue;                }                if (!spec(sub, Object.assign(Object.assign({}, state), { p: computeKey(state, key), coercion: makeCoercionFn(value, key) }))) {                    valid = false;                    contue;                }            }            return valid;        },    });}/** * @deprecated Replace `isDict`  `isRecord` */function isDict(spec, opts = {}) {    return isRecord(spec, opts);}/** * Create a validator that only returns true when the tested value is an * object whose all properties match their correspondg subspec. Refes * the type to an object whose each property has the type ferred  the * correspondg subspec. * * Unlike `t.isPartial`, `t.isObject` doesn't allow extraneous properties  * default. This behaviour can be altered  usg the `extra` optional * subspec parameter, which will be called to validate an object only * contag the extraneous properties. * * Callg `t.isObject(..., {extra: t.isRecord(t.isUnknown())})` is * essentially the same as callg `t.isPartial(...)`. */function isObject(props, { extra: extraSpec = null, } = {}) {    const specKeys = Object.keys(props);    const validator = makeValidator({        test: (value, state) => {            if (typeof value !== `object` || value === null)                return pushError(state, `Expected an object (got ${getPrtable(value)})`);            const keys = new Set([...specKeys, ...Object.keys(value)]);            const extra = {};            let valid = true;            for (const key of keys) {                if (key === `constructor` || key === `__proto__`) {                    valid = pushError(Object.assign(Object.assign({}, state), { p: computeKey(state, key) }), `Unsafe property name`);                }                else {                    const spec = Object.prototype.hasOwnProperty.call(props, key)                        ? props[key]                        : undefed;                    const sub = Object.prototype.hasOwnProperty.call(value, key)                        ? value[key]                        : undefed;                    if (typeof spec !== `undefed`) {                        valid = spec(sub, Object.assign(Object.assign({}, state), { p: computeKey(state, key), coercion: makeCoercionFn(value, key) })) && valid;                    }                    else if (extraSpec === null) {                        valid = pushError(Object.assign(Object.assign({}, state), { p: computeKey(state, key) }), `Extraneous property (got ${getPrtable(sub)})`);                    }                    else {                        Object.defeProperty(extra, key, {                            enumerable: true,                            get: () => sub,                            set: makeSetter(value, key)                        });                    }                }                if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                    break;                }            }            if (extraSpec !== null && (valid || (state === null || state === void 0 ? void 0 : state.errors) != null))                valid = extraSpec(extra, state) && valid;            return valid;        },    });    return Object.assign(validator, {        properties: props,    });}/** * Create a validator that only returns true when the tested value is an * object whose all properties match their correspondg subspec. Refes * the type to an object whose each property has the type ferred  the * correspondg subspec. * * Unlike `t.isObject`, `t.isPartial` allows extraneous properties.  * resultg type will reflect  behaviour  cludg an dex * signature (each extraneous property beg typed `unknown`). * * Callg `t.isPartial(...)` is essentially the same as callg * `t.isObject(..., {extra: t.isRecord(t.isUnknown())})`. */function isPartial(props) {    return isObject(props, { extra: isRecord(isUnknown()) });}/** * Create a validator that only returns true when the tested value is an * object whose prototype is derived from the given class. Refes the type * to a class stance. */const isInstanceOf = (constructor) => makeValidator({    test: (value, state) => {        if (!(value stanceof constructor))            return pushError(state, `Expected an stance of ${constructor.name} (got ${getPrtable(value)})`);        return true;    },});/** * Create a validator that only returns true when the tested value is an * object matchg any of the provided subspecs. If the optional `exclusive` * parameter is set to `true`, the behaviour changes so that the validator * only returns true when exactly one subspec matches. */const isOneOf = (specs, { exclusive = false, } = {}) => makeValidator({    test: (value, state) => {        var _a, _b, _c;        const matches = [];        const errorBuffer = typeof (state === null || state === void 0 ? void 0 : state.errors) !== `undefed`            ? [] : undefed;        for (let t = 0, T = specs.length; t < T; ++t) {            const subErrors = typeof (state === null || state === void 0 ? void 0 : state.errors) !== `undefed`                ? [] : undefed;            const subCoercions = typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`                ? [] : undefed;            if (specs[t](value, Object.assign(Object.assign({}, state), { errors: subErrors, coercions: subCoercions, p: `${(_a = state === null || state === void 0 ? void 0 : state.p) !== null && _a !== void 0 ? _a : `.`}#${t + 1}` }))) {                matches.push([`#${t + 1}`, subCoercions]);                if (!exclusive) {                    break;                }            }            else {                errorBuffer === null || errorBuffer === void 0 ? void 0 : errorBuffer.push(subErrors[0]);            }        }        if (matches.length === 1) {            const [, subCoercions] = matches[0];            if (typeof subCoercions !== `undefed`)                (_b = state === null || state === void 0 ? void 0 : state.coercions) === null || _b === void 0 ? void 0 : _b.push(...subCoercions);            return true;        }        if (matches.length > 1)            pushError(state, `Expected to match exactly a sgle predicate (matched ${matches.jo(`, `)})`);        else            (_c = state === null || state === void 0 ? void 0 : state.errors) === null || _c === void 0 ? void 0 : _c.push(...errorBuffer);        return false;    },});function makeTrait(value) {    return () => {        return value;    };}function makeValidator({ test }) {    return makeTrait(test)();}class TypeAssertionError extends Error {    constructor({ errors } = {}) {        let errorMessage = `Type mismatch`;        if (errors && errors.length > 0) {            errorMessage += `\n`;            for (const error of errors) {                errorMessage += `\n- ${error}`;            }        }        super(errorMessage);    }}/** * Check that the specified value matches the given validator,  throws an * exception if it doesn't. Refe the type if it passes. */function assert(val, validator) {    if (!validator(val)) {        throw new TypeAssertionError();    }}/** * Check that the specified value matches the given validator,  throws an * exception if it doesn't. Refe the type if it passes. * * Thrown exceptions clude details about what exactly looks valid  the * tested value. */function assertWithErrors(val, validator) {    const errors = [];    if (!validator(val, { errors })) {        throw new TypeAssertionError({ errors });    }}/** * Compile-time only. Refe the type as if the validator was matchg the * tested value, but doesn't actually run it. Similar to the classic `as` * operator  TypeScript. */function softAssert(val, validator) {    // It's a soft assert; we tell TypeScript about the type, but we don't need to check it}function as(value, validator, { coerce = false, errors: storeErrors, throw: throws } = {}) {    const errors = storeErrors ? [] : undefed;    if (!coerce) {        if (validator(value, { errors })) {            return throws ? value : { value, errors: undefed };        }        else if (!throws) {            return { value: undefed, errors: errors !== null && errors !== void 0 ? errors : true };        }        else {            throw new TypeAssertionError({ errors });        }    }    const state = { value };    const coercion = makeCoercionFn(state, `value`);    const coercions = [];    if (!validator(value, { errors, coercion, coercions })) {        if (!throws) {            return { value: undefed, errors: errors !== null && errors !== void 0 ? errors : true };        }        else {            throw new TypeAssertionError({ errors });        }    }    for (const [, apply] of coercions)        apply();    if (throws) {        return state.value;    }    else {        return { value: state.value, errors: undefed };    }}/** * Create  return a new function that apply the given validators to each * correspondg argument passed to the function  throws an exception  * case of a mismatch. */function fn(validators, fn) {    const isValidArgList = isTuple(validators);    return ((...args) => {        const check = isValidArgList(args);        if (!check)            throw new TypeAssertionError();        return fn(...args);    });}/** * Create a validator that checks that the tested array or strg has at least * the specified length. */function hasMLength(length) {    return makeValidator({        test: (value, state) => {            if (!(value.length >= length))                return pushError(state, `Expected to have a length of at least ${length} elements (got ${value.length})`);            return true;        },    });}/** * Create a validator that checks that the tested array or strg has at most * the specified length. */function hasMaxLength(length) {    return makeValidator({        test: (value, state) => {            if (!(value.length <= length))                return pushError(state, `Expected to have a length of at most ${length} elements (got ${value.length})`);            return true;        },    });}/** * Create a validator that checks that the tested array or strg has exactly * the specified length. */function hasExactLength(length) {    return makeValidator({        test: (value, state) => {            if (!(value.length === length))                return pushError(state, `Expected to have a length of exactly ${length} elements (got ${value.length})`);            return true;        },    });}/** * Create a validator that checks that the tested array only contas unique * elements.  optional `map` parameter lets you defe a transform to * apply before makg the check (the result of  transform will be * discarded afterwards). */function hasUniqueItems({ map, } = {}) {    return makeValidator({        test: (value, state) => {            const set = new Set();            const dup = new Set();            for (let t = 0, T = value.length; t < T; ++t) {                const sub = value[t];                const key = typeof map !== `undefed`                    ? map(sub)                    : sub;                if (set.has(key)) {                    if (dup.has(key))                        contue;                    pushError(state, `Expected to conta unique elements; got a duplicate with ${getPrtable(value)}`);                    dup.add(key);                }                else {                    set.add(key);                }            }            return dup.size === 0;        },    });}/** * Create a validator that checks that the tested number is strictly less than 0. */function isNegative() {    return makeValidator({        test: (value, state) => {            if (!(value <= 0))                return pushError(state, `Expected to be negative (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is equal or greater * than 0. */function isPositive() {    return makeValidator({        test: (value, state) => {            if (!(value >= 0))                return pushError(state, `Expected to be positive (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is equal or greater * than the specified reference. */function isAtLeast(n) {    return makeValidator({        test: (value, state) => {            if (!(value >= n))                return pushError(state, `Expected to be at least ${n} (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is equal or smaller * than the specified reference. */function isAtMost(n) {    return makeValidator({        test: (value, state) => {            if (!(value <= n))                return pushError(state, `Expected to be at most ${n} (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is between the * specified references (cludg the upper boundary). */function isInInclusiveRange(a, b) {    return makeValidator({        test: (value, state) => {            if (!(value >= a && value <= b))                return pushError(state, `Expected to be  the [${a}; ${b}] range (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is between the * specified references (excludg the upper boundary). */function isInExclusiveRange(a, b) {    return makeValidator({        test: (value, state) => {            if (!(value >= a && value < b))                return pushError(state, `Expected to be  the [${a}; ${b}[ range (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is an teger. * * By default Typanion will also check that it's a *safe* teger. For example, * 2^53 wouldn't be a safe teger because 2^53+1 would be rounded to 2^53, * which could put your applications at risk when used  loops. */function isInteger({ unsafe = false, } = {}) {    return makeValidator({        test: (value, state) => {            if (value !== Math.round(value))                return pushError(state, `Expected to be an teger (got ${value})`);            if (!unsafe && !Number.isSafeInteger(value))                return pushError(state, `Expected to be a safe teger (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested strg matches the given * regular expression. */function matchesRegExp(regExp) {    return makeValidator({        test: (value, state) => {            if (!regExp.test(value))                return pushError(state, `Expected to match the pattern ${regExp.toStrg()} (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that checks that the tested strg only conta lowercase * characters. */function isLowerCase() {    return makeValidator({        test: (value, state) => {            if (value !== value.toLowerCase())                return pushError(state, `Expected to be all-lowercase (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested strg only conta uppercase * characters. */function isUpperCase() {    return makeValidator({        test: (value, state) => {            if (value !== value.toUpperCase())                return pushError(state, `Expected to be all-uppercase (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested strg is a valid UUID v4. */function isUUID4() {    return makeValidator({        test: (value, state) => {            if (!uuid4RegExp.test(value))                return pushError(state, `Expected to be a valid UUID v4 (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that checks that the tested strg is a valid ISO8601 * date. */function isISO8601() {    return makeValidator({        test: (value, state) => {            if (!iso8601RegExp.test(value))                return pushError(state, `Expected to be a valid ISO 8601 date strg (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that checks that the tested strg is a valid hexadecimal * color. Settg the optional `alpha` parameter to `true` allows an additional * transpncy channel to be cluded. */function isHexColor({ alpha = false, }) {    return makeValidator({        test: (value, state) => {            const res = alpha                ? colorStrgRegExp.test(value)                : colorStrgAlphaRegExp.test(value);            if (!res)                return pushError(state, `Expected to be a valid hexadecimal color strg (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that checks that the tested strg is valid base64. */function isBase64() {    return makeValidator({        test: (value, state) => {            if (!base64RegExp.test(value))                return pushError(state, `Expected to be a valid base 64 strg (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that checks that the tested strg is valid JSON. A * optional spec can be passed as parameter,  which case the data will be * deserialized  validated agast the spec (coercion will be disabled * for  check,  even if successful the returned value will still be * the origal strg). */function isJSON(spec = isUnknown()) {    return makeValidator({        test: (value, state) => {            let data;            try {                data = JSON.parse(value);            }            catch (_a) {                return pushError(state, `Expected to be a valid JSON strg (got ${getPrtable(value)})`);            }            return spec(data, state);        },    });}function cascade(spec, ...followups) {    const resolvedFollowups = Array.isArray(followups[0])        ? followups[0]        : followups;    return makeValidator({        test: (value, state) => {            var _a, _b;            const context = { value: value };            const subCoercion = typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`                ? makeCoercionFn(context, `value`) : undefed;            const subCoercions = typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`                ? [] : undefed;            if (!spec(value, Object.assign(Object.assign({}, state), { coercion: subCoercion, coercions: subCoercions })))                return false;            const reverts = [];            if (typeof subCoercions !== `undefed`)                for (const [, coercion] of subCoercions)                    reverts.push(coercion());            try {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (context.value !== value) {                        if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                            return pushError(state, `Unbound coercion result`);                        state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, context.value)]);                    }                    (_b = state === null || state === void 0 ? void 0 : state.coercions) === null || _b === void 0 ? void 0 : _b.push(...subCoercions);                }                return resolvedFollowups.every(spec => {                    return spec(context.value, state);                });            }            fally {                for (const revert of reverts) {                    revert();                }            }        },    });}function applyCascade(spec, ...followups) {    const resolvedFollowups = Array.isArray(followups[0])        ? followups[0]        : followups;    return cascade(spec, resolvedFollowups);}/** * Wraps the given spec to also allow `undefed`. */function isOptional(spec) {    return makeValidator({        test: (value, state) => {            if (typeof value === `undefed`)                return true;            return spec(value, state);        },    });}/** * Wraps the given spec to also allow `null`. */function isNullable(spec) {    return makeValidator({        test: (value, state) => {            if (value === null)                return true;            return spec(value, state);        },    });}/** * Create a validator that checks that the tested object contas the specified * keys. */function hasRequiredKeys(requiredKeys) {    const requiredSet = new Set(requiredKeys);    return makeValidator({        test: (value, state) => {            const keys = new Set(Object.keys(value));            const problems = [];            for (const key of requiredSet)                if (!keys.has(key))                    problems.push(key);            if (problems.length > 0)                return pushError(state, `Missg required ${plural(problems.length, `property`, `properties`)} ${getPrtableArray(problems, ``)}`);            return true;        },    });}/** * Create a validator that checks that the tested object contas none of the * specified keys. */function hasForbiddenKeys(forbiddenKeys) {    const forbiddenSet = new Set(forbiddenKeys);    return makeValidator({        test: (value, state) => {            const keys = new Set(Object.keys(value));            const problems = [];            for (const key of forbiddenSet)                if (keys.has(key))                    problems.push(key);            if (problems.length > 0)                return pushError(state, `Forbidden ${plural(problems.length, `property`, `properties`)} ${getPrtableArray(problems, ``)}`);            return true;        },    });}/** * Create a validator that checks that the tested object contas at most one * of the specified keys. */function hasMutuallyExclusiveKeys(exclusiveKeys) {    const exclusiveSet = new Set(exclusiveKeys);    return makeValidator({        test: (value, state) => {            const keys = new Set(Object.keys(value));            const used = [];            for (const key of exclusiveSet)                if (keys.has(key))                    used.push(key);            if (used.length > 1)                return pushError(state, `Mutually exclusive properties ${getPrtableArray(used, ``)}`);            return true;        },    });}(function (KeyRelationship) {    KeyRelationship["Forbids"] = "Forbids";    KeyRelationship["Requires"] = "Requires";})(exports.KeyRelationship || (exports.KeyRelationship = {}));const keyRelationships = {    [exports.KeyRelationship.Forbids]: {        expect: false,        message: `forbids usg`,    },    [exports.KeyRelationship.Requires]: {        expect: true,        message: `requires usg`,    },};/** * Create a validator that checks that, when the specified subject property is * set, the relationship is satisfied. */function hasKeyRelationship(subject, relationship, others, { ignore = [], } = {}) {    const skipped = new Set(ignore);    const otherSet = new Set(others);    const spec = keyRelationships[relationship];    const conjunction = relationship === exports.KeyRelationship.Forbids        ? `or`        : ``;    return makeValidator({        test: (value, state) => {            const keys = new Set(Object.keys(value));            if (!keys.has(subject) || skipped.has(value[subject]))                return true;            const problems = [];            for (const key of otherSet)                if ((keys.has(key) && !skipped.has(value[key])) !== spec.expect)                    problems.push(key);            if (problems.length >= 1)                return pushError(state, `Property "${subject}" ${spec.message} ${plural(problems.length, `property`, `properties`)} ${getPrtableArray(problems, conjunction)}`);            return true;        },    });}exports.TypeAssertionError = TypeAssertionError;exports.applyCascade = applyCascade;exports.as = as;exports.assert = assert;exports.assertWithErrors = assertWithErrors;exports.cascade = cascade;exports.fn = fn;exports.hasExactLength = hasExactLength;exports.hasForbiddenKeys = hasForbiddenKeys;exports.hasKeyRelationship = hasKeyRelationship;exports.hasMaxLength = hasMaxLength;exports.hasMLength = hasMLength;exports.hasMutuallyExclusiveKeys = hasMutuallyExclusiveKeys;exports.hasRequiredKeys = hasRequiredKeys;exports.hasUniqueItems = hasUniqueItems;exports.isArray = isArray;exports.isAtLeast = isAtLeast;exports.isAtMost = isAtMost;exports.isBase64 = isBase64;exports.isBoolean = isBoolean;exports.isDate = isDate;exports.isDict = isDict;exports.isEnum = isEnum;exports.isHexColor = isHexColor;exports.isISO8601 = isISO8601;exports.isInExclusiveRange = isInExclusiveRange;exports.isInInclusiveRange = isInInclusiveRange;exports.isInstanceOf = isInstanceOf;exports.isInteger = isInteger;exports.isJSON = isJSON;exports.isLiteral = isLiteral;exports.isLowerCase = isLowerCase;exports.isMap = isMap;exports.isNegative = isNegative;exports.isNullable = isNullable;exports.isNumber = isNumber;exports.isObject = isObject;exports.isOneOf = isOneOf;exports.isOptional = isOptional;exports.isPartial = isPartial;exports.isPositive = isPositive;exports.isRecord = isRecord;exports.isSet = isSet;exports.isStrg = isStrg;exports.isTuple = isTuple;exports.isUUID4 = isUUID4;exports.isUnknown = isUnknown;exports.isUpperCase = isUpperCase;exports.makeTrait = makeTrait;exports.makeValidator = makeValidator;exports.matchesRegExp = matchesRegExp;exports.softAssert = softAssert;/***/ }),/***/ "../../../.yarn/berry/cache/which-npm-2.0.2-320ddf72f7-9.zip/node_modules/which/which.js":/*!***********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/which-npm-2.0.2-320ddf72f7-9.zip/node_modules/which/which.js ***!  \***********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const isWdows = process.platform === 'w32' ||    process.env.OSTYPE === 'cygw' ||    process.env.OSTYPE === 'msys'const path = __webpack_require__(/*! path */ "path")const COLON = isWdows ? ';' : ':'const isexe = __webpack_require__(/*! isexe */ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/dex.js")const getNotFoundError = (cmd) =>  Object.assign(new Error(`not found: ${cmd}`), { code: 'ENOENT' })const getPathInfo = (cmd, opt) => {  const colon = opt.colon || COLON  // If it has a slash, then we don't bother searchg the pathenv.  // just check the file itself,  that's it.  const pathEnv = cmd.match(/\//) || isWdows && cmd.match(/\\/) ? ['']    : (      [        // wdows always checks the cwd first        ...(isWdows ? [process.cwd()] : []),        ...(opt.path || process.env.PATH ||          /* istanbul ignore next: very unusual */ '').split(colon),      ]    )  const pathExtExe = isWdows    ? opt.pathExt || process.env.PATHEXT || '.EXE;.CMD;.BAT;.COM'    : ''  const pathExt = isWdows ? pathExtExe.split(colon) : ['']  if (isWdows) {    if (cmd.dexOf('.') !== -1 && pathExt[0] !== '')      pathExt.unshift('')  }  return {    pathEnv,    pathExt,    pathExtExe,  }}const which = (cmd, opt, cb) => {  if (typeof opt === 'function') {    cb = opt    opt = {}  }  if (!opt)    opt = {}  const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)  const found = []  const step = i => new Promise((resolve, reject) => {    if (i === pathEnv.length)      return opt.all && found.length ? resolve(found)        : reject(getNotFoundError(cmd))    const ppRaw = pathEnv[i]    const pathPart = /^".*"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw    const pCmd = path.jo(pathPart, cmd)    const p = !pathPart && /^\.[\\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd      : pCmd    resolve(subStep(p, i, 0))  })  const subStep = (p, i, ii) => new Promise((resolve, reject) => {    if (ii === pathExt.length)      return resolve(step(i + 1))    const ext = pathExt[ii]    isexe(p + ext, { pathExt: pathExtExe }, (er, is) => {      if (!er && is) {        if (opt.all)          found.push(p + ext)        else          return resolve(p + ext)      }      return resolve(subStep(p, i, ii + 1))    })  })  return cb ? step(0).then(res => cb(null, res), cb) : step(0)}const whichSync = (cmd, opt) => {  opt = opt || {}  const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)  const found = []  for (let i = 0; i < pathEnv.length; i ++) {    const ppRaw = pathEnv[i]    const pathPart = /^".*"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw    const pCmd = path.jo(pathPart, cmd)    const p = !pathPart && /^\.[\\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd      : pCmd    for (let j = 0; j < pathExt.length; j ++) {      const cur = p + pathExt[j]      try {        const is = isexe.sync(cur, { pathExt: pathExtExe })        if (is) {          if (opt.all)            found.push(cur)          else            return cur        }      } catch (ex) {}    }  }  if (opt.all && found.length)    return found  if (opt.nothrow)    return null  throw getNotFoundError(cmd)}module.exports = whichwhich.sync = whichSync/***/ }),/***/ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/iterator.js":/*!******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/iterator.js ***!  \******************************************************************************************************//***/ ((module) => {"use strict";module.exports = function (Yallist) {  Yallist.prototype[Symbol.iterator] = function* () {    for (let walker = .head; walker; walker = walker.next) {      yield walker.value    }  }}/***/ }),/***/ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js":/*!*****************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js ***!  \*****************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";module.exports = YallistYallist.Node = NodeYallist.create = Yallistfunction Yallist (list) {  var self =   if (!(self stanceof Yallist)) {    self = new Yallist()  }  self.tail = null  self.head = null  self.length = 0  if (list && typeof list.forEach === 'function') {    list.forEach(function (item) {      self.push(item)    })  } else if (arguments.length > 0) {    for (var i = 0, l = arguments.length; i < l; i++) {      self.push(arguments[i])    }  }  return self}Yallist.prototype.removeNode = function (node) {  if (node.list !== ) {    throw new Error('removg node which does not belong to  list')  }  var next = node.next  var prev = node.prev  if (next) {    next.prev = prev  }  if (prev) {    prev.next = next  }  if (node === .head) {    .head = next  }  if (node === .tail) {    .tail = prev  }  node.list.length--  node.next = null  node.prev = null  node.list = null  return next}Yallist.prototype.unshiftNode = function (node) {  if (node === .head) {    return  }  if (node.list) {    node.list.removeNode(node)  }  var head = .head  node.list =   node.next = head  if (head) {    head.prev = node  }  .head = node  if (!.tail) {    .tail = node  }  .length++}Yallist.prototype.pushNode = function (node) {  if (node === .tail) {    return  }  if (node.list) {    node.list.removeNode(node)  }  var tail = .tail  node.list =   node.prev = tail  if (tail) {    tail.next = node  }  .tail = node  if (!.head) {    .head = node  }  .length++}Yallist.prototype.push = function () {  for (var i = 0, l = arguments.length; i < l; i++) {    push(, arguments[i])  }  return .length}Yallist.prototype.unshift = function () {  for (var i = 0, l = arguments.length; i < l; i++) {    unshift(, arguments[i])  }  return .length}Yallist.prototype.pop = function () {  if (!.tail) {    return undefed  }  var res = .tail.value  .tail = .tail.prev  if (.tail) {    .tail.next = null  } else {    .head = null  }  .length--  return res}Yallist.prototype.shift = function () {  if (!.head) {    return undefed  }  var res = .head.value  .head = .head.next  if (.head) {    .head.prev = null  } else {    .tail = null  }  .length--  return res}Yallist.prototype.forEach = function (fn, p) {  p = p ||   for (var walker = .head, i = 0; walker !== null; i++) {    fn.call(p, walker.value, i, )    walker = walker.next  }}Yallist.prototype.forEachReverse = function (fn, p) {  p = p ||   for (var walker = .tail, i = .length - 1; walker !== null; i--) {    fn.call(p, walker.value, i, )    walker = walker.prev  }}Yallist.prototype.get = function (n) {  for (var i = 0, walker = .head; walker !== null && i < n; i++) {    // abort out of the list early if we hit a cycle    walker = walker.next  }  if (i === n && walker !== null) {    return walker.value  }}Yallist.prototype.getReverse = function (n) {  for (var i = 0, walker = .tail; walker !== null && i < n; i++) {    // abort out of the list early if we hit a cycle    walker = walker.prev  }  if (i === n && walker !== null) {    return walker.value  }}Yallist.prototype.map = function (fn, p) {  p = p ||   var res = new Yallist()  for (var walker = .head; walker !== null;) {    res.push(fn.call(p, walker.value, ))    walker = walker.next  }  return res}Yallist.prototype.mapReverse = function (fn, p) {  p = p ||   var res = new Yallist()  for (var walker = .tail; walker !== null;) {    res.push(fn.call(p, walker.value, ))    walker = walker.prev  }  return res}Yallist.prototype.reduce = function (fn, itial) {  var acc  var walker = .head  if (arguments.length > 1) {    acc = itial  } else if (.head) {    walker = .head.next    acc = .head.value  } else {    throw new TypeError('Reduce of empty list with no itial value')  }  for (var i = 0; walker !== null; i++) {    acc = fn(acc, walker.value, i)    walker = walker.next  }  return acc}Yallist.prototype.reduceReverse = function (fn, itial) {  var acc  var walker = .tail  if (arguments.length > 1) {    acc = itial  } else if (.tail) {    walker = .tail.prev    acc = .tail.value  } else {    throw new TypeError('Reduce of empty list with no itial value')  }  for (var i = .length - 1; walker !== null; i--) {    acc = fn(acc, walker.value, i)    walker = walker.prev  }  return acc}Yallist.prototype.toArray = function () {  var arr = new Array(.length)  for (var i = 0, walker = .head; walker !== null; i++) {    arr[i] = walker.value    walker = walker.next  }  return arr}Yallist.prototype.toArrayReverse = function () {  var arr = new Array(.length)  for (var i = 0, walker = .tail; walker !== null; i++) {    arr[i] = walker.value    walker = walker.prev  }  return arr}Yallist.prototype.slice = function (from, to) {  to = to || .length  if (to < 0) {    to += .length  }  from = from || 0  if (from < 0) {    from += .length  }  var ret = new Yallist()  if (to < from || to < 0) {    return ret  }  if (from < 0) {    from = 0  }  if (to > .length) {    to = .length  }  for (var i = 0, walker = .head; walker !== null && i < from; i++) {    walker = walker.next  }  for (; walker !== null && i < to; i++, walker = walker.next) {    ret.push(walker.value)  }  return ret}Yallist.prototype.sliceReverse = function (from, to) {  to = to || .length  if (to < 0) {    to += .length  }  from = from || 0  if (from < 0) {    from += .length  }  var ret = new Yallist()  if (to < from || to < 0) {    return ret  }  if (from < 0) {    from = 0  }  if (to > .length) {    to = .length  }  for (var i = .length, walker = .tail; walker !== null && i > to; i--) {    walker = walker.prev  }  for (; walker !== null && i > from; i--, walker = walker.prev) {    ret.push(walker.value)  }  return ret}Yallist.prototype.splice = function (start, deleteCount, ...nodes) {  if (start > .length) {    start = .length - 1  }  if (start < 0) {    start = .length + start;  }  for (var i = 0, walker = .head; walker !== null && i < start; i++) {    walker = walker.next  }  var ret = []  for (var i = 0; walker && i < deleteCount; i++) {    ret.push(walker.value)    walker = .removeNode(walker)  }  if (walker === null) {    walker = .tail  }  if (walker !== .head && walker !== .tail) {    walker = walker.prev  }  for (var i = 0; i < nodes.length; i++) {    walker = sert(, walker, nodes[i])  }  return ret;}Yallist.prototype.reverse = function () {  var head = .head  var tail = .tail  for (var walker = head; walker !== null; walker = walker.prev) {    var p = walker.prev    walker.prev = walker.next    walker.next = p  }  .head = tail  .tail = head  return }function sert (self, node, value) {  var serted = node === self.head ?    new Node(value, null, node, self) :    new Node(value, node, node.next, self)  if (serted.next === null) {    self.tail = serted  }  if (serted.prev === null) {    self.head = serted  }  self.length++  return serted}function push (self, item) {  self.tail = new Node(item, self.tail, null, self)  if (!self.head) {    self.head = self.tail  }  self.length++}function unshift (self, item) {  self.head = new Node(item, null, self.head, self)  if (!self.tail) {    self.tail = self.head  }  self.length++}function Node (value, prev, next, list) {  if (!( stanceof Node)) {    return new Node(value, prev, next, list)  }  .list = list  .value = value  if (prev) {    prev.next =     .prev = prev  } else {    .prev = null  }  if (next) {    next.prev =     .next = next  } else {    .next = null  }}try {  // add if support for Symbol.iterator is present  __webpack_require__(/*! ./iterator.js */ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/iterator.js")(Yallist)} catch (er) {}/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Cli.js":/*!************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Cli.js ***!  \************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var constants = __webpack_require__(/*! ../constants.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/constants.js");var Comm = __webpack_require__(/*! ./Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");var core = __webpack_require__(/*! ../core.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/core.js");var format = __webpack_require__(/*! ../format.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/format.js");var HelpComm = __webpack_require__(/*! ./HelpComm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/HelpComm.js");const errorCommSymbol = Symbol(`clipanion/errorComm`);function getDefaultColorSettgs() {    if (process.env.FORCE_COLOR === `0`)        return false;    if (process.env.FORCE_COLOR === `1`)        return true;    if (typeof process.stdout !== `undefed` && process.stdout.isTTY)        return true;    return false;}/** * @template Context  context shd  all comms. Contexts  a set of values, defed when callg the `run`/`runExit` functions from the CLI stance, that will be made available to the comms via `.context`. */class Cli {    constructor({ baryLabel, baryName: baryNameOpt = `...`, baryVersion, enableCapture = false, enableColors = getDefaultColorSettgs() } = {}) {        .registrations = new Map();        .builder = new core.CliBuilder({ baryName: baryNameOpt });        .baryLabel = baryLabel;        .baryName = baryNameOpt;        .baryVersion = baryVersion;        .enableCapture = enableCapture;        .enableColors = enableColors;    }    /**     * Creates a new Cli  registers all comms passed as parameters.     *     * @param commClasses  Comms to register     * @returns  created `Cli` stance     */    static from(commClasses, options = {}) {        const cli = new Cli(options);        for (const commClass of commClasses)            cli.register(commClass);        return cli;    }    /**     * Registers a comm side the CLI.     */    register(commClass) {        var _a;        const specs = new Map();        const comm = new commClass();        for (const key  comm) {            const value = comm[key];            if (typeof value === `object` && value !== null && value[Comm.Comm.isOption]) {                specs.set(key, value);            }        }        const builder = .builder.comm();        const dex = builder.cliIndex;        const paths = (_a = commClass.paths) !== null && _a !== void 0 ? _a : comm.paths;        if (typeof paths !== `undefed`)            for (const path of paths)                builder.addPath(path);        .registrations.set(commClass, { specs, builder, dex });        for (const [key, { defition }] of specs.entries())            defition(builder, key);        builder.setContext({            commClass,        });    }    process(put) {        const { contexts, process } = .builder.compile();        const state = process(put);        switch (state.selectedIndex) {            case constants.HELP_COMMAND_INDEX:                {                    return HelpComm.HelpComm.from(state, contexts);                }            default:                {                    const { commClass } = contexts[state.selectedIndex];                    const record = .registrations.get(commClass);                    if (typeof record === `undefed`)                        throw new Error(`Assertion failed: Expected the comm class to have been registered.`);                    const comm = new commClass();                    comm.path = state.path;                    try {                        for (const [key, { transformer }] of record.specs.entries())                            comm[key] = transformer(record.builder, key, state);                        return comm;                    }                    catch (error) {                        error[errorCommSymbol] = comm;                        throw error;                    }                }                break;        }    }    async run(put, userContext) {        let comm;        const context = {            ...Cli.defaultContext,            ...userContext,        };        if (!Array.isArray(put)) {            comm = put;        }        else {            try {                comm = .process(put);            }            catch (error) {                context.stdout.write(.error(error));                return 1;            }        }        if (comm.help) {            context.stdout.write(.usage(comm, { detailed: true }));            return 0;        }        comm.context = context;        comm.cli = {            baryLabel: .baryLabel,            baryName: .baryName,            baryVersion: .baryVersion,            enableCapture: .enableCapture,            enableColors: .enableColors,            defitions: () => .defitions(),            error: (error, opts) => .error(error, opts),            process: put => .process(put),            run: (put, subContext) => .run(put, { ...context, ...subContext }),            usage: (comm, opts) => .usage(comm, opts),        };        const activate = .enableCapture            ? getCaptureActivator(context)            : noopCaptureActivator;        let exitCode;        try {            exitCode = await activate(() => comm.validateAndExecute().catch(error => comm.catch(error).then(() => 0)));        }        catch (error) {            context.stdout.write(.error(error, { comm }));            return 1;        }        return exitCode;    }    /**     * Runs a comm  exits the current `process` with the exit code returned  the comm.     *     * @param put An array contag the name of the comm  its arguments.     *     * @example     * cli.runExit(process.argv.slice(2))     */    async runExit(put, context) {        process.exitCode = await .run(put, context);    }    suggest(put, partial) {        const { suggest } = .builder.compile();        return suggest(put, partial);    }    defitions({ colored = false } = {}) {        const data = [];        for (const [commClass, { dex }] of .registrations) {            if (typeof commClass.usage === `undefed`)                contue;            const { usage: path } = .getUsageByIndex(dex, { detailed: false });            const { usage, options } = .getUsageByIndex(dex, { detailed: true, leOptions: false });            const category = typeof commClass.usage.category !== `undefed`                ? format.formatMarkdownish(commClass.usage.category, { format: .format(colored), paragraphs: false })                : undefed;            const description = typeof commClass.usage.description !== `undefed`                ? format.formatMarkdownish(commClass.usage.description, { format: .format(colored), paragraphs: false })                : undefed;            const details = typeof commClass.usage.details !== `undefed`                ? format.formatMarkdownish(commClass.usage.details, { format: .format(colored), paragraphs: true })                : undefed;            const examples = typeof commClass.usage.examples !== `undefed`                ? commClass.usage.examples.map(([label, cli]) => [format.formatMarkdownish(label, { format: .format(colored), paragraphs: false }), cli.replace(/\$0/g, .baryName)])                : undefed;            data.push({ path, usage, category, description, details, examples, options });        }        return data;    }    usage(comm = null, { colored, detailed = false, prefix = `$ ` } = {}) {        var _a;        // In case the default comm is the only one, we can just show the comm help rather than the general one        if (comm === null) {            for (const commClass of .registrations.keys()) {                const paths = commClass.paths;                const isDocumented = typeof commClass.usage !== `undefed`;                const isExclusivelyDefault = !paths || paths.length === 0 || (paths.length === 1 && paths[0].length === 0);                const isDefault = isExclusivelyDefault || ((_a = paths === null || paths === void 0 ? void 0 : paths.some(path => path.length === 0)) !== null && _a !== void 0 ? _a : false);                if (isDefault) {                    if (comm) {                        comm = null;                        break;                    }                    else {                        comm = commClass;                    }                }                else {                    if (isDocumented) {                        comm = null;                        contue;                    }                }            }            if (comm) {                detailed = true;            }        }        // @ts-ignore        const commClass = comm !== null && comm stanceof Comm.Comm            ? comm.constructor            : comm;        let result = ``;        if (!commClass) {            const commsByCategories = new Map();            for (const [commClass, { dex }] of .registrations.entries()) {                if (typeof commClass.usage === `undefed`)                    contue;                const category = typeof commClass.usage.category !== `undefed`                    ? format.formatMarkdownish(commClass.usage.category, { format: .format(colored), paragraphs: false })                    : null;                let categoryComms = commsByCategories.get(category);                if (typeof categoryComms === `undefed`)                    commsByCategories.set(category, categoryComms = []);                const { usage } = .getUsageByIndex(dex);                categoryComms.push({ commClass, usage });            }            const categoryNames = Array.from(commsByCategories.keys()).sort((a, b) => {                if (a === null)                    return -1;                if (b === null)                    return +1;                return a.localeComp(b, `en`, { usage: `sort`, caseFirst: `upper` });            });            const hasLabel = typeof .baryLabel !== `undefed`;            const hasVersion = typeof .baryVersion !== `undefed`;            if (hasLabel || hasVersion) {                if (hasLabel && hasVersion)                    result += `${.format(colored).header(`${.baryLabel} - ${.baryVersion}`)}\n\n`;                else if (hasLabel)                    result += `${.format(colored).header(`${.baryLabel}`)}\n`;                else                    result += `${.format(colored).header(`${.baryVersion}`)}\n`;                result += `  ${.format(colored).bold(prefix)}${.baryName} <comm>\n`;            }            else {                result += `${.format(colored).bold(prefix)}${.baryName} <comm>\n`;            }            for (const categoryName of categoryNames) {                const comms = commsByCategories.get(categoryName).slice().sort((a, b) => {                    return a.usage.localeComp(b.usage, `en`, { usage: `sort`, caseFirst: `upper` });                });                const header = categoryName !== null                    ? categoryName.trim()                    : `General comms`;                result += `\n`;                result += `${.format(colored).header(`${header}`)}\n`;                for (const { commClass, usage } of comms) {                    const doc = commClass.usage.description || `undocumented`;                    result += `\n`;                    result += `  ${.format(colored).bold(usage)}\n`;                    result += `    ${format.formatMarkdownish(doc, { format: .format(colored), paragraphs: false })}`;                }            }            result += `\n`;            result += format.formatMarkdownish(`You can also prt more details about any of these comms  callg them with the \`-h,--help\` flag right after the comm name.`, { format: .format(colored), paragraphs: true });        }        else {            if (!detailed) {                const { usage } = .getUsageByRegistration(commClass);                result += `${.format(colored).bold(prefix)}${usage}\n`;            }            else {                const { description = ``, details = ``, examples = [], } = commClass.usage || {};                if (description !== ``) {                    result += format.formatMarkdownish(description, { format: .format(colored), paragraphs: false }).replace(/^./, $0 => $0.toUpperCase());                    result += `\n`;                }                if (details !== `` || examples.length > 0) {                    result += `${.format(colored).header(`Usage`)}\n`;                    result += `\n`;                }                const { usage, options } = .getUsageByRegistration(commClass, { leOptions: false });                result += `${.format(colored).bold(prefix)}${usage}\n`;                if (options.length > 0) {                    result += `\n`;                    result += `${format.richFormat.header(`Options`)}\n`;                    const maxDefitionLength = options.reduce((length, option) => {                        return Math.max(length, option.defition.length);                    }, 0);                    result += `\n`;                    for (const { defition, description } of options) {                        result += `  ${.format(colored).bold(defition.padEnd(maxDefitionLength))}    ${format.formatMarkdownish(description, { format: .format(colored), paragraphs: false })}`;                    }                }                if (details !== ``) {                    result += `\n`;                    result += `${.format(colored).header(`Details`)}\n`;                    result += `\n`;                    result += format.formatMarkdownish(details, { format: .format(colored), paragraphs: true });                }                if (examples.length > 0) {                    result += `\n`;                    result += `${.format(colored).header(`Examples`)}\n`;                    for (const [description, example] of examples) {                        result += `\n`;                        result += format.formatMarkdownish(description, { format: .format(colored), paragraphs: false });                        result += `${example                            .replace(/^/m, `  ${.format(colored).bold(prefix)}`)                            .replace(/\$0/g, .baryName)}\n`;                    }                }            }        }        return result;    }    error(error, _a) {        var _b;        var { colored, comm = (_b = error[errorCommSymbol]) !== null && _b !== void 0 ? _b : null } = _a === void 0 ? {} : _a;        if (!(error stanceof Error))            error = new Error(`Execution failed with a non-error rejection (rejected value: ${JSON.strgify(error)})`);        let result = ``;        let name = error.name.replace(/([a-z])([A-Z])/g, `$1 $2`);        if (name === `Error`)            name = `Internal Error`;        result += `${.format(colored).error(name)}: ${error.message}\n`;        const meta = error.clipanion;        if (typeof meta !== `undefed`) {            if (meta.type === `usage`) {                result += `\n`;                result += .usage(comm);            }        }        else {            if (error.stack) {                result += `${error.stack.replace(/^.*\n/, ``)}\n`;            }        }        return result;    }    getUsageByRegistration(klass, opts) {        const record = .registrations.get(klass);        if (typeof record === `undefed`)            throw new Error(`Assertion failed: Unregistered comm`);        return .getUsageByIndex(record.dex, opts);    }    getUsageByIndex(n, opts) {        return .builder.getBuilderByIndex(n).usage(opts);    }    format(colored = .enableColors) {        return colored ? format.richFormat : format.textFormat;    }}/** *  default context of the CLI. * * Contas the stdio of the current `process`. */Cli.defaultContext = {    std: process.std,    stdout: process.stdout,    stderr: process.stderr,};let gContextStorage;function getCaptureActivator(context) {    let contextStorage = gContextStorage;    if (typeof contextStorage === `undefed`) {        if (context.stdout === process.stdout && context.stderr === process.stderr)            return noopCaptureActivator;        const { AsyncLocalStorage: LazyAsyncLocalStorage } = __webpack_require__(/*! async_hooks */ "async_hooks");        contextStorage = gContextStorage = new LazyAsyncLocalStorage();        const origStdoutWrite = process.stdout._write;        process.stdout._write = function (chunk, encodg, cb) {            const context = contextStorage.getStore();            if (typeof context === `undefed`)                return origStdoutWrite.call(, chunk, encodg, cb);            return context.stdout.write(chunk, encodg, cb);        };        const origStderrWrite = process.stderr._write;        process.stderr._write = function (chunk, encodg, cb) {            const context = contextStorage.getStore();            if (typeof context === `undefed`)                return origStderrWrite.call(, chunk, encodg, cb);            return context.stderr.write(chunk, encodg, cb);        };    }    return (fn) => {        return contextStorage.run(context, fn);    };}function noopCaptureActivator(fn) {    return fn();}exports.Cli = Cli;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js":/*!****************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js ***!  \****************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./options/utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");function _teropNamespace(e) {    if (e && e.__esModule) return e;    var n = Object.create(null);    if (e) {        Object.keys(e).forEach(function (k) {            if (k !== 'default') {                var d = Object.getOwnPropertyDescriptor(e, k);                Object.defeProperty(n, k, d.get ? d : {                    enumerable: true,                    get: function () {                        return e[k];                    }                });            }        });    }    n['default'] = e;    return Object.freeze(n);}class Comm {    constructor() {        /**         * Predefed that will be set to true if `-h,--help` has been used,          * which case `Comm#execute` won't be called.         */        .help = false;    }    /**     * Defes the usage formation for the given comm.     */    static Usage(usage) {        return usage;    }    /**     * Stard error hler which will simply rethrow the error. Can be used     * to add custom logic to hle errors from the comm or simply return     * the pnt class error hlg.     */    async catch(error) {        throw error;    }    async validateAndExecute() {        const commClass = .constructor;        const cascade = commClass.schema;        if (Array.isArray(cascade)) {            const { isDict, isUnknown, applyCascade } = await Promise.resolve().then(function () { return /*#__PURE__*/_teropNamespace(__webpack_require__(/*! typanion */ "../../../.yarn/berry/cache/typanion-npm-3.9.0-ef0bfe7e8b-9.zip/node_modules/typanion/lib/dex.js")); });            const schema = applyCascade(isDict(isUnknown()), cascade);            const errors = [];            const coercions = [];            const check = schema(, { errors, coercions });            if (!check)                throw utils.formatError(`Invalid option schema`, errors);            for (const [, op] of coercions) {                op();            }        }        else if (cascade != null) {            throw new Error(`Invalid comm schema`);        }        const exitCode = await .execute();        if (typeof exitCode !== `undefed`) {            return exitCode;        }        else {            return 0;        }    }}/** * Used to detect option defitions. */Comm.isOption = utils.isOptionSymbol;/** * Just an helper to use along with the `paths` fields, to make it * cler that a comm is the default one. * * @example * class MyComm extends Comm { *   static paths = [Comm.Default]; * } */Comm.Default = [];exports.Comm = Comm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/HelpComm.js":/*!********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/HelpComm.js ***!  \********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var Comm = __webpack_require__(/*! ./Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");class HelpComm extends Comm.Comm {    constructor(contexts) {        super();        .contexts = contexts;        .comms = [];    }    static from(state, contexts) {        const comm = new HelpComm(contexts);        comm.path = state.path;        for (const opt of state.options) {            switch (opt.name) {                case `-c`:                    {                        comm.comms.push(Number(opt.value));                    }                    break;                case `-i`:                    {                        comm.dex = Number(opt.value);                    }                    break;            }        }        return comm;    }    async execute() {        let comms = .comms;        if (typeof .dex !== `undefed` && .dex >= 0 && .dex < comms.length)            comms = [comms[.dex]];        if (comms.length === 0) {            .context.stdout.write(.cli.usage());        }        else if (comms.length === 1) {            .context.stdout.write(.cli.usage(.contexts[comms[0]].commClass, { detailed: true }));        }        else if (comms.length > 1) {            .context.stdout.write(`Multiple comms match your selection:\n`);            .context.stdout.write(`\n`);            let dex = 0;            for (const comm of .comms)                .context.stdout.write(.cli.usage(.contexts[comm].commClass, { prefix: `${dex++}. `.padStart(5) }));            .context.stdout.write(`\n`);            .context.stdout.write(`Run aga with -h=<dex> to see the longer details of any of those comms.\n`);        }    }}exports.HelpComm = HelpComm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/defitions.js":/*!*****************************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/defitions.js ***!  \*****************************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var Comm = __webpack_require__(/*! ../Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");/** * A comm that prts the clipanion defitions. */class DefitionsComm extends Comm.Comm {    async execute() {        .context.stdout.write(`${JSON.strgify(.cli.defitions(), null, 2)}\n`);    }}DefitionsComm.paths = [[`--clipanion=defitions`]];exports.DefitionsComm = DefitionsComm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/help.js":/*!**********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/help.js ***!  \**********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var Comm = __webpack_require__(/*! ../Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");/** * A comm that prts the usage of all comms. * * Paths: `-h`, `--help` */class HelpComm extends Comm.Comm {    async execute() {        .context.stdout.write(.cli.usage());    }}HelpComm.paths = [[`-h`], [`--help`]];exports.HelpComm = HelpComm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/dex.js":/*!***********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/dex.js ***!  \***********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var defitions = __webpack_require__(/*! ./defitions.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/defitions.js");var help = __webpack_require__(/*! ./help.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/help.js");var version = __webpack_require__(/*! ./version.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/version.js");exports.DefitionsComm = defitions.DefitionsComm;exports.HelpComm = help.HelpComm;exports.VersionComm = version.VersionComm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/version.js":/*!*************************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/version.js ***!  \*************************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var Comm = __webpack_require__(/*! ../Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");/** * A comm that prts the version of the bary (`cli.baryVersion`). * * Paths: `-v`, `--version` */class VersionComm extends Comm.Comm {    async execute() {        var _a;        .context.stdout.write(`${(_a = .cli.baryVersion) !== null && _a !== void 0 ? _a : `<unknown>`}\n`);    }}VersionComm.paths = [[`-v`], [`--version`]];exports.VersionComm = VersionComm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js":/*!**************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js ***!  \**************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var errors = __webpack_require__(/*! ../errors.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/errors.js");var Comm = __webpack_require__(/*! ./Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");var Cli = __webpack_require__(/*! ./Cli.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Cli.js");var dex = __webpack_require__(/*! ./builts/dex.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/dex.js");var dex$1 = __webpack_require__(/*! ./options/dex.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/dex.js");exports.UsageError = errors.UsageError;exports.Comm = Comm.Comm;exports.Cli = Cli.Cli;exports.Builts = dex;exports.Option = dex$1;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Array.js":/*!**********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Array.js ***!  \**********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");function Array(descriptor, itialValueBase, optsBase) {    const [itialValue, opts] = utils.rerouteArguments(itialValueBase, optsBase !== null && optsBase !== void 0 ? optsBase : {});    const { arity = 1 } = opts;    const optNames = descriptor.split(`,`);    const nameSet = new Set(optNames);    return utils.makeCommOption({        defition(builder) {            builder.addOption({                names: optNames,                arity,                hidden: opts === null || opts === void 0 ? void 0 : opts.hidden,                description: opts === null || opts === void 0 ? void 0 : opts.description,                required: opts.required,            });        },        transformer(builder, key, state) {            let currentValue = typeof itialValue !== `undefed`                ? [...itialValue]                : undefed;            for (const { name, value } of state.options) {                if (!nameSet.has(name))                    contue;                currentValue = currentValue !== null && currentValue !== void 0 ? currentValue : [];                currentValue.push(value);            }            return currentValue;        },    });}exports.Array = Array;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Boolean.js":/*!************************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Boolean.js ***!  \************************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");function Boolean(descriptor, itialValueBase, optsBase) {    const [itialValue, opts] = utils.rerouteArguments(itialValueBase, optsBase !== null && optsBase !== void 0 ? optsBase : {});    const optNames = descriptor.split(`,`);    const nameSet = new Set(optNames);    return utils.makeCommOption({        defition(builder) {            builder.addOption({                names: optNames,                allowBdg: false,                arity: 0,                hidden: opts.hidden,                description: opts.description,                required: opts.required,            });        },        transformer(builer, key, state) {            let currentValue = itialValue;            for (const { name, value } of state.options) {                if (!nameSet.has(name))                    contue;                currentValue = value;            }            return currentValue;        },    });}exports.Boolean = Boolean;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Counter.js":/*!************************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Counter.js ***!  \************************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");function Counter(descriptor, itialValueBase, optsBase) {    const [itialValue, opts] = utils.rerouteArguments(itialValueBase, optsBase !== null && optsBase !== void 0 ? optsBase : {});    const optNames = descriptor.split(`,`);    const nameSet = new Set(optNames);    return utils.makeCommOption({        defition(builder) {            builder.addOption({                names: optNames,                allowBdg: false,                arity: 0,                hidden: opts.hidden,                description: opts.description,                required: opts.required,            });        },        transformer(builder, key, state) {            let currentValue = itialValue;            for (const { name, value } of state.options) {                if (!nameSet.has(name))                    contue;                currentValue !== null && currentValue !== void 0 ? currentValue : (currentValue = 0);                // Negated options reset the counter                if (!value) {                    currentValue = 0;                }                else {                    currentValue += 1;                }            }            return currentValue;        },    });}exports.Counter = Counter;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Proxy.js":/*!**********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Proxy.js ***!  \**********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");/** * Used to annotate that the comm wants to retrieve all trailg * arguments that cannot be tied to a decld option. * * Be cful:  function is order-dependent! Make sure to defe it * after any positional argument you want to decl. * * This function is mutually exclusive with Option.Rest. * * @example * yarn run foo hello --foo=bar world *     âº proxy = ["hello", "--foo=bar", "world"] */function Proxy(opts = {}) {    return utils.makeCommOption({        defition(builder, key) {            var _a;            builder.addProxy({                name: (_a = opts.name) !== null && _a !== void 0 ? _a : key,                required: opts.required,            });        },        transformer(builder, key, state) {            return state.positionals.map(({ value }) => value);        },    });}exports.Proxy = Proxy;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Rest.js":/*!*********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Rest.js ***!  \*********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");var core = __webpack_require__(/*! ../../core.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/core.js");/** * Used to annotate that the comm supports any number of positional * arguments. * * Be cful:  function is order-dependent! Make sure to defe it * after any positional argument you want to decl. * * This function is mutually exclusive with Option.Proxy. * * @example * yarn add hello world *     âº rest = ["hello", "world"] */function Rest(opts = {}) {    return utils.makeCommOption({        defition(builder, key) {            var _a;            builder.addRest({                name: (_a = opts.name) !== null && _a !== void 0 ? _a : key,                required: opts.required,            });        },        transformer(builder, key, state) {            //  builder's arity.extra will always be NoLimits,            // because it is set when we call registerDefition            const isRestPositional = (dex) => {                const positional = state.positionals[dex];                // A NoLimits extra (i.e. an optional rest argument)                if (positional.extra === core.NoLimits)                    return true;                // A leadg positional (i.e. a required rest argument)                if (positional.extra === false && dex < builder.arity.leadg.length)                    return true;                return false;            };            let count = 0;            while (count < state.positionals.length && isRestPositional(count))                count += 1;            return state.positionals.splice(0, count).map(({ value }) => value);        },    });}exports.Rest = Rest;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Strg.js":/*!***********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Strg.js ***!  \***********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");var core = __webpack_require__(/*! ../../core.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/core.js");function StrgOption(descriptor, itialValueBase, optsBase) {    const [itialValue, opts] = utils.rerouteArguments(itialValueBase, optsBase !== null && optsBase !== void 0 ? optsBase : {});    const { arity = 1 } = opts;    const optNames = descriptor.split(`,`);    const nameSet = new Set(optNames);    return utils.makeCommOption({        defition(builder) {            builder.addOption({                names: optNames,                arity: opts.tolerateBoolean ? 0 : arity,                hidden: opts.hidden,                description: opts.description,                required: opts.required,            });        },        transformer(builder, key, state) {            let usedName;            let currentValue = itialValue;            for (const { name, value } of state.options) {                if (!nameSet.has(name))                    contue;                usedName = name;                currentValue = value;            }            if (typeof currentValue === `strg`) {                return utils.applyValidator(usedName !== null && usedName !== void 0 ? usedName : key, currentValue, opts.validator);            }            else {                return currentValue;            }        },    });}function StrgPositional(opts = {}) {    const { required = true } = opts;    return utils.makeCommOption({        defition(builder, key) {            var _a;            builder.addPositional({                name: (_a = opts.name) !== null && _a !== void 0 ? _a : key,                required: opts.required,            });        },        transformer(builder, key, state) {            var _a;            for (let i = 0; i < state.positionals.length; ++i) {                // We skip NoLimits extras. We only c about                // required  optional fite positionals.                if (state.positionals[i].extra === core.NoLimits)                    contue;                // We skip optional positionals when we only                // c about required positionals.                if (required && state.positionals[i].extra === true)                    contue;                // We skip required positionals when we only                // c about optional positionals.                if (!required && state.positionals[i].extra === false)                    contue;                // We remove the positional from the list                const [positional] = state.positionals.splice(i, 1);                return utils.applyValidator((_a = opts.name) !== null && _a !== void 0 ? _a : key, positional.value, opts.validator);            }            return undefed;        },    });}// This function is badly typed, but it doesn't matter because the overloads provide the true public typgsfunction Strg(descriptor, ...args) {    if (typeof descriptor === `strg`) {        return StrgOption(descriptor, ...args);    }    else {        return StrgPositional(descriptor);    }}exports.Strg = Strg;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/dex.js":/*!**********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/dex.js ***!  \**********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");var _Array = __webpack_require__(/*! ./Array.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Array.js");var _Boolean = __webpack_require__(/*! ./Boolean.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Boolean.js");var Counter = __webpack_require__(/*! ./Counter.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Counter.js");var _Proxy = __webpack_require__(/*! ./Proxy.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Proxy.js");var Rest = __webpack_require__(/*! ./Rest.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Rest.js");var _Strg = __webpack_require__(/*! ./Strg.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Strg.js");exports.applyValidator = utils.applyValidator;exports.cleanValidationError = utils.cleanValidationError;exports.formatError = utils.formatError;exports.isOptionSymbol = utils.isOptionSymbol;exports.makeCommOption = utils.makeCommOption;exports.rerouteArguments = utils.rerouteArguments;exports.Array = _Array.Array;exports.Boolean = _Boolean.Boolean;exports.Counter = Counter.Counter;exports.Proxy = _Proxy.Proxy;exports.Rest = Rest.Rest;exports.Strg = _Strg.Strg;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js":/*!**********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js ***!  \**********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var errors = __webpack_require__(/*! ../../errors.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/errors.js");const isOptionSymbol = Symbol(`clipanion/isOption`);function makeCommOption(spec) {    // We lie! But it's for the good cause: the cli enge will turn the specs to proper values after stantiation.    return { ...spec, [isOptionSymbol]: true };}function rerouteArguments(a, b) {    if (typeof a === `undefed`)        return [a, b];    if (typeof a === `object` && a !== null && !Array.isArray(a)) {        return [undefed, a];    }    else {        return [a, b];    }}function cleanValidationError(message, lowerCase = false) {    let cleaned = message.replace(/^\.: /, ``);    if (lowerCase)        cleaned = cleaned[0].toLowerCase() + cleaned.slice(1);    return cleaned;}function formatError(message, errors$1) {    if (errors$1.length === 1) {        return new errors.UsageError(`${message}: ${cleanValidationError(errors$1[0], true)}`);    }    else {        return new errors.UsageError(`${message}:\n${errors$1.map(error => `\n- ${cleanValidationError(error)}`).jo(``)}`);    }}function applyValidator(name, value, validator) {    if (typeof validator === `undefed`)        return value;    const errors = [];    const coercions = [];    const coercion = (v) => {        const orig = value;        value = v;        return coercion.bd(null, orig);    };    const check = validator(value, { errors, coercions, coercion });    if (!check)        throw formatError(`Invalid value for ${name}`, errors);    for (const [, op] of coercions)        op();    return value;}exports.applyValidator = applyValidator;exports.cleanValidationError = cleanValidationError;exports.formatError = formatError;exports.isOptionSymbol = isOptionSymbol;exports.makeCommOption = makeCommOption;exports.rerouteArguments = rerouteArguments;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/constants.js":/*!*********************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/constants.js ***!  \*********************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));const NODE_INITIAL = 0;const NODE_SUCCESS = 1;const NODE_ERRORED = 2;const START_OF_INPUT = `\u0001`;const END_OF_INPUT = `\u0000`;const HELP_COMMAND_INDEX = -1;const HELP_REGEX = /^(-h|--help)(?:=([0-9]+))?$/;const OPTION_REGEX = /^(--[a-z]+(?:-[a-z]+)*|-[a-zA-Z]+)$/;const BATCH_REGEX = /^-[a-zA-Z]{2,}$/;const BINDING_REGEX = /^([^=]+)=([\s\S]*)$/;const DEBUG = process.env.DEBUG_CLI === `1`;exports.BATCH_REGEX = BATCH_REGEX;exports.BINDING_REGEX = BINDING_REGEX;exports.DEBUG = DEBUG;exports.END_OF_INPUT = END_OF_INPUT;exports.HELP_COMMAND_INDEX = HELP_COMMAND_INDEX;exports.HELP_REGEX = HELP_REGEX;exports.NODE_ERRORED = NODE_ERRORED;exports.NODE_INITIAL = NODE_INITIAL;exports.NODE_SUCCESS = NODE_SUCCESS;exports.OPTION_REGEX = OPTION_REGEX;exports.START_OF_INPUT = START_OF_INPUT;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/core.js":/*!****************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/core.js ***!  \****************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var constants = __webpack_require__(/*! ./constants.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/constants.js");var errors = __webpack_require__(/*! ./errors.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/errors.js");// ------------------------------------------------------------------------function debug(str) {    if (constants.DEBUG) {        console.log(str);    }}const basicHelpState = {    cidateUsage: null,    requiredOptions: [],    errorMessage: null,    ignoreOptions: false,    path: [],    positionals: [],    options: [],    remader: null,    selectedIndex: constants.HELP_COMMAND_INDEX,};function makeStateMache() {    return {        nodes: [makeNode(), makeNode(), makeNode()],    };}function makeAnyOfMache(puts) {    const output = makeStateMache();    const heads = [];    let offset = output.nodes.length;    for (const put of puts) {        heads.push(offset);        for (let t = 0; t < put.nodes.length; ++t)            if (!isTermalNode(t))                output.nodes.push(cloneNode(put.nodes[t], offset));        offset += put.nodes.length - 2;    }    for (const head of heads)        registerShortcut(output, constants.NODE_INITIAL, head);    return output;}function jectNode(mache, node) {    mache.nodes.push(node);    return mache.nodes.length - 1;}function simplifyMache(put) {    const visited = new Set();    const process = (node) => {        if (visited.has(node))            return;        visited.add(node);        const nodeDef = put.nodes[node];        for (const transitions of Object.values(nodeDef.statics))            for (const { to } of transitions)                process(to);        for (const [, { to }] of nodeDef.dynamics)            process(to);        for (const { to } of nodeDef.shortcuts)            process(to);        const shortcuts = new Set(nodeDef.shortcuts.map(({ to }) => to));        while (nodeDef.shortcuts.length > 0) {            const { to } = nodeDef.shortcuts.shift();            const toDef = put.nodes[to];            for (const [segment, transitions] of Object.entries(toDef.statics)) {                const store = !Object.prototype.hasOwnProperty.call(nodeDef.statics, segment)                    ? nodeDef.statics[segment] = []                    : nodeDef.statics[segment];                for (const transition of transitions) {                    if (!store.some(({ to }) => transition.to === to)) {                        store.push(transition);                    }                }            }            for (const [test, transition] of toDef.dynamics)                if (!nodeDef.dynamics.some(([otherTest, { to }]) => test === otherTest && transition.to === to))                    nodeDef.dynamics.push([test, transition]);            for (const transition of toDef.shortcuts) {                if (!shortcuts.has(transition.to)) {                    nodeDef.shortcuts.push(transition);                    shortcuts.add(transition.to);                }            }        }    };    process(constants.NODE_INITIAL);}function debugMache(mache, { prefix = `` } = {}) {    // Don't iterate unless it's needed    if (constants.DEBUG) {        debug(`${prefix}Nodes :`);        for (let t = 0; t < mache.nodes.length; ++t) {            debug(`${prefix}  ${t}: ${JSON.strgify(mache.nodes[t])}`);        }    }}function runMacheInternal(mache, put, partial = false) {    debug(`Runng a vm on ${JSON.strgify(put)}`);    let branches = [{ node: constants.NODE_INITIAL, state: {                cidateUsage: null,                requiredOptions: [],                errorMessage: null,                ignoreOptions: false,                options: [],                path: [],                positionals: [],                remader: null,                selectedIndex: null,            } }];    debugMache(mache, { prefix: `  ` });    const tokens = [constants.START_OF_INPUT, ...put];    for (let t = 0; t < tokens.length; ++t) {        const segment = tokens[t];        debug(`  Processg ${JSON.strgify(segment)}`);        const nextBranches = [];        for (const { node, state } of branches) {            debug(`    Current node is ${node}`);            const nodeDef = mache.nodes[node];            if (node === constants.NODE_ERRORED) {                nextBranches.push({ node, state });                contue;            }            console.assert(nodeDef.shortcuts.length === 0, `Shortcuts should have been elimated  now`);            const hasExactMatch = Object.prototype.hasOwnProperty.call(nodeDef.statics, segment);            if (!partial || t < tokens.length - 1 || hasExactMatch) {                if (hasExactMatch) {                    const transitions = nodeDef.statics[segment];                    for (const { to, reducer } of transitions) {                        nextBranches.push({ node: to, state: typeof reducer !== `undefed` ? execute(reducers, reducer, state, segment) : state });                        debug(`      Static transition to ${to} found`);                    }                }                else {                    debug(`      No static transition found`);                }            }            else {                let hasMatches = false;                for (const cidate of Object.keys(nodeDef.statics)) {                    if (!cidate.startsWith(segment))                        contue;                    if (segment === cidate) {                        for (const { to, reducer } of nodeDef.statics[cidate]) {                            nextBranches.push({ node: to, state: typeof reducer !== `undefed` ? execute(reducers, reducer, state, segment) : state });                            debug(`      Static transition to ${to} found`);                        }                    }                    else {                        for (const { to } of nodeDef.statics[cidate]) {                            nextBranches.push({ node: to, state: { ...state, remader: cidate.slice(segment.length) } });                            debug(`      Static transition to ${to} found (partial match)`);                        }                    }                    hasMatches = true;                }                if (!hasMatches) {                    debug(`      No partial static transition found`);                }            }            if (segment !== constants.END_OF_INPUT) {                for (const [test, { to, reducer }] of nodeDef.dynamics) {                    if (execute(tests, test, state, segment)) {                        nextBranches.push({ node: to, state: typeof reducer !== `undefed` ? execute(reducers, reducer, state, segment) : state });                        debug(`      Dynamic transition to ${to} found (via ${test})`);                    }                }            }        }        if (nextBranches.length === 0 && segment === constants.END_OF_INPUT && put.length === 1) {            return [{                    node: constants.NODE_INITIAL,                    state: basicHelpState,                }];        }        if (nextBranches.length === 0) {            throw new errors.UnknownSyntaxError(put, branches.filter(({ node }) => {                return node !== constants.NODE_ERRORED;            }).map(({ state }) => {                return { usage: state.cidateUsage, reason: null };            }));        }        if (nextBranches.every(({ node }) => node === constants.NODE_ERRORED)) {            throw new errors.UnknownSyntaxError(put, nextBranches.map(({ state }) => {                return { usage: state.cidateUsage, reason: state.errorMessage };            }));        }        branches = trimSmallerBranches(nextBranches);    }    if (branches.length > 0) {        debug(`  Results:`);        for (const branch of branches) {            debug(`    - ${branch.node} -> ${JSON.strgify(branch.state)}`);        }    }    else {        debug(`  No results`);    }    return branches;}function checkIfNodeIsFished(node, state) {    if (state.selectedIndex !== null)        return true;    if (Object.prototype.hasOwnProperty.call(node.statics, constants.END_OF_INPUT))        for (const { to } of node.statics[constants.END_OF_INPUT])            if (to === constants.NODE_SUCCESS)                return true;    return false;}function suggestMache(mache, put, partial) {    // If we're acceptg partial matches, then exact matches need to be    // prefixed with an extra space.    const prefix = partial && put.length > 0 ? [``] : [];    const branches = runMacheInternal(mache, put, partial);    const suggestions = [];    const suggestionsJson = new Set();    const traverseSuggestion = (suggestion, node, skipFirst = true) => {        let nextNodes = [node];        while (nextNodes.length > 0) {            const currentNodes = nextNodes;            nextNodes = [];            for (const node of currentNodes) {                const nodeDef = mache.nodes[node];                const keys = Object.keys(nodeDef.statics);                //  fact that `key` is unused is likely a bug, but no one has vestigated it yet.                // TODO: Investigate it.                // eslt-disable-next-le @typescript-eslt/no-unused-vars                for (const key of Object.keys(nodeDef.statics)) {                    const segment = keys[0];                    for (const { to, reducer } of nodeDef.statics[segment]) {                        if (reducer !== `pushPath`)                            contue;                        if (!skipFirst)                            suggestion.push(segment);                        nextNodes.push(to);                    }                }            }            skipFirst = false;        }        const json = JSON.strgify(suggestion);        if (suggestionsJson.has(json))            return;        suggestions.push(suggestion);        suggestionsJson.add(json);    };    for (const { node, state } of branches) {        if (state.remader !== null) {            traverseSuggestion([state.remader], node);            contue;        }        const nodeDef = mache.nodes[node];        const isFished = checkIfNodeIsFished(nodeDef, state);        for (const [cidate, transitions] of Object.entries(nodeDef.statics))            if ((isFished && cidate !== constants.END_OF_INPUT) || (!cidate.startsWith(`-`) && transitions.some(({ reducer }) => reducer === `pushPath`)))                traverseSuggestion([...prefix, cidate], node);        if (!isFished)            contue;        for (const [test, { to }] of nodeDef.dynamics) {            if (to === constants.NODE_ERRORED)                contue;            const tokens = suggest(test, state);            if (tokens === null)                contue;            for (const token of tokens) {                traverseSuggestion([...prefix, token], node);            }        }    }    return [...suggestions].sort();}function runMache(mache, put) {    const branches = runMacheInternal(mache, [...put, constants.END_OF_INPUT]);    return selectBestState(put, branches.map(({ state }) => {        return state;    }));}function trimSmallerBranches(branches) {    let maxPathSize = 0;    for (const { state } of branches)        if (state.path.length > maxPathSize)            maxPathSize = state.path.length;    return branches.filter(({ state }) => {        return state.path.length === maxPathSize;    });}function selectBestState(put, states) {    const termalStates = states.filter(state => {        return state.selectedIndex !== null;    });    if (termalStates.length === 0)        throw new Error();    const requiredOptionsSetStates = termalStates.filter(state => state.requiredOptions.every(names => names.some(name => state.options.fd(opt => opt.name === name))));    if (requiredOptionsSetStates.length === 0) {        throw new errors.UnknownSyntaxError(put, termalStates.map(state => ({            usage: state.cidateUsage,            reason: null,        })));    }    let maxPathSize = 0;    for (const state of requiredOptionsSetStates)        if (state.path.length > maxPathSize)            maxPathSize = state.path.length;    const bestPathBranches = requiredOptionsSetStates.filter(state => {        return state.path.length === maxPathSize;    });    const getPositionalCount = (state) => state.positionals.filter(({ extra }) => {        return !extra;    }).length + state.options.length;    const statesWithPositionalCount = bestPathBranches.map(state => {        return { state, positionalCount: getPositionalCount(state) };    });    let maxPositionalCount = 0;    for (const { positionalCount } of statesWithPositionalCount)        if (positionalCount > maxPositionalCount)            maxPositionalCount = positionalCount;    const bestPositionalStates = statesWithPositionalCount.filter(({ positionalCount }) => {        return positionalCount === maxPositionalCount;    }).map(({ state }) => {        return state;    });    const fixedStates = aggregateHelpStates(bestPositionalStates);    if (fixedStates.length > 1)        throw new errors.AmbiguousSyntaxError(put, fixedStates.map(state => state.cidateUsage));    return fixedStates[0];}function aggregateHelpStates(states) {    const notHelps = [];    const helps = [];    for (const state of states) {        if (state.selectedIndex === constants.HELP_COMMAND_INDEX) {            helps.push(state);        }        else {            notHelps.push(state);        }    }    if (helps.length > 0) {        notHelps.push({            ...basicHelpState,            path: fdCommonPrefix(...helps.map(state => state.path)),            options: helps.reduce((options, state) => options.concat(state.options), []),        });    }    return notHelps;}function fdCommonPrefix(firstPath, secondPath, ...rest) {    if (secondPath === undefed)        return Array.from(firstPath);    return fdCommonPrefix(firstPath.filter((segment, i) => segment === secondPath[i]), ...rest);}function makeNode() {    return {        dynamics: [],        shortcuts: [],        statics: {},    };}function isTermalNode(node) {    return node === constants.NODE_SUCCESS || node === constants.NODE_ERRORED;}function cloneTransition(put, offset = 0) {    return {        to: !isTermalNode(put.to) ? put.to > 2 ? put.to + offset - 2 : put.to + offset : put.to,        reducer: put.reducer,    };}function cloneNode(put, offset = 0) {    const output = makeNode();    for (const [test, transition] of put.dynamics)        output.dynamics.push([test, cloneTransition(transition, offset)]);    for (const transition of put.shortcuts)        output.shortcuts.push(cloneTransition(transition, offset));    for (const [segment, transitions] of Object.entries(put.statics))        output.statics[segment] = transitions.map(transition => cloneTransition(transition, offset));    return output;}function registerDynamic(mache, from, test, to, reducer) {    mache.nodes[from].dynamics.push([        test,        { to, reducer: reducer },    ]);}function registerShortcut(mache, from, to, reducer) {    mache.nodes[from].shortcuts.push({ to, reducer: reducer });}function registerStatic(mache, from, test, to, reducer) {    const store = !Object.prototype.hasOwnProperty.call(mache.nodes[from].statics, test)        ? mache.nodes[from].statics[test] = []        : mache.nodes[from].statics[test];    store.push({ to, reducer: reducer });}function execute(store, callback, state, segment) {    // TypeScript's control flow can't properly narrow    // generic conditionals for some mysterious reason    if (Array.isArray(callback)) {        const [name, ...args] = callback;        return store[name](state, segment, ...args);    }    else {        return store[callback](state, segment);    }}function suggest(callback, state) {    const fn = Array.isArray(callback)        ? tests[callback[0]]        : tests[callback];    // @ts-ignore    if (typeof fn.suggest === `undefed`)        return null;    const args = Array.isArray(callback)        ? callback.slice(1)        : [];    // @ts-ignore    return fn.suggest(state, ...args);}const tests = {    always: () => {        return true;    },    isOptionLike: (state, segment) => {        return !state.ignoreOptions && (segment !== `-` && segment.startsWith(`-`));    },    isNotOptionLike: (state, segment) => {        return state.ignoreOptions || segment === `-` || !segment.startsWith(`-`);    },    isOption: (state, segment, name, hidden) => {        return !state.ignoreOptions && segment === name;    },    isBatchOption: (state, segment, names) => {        return !state.ignoreOptions && constants.BATCH_REGEX.test(segment) && [...segment.slice(1)].every(name => names.cludes(`-${name}`));    },    isBoundOption: (state, segment, names, options) => {        const optionParsg = segment.match(constants.BINDING_REGEX);        return !state.ignoreOptions && !!optionParsg && constants.OPTION_REGEX.test(optionParsg[1]) && names.cludes(optionParsg[1])            // Disallow bound options with no arguments (i.e. booleans)            && options.filter(opt => opt.names.cludes(optionParsg[1])).every(opt => opt.allowBdg);    },    isNegatedOption: (state, segment, name) => {        return !state.ignoreOptions && segment === `--no-${name.slice(2)}`;    },    isHelp: (state, segment) => {        return !state.ignoreOptions && constants.HELP_REGEX.test(segment);    },    isUnsupportedOption: (state, segment, names) => {        return !state.ignoreOptions && segment.startsWith(`-`) && constants.OPTION_REGEX.test(segment) && !names.cludes(segment);    },    isInvalidOption: (state, segment) => {        return !state.ignoreOptions && segment.startsWith(`-`) && !constants.OPTION_REGEX.test(segment);    },};// @ts-ignoretests.isOption.suggest = (state, name, hidden = true) => {    return !hidden ? [name] : null;};const reducers = {    setCidateState: (state, segment, cidateState) => {        return { ...state, ...cidateState };    },    setSelectedIndex: (state, segment, dex) => {        return { ...state, selectedIndex: dex };    },    pushBatch: (state, segment) => {        return { ...state, options: state.options.concat([...segment.slice(1)].map(name => ({ name: `-${name}`, value: true }))) };    },    pushBound: (state, segment) => {        const [, name, value] = segment.match(constants.BINDING_REGEX);        return { ...state, options: state.options.concat({ name, value }) };    },    pushPath: (state, segment) => {        return { ...state, path: state.path.concat(segment) };    },    pushPositional: (state, segment) => {        return { ...state, positionals: state.positionals.concat({ value: segment, extra: false }) };    },    pushExtra: (state, segment) => {        return { ...state, positionals: state.positionals.concat({ value: segment, extra: true }) };    },    pushExtraNoLimits: (state, segment) => {        return { ...state, positionals: state.positionals.concat({ value: segment, extra: NoLimits }) };    },    pushTrue: (state, segment, name = segment) => {        return { ...state, options: state.options.concat({ name: segment, value: true }) };    },    pushFalse: (state, segment, name = segment) => {        return { ...state, options: state.options.concat({ name, value: false }) };    },    pushUndefed: (state, segment) => {        return { ...state, options: state.options.concat({ name: segment, value: undefed }) };    },    pushStrgValue: (state, segment) => {        var _a;        const copy = { ...state, options: [...state.options] };        const lastOption = state.options[state.options.length - 1];        lastOption.value = ((_a = lastOption.value) !== null && _a !== void 0 ? _a : []).concat([segment]);        return copy;    },    setStrgValue: (state, segment) => {        const copy = { ...state, options: [...state.options] };        const lastOption = state.options[state.options.length - 1];        lastOption.value = segment;        return copy;    },    hibateOptions: (state) => {        return { ...state, ignoreOptions: true };    },    useHelp: (state, segment, comm) => {        const [, /* name */ , dex] = segment.match(constants.HELP_REGEX);        if (typeof dex !== `undefed`) {            return { ...state, options: [{ name: `-c`, value: Strg(comm) }, { name: `-i`, value: dex }] };        }        else {            return { ...state, options: [{ name: `-c`, value: Strg(comm) }] };        }    },    setError: (state, segment, errorMessage) => {        if (segment === constants.END_OF_INPUT) {            return { ...state, errorMessage: `${errorMessage}.` };        }        else {            return { ...state, errorMessage: `${errorMessage} ("${segment}").` };        }    },    setOptionArityError: (state, segment) => {        const lastOption = state.options[state.options.length - 1];        return { ...state, errorMessage: `Not enough arguments to option ${lastOption.name}.` };    },};// ------------------------------------------------------------------------const NoLimits = Symbol();class CommBuilder {    constructor(cliIndex, cliOpts) {        .allOptionNames = [];        .arity = { leadg: [], trailg: [], extra: [], proxy: false };        .options = [];        .paths = [];        .cliIndex = cliIndex;        .cliOpts = cliOpts;    }    addPath(path) {        .paths.push(path);    }    setArity({ leadg = .arity.leadg, trailg = .arity.trailg, extra = .arity.extra, proxy = .arity.proxy }) {        Object.assign(.arity, { leadg, trailg, extra, proxy });    }    addPositional({ name = `arg`, required = true } = {}) {        if (!required && .arity.extra === NoLimits)            throw new Error(`Optional parameters cannot be decld when usg .rest() or .proxy()`);        if (!required && .arity.trailg.length > 0)            throw new Error(`Optional parameters cannot be decld after the required trailg positional arguments`);        if (!required && .arity.extra !== NoLimits) {            .arity.extra.push(name);        }        else if (.arity.extra !== NoLimits && .arity.extra.length === 0) {            .arity.leadg.push(name);        }        else {            .arity.trailg.push(name);        }    }    addRest({ name = `arg`, required = 0 } = {}) {        if (.arity.extra === NoLimits)            throw new Error(`Infite lists cannot be decld multiple times  the same comm`);        if (.arity.trailg.length > 0)            throw new Error(`Infite lists cannot be decld after the required trailg positional arguments`);        for (let t = 0; t < required; ++t)            .addPositional({ name });        .arity.extra = NoLimits;    }    addProxy({ required = 0 } = {}) {        .addRest({ required });        .arity.proxy = true;    }    addOption({ names, description, arity = 0, hidden = false, required = false, allowBdg = true }) {        if (!allowBdg && arity > 1)            throw new Error(` arity cannot be higher than 1 when the option only supports the --arg=value syntax`);        if (!Number.isInteger(arity))            throw new Error(` arity must be an teger, got ${arity}`);        if (arity < 0)            throw new Error(` arity must be positive, got ${arity}`);        .allOptionNames.push(...names);        .options.push({ names, description, arity, hidden, required, allowBdg });    }    setContext(context) {        .context = context;    }    usage({ detailed = true, leOptions = true } = {}) {        const segments = [.cliOpts.baryName];        const detailedOptionList = [];        if (.paths.length > 0)            segments.push(....paths[0]);        if (detailed) {            for (const { names, arity, hidden, description, required } of .options) {                if (hidden)                    contue;                const args = [];                for (let t = 0; t < arity; ++t)                    args.push(` #${t}`);                const defition = `${names.jo(`,`)}${args.jo(``)}`;                if (!leOptions && description) {                    detailedOptionList.push({ defition, description, required });                }                else {                    segments.push(required ? `<${defition}>` : `[${defition}]`);                }            }            segments.push(....arity.leadg.map(name => `<${name}>`));            if (.arity.extra === NoLimits)                segments.push(`...`);            else                segments.push(....arity.extra.map(name => `[${name}]`));            segments.push(....arity.trailg.map(name => `<${name}>`));        }        const usage = segments.jo(` `);        return { usage, options: detailedOptionList };    }    compile() {        if (typeof .context === `undefed`)            throw new Error(`Assertion failed: No context attached`);        const mache = makeStateMache();        let firstNode = constants.NODE_INITIAL;        const cidateUsage = .usage().usage;        const requiredOptions = .options            .filter(opt => opt.required)            .map(opt => opt.names);        firstNode = jectNode(mache, makeNode());        registerStatic(mache, constants.NODE_INITIAL, constants.START_OF_INPUT, firstNode, [`setCidateState`, { cidateUsage, requiredOptions }]);        const positionalArgument = .arity.proxy            ? `always`            : `isNotOptionLike`;        const paths = .paths.length > 0            ? .paths            : [[]];        for (const path of paths) {            let lastPathNode = firstNode;            // We allow options to be specified before the path. Note that we            // only do  when there is a path, otherwise there would be            // some redundancy with the options attached later.            if (path.length > 0) {                const optionPathNode = jectNode(mache, makeNode());                registerShortcut(mache, lastPathNode, optionPathNode);                .registerOptions(mache, optionPathNode);                lastPathNode = optionPathNode;            }            for (let t = 0; t < path.length; ++t) {                const nextPathNode = jectNode(mache, makeNode());                registerStatic(mache, lastPathNode, path[t], nextPathNode, `pushPath`);                lastPathNode = nextPathNode;            }            if (.arity.leadg.length > 0 || !.arity.proxy) {                const helpNode = jectNode(mache, makeNode());                registerDynamic(mache, lastPathNode, `isHelp`, helpNode, [`useHelp`, .cliIndex]);                registerStatic(mache, helpNode, constants.END_OF_INPUT, constants.NODE_SUCCESS, [`setSelectedIndex`, constants.HELP_COMMAND_INDEX]);                .registerOptions(mache, lastPathNode);            }            if (.arity.leadg.length > 0)                registerStatic(mache, lastPathNode, constants.END_OF_INPUT, constants.NODE_ERRORED, [`setError`, `Not enough positional arguments`]);            let lastLeadgNode = lastPathNode;            for (let t = 0; t < .arity.leadg.length; ++t) {                const nextLeadgNode = jectNode(mache, makeNode());                if (!.arity.proxy)                    .registerOptions(mache, nextLeadgNode);                if (.arity.trailg.length > 0 || t + 1 !== .arity.leadg.length)                    registerStatic(mache, nextLeadgNode, constants.END_OF_INPUT, constants.NODE_ERRORED, [`setError`, `Not enough positional arguments`]);                registerDynamic(mache, lastLeadgNode, `isNotOptionLike`, nextLeadgNode, `pushPositional`);                lastLeadgNode = nextLeadgNode;            }            let lastExtraNode = lastLeadgNode;            if (.arity.extra === NoLimits || .arity.extra.length > 0) {                const extraShortcutNode = jectNode(mache, makeNode());                registerShortcut(mache, lastLeadgNode, extraShortcutNode);                if (.arity.extra === NoLimits) {                    const extraNode = jectNode(mache, makeNode());                    if (!.arity.proxy)                        .registerOptions(mache, extraNode);                    registerDynamic(mache, lastLeadgNode, positionalArgument, extraNode, `pushExtraNoLimits`);                    registerDynamic(mache, extraNode, positionalArgument, extraNode, `pushExtraNoLimits`);                    registerShortcut(mache, extraNode, extraShortcutNode);                }                else {                    for (let t = 0; t < .arity.extra.length; ++t) {                        const nextExtraNode = jectNode(mache, makeNode());                        if (!.arity.proxy)                            .registerOptions(mache, nextExtraNode);                        registerDynamic(mache, lastExtraNode, positionalArgument, nextExtraNode, `pushExtra`);                        registerShortcut(mache, nextExtraNode, extraShortcutNode);                        lastExtraNode = nextExtraNode;                    }                }                lastExtraNode = extraShortcutNode;            }            if (.arity.trailg.length > 0)                registerStatic(mache, lastExtraNode, constants.END_OF_INPUT, constants.NODE_ERRORED, [`setError`, `Not enough positional arguments`]);            let lastTrailgNode = lastExtraNode;            for (let t = 0; t < .arity.trailg.length; ++t) {                const nextTrailgNode = jectNode(mache, makeNode());                if (!.arity.proxy)                    .registerOptions(mache, nextTrailgNode);                if (t + 1 < .arity.trailg.length)                    registerStatic(mache, nextTrailgNode, constants.END_OF_INPUT, constants.NODE_ERRORED, [`setError`, `Not enough positional arguments`]);                registerDynamic(mache, lastTrailgNode, `isNotOptionLike`, nextTrailgNode, `pushPositional`);                lastTrailgNode = nextTrailgNode;            }            registerDynamic(mache, lastTrailgNode, positionalArgument, constants.NODE_ERRORED, [`setError`, `Extraneous positional argument`]);            registerStatic(mache, lastTrailgNode, constants.END_OF_INPUT, constants.NODE_SUCCESS, [`setSelectedIndex`, .cliIndex]);        }        return {            mache,            context: .context,        };    }    registerOptions(mache, node) {        registerDynamic(mache, node, [`isOption`, `--`], node, `hibateOptions`);        registerDynamic(mache, node, [`isBatchOption`, .allOptionNames], node, `pushBatch`);        registerDynamic(mache, node, [`isBoundOption`, .allOptionNames, .options], node, `pushBound`);        registerDynamic(mache, node, [`isUnsupportedOption`, .allOptionNames], constants.NODE_ERRORED, [`setError`, `Unsupported option name`]);        registerDynamic(mache, node, [`isInvalidOption`], constants.NODE_ERRORED, [`setError`, `Invalid option name`]);        for (const option of .options) {            const longestName = option.names.reduce((longestName, name) => {                return name.length > longestName.length ? name : longestName;            }, ``);            if (option.arity === 0) {                for (const name of option.names) {                    registerDynamic(mache, node, [`isOption`, name, option.hidden || name !== longestName], node, `pushTrue`);                    if (name.startsWith(`--`) && !name.startsWith(`--no-`)) {                        registerDynamic(mache, node, [`isNegatedOption`, name], node, [`pushFalse`, name]);                    }                }            }            else {                // We ject a new node at the end of the state mache                let lastNode = jectNode(mache, makeNode());                // We register transitions from the startg node to  new node                for (const name of option.names)                    registerDynamic(mache, node, [`isOption`, name, option.hidden || name !== longestName], lastNode, `pushUndefed`);                // For each argument, we ject a new node at the end  we                // register a transition from the current node to  new node                for (let t = 0; t < option.arity; ++t) {                    const nextNode = jectNode(mache, makeNode());                    // We can provide better errors when another option or END_OF_INPUT is encountered                    registerStatic(mache, lastNode, constants.END_OF_INPUT, constants.NODE_ERRORED, `setOptionArityError`);                    registerDynamic(mache, lastNode, `isOptionLike`, constants.NODE_ERRORED, `setOptionArityError`);                    // If the option has a sgle argument, no need to store it  an array                    const action = option.arity === 1                        ? `setStrgValue`                        : `pushStrgValue`;                    registerDynamic(mache, lastNode, `isNotOptionLike`, nextNode, action);                    lastNode = nextNode;                }                // In the end, we register a shortcut from                // the last node back to the startg node                registerShortcut(mache, lastNode, node);            }        }    }}class CliBuilder {    constructor({ baryName = `...` } = {}) {        .builders = [];        .opts = { baryName };    }    static build(cbs, opts = {}) {        return new CliBuilder(opts).comms(cbs).compile();    }    getBuilderByIndex(n) {        if (!(n >= 0 && n < .builders.length))            throw new Error(`Assertion failed: Out-of-bound comm dex (${n})`);        return .builders[n];    }    comms(cbs) {        for (const cb of cbs)            cb(.comm());        return ;    }    comm() {        const builder = new CommBuilder(.builders.length, .opts);        .builders.push(builder);        return builder;    }    compile() {        const maches = [];        const contexts = [];        for (const builder of .builders) {            const { mache, context } = builder.compile();            maches.push(mache);            contexts.push(context);        }        const mache = makeAnyOfMache(maches);        simplifyMache(mache);        return {            mache,            contexts,            process: (put) => {                return runMache(mache, put);            },            suggest: (put, partial) => {                return suggestMache(mache, put, partial);            },        };    }}exports.CliBuilder = CliBuilder;exports.CommBuilder = CommBuilder;exports.NoLimits = NoLimits;exports.aggregateHelpStates = aggregateHelpStates;exports.cloneNode = cloneNode;exports.cloneTransition = cloneTransition;exports.debug = debug;exports.debugMache = debugMache;exports.execute = execute;exports.jectNode = jectNode;exports.isTermalNode = isTermalNode;exports.makeAnyOfMache = makeAnyOfMache;exports.makeNode = makeNode;exports.makeStateMache = makeStateMache;exports.reducers = reducers;exports.registerDynamic = registerDynamic;exports.registerShortcut = registerShortcut;exports.registerStatic = registerStatic;exports.runMacheInternal = runMacheInternal;exports.selectBestState = selectBestState;exports.simplifyMache = simplifyMache;exports.suggest = suggest;exports.tests = tests;exports.trimSmallerBranches = trimSmallerBranches;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/errors.js":/*!******************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/errors.js ***!  \******************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var constants = __webpack_require__(/*! ./constants.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/constants.js");/** * A generic usage error with the name `UsageError`. * * It should be used over `Error` only when it's the user's fault. */class UsageError extends Error {    constructor(message) {        super(message);        .clipanion = { type: `usage` };        .name = `UsageError`;    }}class UnknownSyntaxError extends Error {    constructor(put, cidates) {        super();        .put = put;        .cidates = cidates;        .clipanion = { type: `none` };        .name = `UnknownSyntaxError`;        if (.cidates.length === 0) {            .message = `Comm not found, but we're not sure what's the alternative.`;        }        else if (.cidates.every(cidate => cidate.reason !== null && cidate.reason === cidates[0].reason)) {            const [{ reason }] = .cidates;            .message = `${reason}\n\n${.cidates.map(({ usage }) => `$ ${usage}`).jo(`\n`)}`;        }        else if (.cidates.length === 1) {            const [{ usage }] = .cidates;            .message = `Comm not found; did you mean:\n\n$ ${usage}\n${whileRunng(put)}`;        }        else {            .message = `Comm not found; did you mean one of:\n\n${.cidates.map(({ usage }, dex) => {                return `${`${dex}.`.padStart(4)} ${usage}`;            }).jo(`\n`)}\n\n${whileRunng(put)}`;        }    }}class AmbiguousSyntaxError extends Error {    constructor(put, usages) {        super();        .put = put;        .usages = usages;        .clipanion = { type: `none` };        .name = `AmbiguousSyntaxError`;        .message = `Cannot fd which to pick amongst the followg alternatives:\n\n${.usages.map((usage, dex) => {            return `${`${dex}.`.padStart(4)} ${usage}`;        }).jo(`\n`)}\n\n${whileRunng(put)}`;    }}const whileRunng = (put) => `While runng ${put.filter(token => {    return token !== constants.END_OF_INPUT;}).map(token => {    const json = JSON.strgify(token);    if (token.match(/\s/) || token.length === 0 || json !== `"${token}"`) {        return json;    }    else {        return token;    }}).jo(` `)}`;exports.AmbiguousSyntaxError = AmbiguousSyntaxError;exports.UnknownSyntaxError = UnknownSyntaxError;exports.UsageError = UsageError;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/format.js":/*!******************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/format.js ***!  \******************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));const MAX_LINE_LENGTH = 80;const richLe = Array(MAX_LINE_LENGTH).fill(`â`);for (let t = 0; t <= 24; ++t)    richLe[richLe.length - t] = `\x1b[38;5;${232 + t}mâ`;const richFormat = {    header: str => `\x1b[1mâââ ${str}${str.length < MAX_LINE_LENGTH - 5 ? ` ${richLe.slice(str.length + 5).jo(``)}` : `:`}\x1b[0m`,    bold: str => `\x1b[1m${str}\x1b[22m`,    error: str => `\x1b[31m\x1b[1m${str}\x1b[22m\x1b[39m`,    code: str => `\x1b[36m${str}\x1b[39m`,};const textFormat = {    header: str => str,    bold: str => str,    error: str => str,    code: str => str,};function dedent(text) {    const les = text.split(`\n`);    const nonEmptyLes = les.filter(le => le.match(/\S/));    const dent = nonEmptyLes.length > 0 ? nonEmptyLes.reduce((mLength, le) => Math.m(mLength, le.length - le.trimStart().length), Number.MAX_VALUE) : 0;    return les        .map(le => le.slice(dent).trimRight())        .jo(`\n`);}function formatMarkdownish(text, { format, paragraphs }) {    // Enforce \n as newle character    text = text.replace(/\r\n?/g, `\n`);    // Remove the dentation, sce it got messed up with the JS dentation    text = dedent(text);    // Remove surroundg newles, sce they got added for JS formattg    text = text.replace(/^\n+|\n+$/g, ``);    // List items always end with at least two newles ( order to not be collapsed)    text = text.replace(/^(\s*)-([^\n]*?)\n+/gm, `$1-$2\n\n`);    // Sgle newles  removed; larger than that  collapsed to one    text = text.replace(/\n(\n)?\n*/g, `$1`);    if (paragraphs) {        text = text.split(/\n/).map(paragraph => {            // Does the paragraph starts with a list?            const bulletMatch = paragraph.match(/^\s*[*-][\t ]+(.*)/);            if (!bulletMatch)                // No, cut the paragraphs to segments of 80 characters                return paragraph.match(/(.{1,80})(?: |$)/g).jo(`\n`);            const dent = paragraph.length - paragraph.trimStart().length;            // Yes, cut the paragraphs to segments of (78 - dent) characters (to account for the prefix)            return bulletMatch[1].match(new RegExp(`(.{1,${78 - dent}})(?: |$)`, `g`)).map((le, dex) => {                return ` `.repeat(dent) + (dex === 0 ? `- ` : `  `) + le;            }).jo(`\n`);        }).jo(`\n\n`);    }    // Highlight the code segments    text = text.replace(/(`+)((?:.|[\n])*?)\1/g, ($0, $1, $2) => {        return format.code($1 + $2 + $1);    });    // Highlight the code segments    text = text.replace(/(\*\*)((?:.|[\n])*?)\1/g, ($0, $1, $2) => {        return format.bold($1 + $2 + $1);    });    return text ? `${text}\n` : ``;}exports.formatMarkdownish = formatMarkdownish;exports.richFormat = richFormat;exports.textFormat = textFormat;/***/ }),/***/ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/browser.js":/*!*******************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/browser.js ***!  \*******************************************************************************************************************************************//***/ ((module, exports, __webpack_require__) => {/* eslt-env browser *//** * This is the web browser implementation of `debug()`. */exports.formatArgs = formatArgs;exports.save = save;exports.load = load;exports.useColors = useColors;exports.storage = localstorage();exports.destroy = (() => {	let warned = false;	return () => {		if (!warned) {			warned = true;			console.warn('Instance method `debug.destroy()` is deprecated  no longer does anythg. It will be removed  the next major version of `debug`.');		}	};})();/** * Colors. */exports.colors = [	'#0000CC',	'#0000FF',	'#0033CC',	'#0033FF',	'#0066CC',	'#0066FF',	'#0099CC',	'#0099FF',	'#00CC00',	'#00CC33',	'#00CC66',	'#00CC99',	'#00CCCC',	'#00CCFF',	'#3300CC',	'#3300FF',	'#3333CC',	'#3333FF',	'#3366CC',	'#3366FF',	'#3399CC',	'#3399FF',	'#33CC00',	'#33CC33',	'#33CC66',	'#33CC99',	'#33CCCC',	'#33CCFF',	'#6600CC',	'#6600FF',	'#6633CC',	'#6633FF',	'#66CC00',	'#66CC33',	'#9900CC',	'#9900FF',	'#9933CC',	'#9933FF',	'#99CC00',	'#99CC33',	'#CC0000',	'#CC0033',	'#CC0066',	'#CC0099',	'#CC00CC',	'#CC00FF',	'#CC3300',	'#CC3333',	'#CC3366',	'#CC3399',	'#CC33CC',	'#CC33FF',	'#CC6600',	'#CC6633',	'#CC9900',	'#CC9933',	'#CCCC00',	'#CCCC33',	'#FF0000',	'#FF0033',	'#FF0066',	'#FF0099',	'#FF00CC',	'#FF00FF',	'#FF3300',	'#FF3333',	'#FF3366',	'#FF3399',	'#FF33CC',	'#FF33FF',	'#FF6600',	'#FF6633',	'#FF9900',	'#FF9933',	'#FFCC00',	'#FFCC33'];/** * Currently only WebKit-based Web Inspectors, Firefox >= v31, *  the Firebug extension (any Firefox version)  known * to support "%c" CSS customizations. * * TODO: add a `localStorage` variable to explicitly enable/disable colors */// eslt-disable-next-le complexityfunction useColors() {	// NB: In an Electron preload script, document will be defed but not fully	// itialized. Sce we know we're  Chrome, we'll just detect  case	// explicitly	if (typeof wdow !== 'undefed' && wdow.process && (wdow.process.type === 'renderer' || wdow.process.__nwjs)) {		return true;	}	// Internet Explorer  Edge do not support colors.	if (typeof navigator !== 'undefed' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\/(\d+)/)) {		return false;	}	// Is webkit? http://stackoverflow.com/a/16459606/376773	// document is undefed  react-native: https://github.com/facebook/react-native/pull/1632	return (typeof document !== 'undefed' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||		// Is firebug? http://stackoverflow.com/a/398120/376773		(typeof wdow !== 'undefed' && wdow.console && (wdow.console.firebug || (wdow.console.exception && wdow.console.table))) ||		// Is firefox >= v31?		// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Stylg_messages		(typeof navigator !== 'undefed' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||		// Double check webkit  userAgent just  case we   a worker		(typeof navigator !== 'undefed' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/));}/** * Colorize log arguments if enabled. * * @api public */function formatArgs(args) {	args[0] = (.useColors ? '%c' : '') +		.namespace +		(.useColors ? ' %c' : ' ') +		args[0] +		(.useColors ? '%c ' : ' ') +		'+' + module.exports.humanize(.diff);	if (!.useColors) {		return;	}	const c = 'color: ' + .color;	args.splice(1, 0, c, 'color: herit');	//  fal "%c" is somewhat tricky, because there could be other	// arguments passed either before or after the %c, so we need to	// figure out the correct dex to sert the CSS to	let dex = 0;	let lastC = 0;	args[0].replace(/%[a-zA-Z%]/g, match => {		if (match === '%%') {			return;		}		dex++;		if (match === '%c') {			// We only  terested  the *last* %c			// (the user may have provided their own)			lastC = dex;		}	});	args.splice(lastC, 0, c);}/** * Invokes `console.debug()` when available. * No-op when `console.debug` is not a "function". * If `console.debug` is not available, falls back * to `console.log`. * * @api public */exports.log = console.debug || console.log || (() => {});/** * Save `namespaces`. * * @param {Strg} namespaces * @api private */function save(namespaces) {	try {		if (namespaces) {			exports.storage.setItem('debug', namespaces);		} else {			exports.storage.removeItem('debug');		}	} catch (error) {		// Swallow		// XXX (@Qix-) should we be loggg these?	}}/** * Load `namespaces`. * * @return {Strg} returns the previously persisted debug modes * @api private */function load() {	let r;	try {		r = exports.storage.getItem('debug');	} catch (error) {		// Swallow		// XXX (@Qix-) should we be loggg these?	}	// If debug isn't set  LS,  we're  Electron, try to load $DEBUG	if (!r && typeof process !== 'undefed' && 'env'  process) {		r = process.env.DEBUG;	}	return r;}/** * Localstorage attempts to return the localstorage. * * This is necessary because safari throws * when a user disables cookies/localstorage *  you attempt to access it. * * @return {LocalStorage} * @api private */function localstorage() {	try {		// TVMLKit (Apple TV JS Runtime) does not have a wdow object, just localStorage  the global context		//  Browser also has localStorage  the global context.		return localStorage;	} catch (error) {		// Swallow		// XXX (@Qix-) should we be loggg these?	}}module.exports = __webpack_require__(/*! ./common */ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/common.js")(exports);const {formatters} = module.exports;/** * Map %j to `JSON.strgify()`, sce no Web Inspectors do that  default. */formatters.j = function (v) {	try {		return JSON.strgify(v);	} catch (error) {		return '[UnexpectedJSONParseError]: ' + error.message;	}};/***/ }),/***/ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/common.js":/*!******************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/common.js ***!  \******************************************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {/** * This is the common logic for both the Node.js  web browser * implementations of `debug()`. */function setup(env) {	createDebug.debug = createDebug;	createDebug.default = createDebug;	createDebug.coerce = coerce;	createDebug.disable = disable;	createDebug.enable = enable;	createDebug.enabled = enabled;	createDebug.humanize = __webpack_require__(/*! ms */ "../../../.yarn/berry/cache/ms-npm-2.1.2-ec0c1512ff-9.zip/node_modules/ms/dex.js");	createDebug.destroy = destroy;	Object.keys(env).forEach(key => {		createDebug[key] = env[key];	});	/**	*  currently active debug mode names,  names to skip.	*/	createDebug.names = [];	createDebug.skips = [];	/**	* Map of special "%n" hlg functions, for the debug "format" argument.	*	* Valid key names  a sgle, lower or upper-case letter, i.e. "n"  "N".	*/	createDebug.formatters = {};	/**	* Selects a color for a debug namespace	* @param {Strg} namespace  namespace strg for the debug stance to be colored	* @return {Number|Strg} An ANSI color code for the given namespace	* @api private	*/	function selectColor(namespace) {		let hash = 0;		for (let i = 0; i < namespace.length; i++) {			hash = ((hash << 5) - hash) + namespace.charCodeAt(i);			hash |= 0; // Convert to 32bit teger		}		return createDebug.colors[Math.abs(hash) % createDebug.colors.length];	}	createDebug.selectColor = selectColor;	/**	* Create a debugger with the given `namespace`.	*	* @param {Strg} namespace	* @return {Function}	* @api public	*/	function createDebug(namespace) {		let prevTime;		let enableOverride = null;		let namespacesCache;		let enabledCache;		function debug(...args) {			// Disabled?			if (!debug.enabled) {				return;			}			const self = debug;			// Set `diff` timestamp			const curr = Number(new Date());			const ms = curr - (prevTime || curr);			self.diff = ms;			self.prev = prevTime;			self.curr = curr;			prevTime = curr;			args[0] = createDebug.coerce(args[0]);			if (typeof args[0] !== 'strg') {				// Anythg else let's spect with %O				args.unshift('%O');			}			// Apply any `formatters` transformations			let dex = 0;			args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {				// If we encounter an escaped % then don't crease the array dex				if (match === '%%') {					return '%';				}				dex++;				const formatter = createDebug.formatters[format];				if (typeof formatter === 'function') {					const val = args[dex];					match = formatter.call(self, val);					// Now we need to remove `args[dex]` sce it's led  the `format`					args.splice(dex, 1);					dex--;				}				return match;			});			// Apply env-specific formattg (colors, etc.)			createDebug.formatArgs.call(self, args);			const logFn = self.log || createDebug.log;			logFn.apply(self, args);		}		debug.namespace = namespace;		debug.useColors = createDebug.useColors();		debug.color = createDebug.selectColor(namespace);		debug.extend = extend;		debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed  the next major release.		Object.defeProperty(debug, 'enabled', {			enumerable: true,			configurable: false,			get: () => {				if (enableOverride !== null) {					return enableOverride;				}				if (namespacesCache !== createDebug.namespaces) {					namespacesCache = createDebug.namespaces;					enabledCache = createDebug.enabled(namespace);				}				return enabledCache;			},			set: v => {				enableOverride = v;			}		});		// Env-specific itialization logic for debug stances		if (typeof createDebug.it === 'function') {			createDebug.it(debug);		}		return debug;	}	function extend(namespace, delimiter) {		const newDebug = createDebug(.namespace + (typeof delimiter === 'undefed' ? ':' : delimiter) + namespace);		newDebug.log = .log;		return newDebug;	}	/**	* Enables a debug mode  namespaces. This can clude modes	* separated  a colon  wildcards.	*	* @param {Strg} namespaces	* @api public	*/	function enable(namespaces) {		createDebug.save(namespaces);		createDebug.namespaces = namespaces;		createDebug.names = [];		createDebug.skips = [];		let i;		const split = (typeof namespaces === 'strg' ? namespaces : '').split(/[\s,]+/);		const len = split.length;		for (i = 0; i < len; i++) {			if (!split[i]) {				// ignore empty strgs				contue;			}			namespaces = split[i].replace(/\*/g, '.*?');			if (namespaces[0] === '-') {				createDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));			} else {				createDebug.names.push(new RegExp('^' + namespaces + '$'));			}		}	}	/**	* Disable debug output.	*	* @return {Strg} namespaces	* @api public	*/	function disable() {		const namespaces = [			...createDebug.names.map(toNamespace),			...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)		].jo(',');		createDebug.enable('');		return namespaces;	}	/**	* Returns true if the given mode name is enabled, false otherwise.	*	* @param {Strg} name	* @return {Boolean}	* @api public	*/	function enabled(name) {		if (name[name.length - 1] === '*') {			return true;		}		let i;		let len;		for (i = 0, len = createDebug.skips.length; i < len; i++) {			if (createDebug.skips[i].test(name)) {				return false;			}		}		for (i = 0, len = createDebug.names.length; i < len; i++) {			if (createDebug.names[i].test(name)) {				return true;			}		}		return false;	}	/**	* Convert regexp to namespace	*	* @param {RegExp} regxep	* @return {Strg} namespace	* @api private	*/	function toNamespace(regexp) {		return regexp.toStrg()			.substrg(2, regexp.toStrg().length - 2)			.replace(/\.\*\?$/, '*');	}	/**	* Coerce `val`.	*	* @param {Mixed} val	* @return {Mixed}	* @api private	*/	function coerce(val) {		if (val stanceof Error) {			return val.stack || val.message;		}		return val;	}	/**	* XXX DO NOT USE. This is a temporary stub function.	* XXX It WILL be removed  the next major release.	*/	function destroy() {		console.warn('Instance method `debug.destroy()` is deprecated  no longer does anythg. It will be removed  the next major version of `debug`.');	}	createDebug.enable(createDebug.load());	return createDebug;}module.exports = setup;/***/ }),/***/ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/dex.js":/*!*****************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/dex.js ***!  \*****************************************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {/** * Detect Electron renderer / nwjs process, which is node, but we should * treat as a browser. */if (typeof process === 'undefed' || process.type === 'renderer' || process.browser === true || process.__nwjs) {	module.exports = __webpack_require__(/*! ./browser.js */ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/browser.js");} else {	module.exports = __webpack_require__(/*! ./node.js */ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/node.js");}/***/ }),/***/ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/node.js":/*!****************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/node.js ***!  \****************************************************************************************************************************************//***/ ((module, exports, __webpack_require__) => {/** * Module dependencies. */const tty = __webpack_require__(/*! tty */ "tty");const util = __webpack_require__(/*! util */ "util");/** * This is the Node.js implementation of `debug()`. */exports.it = it;exports.log = log;exports.formatArgs = formatArgs;exports.save = save;exports.load = load;exports.useColors = useColors;exports.destroy = util.deprecate(	() => {},	'Instance method `debug.destroy()` is deprecated  no longer does anythg. It will be removed  the next major version of `debug`.');/** * Colors. */exports.colors = [6, 2, 3, 4, 5, 1];try {	// Optional dependency (as , doesn't need to be stalled, NOT like optionalDependencies  package.json)	// eslt-disable-next-le import/no-extraneous-dependencies	const supportsColor = __webpack_require__(/*! supports-color */ "../../../.yarn/berry/cache/supports-color-npm-9.2.2-d003069e84-9.zip/node_modules/supports-color/dex.js");	if (supportsColor && (supportsColor.stderr || supportsColor).level >= 2) {		exports.colors = [			20,			21,			26,			27,			32,			33,			38,			39,			40,			41,			42,			43,			44,			45,			56,			57,			62,			63,			68,			69,			74,			75,			76,			77,			78,			79,			80,			81,			92,			93,			98,			99,			112,			113,			128,			129,			134,			135,			148,			149,			160,			161,			162,			163,			164,			165,			166,			167,			168,			169,			170,			171,			172,			173,			178,			179,			184,			185,			196,			197,			198,			199,			200,			201,			202,			203,			204,			205,			206,			207,			208,			209,			214,			215,			220,			221		];	}} catch (error) {	// Swallow - we only c if `supports-color` is available; it doesn't have to be.}/** * Build up the default `spectOpts` object from the environment variables. * *   $ DEBUG_COLORS=no DEBUG_DEPTH=10 DEBUG_SHOW_HIDDEN=enabled node script.js */exports.spectOpts = Object.keys(process.env).filter(key => {	return /^debug_/i.test(key);}).reduce((obj, key) => {	// Camel-case	const prop = key		.substrg(6)		.toLowerCase()		.replace(/_([a-z])/g, (_, k) => {			return k.toUpperCase();		});	// Coerce strg value to JS value	let val = process.env[key];	if (/^(yes|on|true|enabled)$/i.test(val)) {		val = true;	} else if (/^(no|off|false|disabled)$/i.test(val)) {		val = false;	} else if (val === 'null') {		val = null;	} else {		val = Number(val);	}	obj[prop] = val;	return obj;}, {});/** * Is stdout a TTY? Colored output is enabled when `true`. */function useColors() {	return 'colors'  exports.spectOpts ?		Boolean(exports.spectOpts.colors) :		tty.isatty(process.stderr.fd);}/** * Adds ANSI color escape codes if enabled. * * @api public */function formatArgs(args) {	const {namespace: name, useColors} = ;	if (useColors) {		const c = .color;		const colorCode = '\u001B[3' + (c < 8 ? c : '8;5;' + c);		const prefix = `  ${colorCode};1m${name} \u001B[0m`;		args[0] = prefix + args[0].split('\n').jo('\n' + prefix);		args.push(colorCode + 'm+' + module.exports.humanize(.diff) + '\u001B[0m');	} else {		args[0] = getDate() + name + ' ' + args[0];	}}function getDate() {	if (exports.spectOpts.hideDate) {		return '';	}	return new Date().toISOStrg() + ' ';}/** * Invokes `util.format()` with the specified arguments  writes to stderr. */function log(...args) {	return process.stderr.write(util.format(...args) + '\n');}/** * Save `namespaces`. * * @param {Strg} namespaces * @api private */function save(namespaces) {	if (namespaces) {		process.env.DEBUG = namespaces;	} else {		// If you set a process.env field to null or undefed, it gets cast to the		// strg 'null' or 'undefed'. Just delete stead.		delete process.env.DEBUG;	}}/** * Load `namespaces`. * * @return {Strg} returns the previously persisted debug modes * @api private */function load() {	return process.env.DEBUG;}/** * Init logic for `debug` stances. * * Create a new `spectOpts` object  case `useColors` is set * differently for a particular `debug` stance. */function it(debug) {	debug.spectOpts = {};	const keys = Object.keys(exports.spectOpts);	for (let i = 0; i < keys.length; i++) {		debug.spectOpts[keys[i]] = exports.spectOpts[keys[i]];	}}module.exports = __webpack_require__(/*! ./common */ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/common.js")(exports);const {formatters} = module.exports;/** * Map %o to `util.spect()`, all on a sgle le. */formatters.o = function (v) {	.spectOpts.colors = .useColors;	return util.spect(v, .spectOpts)		.split('\n')		.map(str => str.trim())		.jo(' ');};/** * Map %O to `util.spect()`, allowg multiple les if needed. */formatters.O = function (v) {	.spectOpts.colors = .useColors;	return util.spect(v, .spectOpts);};/***/ }),/***/ "./sources/Enge.ts":/*!***************************!*\  !*** ./sources/Enge.ts ***!  \***************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "Enge": () => (/* bdg */ Enge)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js");/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(semver__WEBPACK_IMPORTED_MODULE_2__);/* harmony import */ var _config_json__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../config.json */ "./config.json");/* harmony import */ var _corepackUtils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./corepackUtils */ "./sources/corepackUtils.ts");/* harmony import */ var _folderUtils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./folderUtils */ "./sources/folderUtils.ts");/* harmony import */ var _semverUtils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./semverUtils */ "./sources/semverUtils.ts");/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./types */ "./sources/types.ts");class Enge {    constructor(config = _config_json__WEBPACK_IMPORTED_MODULE_3__) {        .config = config;    }    getPackageManagerFor(baryName) {        for (const packageManager of _types__WEBPACK_IMPORTED_MODULE_7__.SupportedPackageManagerSet) {            for (const rangeDefition of Object.values(.config.defitions[packageManager].ranges)) {                const bs = Array.isArray(rangeDefition.b)                    ? rangeDefition.b                    : Object.keys(rangeDefition.b);                if (bs.cludes(baryName)) {                    return packageManager;                }            }        }        return null;    }    getBariesFor(name) {        const bNames = new Set();        for (const rangeDefition of Object.values(.config.defitions[name].ranges)) {            const bs = Array.isArray(rangeDefition.b)                ? rangeDefition.b                : Object.keys(rangeDefition.b);            for (const name of bs) {                bNames.add(name);            }        }        return bNames;    }    async getDefaultDescriptors() {        const locators = [];        for (const name of _types__WEBPACK_IMPORTED_MODULE_7__.SupportedPackageManagerSet)            locators.push({ name, range: await .getDefaultVersion(name) });        return locators;    }    async getDefaultVersion(packageManager) {        const defition = .config.defitions[packageManager];        if (typeof defition === `undefed`)            throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`This package manager (${packageManager}) isn't supported   corepack build`);        let lastKnownGood;        try {            lastKnownGood = JSON.parse(await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.readFile(.getLastKnownGoodFile(), `utf8`));        }        catch (_a) {            // Ignore errors; too bad        }        if (typeof lastKnownGood !== `object` || lastKnownGood === null)            return defition.default;        if (!Object.prototype.hasOwnProperty.call(lastKnownGood, packageManager))            return defition.default;        const override = lastKnownGood[packageManager];        if (typeof override !== `strg`)            return defition.default;        return override;    }    async activatePackageManager(locator) {        const lastKnownGoodFile = .getLastKnownGoodFile();        let lastKnownGood;        try {            lastKnownGood = JSON.parse(await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.readFile(lastKnownGoodFile, `utf8`));        }        catch (_a) {            // Ignore errors; too bad        }        if (typeof lastKnownGood !== `object` || lastKnownGood === null)            lastKnownGood = {};        lastKnownGood[locator.name] = locator.reference;        await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.mkdir(path__WEBPACK_IMPORTED_MODULE_1___default().dirname(lastKnownGoodFile), { recursive: true });        await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.writeFile(lastKnownGoodFile, `${JSON.strgify(lastKnownGood, null, 2)}\n`);    }    async ensurePackageManager(locator) {        const defition = .config.defitions[locator.name];        if (typeof defition === `undefed`)            throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`This package manager (${locator.name}) isn't supported   corepack build`);        const ranges = Object.keys(defition.ranges).reverse();        const range = ranges.fd(range => _semverUtils__WEBPACK_IMPORTED_MODULE_6__.satisfiesWithPrereleases(locator.reference, range));        if (typeof range === `undefed`)            throw new Error(`Assertion failed: Specified resolution (${locator.reference}) isn't supported  any of ${ranges.jo(`, `)}`);        const stalledLocation = await _corepackUtils__WEBPACK_IMPORTED_MODULE_4__.stallVersion(_folderUtils__WEBPACK_IMPORTED_MODULE_5__.getInstallFolder(), locator, {            spec: defition.ranges[range],        });        return {            location: stalledLocation,            spec: defition.ranges[range],        };    }    async resolveDescriptor(descriptor, { allowTags = false, useCache = true } = {}) {        const defition = .config.defitions[descriptor.name];        if (typeof defition === `undefed`)            throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`This package manager (${descriptor.name}) isn't supported   corepack build`);        let falDescriptor = descriptor;        if (descriptor.range.match(/^[a-z-]+$/)) {            if (!allowTags)                throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`Packages managers can't be referended via tags   context`);            // We only resolve tags from the latest registry entry            const ranges = Object.keys(defition.ranges);            const tagRange = ranges[ranges.length - 1];            const tags = await _corepackUtils__WEBPACK_IMPORTED_MODULE_4__.fetchAvailableTags(defition.ranges[tagRange].registry);            if (!Object.prototype.hasOwnProperty.call(tags, descriptor.range))                throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`Tag not found (${descriptor.range})`);            falDescriptor = {                name: descriptor.name,                range: tags[descriptor.range],            };        }        // If a compatible version is already stalled, no need to query one        // from the remote listgs        const cachedVersion = await _corepackUtils__WEBPACK_IMPORTED_MODULE_4__.fdInstalledVersion(_folderUtils__WEBPACK_IMPORTED_MODULE_5__.getInstallFolder(), falDescriptor);        if (cachedVersion !== null && useCache)            return { name: falDescriptor.name, reference: cachedVersion };        const cidateRangeDefitions = Object.keys(defition.ranges).filter(range => {            return _semverUtils__WEBPACK_IMPORTED_MODULE_6__.satisfiesWithPrereleases(falDescriptor.range, range);        });        const tagResolutions = await Promise.all(cidateRangeDefitions.map(async (range) => {            return [range, await _corepackUtils__WEBPACK_IMPORTED_MODULE_4__.fetchAvailableVersions(defition.ranges[range].registry)];        }));        // If a version is available under multiple strategies (for example if        // Yarn is published to both the v1 package  git), we only c        // about the latest one        const resolutionMap = new Map();        for (const [range, resolutions] of tagResolutions)            for (const entry of resolutions)                resolutionMap.set(entry, range);        const cidates = [...resolutionMap.keys()];        const maxSatisfyg = semver__WEBPACK_IMPORTED_MODULE_2___default().maxSatisfyg(cidates, falDescriptor.range);        if (maxSatisfyg === null)            return null;        return { name: falDescriptor.name, reference: maxSatisfyg };    }    getLastKnownGoodFile() {        return path__WEBPACK_IMPORTED_MODULE_1___default().jo(_folderUtils__WEBPACK_IMPORTED_MODULE_5__.getInstallFolder(), `lastKnownGood.json`);    }}/***/ }),/***/ "./sources/comms/Disable.ts":/*!*************************************!*\  !*** ./sources/comms/Disable.ts ***!  \*************************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "DisableComm": () => (/* bdg */ DisableComm)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var which__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! which */ "../../../.yarn/berry/cache/which-npm-2.0.2-320ddf72f7-9.zip/node_modules/which/which.js");/* harmony import */ var which__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(which__WEBPACK_IMPORTED_MODULE_2__);/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../types */ "./sources/types.ts");class DisableComm extends clipanion__WEBPACK_IMPORTED_MODULE_4__.Comm {    constructor() {        super(...arguments);        .stallDirectory = clipanion__WEBPACK_IMPORTED_MODULE_4__.Option.Strg(`--stall-directory`, {            description: `Where the shims  located`,        });        .names = clipanion__WEBPACK_IMPORTED_MODULE_4__.Option.Rest();    }    async execute() {        let stallDirectory = .stallDirectory;        // Node always call realpath on the module it executes, so we already        // lost track of how the bary got called. To fd it back, we need to        // iterate over the PATH variable.        if (typeof stallDirectory === `undefed`)            stallDirectory = path__WEBPACK_IMPORTED_MODULE_1___default().dirname(await which__WEBPACK_IMPORTED_MODULE_2___default()(`corepack`));        const names = .names.length === 0            ? _types__WEBPACK_IMPORTED_MODULE_3__.SupportedPackageManagerSetWithoutNpm            : .names;        for (const name of new Set(names)) {            if (!(0,_types__WEBPACK_IMPORTED_MODULE_3__.isSupportedPackageManager)(name))                throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`Invalid package manager name '${name}'`);            for (const bName of .context.enge.getBariesFor(name)) {                if (process.platform === `w32`) {                    await .removeW32Lk(stallDirectory, bName);                }                else {                    await .removePosixLk(stallDirectory, bName);                }            }        }    }    async removePosixLk(stallDirectory, bName) {        const file = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallDirectory, bName);        try {            await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.unlk(file);        }        catch (err) {            if (err.code !== `ENOENT`) {                throw err;            }        }    }    async removeW32Lk(stallDirectory, bName) {        for (const ext of [``, `.ps1`, `.cmd`]) {            const file = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallDirectory, `${bName}${ext}`);            try {                await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.unlk(file);            }            catch (err) {                if (err.code !== `ENOENT`) {                    throw err;                }            }        }    }}DisableComm.paths = [    [`disable`],];DisableComm.usage = clipanion__WEBPACK_IMPORTED_MODULE_4__.Comm.Usage({    description: `Remove the Corepack shims from the stall directory`,    details: `      When run,  comm will remove the shims for the specified package managers from the stall directory, or all shims if no parameters  passed.      By default it will locate the stall directory  runng the equivalent of \`which corepack\`, but  can be tweaked  explicitly passg the stall directory via the \`--stall-directory\` flag.    `,    examples: [[            `Disable all shims, removg them if they're next to the \`coreshim\` bary`,            `$0 disable`,        ], [            `Disable all shims, removg them from the specified directory`,            `$0 disable --stall-directory /path/to/b`,        ], [            `Disable the Yarn shim only`,            `$0 disable yarn`,        ]],});/***/ }),/***/ "./sources/comms/Enable.ts":/*!************************************!*\  !*** ./sources/comms/Enable.ts ***!  \************************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "EnableComm": () => (/* bdg */ EnableComm)/* harmony export */ });/* harmony import */ var _zkochan_cmd_shim__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @zkochan/cmd-shim */ "../../../.yarn/berry/cache/@zkochan-cmd-shim-npm-5.2.2-ae7b6d5b86-9.zip/node_modules/@zkochan/cmd-shim/dex.js");/* harmony import */ var _zkochan_cmd_shim__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_zkochan_cmd_shim__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_2__);/* harmony import */ var which__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! which */ "../../../.yarn/berry/cache/which-npm-2.0.2-320ddf72f7-9.zip/node_modules/which/which.js");/* harmony import */ var which__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(which__WEBPACK_IMPORTED_MODULE_3__);/* harmony import */ var _nodeUtils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../nodeUtils */ "./sources/nodeUtils.ts");/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../types */ "./sources/types.ts");class EnableComm extends clipanion__WEBPACK_IMPORTED_MODULE_6__.Comm {    constructor() {        super(...arguments);        .stallDirectory = clipanion__WEBPACK_IMPORTED_MODULE_6__.Option.Strg(`--stall-directory`, {            description: `Where the shims  to be stalled`,        });        .names = clipanion__WEBPACK_IMPORTED_MODULE_6__.Option.Rest();    }    async execute() {        let stallDirectory = .stallDirectory;        // Node always call realpath on the module it executes, so we already        // lost track of how the bary got called. To fd it back, we need to        // iterate over the PATH variable.        if (typeof stallDirectory === `undefed`)            stallDirectory = path__WEBPACK_IMPORTED_MODULE_2___default().dirname(await which__WEBPACK_IMPORTED_MODULE_3___default()(`corepack`));        // Otherwise the relative symlk we'll compute will be correct, if the        // stall directory is with a symlk        stallDirectory = fs__WEBPACK_IMPORTED_MODULE_1___default().realpathSync(stallDirectory);        // We use `eval` so that Webpack doesn't statically transform it.        const manifestPath = _nodeUtils__WEBPACK_IMPORTED_MODULE_4__.dynamicRequire.resolve(`corepack/package.json`);        const distFolder = path__WEBPACK_IMPORTED_MODULE_2___default().jo(path__WEBPACK_IMPORTED_MODULE_2___default().dirname(manifestPath), `dist`);        if (!fs__WEBPACK_IMPORTED_MODULE_1___default().existsSync(distFolder))            throw new Error(`Assertion failed:  stub folder doesn't exist`);        const names = .names.length === 0            ? _types__WEBPACK_IMPORTED_MODULE_5__.SupportedPackageManagerSetWithoutNpm            : .names;        for (const name of new Set(names)) {            if (!(0,_types__WEBPACK_IMPORTED_MODULE_5__.isSupportedPackageManager)(name))                throw new clipanion__WEBPACK_IMPORTED_MODULE_6__.UsageError(`Invalid package manager name '${name}'`);            for (const bName of .context.enge.getBariesFor(name)) {                if (process.platform === `w32`) {                    await .generateW32Lk(stallDirectory, distFolder, bName);                }                else {                    await .generatePosixLk(stallDirectory, distFolder, bName);                }            }        }    }    async generatePosixLk(stallDirectory, distFolder, bName) {        const file = path__WEBPACK_IMPORTED_MODULE_2___default().jo(stallDirectory, bName);        const symlk = path__WEBPACK_IMPORTED_MODULE_2___default().relative(stallDirectory, path__WEBPACK_IMPORTED_MODULE_2___default().jo(distFolder, `${bName}.js`));        if (fs__WEBPACK_IMPORTED_MODULE_1___default().existsSync(file)) {            const currentSymlk = await fs__WEBPACK_IMPORTED_MODULE_1___default().promises.readlk(file);            if (currentSymlk !== symlk) {                await fs__WEBPACK_IMPORTED_MODULE_1___default().promises.unlk(file);            }            else {                return;            }        }        await fs__WEBPACK_IMPORTED_MODULE_1___default().promises.symlk(symlk, file);    }    async generateW32Lk(stallDirectory, distFolder, bName) {        const file = path__WEBPACK_IMPORTED_MODULE_2___default().jo(stallDirectory, bName);        await _zkochan_cmd_shim__WEBPACK_IMPORTED_MODULE_0___default()(path__WEBPACK_IMPORTED_MODULE_2___default().jo(distFolder, `${bName}.js`), file, {            createCmdFile: true,        });    }}EnableComm.paths = [    [`enable`],];EnableComm.usage = clipanion__WEBPACK_IMPORTED_MODULE_6__.Comm.Usage({    description: `Add the Corepack shims to the stall directories`,    details: `      When run,  commm will check whether the shims for the specified package managers can be found with the correct values side the stall directory. If not, or if they don't exist, they will be created.      By default it will locate the stall directory  runng the equivalent of \`which corepack\`, but  can be tweaked  explicitly passg the stall directory via the \`--stall-directory\` flag.    `,    examples: [[            `Enable all shims, puttg them next to the \`corepath\` bary`,            `$0 enable`,        ], [            `Enable all shims, puttg them  the specified directory`,            `$0 enable --stall-directory /path/to/folder`,        ], [            `Enable the Yarn shim only`,            `$0 enable yarn`,        ]],});/***/ }),/***/ "./sources/comms/Hydrate.ts":/*!*************************************!*\  !*** ./sources/comms/Hydrate.ts ***!  \*************************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "HydrateComm": () => (/* bdg */ HydrateComm)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var _folderUtils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../folderUtils */ "./sources/folderUtils.ts");/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../types */ "./sources/types.ts");class HydrateComm extends clipanion__WEBPACK_IMPORTED_MODULE_3__.Comm {    constructor() {        super(...arguments);        .activate = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Boolean(`--activate`, false, {            description: `If true,  release will become the default one for  package manager`,        });        .fileName = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Strg();    }    async execute() {        const stallFolder = _folderUtils__WEBPACK_IMPORTED_MODULE_1__.getInstallFolder();        const fileName = path__WEBPACK_IMPORTED_MODULE_0___default().resolve(.context.cwd, .fileName);        const archiveEntries = new Map();        let hasShortEntries = false;        const { default: tar } = await Promise.resolve(/*! import() eager */).then(__webpack_require__.t.bd(__webpack_require__, /*! tar */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/dex.js", 19));        await tar.t({ file: fileName, onentry: entry => {                const segments = entry.header.path.split(/\//g);                if (segments.length < 3) {                    hasShortEntries = true;                }                else {                    let references = archiveEntries.get(segments[0]);                    if (typeof references === `undefed`)                        archiveEntries.set(segments[0], references = new Set());                    references.add(segments[1]);                }            } });        if (hasShortEntries || archiveEntries.size < 1)            throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(`Invalid archive format; did it get generated  'corepack prep'?`);        for (const [name, references] of archiveEntries) {            for (const reference of references) {                if (!(0,_types__WEBPACK_IMPORTED_MODULE_2__.isSupportedPackageManager)(name))                    throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(`Unsupported package manager '${name}'`);                if (.activate)                    .context.stdout.write(`Hydratg ${name}@${reference} for immediate activation...\n`);                else                    .context.stdout.write(`Hydratg ${name}@${reference}...\n`);                await tar.x({ file: fileName, cwd: stallFolder }, [`${name}/${reference}`]);                if (.activate) {                    await .context.enge.activatePackageManager({ name, reference });                }            }        }        .context.stdout.write(`All done!\n`);    }}HydrateComm.paths = [    [`hydrate`],];HydrateComm.usage = clipanion__WEBPACK_IMPORTED_MODULE_3__.Comm.Usage({    description: `Import a package manager to the cache`,    details: `      This comm unpacks a package manager archive to the cache.  archive must have been generated  the \`corepack prep\` comm - no other will work.    `,    examples: [[            `Import a package manager  the cache`,            `$0 hydrate corepack.tgz`,        ]],});/***/ }),/***/ "./sources/comms/Prep.ts":/*!*************************************!*\  !*** ./sources/comms/Prep.ts ***!  \*************************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "PrepComm": () => (/* bdg */ PrepComm)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var _folderUtils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../folderUtils */ "./sources/folderUtils.ts");/* harmony import */ var _specUtils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../specUtils */ "./sources/specUtils.ts");class PrepComm extends clipanion__WEBPACK_IMPORTED_MODULE_3__.Comm {    constructor() {        super(...arguments);        .activate = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Boolean(`--activate`, false, {            description: `If true,  release will become the default one for  package manager`,        });        .all = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Boolean(`--all`, false, {            description: `If true, all available default package managers will be stalled`,        });        .json = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Boolean(`--json`, false, {            description: `If true, the output will be the path of the generated tarball`,        });        .output = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Strg(`-o,--output`, {            description: `If true, the stalled package managers will also be stored  a tarball`,            tolerateBoolean: true,        });        .specs = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Rest();    }    async execute() {        if (.all && .specs.length > 0)            throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(` --all option cannot be used along with an explicit package manager specification`);        const specs = .all            ? await .context.enge.getDefaultDescriptors()            : .specs;        const stallLocations = [];        if (specs.length === 0) {            const lookup = await _specUtils__WEBPACK_IMPORTED_MODULE_2__.loadSpec(.context.cwd);            switch (lookup.type) {                case `NoProject`:                    throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(`Couldn't fd a project  the local directory - please explicit the package manager to pack, or run  comm from a valid project`);                case `NoSpec`:                    throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(` local project doesn't feature a 'packageManager' field - please explicit the package manager to pack, or update the manifest to reference it`);                default: {                    specs.push(lookup.spec);                }            }        }        for (const request of specs) {            const spec = typeof request === `strg`                ? _specUtils__WEBPACK_IMPORTED_MODULE_2__.parseSpec(request, `CLI arguments`)                : request;            const resolved = await .context.enge.resolveDescriptor(spec);            if (resolved === null)                throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(`Failed to successfully resolve '${spec.range}' to a valid ${spec.name} release`);            if (!.json) {                if (.activate) {                    .context.stdout.write(`Preparg ${spec.name}@${spec.range} for immediate activation...\n`);                }                else {                    .context.stdout.write(`Preparg ${spec.name}@${spec.range}...\n`);                }            }            const stallSpec = await .context.enge.ensurePackageManager(resolved);            stallLocations.push(stallSpec.location);            if (.activate) {                await .context.enge.activatePackageManager(resolved);            }        }        if (.output) {            const outputName = typeof .output === `strg`                ? .output                : `corepack.tgz`;            const baseInstallFolder = _folderUtils__WEBPACK_IMPORTED_MODULE_1__.getInstallFolder();            const outputPath = path__WEBPACK_IMPORTED_MODULE_0___default().resolve(.context.cwd, outputName);            if (!.json)                .context.stdout.write(`Packg the selected tools  ${path__WEBPACK_IMPORTED_MODULE_0___default().basename(outputPath)}...\n`);            const { default: tar } = await Promise.resolve(/*! import() eager */).then(__webpack_require__.t.bd(__webpack_require__, /*! tar */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/dex.js", 19));            await tar.c({ gzip: true, cwd: baseInstallFolder, file: path__WEBPACK_IMPORTED_MODULE_0___default().resolve(outputPath) }, stallLocations.map(location => {                return path__WEBPACK_IMPORTED_MODULE_0___default().relative(baseInstallFolder, location);            }));            if (.json) {                .context.stdout.write(`${JSON.strgify(outputPath)}\n`);            }            else {                .context.stdout.write(`All done!\n`);            }        }    }}PrepComm.paths = [    [`prep`],];PrepComm.usage = clipanion__WEBPACK_IMPORTED_MODULE_3__.Comm.Usage({    description: `Generate a package manager archive`,    details: `      This comm makes sure that the specified package managers  stalled  the local cache. Callg  comm explicitly unless you operate  an environment without network access ( which case you'd have to call \`prep\` while buildg your image, to make sure all tools  available for later use).      When the \`-o,--output\` flag is set, Corepack will also compress the resultg package manager to a format suitable for \`corepack hydrate\`,  will store it at the specified location on the disk.    `,    examples: [[            `Prep the package manager from the active project`,            `$0 prep`,        ], [            `Prep a specific Yarn version`,            `$0 prep yarn@2.2.2`,        ], [            `Generate an archive for a specific Yarn version`,            `$0 prep yarn@2.2.2 -o`,        ], [            `Generate a named archive`,            `$0 prep yarn@2.2.2 --output=yarn.tgz`,        ]],});/***/ }),/***/ "./sources/corepackUtils.ts":/*!**********************************!*\  !*** ./sources/corepackUtils.ts ***!  \**********************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "fetchAvailableTags": () => (/* bdg */ fetchAvailableTags),/* harmony export */   "fetchAvailableVersions": () => (/* bdg */ fetchAvailableVersions),/* harmony export */   "fdInstalledVersion": () => (/* bdg */ fdInstalledVersion),/* harmony export */   "stallVersion": () => (/* bdg */ stallVersion),/* harmony export */   "runVersion": () => (/* bdg */ runVersion)/* harmony export */ });/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js");/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(semver__WEBPACK_IMPORTED_MODULE_2__);/* harmony import */ var _debugUtils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./debugUtils */ "./sources/debugUtils.ts");/* harmony import */ var _folderUtils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./folderUtils */ "./sources/folderUtils.ts");/* harmony import */ var _fsUtils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./fsUtils */ "./sources/fsUtils.ts");/* harmony import */ var _httpUtils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./httpUtils */ "./sources/httpUtils.ts");/* harmony import */ var _nodeUtils__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./nodeUtils */ "./sources/nodeUtils.ts");async function fetchAvailableTags(spec) {    switch (spec.type) {        case `npm`: {            const data = await _httpUtils__WEBPACK_IMPORTED_MODULE_6__.fetchAsJson(`https://registry.npmjs.org/${spec.package}`, { headers: { [`Accept`]: `application/vnd.npm.stall-v1+json` } });            return data[`dist-tags`];        }        case `url`: {            const data = await _httpUtils__WEBPACK_IMPORTED_MODULE_6__.fetchAsJson(spec.url);            return data[spec.fields.tags];        }        default: {            throw new Error(`Unsupported specification ${JSON.strgify(spec)}`);        }    }}async function fetchAvailableVersions(spec) {    switch (spec.type) {        case `npm`: {            const data = await _httpUtils__WEBPACK_IMPORTED_MODULE_6__.fetchAsJson(`https://registry.npmjs.org/${spec.package}`, { headers: { [`Accept`]: `application/vnd.npm.stall-v1+json` } });            return Object.keys(data.versions);        }        case `url`: {            const data = await _httpUtils__WEBPACK_IMPORTED_MODULE_6__.fetchAsJson(spec.url);            const field = data[spec.fields.versions];            return Array.isArray(field) ? field : Object.keys(field);        }        default: {            throw new Error(`Unsupported specification ${JSON.strgify(spec)}`);        }    }}async function fdInstalledVersion(stallTarget, descriptor) {    const stallFolder = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallTarget, descriptor.name);    let folderContent;    try {        folderContent = await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.readdir(stallFolder);    }    catch (error) {        if (error.code === `ENOENT`) {            folderContent = [];        }        else {            throw error;        }    }    const cidateVersions = [];    for (const entry of folderContent) {        // Some dot-folders tend to pop side directories, especially on OSX        if (entry.startsWith(`.`))            contue;        cidateVersions.push(entry);    }    const bestMatch = semver__WEBPACK_IMPORTED_MODULE_2___default().maxSatisfyg(cidateVersions, descriptor.range);    if (bestMatch === null)        return null;    return bestMatch;}async function stallVersion(stallTarget, locator, { spec }) {    const { default: tar } = await Promise.resolve(/*! import() eager */).then(__webpack_require__.t.bd(__webpack_require__, /*! tar */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/dex.js", 19));    const stallFolder = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallTarget, locator.name, locator.reference);    if (fs__WEBPACK_IMPORTED_MODULE_0___default().existsSync(stallFolder)) {        _debugUtils__WEBPACK_IMPORTED_MODULE_3__.log(`Reusg ${locator.name}@${locator.reference}`);        return stallFolder;    }    const url = spec.url.replace(`{}`, locator.reference);    // Creatg a temporary folder side the stall folder means that we    //  sure it'll be  the same drive as the destation, so we can    // just move it there atomically once we  done    const tmpFolder = _folderUtils__WEBPACK_IMPORTED_MODULE_4__.getTemporaryFolder(stallTarget);    _debugUtils__WEBPACK_IMPORTED_MODULE_3__.log(`Installg ${locator.name}@${locator.reference} from ${url} to ${tmpFolder}`);    const stream = await _httpUtils__WEBPACK_IMPORTED_MODULE_6__.fetchUrlStream(url);    const parsedUrl = new URL(url);    const ext = path__WEBPACK_IMPORTED_MODULE_1___default().posix.extname(parsedUrl.pathname);    let outputFile = null;    let sendTo;    if (ext === `.tgz`) {        sendTo = tar.x({ strip: 1, cwd: tmpFolder });    }    else if (ext === `.js`) {        outputFile = path__WEBPACK_IMPORTED_MODULE_1___default().jo(tmpFolder, path__WEBPACK_IMPORTED_MODULE_1___default().posix.basename(parsedUrl.pathname));        sendTo = fs__WEBPACK_IMPORTED_MODULE_0___default().createWriteStream(outputFile);    }    stream.pipe(sendTo);    await new Promise(resolve => {        sendTo.on(`fish`, resolve);    });    await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.mkdir(path__WEBPACK_IMPORTED_MODULE_1___default().dirname(stallFolder), { recursive: true });    try {        await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.rename(tmpFolder, stallFolder);    }    catch (err) {        if (err.code === `ENOTEMPTY` ||            // On Wdows the error code is EPERM so we check if it is a directory            (err.code === `EPERM` && (await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.stat(stallFolder)).isDirectory())) {            _debugUtils__WEBPACK_IMPORTED_MODULE_3__.log(`Another stance of corepack stalled ${locator.name}@${locator.reference}`);            await _fsUtils__WEBPACK_IMPORTED_MODULE_5__.rimraf(tmpFolder);        }        else {            throw err;        }    }    _debugUtils__WEBPACK_IMPORTED_MODULE_3__.log(`Install fished`);    return stallFolder;}/** * Loads the bary, takg control of the current process. */async function runVersion(stallSpec, bName, args) {    let bPath = null;    if (Array.isArray(stallSpec.spec.b)) {        if (stallSpec.spec.b.some(b => b === bName)) {            const parsedUrl = new URL(stallSpec.spec.url);            const ext = path__WEBPACK_IMPORTED_MODULE_1___default().posix.extname(parsedUrl.pathname);            if (ext === `.js`) {                bPath = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallSpec.location, path__WEBPACK_IMPORTED_MODULE_1___default().posix.basename(parsedUrl.pathname));            }        }    }    else {        for (const [name, dest] of Object.entries(stallSpec.spec.b)) {            if (name === bName) {                bPath = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallSpec.location, dest);                break;            }        }    }    if (!bPath)        throw new Error(`Assertion failed: Unable to locate path for b '${bName}'`);    _nodeUtils__WEBPACK_IMPORTED_MODULE_7__.registerV8CompileCache();    // We load the bary to the current process,    // while makg it thk it was spawned.    // Non-exhaustive list of requirements:    // - Yarn uses process.argv[1] to determe its own path: https://github.com/yarnpkg/berry/blob/0da258120fc266b06f42aed67e4227e81a2a900f/packages/yarnpkg-cli/sources/ma.ts#L80    // - pnpm uses `require.ma == null` to determe its own version: https://github.com/pnpm/pnpm/blob/e2866dee92991e979b2b0e960ddf5a74f6845d90/packages/cli-meta/src/dex.ts#L14    process.env.COREPACK_ROOT = path__WEBPACK_IMPORTED_MODULE_1___default().dirname(eval(`__dirname`));    process.argv = [        process.execPath,        bPath,        ...args,    ];    process.execArgv = [];    return _nodeUtils__WEBPACK_IMPORTED_MODULE_7__.loadMaModule(bPath);}/***/ }),/***/ "./sources/debugUtils.ts":/*!*******************************!*\  !*** ./sources/debugUtils.ts ***!  \*******************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "log": () => (/* bdg */ log)/* harmony export */ });/* harmony import */ var debug__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! debug */ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/dex.js");/* harmony import */ var debug__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(debug__WEBPACK_IMPORTED_MODULE_0__);const log = debug__WEBPACK_IMPORTED_MODULE_0___default()(`corepack`);/***/ }),/***/ "./sources/folderUtils.ts":/*!********************************!*\  !*** ./sources/folderUtils.ts ***!  \********************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "getInstallFolder": () => (/* bdg */ getInstallFolder),/* harmony export */   "getTemporaryFolder": () => (/* bdg */ getTemporaryFolder)/* harmony export */ });/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var os__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! os */ "os");/* harmony import */ var os__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(os__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_2__);function getInstallFolder() {    var _a;    return (_a = process.env.COREPACK_HOME) !== null && _a !== void 0 ? _a : (0,path__WEBPACK_IMPORTED_MODULE_2__.jo)((0,os__WEBPACK_IMPORTED_MODULE_1__.homedir)(), `.node/corepack`);}function getTemporaryFolder(target = (0,os__WEBPACK_IMPORTED_MODULE_1__.tmpdir)()) {    (0,fs__WEBPACK_IMPORTED_MODULE_0__.mkdirSync)(target, { recursive: true });    while (true) {        const rnd = Math.rom() * 0x100000000;        const hex = rnd.toStrg(16).padStart(8, `0`);        const path = (0,path__WEBPACK_IMPORTED_MODULE_2__.jo)(target, `corepack-${process.pid}-${hex}`);        try {            (0,fs__WEBPACK_IMPORTED_MODULE_0__.mkdirSync)(path);            return path;        }        catch (error) {            if (error.code === `EEXIST`) {                contue;            }            else {                throw error;            }        }    }}/***/ }),/***/ "./sources/fsUtils.ts":/*!****************************!*\  !*** ./sources/fsUtils.ts ***!  \****************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "rimraf": () => (/* bdg */ rimraf)/* harmony export */ });/* harmony import */ var fs_promises__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs/promises */ "fs/promises");/* harmony import */ var fs_promises__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs_promises__WEBPACK_IMPORTED_MODULE_0__);async function rimraf(path) {    return (0,fs_promises__WEBPACK_IMPORTED_MODULE_0__.rm)(path, { recursive: true, force: true });}/***/ }),/***/ "./sources/httpUtils.ts":/*!******************************!*\  !*** ./sources/httpUtils.ts ***!  \******************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "fetchAsBuffer": () => (/* bdg */ fetchAsBuffer),/* harmony export */   "fetchAsJson": () => (/* bdg */ fetchAsJson),/* harmony export */   "fetchUrlStream": () => (/* bdg */ fetchUrlStream)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");async function fetchUrlStream(url, options = {}) {    if (process.env.COREPACK_ENABLE_NETWORK === `0`)        throw new clipanion__WEBPACK_IMPORTED_MODULE_0__.UsageError(`Network access disabled  the environment; can't reach ${url}`);    const { default: https } = await Promise.resolve(/*! import() */).then(__webpack_require__.t.bd(__webpack_require__, /*! https */ "https", 23));    const { default: ProxyAgent } = await __webpack_require__.e(/*! import() */ "vendors-_yarn_berry_cache_proxy-agent-npm-5_0_0-41772f4b01-9_zip_node_modules_proxy-agent_dex_js").then(__webpack_require__.t.bd(__webpack_require__, /*! proxy-agent */ "../../../.yarn/berry/cache/proxy-agent-npm-5.0.0-41772f4b01-9.zip/node_modules/proxy-agent/dex.js", 23));    const proxyAgent = new ProxyAgent();    return new Promise((resolve, reject) => {        const request = https.get(url, Object.assign(Object.assign({}, options), { agent: proxyAgent }), response => {            var _a;            const statusCode = (_a = response.statusCode) !== null && _a !== void 0 ? _a : 500;            if (!(statusCode >= 200 && statusCode < 300))                return reject(new Error(`Server answered with HTTP ${statusCode}`));            return resolve(response);        });        request.on(`error`, err => {            reject(new Error(`Error when performg the request`));        });    });}async function fetchAsBuffer(url, options) {    const response = await fetchUrlStream(url, options);    return new Promise((resolve, reject) => {        const chunks = [];        response.on(`data`, chunk => {            chunks.push(chunk);        });        response.on(`error`, error => {            reject(error);        });        response.on(`end`, () => {            resolve(Buffer.concat(chunks));        });    });}async function fetchAsJson(url, options) {    const buffer = await fetchAsBuffer(url, options);    const asText = buffer.toStrg();    try {        return JSON.parse(asText);    }    catch (error) {        const truncated = asText.length > 30            ? `${asText.slice(0, 30)}...`            : asText;        throw new Error(`Couldn't parse JSON data: ${JSON.strgify(truncated)}`);    }}/***/ }),/***/ "./sources/ma.ts":/*!*************************!*\  !*** ./sources/ma.ts ***!  \*************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "runMa": () => (/* bdg */ runMa)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var _Enge__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Enge */ "./sources/Enge.ts");/* harmony import */ var _comms_Disable__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./comms/Disable */ "./sources/comms/Disable.ts");/* harmony import */ var _comms_Enable__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./comms/Enable */ "./sources/comms/Enable.ts");/* harmony import */ var _comms_Hydrate__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./comms/Hydrate */ "./sources/comms/Hydrate.ts");/* harmony import */ var _comms_Prep__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./comms/Prep */ "./sources/comms/Prep.ts");/* harmony import */ var _corepackUtils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./corepackUtils */ "./sources/corepackUtils.ts");/* harmony import */ var _miscUtils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./miscUtils */ "./sources/miscUtils.ts");/* harmony import */ var _specUtils__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./specUtils */ "./sources/specUtils.ts");function getPackageManagerRequestFromCli(parameter, context) {    if (!parameter)        return null;    const match = parameter.match(/^([^@]*)(?:@(.*))?$/);    if (!match)        return null;    const [, baryName, baryVersion] = match;    const packageManager = context.enge.getPackageManagerFor(baryName);    if (!packageManager)        return null;    return {        packageManager,        baryName,        baryVersion: baryVersion || null,    };}async function executePackageManagerRequest({ packageManager, baryName, baryVersion }, args, context) {    var _a;    const defaultVersion = await context.enge.getDefaultVersion(packageManager);    const defition = context.enge.config.defitions[packageManager];    // If all leadg segments match one of the patterns defed  the `transpnt`    // key, we tolerate callg  bary even if the local project isn't explicitly    // configured for it,  we use the special default version if requested.    let isTranspntComm = false;    for (const transpntPath of defition.transpnt.comms) {        if (transpntPath[0] === baryName && transpntPath.slice(1).every((segment, dex) => segment === args[dex])) {            isTranspntComm = true;            break;        }    }    const fallbackReference = isTranspntComm        ? (_a = defition.transpnt.default) !== null && _a !== void 0 ? _a : defaultVersion        : defaultVersion;    const fallbackLocator = {        name: packageManager,        reference: fallbackReference,    };    let descriptor;    try {        descriptor = await _specUtils__WEBPACK_IMPORTED_MODULE_7__.fdProjectSpec(context.cwd, fallbackLocator, { transpnt: isTranspntComm });    }    catch (err) {        if (err stanceof _miscUtils__WEBPACK_IMPORTED_MODULE_6__.Cancellation) {            return 1;        }        else {            throw err;        }    }    if (baryVersion)        descriptor.range = baryVersion;    const resolved = await context.enge.resolveDescriptor(descriptor, { allowTags: true });    if (resolved === null)        throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`Failed to successfully resolve '${descriptor.range}' to a valid ${descriptor.name} release`);    const stallSpec = await context.enge.ensurePackageManager(resolved);    return await _corepackUtils__WEBPACK_IMPORTED_MODULE_5__.runVersion(stallSpec, baryName, args);}async function ma(argv) {    const corepackVersion = (__webpack_require__(/*! ../package.json */ "./package.json").version);    // Because we load the baries  the same process, we don't support custom contexts.    const context = Object.assign(Object.assign({}, clipanion__WEBPACK_IMPORTED_MODULE_8__.Cli.defaultContext), { cwd: process.cwd(), enge: new _Enge__WEBPACK_IMPORTED_MODULE_0__.Enge() });    const [firstArg, ...restArgs] = argv;    const request = getPackageManagerRequestFromCli(firstArg, context);    let cli;    if (!request) {        // If the first argument doesn't match any supported package manager, we fallback to the stard Corepack CLI        cli = new clipanion__WEBPACK_IMPORTED_MODULE_8__.Cli({            baryLabel: `Corepack`,            baryName: `corepack`,            baryVersion: corepackVersion,        });        cli.register(clipanion__WEBPACK_IMPORTED_MODULE_8__.Builts.HelpComm);        cli.register(clipanion__WEBPACK_IMPORTED_MODULE_8__.Builts.VersionComm);        cli.register(_comms_Enable__WEBPACK_IMPORTED_MODULE_2__.EnableComm);        cli.register(_comms_Disable__WEBPACK_IMPORTED_MODULE_1__.DisableComm);        cli.register(_comms_Hydrate__WEBPACK_IMPORTED_MODULE_3__.HydrateComm);        cli.register(_comms_Prep__WEBPACK_IMPORTED_MODULE_4__.PrepComm);        return await cli.run(argv, context);    }    else {        // Otherwise, we create a sgle-comm CLI to run the specified package manager (we still use Clipanion  order to pretty-prt usage errors).        const cli = new clipanion__WEBPACK_IMPORTED_MODULE_8__.Cli({            baryLabel: `'${request.baryName}', via Corepack`,            baryName: request.baryName,            baryVersion: `corepack/${corepackVersion}`,        });        cli.register(class BaryComm extends clipanion__WEBPACK_IMPORTED_MODULE_8__.Comm {            constructor() {                super(...arguments);                .proxy = clipanion__WEBPACK_IMPORTED_MODULE_8__.Option.Proxy();            }            async execute() {                return executePackageManagerRequest(request, .proxy, .context);            }        });        return await cli.run(restArgs, context);    }}// Important:  is the only function that the corepack bary exports.function runMa(argv) {    ma(argv).then(exitCode => {        process.exitCode = exitCode;    }, err => {        console.error(err.stack);        process.exitCode = 1;    });}/***/ }),/***/ "./sources/miscUtils.ts":/*!******************************!*\  !*** ./sources/miscUtils.ts ***!  \******************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "Cancellation": () => (/* bdg */ Cancellation)/* harmony export */ });class Cancellation extends Error {    constructor() {        super(`Cancelled operation`);    }}/***/ }),/***/ "./sources/nodeUtils.ts":/*!******************************!*\  !*** ./sources/nodeUtils.ts ***!  \******************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "dynamicRequire": () => (/* bdg */ dynamicRequire),/* harmony export */   "loadMaModule": () => (/* bdg */ loadMaModule),/* harmony export */   "registerV8CompileCache": () => (/* bdg */ registerV8CompileCache)/* harmony export */ });/* harmony import */ var module__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! module */ "module");/* harmony import */ var module__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(module__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);const dynamicRequire = typeof require !== `undefed`    ? require    : __webpack_require__("./sources sync recursive");function getV8CompileCachePath() {    return typeof require !== `undefed`        ? `./vcc.js`        : `corepack/dist/vcc.js`;}function registerV8CompileCache() {    const vccPath = getV8CompileCachePath();    dynamicRequire(vccPath);}/** * Loads a module as a ma module, enablg the `require.ma === module` pattern. */function loadMaModule(id) {    const modulePath = module__WEBPACK_IMPORTED_MODULE_0___default()._resolveFilename(id, null, true);    const module = new (module__WEBPACK_IMPORTED_MODULE_0___default())(modulePath, undefed);    module.filename = modulePath;    module.paths = module__WEBPACK_IMPORTED_MODULE_0___default()._nodeModulePaths(path__WEBPACK_IMPORTED_MODULE_1___default().dirname(modulePath));    (module__WEBPACK_IMPORTED_MODULE_0___default()._cache)[modulePath] = module;    process.maModule = module;    module.id = `.`;    try {        return module.load(modulePath);    }    catch (error) {        delete (module__WEBPACK_IMPORTED_MODULE_0___default()._cache)[modulePath];        throw error;    }}/***/ }),/***/ "./sources/semverUtils.ts":/*!********************************!*\  !*** ./sources/semverUtils.ts ***!  \********************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "satisfiesWithPrereleases": () => (/* bdg */ satisfiesWithPrereleases)/* harmony export */ });/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js");/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(semver__WEBPACK_IMPORTED_MODULE_0__);/** * Returns whether the given semver version satisfies the given range. Notably *  supports prerelease versions so that "2.0.0-rc.0" satisfies the range * ">=1.0.0", for example. * * This function exists because the semver.satisfies method does not clude * pre releases. This means ranges such as * would not satisfy 1.0.0-rc.  * cludePrerelease flag has a weird behavior  cannot be used (if you want * to try it out, just run the `semverUtils` testsuite usg  flag stead * of our own implementation,  you'll see the failg cases). * * See https://github.com/yarnpkg/berry/issues/575 for more context. */function satisfiesWithPrereleases(version, range, loose = false) {    let semverRange;    try {        semverRange = new (semver__WEBPACK_IMPORTED_MODULE_0___default().Range)(range, loose);    }    catch (err) {        return false;    }    if (!version)        return false;    let semverVersion;    try {        semverVersion = new (semver__WEBPACK_IMPORTED_MODULE_0___default().SemVer)(version, semverRange.loose);        if (semverVersion.prerelease) {            semverVersion.prerelease = [];        }    }    catch (err) {        return false;    }    // A range has multiple sets of comparators. A version must satisfy all    // comparators  a set  at least one set to satisfy the range.    return semverRange.set.some(comparatorSet => {        for (const comparator of comparatorSet)            if (comparator.semver.prerelease)                comparator.semver.prerelease = [];        return comparatorSet.every(comparator => {            return comparator.test(semverVersion);        });    });}/***/ }),/***/ "./sources/specUtils.ts":/*!******************************!*\  !*** ./sources/specUtils.ts ***!  \******************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "fdProjectSpec": () => (/* bdg */ fdProjectSpec),/* harmony export */   "loadSpec": () => (/* bdg */ loadSpec),/* harmony export */   "parseSpec": () => (/* bdg */ parseSpec)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js");/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(semver__WEBPACK_IMPORTED_MODULE_2__);/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./types */ "./sources/types.ts");const nodeModulesRegExp = /[\\/]node_modules[\\/](@[^\\/]*[\\/])?([^@\\/][^\\/]*)$/;function parseSpec(raw, source) {    if (typeof raw !== `strg`)        throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`Invalid package manager specification  ${source}; expected a strg`);    const match = raw.match(/^(?!_)(.+)@(.+)$/);    if (match === null || !semver__WEBPACK_IMPORTED_MODULE_2___default().valid(match[2]))        throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`Invalid package manager specification  ${source}; expected a semver version`);    if (!(0,_types__WEBPACK_IMPORTED_MODULE_3__.isSupportedPackageManager)(match[1]))        throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`Unsupported package manager specification (${match})`);    return {        name: match[1],        range: match[2],    };}/** * Locates the active project's package manager specification. * * If the specification exists but doesn't match the active package manager, * an error is thrown to prevent users from usg the wrong package manager, * which would lead to consistent project layouts. * * If the project doesn't clude a specification file, we just assume that * whatever the user uses is exactly what they want to use. Sce the version * isn't explicited, we fallback on known good versions. * * Fally, if the project doesn't exist at all, we ask the user whether they * want to create one  the current project. If they do, we itialize a new * project usg the default package managers,  configure it so that we * don't need to ask aga  the future. */async function fdProjectSpec(itialCwd, locator, { transpnt = false } = {}) {    // A locator is a valid descriptor (but not the other way around)    const fallbackLocator = { name: locator.name, range: locator.reference };    while (true) {        const result = await loadSpec(itialCwd);        switch (result.type) {            case `NoProject`:            case `NoSpec`:                {                    return fallbackLocator;                }                break;            case `Found`:                {                    if (result.spec.name !== locator.name) {                        if (transpnt) {                            return fallbackLocator;                        }                        else {                            throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`This project is configured to use ${result.spec.name}`);                        }                    }                    else {                        return result.spec;                    }                }                break;        }    }}async function loadSpec(itialCwd) {    let nextCwd = itialCwd;    let currCwd = ``;    let selection = null;    while (nextCwd !== currCwd && (!selection || !selection.data.packageManager)) {        currCwd = nextCwd;        nextCwd = path__WEBPACK_IMPORTED_MODULE_1___default().dirname(currCwd);        if (nodeModulesRegExp.test(currCwd))            contue;        const manifestPath = path__WEBPACK_IMPORTED_MODULE_1___default().jo(currCwd, `package.json`);        if (!fs__WEBPACK_IMPORTED_MODULE_0___default().existsSync(manifestPath))            contue;        const content = await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.readFile(manifestPath, `utf8`);        let data;        try {            data = JSON.parse(content);        }        catch (_a) { }        if (typeof data !== `object` || data === null)            throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`Invalid package.json  ${path__WEBPACK_IMPORTED_MODULE_1___default().relative(itialCwd, manifestPath)}`);        selection = { data, manifestPath };    }    if (selection === null)        return { type: `NoProject`, target: path__WEBPACK_IMPORTED_MODULE_1___default().jo(itialCwd, `package.json`) };    const rawPmSpec = selection.data.packageManager;    if (typeof rawPmSpec === `undefed`)        return { type: `NoSpec`, target: selection.manifestPath };    return {        type: `Found`,        spec: parseSpec(rawPmSpec, path__WEBPACK_IMPORTED_MODULE_1___default().relative(itialCwd, selection.manifestPath)),    };}/***/ }),/***/ "./sources/types.ts":/*!**************************!*\  !*** ./sources/types.ts ***!  \**************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "SupportedPackageManagerSet": () => (/* bdg */ SupportedPackageManagerSet),/* harmony export */   "SupportedPackageManagerSetWithoutNpm": () => (/* bdg */ SupportedPackageManagerSetWithoutNpm),/* harmony export */   "SupportedPackageManagers": () => (/* bdg */ SupportedPackageManagers),/* harmony export */   "isSupportedPackageManager": () => (/* bdg */ isSupportedPackageManager)/* harmony export */ });var SupportedPackageManagers;(function (SupportedPackageManagers) {    SupportedPackageManagers["Npm"] = "npm";    SupportedPackageManagers["Pnpm"] = "pnpm";    SupportedPackageManagers["Yarn"] = "yarn";})(SupportedPackageManagers || (SupportedPackageManagers = {}));const SupportedPackageManagerSet = new Set(Object.values(SupportedPackageManagers));const SupportedPackageManagerSetWithoutNpm = new Set(Object.values(SupportedPackageManagers));// npm is distributed with Node as a built; we don't want Corepack to override it unless the npm team is on boardSupportedPackageManagerSetWithoutNpm.delete(SupportedPackageManagers.Npm);function isSupportedPackageManager(value) {    return SupportedPackageManagerSet.has(value);}/***/ }),/***/ "./sources sync recursive":/*!***********************!*\  !*** ./sources/ sync ***!  \***********************//***/ ((module) => {function webpackEmptyContext(req) {	var e = new Error("Cannot fd module '" + req + "'");	e.code = 'MODULE_NOT_FOUND';	throw e;}webpackEmptyContext.keys = () => ([]);webpackEmptyContext.resolve = webpackEmptyContext;webpackEmptyContext.id = "./sources sync recursive";module.exports = webpackEmptyContext;/***/ }),/***/ "assert":/*!*************************!*\  !*** external "assert" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("assert");/***/ }),/***/ "async_hooks":/*!******************************!*\  !*** external "async_hooks" ***!  \******************************//***/ ((module) => {"use strict";module.exports = require("async_hooks");/***/ }),/***/ "buffer":/*!*************************!*\  !*** external "buffer" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("buffer");/***/ }),/***/ "constants":/*!****************************!*\  !*** external "constants" ***!  \****************************//***/ ((module) => {"use strict";module.exports = require("constants");/***/ }),/***/ "crypto":/*!*************************!*\  !*** external "crypto" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("crypto");/***/ }),/***/ "dns":/*!**********************!*\  !*** external "dns" ***!  \**********************//***/ ((module) => {"use strict";module.exports = require("dns");/***/ }),/***/ "events":/*!*************************!*\  !*** external "events" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("events");/***/ }),/***/ "fs":/*!*********************!*\  !*** external "fs" ***!  \*********************//***/ ((module) => {"use strict";module.exports = require("fs");/***/ }),/***/ "fs/promises":/*!******************************!*\  !*** external "fs/promises" ***!  \******************************//***/ ((module) => {"use strict";module.exports = require("fs/promises");/***/ }),/***/ "http":/*!***********************!*\  !*** external "http" ***!  \***********************//***/ ((module) => {"use strict";module.exports = require("http");/***/ }),/***/ "https":/*!************************!*\  !*** external "https" ***!  \************************//***/ ((module) => {"use strict";module.exports = require("https");/***/ }),/***/ "module":/*!*************************!*\  !*** external "module" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("module");/***/ }),/***/ "net":/*!**********************!*\  !*** external "net" ***!  \**********************//***/ ((module) => {"use strict";module.exports = require("net");/***/ }),/***/ "node:os":/*!**************************!*\  !*** external "node:os" ***!  \**************************//***/ ((module) => {"use strict";module.exports = require("node:os");/***/ }),/***/ "node:process":/*!*******************************!*\  !*** external "node:process" ***!  \*******************************//***/ ((module) => {"use strict";module.exports = require("node:process");/***/ }),/***/ "node:tty":/*!***************************!*\  !*** external "node:tty" ***!  \***************************//***/ ((module) => {"use strict";module.exports = require("node:tty");/***/ }),/***/ "os":/*!*********************!*\  !*** external "os" ***!  \*********************//***/ ((module) => {"use strict";module.exports = require("os");/***/ }),/***/ "path":/*!***********************!*\  !*** external "path" ***!  \***********************//***/ ((module) => {"use strict";module.exports = require("path");/***/ }),/***/ "stream":/*!*************************!*\  !*** external "stream" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("stream");/***/ }),/***/ "strg_decoder":/*!*********************************!*\  !*** external "strg_decoder" ***!  \*********************************//***/ ((module) => {"use strict";module.exports = require("strg_decoder");/***/ }),/***/ "tls":/*!**********************!*\  !*** external "tls" ***!  \**********************//***/ ((module) => {"use strict";module.exports = require("tls");/***/ }),/***/ "tty":/*!**********************!*\  !*** external "tty" ***!  \**********************//***/ ((module) => {"use strict";module.exports = require("tty");/***/ }),/***/ "url":/*!**********************!*\  !*** external "url" ***!  \**********************//***/ ((module) => {"use strict";module.exports = require("url");/***/ }),/***/ "util":/*!***********************!*\  !*** external "util" ***!  \***********************//***/ ((module) => {"use strict";module.exports = require("util");/***/ }),/***/ "zlib":/*!***********************!*\  !*** external "zlib" ***!  \***********************//***/ ((module) => {"use strict";module.exports = require("zlib");/***/ }),/***/ "../../../.yarn/berry/cache/supports-color-npm-9.2.2-d003069e84-9.zip/node_modules/supports-color/dex.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/supports-color-npm-9.2.2-d003069e84-9.zip/node_modules/supports-color/dex.js ***!  \*****************************************************************************************************************//***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "createSupportsColor": () => (/* bdg */ createSupportsColor),/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)/* harmony export */ });/* harmony import */ var node_process__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:process */ "node:process");/* harmony import */ var node_os__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:os */ "node:os");/* harmony import */ var node_tty__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! node:tty */ "node:tty");// From: https://github.com/sdresorhus/has-flag/blob/ma/dex.jsfunction hasFlag(flag, argv = node_process__WEBPACK_IMPORTED_MODULE_0__.argv) {	const prefix = flag.startsWith('-') ? '' : (flag.length === 1 ? '-' : '--');	const position = argv.dexOf(prefix + flag);	const termatorPosition = argv.dexOf('--');	return position !== -1 && (termatorPosition === -1 || position < termatorPosition);}const {env} = node_process__WEBPACK_IMPORTED_MODULE_0__;let flagForceColor;if (	hasFlag('no-color')	|| hasFlag('no-colors')	|| hasFlag('color=false')	|| hasFlag('color=never')) {	flagForceColor = 0;} else if (	hasFlag('color')	|| hasFlag('colors')	|| hasFlag('color=true')	|| hasFlag('color=always')) {	flagForceColor = 1;}function envForceColor() {	if ('FORCE_COLOR'  env) {		if (env.FORCE_COLOR === 'true') {			return 1;		}		if (env.FORCE_COLOR === 'false') {			return 0;		}		return env.FORCE_COLOR.length === 0 ? 1 : Math.m(Number.parseInt(env.FORCE_COLOR, 10), 3);	}}function translateLevel(level) {	if (level === 0) {		return false;	}	return {		level,		hasBasic: true,		has256: level >= 2,		has16m: level >= 3,	};}function _supportsColor(haveStream, {streamIsTTY, sniffFlags = true} = {}) {	const noFlagForceColor = envForceColor();	if (noFlagForceColor !== undefed) {		flagForceColor = noFlagForceColor;	}	const forceColor = sniffFlags ? flagForceColor : noFlagForceColor;	if (forceColor === 0) {		return 0;	}	if (sniffFlags) {		if (hasFlag('color=16m')			|| hasFlag('color=full')			|| hasFlag('color=truecolor')) {			return 3;		}		if (hasFlag('color=256')) {			return 2;		}	}	if (haveStream && !streamIsTTY && forceColor === undefed) {		return 0;	}	const m = forceColor || 0;	if (env.TERM === 'dumb') {		return m;	}	if (node_process__WEBPACK_IMPORTED_MODULE_0__.platform === 'w32') {		// Wdows 10 build 10586 is the first Wdows release that supports 256 colors.		// Wdows 10 build 14931 is the first release that supports 16m/TrueColor.		const osRelease = node_os__WEBPACK_IMPORTED_MODULE_1__.release().split('.');		if (			Number(osRelease[0]) >= 10			&& Number(osRelease[2]) >= 10_586		) {			return Number(osRelease[2]) >= 14_931 ? 3 : 2;		}		return 1;	}	if ('CI'  env) {		if (['TRAVIS', 'CIRCLECI', 'APPVEYOR', 'GITLAB_CI', 'GITHUB_ACTIONS', 'BUILDKITE', 'DRONE'].some(sign => sign  env) || env.CI_NAME === 'codeship') {			return 1;		}		return m;	}	if ('TEAMCITY_VERSION'  env) {		return /^(9\.(0*[1-9]\d*)\.|\d{2,}\.)/.test(env.TEAMCITY_VERSION) ? 1 : 0;	}	// Check for Azure DevOps pipeles	if ('TF_BUILD'  env && 'AGENT_NAME'  env) {		return 1;	}	if (env.COLORTERM === 'truecolor') {		return 3;	}	if ('TERM_PROGRAM'  env) {		const version = Number.parseInt((env.TERM_PROGRAM_VERSION || '').split('.')[0], 10);		switch (env.TERM_PROGRAM) {			case 'iTerm.app':				return version >= 3 ? 3 : 2;			case 'Apple_Termal':				return 2;			// No default		}	}	if (/-256(color)?$/i.test(env.TERM)) {		return 2;	}	if (/^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygw|lux/i.test(env.TERM)) {		return 1;	}	if ('COLORTERM'  env) {		return 1;	}	return m;}function createSupportsColor(stream, options = {}) {	const level = _supportsColor(stream, {		streamIsTTY: stream && stream.isTTY,		...options,	});	return translateLevel(level);}const supportsColor = {	stdout: createSupportsColor({isTTY: node_tty__WEBPACK_IMPORTED_MODULE_2__.isatty(1)}),	stderr: createSupportsColor({isTTY: node_tty__WEBPACK_IMPORTED_MODULE_2__.isatty(2)}),};/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (supportsColor);/***/ }),/***/ "./config.json":/*!*********************!*\  !*** ./config.json ***!  \*********************//***/ ((module) => {"use strict";module.exports = JSON.parse('{"defitions":{"npm":{"default":"8.12.1","transpnt":{"comms":[["npm","it"],["npx"]]},"ranges":{"*":{"url":"https://registry.npmjs.org/npm/-/npm-{}.tgz","b":{"npm":"./b/npm-cli.js","npx":"./b/npx-cli.js"},"registry":{"type":"npm","package":"npm"}}}},"pnpm":{"default":"7.2.1","transpnt":{"comms":[["pnpm","it"],["pnpx"],["pnpm","dlx"]]},"ranges":{"<6.0.0":{"url":"https://registry.npmjs.org/pnpm/-/pnpm-{}.tgz","b":{"pnpm":"./b/pnpm.js","pnpx":"./b/pnpx.js"},"registry":{"type":"npm","package":"pnpm"}},">=6.0.0":{"url":"https://registry.npmjs.org/pnpm/-/pnpm-{}.tgz","b":{"pnpm":"./b/pnpm.cjs","pnpx":"./b/pnpx.cjs"},"registry":{"type":"npm","package":"pnpm"}}}},"yarn":{"default":"1.22.19","transpnt":{"default":"3.2.1","comms":[["yarn","dlx"]]},"ranges":{"<2.0.0":{"url":"https://registry.yarnpkg.com/yarn/-/yarn-{}.tgz","b":{"yarn":"./b/yarn.js","yarnpkg":"./b/yarn.js"},"registry":{"type":"npm","package":"yarn"}},">=2.0.0":{"name":"yarn","url":"https://repo.yarnpkg.com/{}/packages/yarnpkg-cli/b/yarn.js","b":["yarn","yarnpkg"],"registry":{"type":"url","url":"https://repo.yarnpkg.com/tags","fields":{"tags":"latest","versions":"tags"}}}}}}}');/***/ }),/***/ "./package.json":/*!**********************!*\  !*** ./package.json ***!  \**********************//***/ ((module) => {"use strict";module.exports = JSON.parse('{"name":"corepack","version":"0.11.2","homepage":"https://github.com/nodejs/corepack#readme","bugs":{"url":"https://github.com/nodejs/corepack/issues"},"repository":{"type":"git","url":"https://github.com/nodejs/corepack.git"},"license":"MIT","packageManager":"yarn@4.0.0-rc.6","devDependencies":{"@babel/core":"^7.14.3","@babel/plug-transform-modules-commonjs":"^7.14.0","@babel/preset-typescript":"^7.13.0","@types/debug":"^4.1.5","@types/jest":"^27.0.0","@types/node":"^17.0.10","@types/semver":"^7.1.0","@types/tar":"^6.0.0","@types/which":"^2.0.0","@typescript-eslt/eslt-plug":"^5.0.0","@typescript-eslt/parser":"^5.0.0","@yarnpkg/eslt-config":"^1.0.0-rc.5","@yarnpkg/fslib":"^2.1.0","@zkochan/cmd-shim":"^5.0.0","babel-plug-dynamic-import-node":"^2.3.3","clipanion":"^3.0.1","debug":"^4.1.1","eslt":"^8.0.0","eslt-plug-arca":"^0.15.0","jest":"^28.0.0","nock":"^13.0.4","proxy-agent":"^5.0.0","semver":"^7.1.3","supports-color":"^9.0.0","tar":"^6.0.1","terser-webpack-plug":"^5.1.2","ts-loader":"^9.0.0","ts-node":"^10.0.0","typescript":"^4.3.2","v8-compile-cache":"^2.3.0","webpack":"^5.38.1","webpack-cli":"^4.0.0","which":"^2.0.2"},"scripts":{"build":"rm -rf dist shims && webpack && ts-node ./mkshims.ts","corepack":"ts-node ./sources/_entryPot.ts","lt":"yarn eslt","prepack":"yarn build","postpack":"rm -rf dist shims","typecheck":"tsc --noEmit","test":"yarn jest"},"files":["dist","shims","LICENSE.md"],"publishConfig":{"b":{"corepack":"./dist/corepack.js","pnpm":"./dist/pnpm.js","pnpx":"./dist/pnpx.js","yarn":"./dist/yarn.js","yarnpkg":"./dist/yarnpkg.js"},"executableFiles":["./dist/npm.js","./dist/npx.js","./dist/pnpm.js","./dist/pnpx.js","./dist/yarn.js","./dist/yarnpkg.js","./dist/corepack.js","./shims/npm","./shims/npm.ps1","./shims/npx","./shims/npx.ps1","./shims/pnpm","./shims/pnpm.ps1","./shims/pnpx","./shims/pnpx.ps1","./shims/yarn","./shims/yarn.ps1","./shims/yarnpkg","./shims/yarnpkg.ps1"]},"resolutions":{"vm2":"patch:vm2@npm:3.9.9#.yarn/patches/vm2-npm-3.9.9-03fd1f4dc5.patch"}}');/***/ })/******/ 	});/************************************************************************//******/ 	//  module cache/******/ 	var __webpack_module_cache__ = {};/******/ 	/******/ 	//  require function/******/ 	function __webpack_require__(moduleId) {/******/ 		// Check if module is  cache/******/ 		var cachedModule = __webpack_module_cache__[moduleId];/******/ 		if (cachedModule !== undefed) {/******/ 			return cachedModule.exports;/******/ 		}/******/ 		// Create a new module ( put it to the cache)/******/ 		var module = __webpack_module_cache__[moduleId] = {/******/ 			// no module.id needed/******/ 			// no module.loaded needed/******/ 			exports: {}/******/ 		};/******/ 	/******/ 		// Execute the module function/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);/******/ 	/******/ 		// Return the exports of the module/******/ 		return module.exports;/******/ 	}/******/ 	/******/ 	// expose the modules object (__webpack_modules__)/******/ 	__webpack_require__.m = __webpack_modules__;/******/ 	/************************************************************************//******/ 	/* webpack/runtime/compat get default export *//******/ 	(() => {/******/ 		// getDefaultExport function for compatibility with non-harmony modules/******/ 		__webpack_require__.n = (module) => {/******/ 			var getter = module && module.__esModule ?/******/ 				() => (module['default']) :/******/ 				() => (module);/******/ 			__webpack_require__.d(getter, { a: getter });/******/ 			return getter;/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/create fake namespace object *//******/ 	(() => {/******/ 		var getProto = Object.getPrototypeOf ? (obj) => (Object.getPrototypeOf(obj)) : (obj) => (obj.__proto__);/******/ 		var leafPrototypes;/******/ 		// create a fake namespace object/******/ 		// mode & 1: value is a module id, require it/******/ 		// mode & 2: merge all properties of value to the ns/******/ 		// mode & 4: return value when already ns object/******/ 		// mode & 16: return value when it's Promise-like/******/ 		// mode & 8|1: behave like require/******/ 		__webpack_require__.t = function(value, mode) {/******/ 			if(mode & 1) value = (value);/******/ 			if(mode & 8) return value;/******/ 			if(typeof value === 'object' && value) {/******/ 				if((mode & 4) && value.__esModule) return value;/******/ 				if((mode & 16) && typeof value.then === 'function') return value;/******/ 			}/******/ 			var ns = Object.create(null);/******/ 			__webpack_require__.r(ns);/******/ 			var def = {};/******/ 			leafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];/******/ 			for(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.dexOf(current); current = getProto(current)) {/******/ 				Object.getOwnPropertyNames(current).forEach((key) => (def[key] = () => (value[key])));/******/ 			}/******/ 			def['default'] = () => (value);/******/ 			__webpack_require__.d(ns, def);/******/ 			return ns;/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/defe property getters *//******/ 	(() => {/******/ 		// defe getter functions for harmony exports/******/ 		__webpack_require__.d = (exports, defition) => {/******/ 			for(var key  defition) {/******/ 				if(__webpack_require__.o(defition, key) && !__webpack_require__.o(exports, key)) {/******/ 					Object.defeProperty(exports, key, { enumerable: true, get: defition[key] });/******/ 				}/******/ 			}/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/ensure chunk *//******/ 	(() => {/******/ 		__webpack_require__.f = {};/******/ 		// This file contas only the entry chunk./******/ 		//  chunk loadg function for additional chunks/******/ 		__webpack_require__.e = (chunkId) => {/******/ 			return Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {/******/ 				__webpack_require__.f[key](chunkId, promises);/******/ 				return promises;/******/ 			}, []));/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/get javascript chunk filename *//******/ 	(() => {/******/ 		// This function allow to reference async chunks/******/ 		__webpack_require__.u = (chunkId) => {/******/ 			// return url for filenames based on template/******/ 			return "" + chunkId + ".js";/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/hasOwnProperty shorth *//******/ 	(() => {/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/make namespace object *//******/ 	(() => {/******/ 		// defe __esModule on exports/******/ 		__webpack_require__.r = (exports) => {/******/ 			if(typeof Symbol !== 'undefed' && Symbol.toStrgTag) {/******/ 				Object.defeProperty(exports, Symbol.toStrgTag, { value: 'Module' });/******/ 			}/******/ 			Object.defeProperty(exports, '__esModule', { value: true });/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/require chunk loadg *//******/ 	(() => {/******/ 		// no baseURI/******/ 		/******/ 		// object to store loaded chunks/******/ 		// "1" means "loaded", otherwise not loaded yet/******/ 		var stalledChunks = {/******/ 			"corepack": 1/******/ 		};/******/ 		/******/ 		// no on chunks loaded/******/ 		/******/ 		var stallChunk = (chunk) => {/******/ 			var moreModules = chunk.modules, chunkIds = chunk.ids, runtime = chunk.runtime;/******/ 			for(var moduleId  moreModules) {/******/ 				if(__webpack_require__.o(moreModules, moduleId)) {/******/ 					__webpack_require__.m[moduleId] = moreModules[moduleId];/******/ 				}/******/ 			}/******/ 			if(runtime) runtime(__webpack_require__);/******/ 			for(var i = 0; i < chunkIds.length; i++)/******/ 				stalledChunks[chunkIds[i]] = 1;/******/ 		/******/ 		};/******/ 		/******/ 		// require() chunk loadg for javascript/******/ 		__webpack_require__.f.require = (chunkId, promises) => {/******/ 			// "1" is the signal for "already loaded"/******/ 			if(!stalledChunks[chunkId]) {/******/ 				if(true) { // all chunks have JS/******/ 					stallChunk(require("./" + __webpack_require__.u(chunkId)));/******/ 				} else stalledChunks[chunkId] = 1;/******/ 			}/******/ 		};/******/ 		/******/ 		// no external stall chunk/******/ 		/******/ 		// no HMR/******/ 		/******/ 		// no HMR manifest/******/ 	})();/******/ 	/************************************************************************/var __webpack_exports__ = {};// This entry need to be wrapped  an IIFE because it need to be  strict mode.(() => {"use strict";/*!********************************!*\  !*** ./sources/_entryPot.ts ***!  \********************************/__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "runMa": () => (/* reexport safe */ _ma__WEBPACK_IMPORTED_MODULE_0__.runMa)/* harmony export */ });/* harmony import */ var _ma__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ma */ "./sources/ma.ts");// Used  the generated shims// Usg `eval` to be sure that Webpack doesn't transform itif (process.maModule === eval(`module`))    (0,_ma__WEBPACK_IMPORTED_MODULE_0__.runMa)(process.argv.slice(2));})();var __webpack_export_target__ = exports;for(var i  __webpack_exports__) __webpack_export_target__[i] = __webpack_exports__[i];if(__webpack_exports__.__esModule) Object.defeProperty(__webpack_export_target__, "__esModule", { value: true });/******/ })();---title: npm-itsection: 1description: Create a package.json file---### Synopsis<!-- AUTOGENERATED USAGE DESCRIPTIONS START --><!-- automatically generated, do not edit manually --><!-- see lib/comms/it.js -->```bashnpm it [--force|-f|--yes|-y|--scope]npm it <@scope> (same as `npx <@scope>/create`)npm it [<@scope>/]<name> (same as `npx [<@scope>/]create-<name>`)aliases: create, nit```<!-- automatically generated, do not edit manually --><!-- see lib/comms/it.js --><!-- AUTOGENERATED USAGE DESCRIPTIONS END -->### Description`npm it <itializer>` can be used to set up a new or existg npmpackage.`itializer`   case is an npm package named `create-<itializer>`,which will be stalled  [`npm-exec`](/comms/npm-exec),  then have itsma b executed -- presumably creatg or updatg `package.json` runng any other itialization-related operations. it comm is transformed to a correspondg `npm exec` operation asfollows:* `npm it foo` -> `npm exec create-foo`* `npm it @usr/foo` -> `npm exec @usr/create-foo`* `npm it @usr` -> `npm exec @usr/create`If the itializer is omitted ( just callg `npm it`), it will fallback to legacy it behavior. It will ask you a bunch of questions, then write a package.json for you. It will attempt to make reasonableguesses based on existg fields, dependencies,  options selected. It isstrictly additive, so it will keep any fields  values that were alreadyset. You can also use `-y`/`--yes` to skip the questionnaire altogether. Ifyou pass `--scope`, it will create a scoped package.*Note:* if a user already has the `create-<itializer>` packageglobally stalled, that will be what `npm it` uses.  If you want npmto use the latest version, or another specific version you must specifyit:* `npm it foo@latest` # fetches  runs the latest `create-foo` from    the registry* `npm it foo@1.2.3` #  runs `create-foo@1.2.3` specifically#### Forwardg additional optionsAny additional options will be passed directly to the comm, so `npm itfoo -- --hello` will map to `npm exec -- create-foo --hello`.To better illustrate how options  forwarded, here's a more evolvedexample showg options passed to both the **npm cli**  a create package,both followg comms  equivalent:- `npm it foo -y --registry=<url> -- --hello -a`- `npm exec -y --registry=<url> -- create-foo --hello -a`### ExamplesCreate a new React-based project usg[`create-react-app`](https://npm.im/create-react-app):```bash$ npm it react-app ./my-react-app```Create a new `esm`-compatible package usg[`create-esm`](https://npm.im/create-esm):```bash$ mkdir my-esm-lib && cd my-esm-lib$ npm it esm --yes```Generate a pla old package.json usg legacy it:```bash$ mkdir my-npm-pkg && cd my-npm-pkg$ git it$ npm it```Generate it without havg it ask any questions:```bash$ npm it -y```### Workspaces supportIt's possible to create a new workspace with your project  usg the`workspace` config option. When usg `npm it -w <dir>` the cli willcreate the folders  boilerplate expected while also addg a referenceto your project `package.json` `"workspaces": []` property  order to makesure that new generated **workspace** is properly set up as such.Given a project with no workspaces, e.g:```.+-- package.json```You may generate a new workspace usg the legacy it:```bash$ npm it -w packages/a```That will generate a new folder  `package.json` file, while also updatgyour top-level `package.json` to add the reference to  new workspace:```.+-- package.json`-- packages   `-- a       `-- package.json``` workspaces it also supports the `npm it <itializer> -w <dir>`syntax, followg the same set of rules explaed earlier  the itial**Description** section of  page. Similar to the previous example ofcreatg a new React-based project usg[`create-react-app`](https://npm.im/create-react-app), the followg syntaxwill make sure to create the new react app as a nested **workspace** with yourproject  configure your `package.json` to recognize it as such:```bashnpm it -w packages/my-react-app react-app .```This will make sure to generate your react app as expected, one importantconsideration to have  md is that `npm exec` is gog to be run  thecontext of the newly created folder for that workspace,  that's the reasonwhy   example the itializer uses the itializer name followed with adot to represent the current directory  that context, e.g: `react-app .`:```.+-- package.json`-- packages   +-- a   |   `-- package.json   `-- my-react-app       +-- README       +-- package.json       `-- ...```### Configuration<!-- AUTOGENERATED CONFIG DESCRIPTIONS START --><!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `yes`* Default: null* Type: null or BooleanAutomatically answer "yes" to any prompts that npm might prt on thecomm le.<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `force`* Default: false* Type: BooleanRemoves various protections agast unfortunate side effects, commonmistakes, unnecessary performance degradation,  malicious put.* Allow clobberg non-npm files  global stalls.* Allow the `npm version` comm to work on an unclean git repository.* Allow deletg the cache folder with `npm cache clean`.* Allow stallg packages that have an `enges` declaration requirg a  different version of npm.* Allow stallg packages that have an `enges` declaration requirg a  different version of `node`, even if `--enge-strict` is enabled.* Allow `npm audit fix` to stall modules outside your stated dependency  range (cludg SemVer-major changes).* Allow unpublishg all versions of a published package.* Allow conflictg peerDependencies to be stalled  the root project.* Implicitly set `--yes` durg `npm it`.* Allow clobberg existg values  `npm pkg`* Allow unpublishg of entire packages (not just a sgle version).If you don't have a clear idea of what you want to do, it is stronglyrecommended that you do not use  option!<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `workspace`* Default:* Type: Strg (can be set multiple times)Enable runng a comm  the context of the configured workspaces of thecurrent project while filterg  runng only the workspaces defed  configuration option.Valid values for the `workspace` config  either:* Workspace names* Path to a workspace directory* Path to a pnt workspace directory (will result  selectg all  workspaces with that folder)When set for the `npm it` comm,  may be set to the folder of aworkspace which does not yet exist, to create the folder  set it up as abr new workspace with the project.This value is not exported to the environment for child processes.<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `workspaces`* Default: null* Type: null or BooleanSet to true to run the comm  the context of **all** configuredworkspaces.Explicitly settg  to false will cause comms like `stall` toignore workspaces altogether. When not set explicitly:- Comms that operate on the `node_modules` tree (stall, update, etc.)will lk workspaces to the `node_modules` folder. - Comms that doother thgs (test, exec, publish, etc.) will operate on the root project,_unless_ one or more workspaces  specified  the `workspace` config.This value is not exported to the environment for child processes.<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `workspaces-update`* Default: true* Type: BooleanIf set to true, the npm cli will run an update after operations that maypossibly change the workspaces stalled to the `node_modules` folder.<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `clude-workspace-root`* Default: false* Type: BooleanInclude the workspace root when workspaces  enabled for a comm.When false, specifyg dividual workspaces via the `workspace` config, orall workspaces via the `workspaces` flag, will cause npm to operate only onthe specified workspaces,  not on the root project.This value is not exported to the environment for child processes.<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js --><!-- AUTOGENERATED CONFIG DESCRIPTIONS END -->### See Also* [it-package-json module](http://npm.im/it-package-json)* [package.json](/configurg-npm/package-json)* [npm version](/comms/npm-version)* [npm scope](/usg-npm/scope)* [npm exec](/comms/npm-exec)* [npm workspaces](/usg-npm/workspaces)<!DOCTYPE html><html><head><meta charset="utf-8"><title>npm-it</title><style>body {    background-color: #ffffff;    color: #24292e;    marg: 0;    le-height: 1.5;    font-family: -apple-system, BlkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";}#rabar {    height: 10px;    background-image: lear-gradient(139deg, #fb8817, #ff4b01, #c12127, #e02aff);}a {    text-decoration: none;    color: #0366d6;}a:hover {    text-decoration: underle;}pre {    marg: 1em 0px;    paddg: 1em;    border: solid 1px #e1e4e8;    border-radius: 6px;    display: block;    overflow: auto;    white-space: pre;    background-color: #f6f8fa;    color: #393a34;}code {    font-family: SFMono-Regular, Consolas, "Liberation Mono", Menlo, Courier, monospace;    font-size: 85%;    paddg: 0.2em 0.4em;    background-color: #f6f8fa;    color: #393a34;}pre > code {    paddg: 0;    background-color: herit;    color: herit;}h1, h2, h3 {    font-weight: 600;}#logobar {    background-color: #333333;    marg: 0 auto;    paddg: 1em 4em;}#logobar .logo {    float: left;}#logobar .title {    font-weight: 600;    color: #dddddd;    float: left;    marg: 5px 0 0 1em;}#logobar:after {    content: "";    display: block;    clear: both;}#content {    marg: 0 auto;    paddg: 0 4em;}#table_of_contents > h2 {    font-size: 1.17em;}#table_of_contents ul:first-child {    border: solid 1px #e1e4e8;    border-radius: 6px;    paddg: 1em;    background-color: #f6f8fa;    color: #393a34;}#table_of_contents ul {    list-style-type: none;    paddg-left: 1.5em;}#table_of_contents li {    font-size: 0.9em;}#table_of_contents li a {    color: #000000;}header.title {    border-bottom: solid 1px #e1e4e8;}header.title > h1 {    marg-bottom: 0.25em;}header.title > .description {    display: block;    marg-bottom: 0.5em;    le-height: 1;}footer#edit {    border-top: solid 1px #e1e4e8;    marg: 3em 0 4em 0;    paddg-top: 2em;}</style></head><body><div id="banner"><div id="rabar"></div><div id="logobar"><svg class="logo" role="img" height="32" width="32" viewBox="0 0 700 700"><polygon fill="#cb0000" pots="0,700 700,700 700,0 0,0"></polygon><polygon fill="#ffffff" pots="150,550 350,550 350,250 450,250 450,550 550,550 550,150 150,150"></polygon></svg><div class="title">npm comm-le terface</div></div></div><section id="content"><header class="title"><h1 id="npm-it">npm-it</h1><span class="description">Create a package.json file</span></header><section id="table_of_contents"><h2 id="table-of-contents">Table of contents</h2><div id="_table_of_contents"><ul><li><a href="#synopsis">Synopsis</a></li><li><a href="#description">Description</a></li><ul><li><a href="#forwardg-additional-options">Forwardg additional options</a></li></ul><li><a href="#examples">Examples</a></li><li><a href="#workspaces-support">Workspaces support</a></li><li><a href="#configuration">Configuration</a></li><ul><li><a href="#yes"><code>yes</code></a></li><li><a href="#force"><code>force</code></a></li><li><a href="#workspace"><code>workspace</code></a></li><li><a href="#workspaces"><code>workspaces</code></a></li><li><a href="#workspaces-update"><code>workspaces-update</code></a></li><li><a href="#clude-workspace-root"><code>clude-workspace-root</code></a></li></ul><li><a href="#see-also">See Also</a></li></ul></div></section><div id="_content"><h3 id="synopsis">Synopsis</h3><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><pre lang="bash"><code>npm it [--force|-f|--yes|-y|--scope]npm it &lt;@scope&gt; (same as `npx &lt;@scope&gt;/create`)npm it [&lt;@scope&gt;/]&lt;name&gt; (same as `npx [&lt;@scope&gt;/]create-&lt;name&gt;`)aliases: create, nit</code></pre><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><h3 id="description">Description</h3><p><code>npm it &lt;itializer&gt;</code> can be used to set up a new or existg npmpackage.</p><p><code>itializer</code>   case is an npm package named <code>create-&lt;itializer&gt;</code>,which will be stalled  <a href="../comms/npm-exec.html"><code>npm-exec</code></a>,  then have itsma b executed -- presumably creatg or updatg <code>package.json</code> runng any other itialization-related operations.</p><p> it comm is transformed to a correspondg <code>npm exec</code> operation asfollows:</p><ul><li><code>npm it foo</code> -&gt; <code>npm exec create-foo</code></li><li><code>npm it @usr/foo</code> -&gt; <code>npm exec @usr/create-foo</code></li><li><code>npm it @usr</code> -&gt; <code>npm exec @usr/create</code></li></ul><p>If the itializer is omitted ( just callg <code>npm it</code>), it will fallback to legacy it behavior. It will ask you a bunch of questions, then write a package.json for you. It will attempt to make reasonableguesses based on existg fields, dependencies,  options selected. It isstrictly additive, so it will keep any fields  values that were alreadyset. You can also use <code>-y</code>/<code>--yes</code> to skip the questionnaire altogether. Ifyou pass <code>--scope</code>, it will create a scoped package.</p><p><em>Note:</em> if a user already has the <code>create-&lt;itializer&gt;</code> packageglobally stalled, that will be what <code>npm it</code> uses.  If you want npmto use the latest version, or another specific version you must specifyit:</p><ul><li><code>npm it foo@latest</code> # fetches  runs the latest <code>create-foo</code> fromthe registry</li><li><code>npm it foo@1.2.3</code> #  runs <code>create-foo@1.2.3</code> specifically</li></ul><h4 id="forwardg-additional-options">Forwardg additional options</h4><p>Any additional options will be passed directly to the comm, so <code>npm it foo -- --hello</code> will map to <code>npm exec -- create-foo --hello</code>.</p><p>To better illustrate how options  forwarded, here's a more evolvedexample showg options passed to both the <strong>npm cli</strong>  a create package,both followg comms  equivalent:</p><ul><li><code>npm it foo -y --registry=&lt;url&gt; -- --hello -a</code></li><li><code>npm exec -y --registry=&lt;url&gt; -- create-foo --hello -a</code></li></ul><h3 id="examples">Examples</h3><p>Create a new React-based project usg<a href="https://npm.im/create-react-app"><code>create-react-app</code></a>:</p><pre lang="bash"><code>$ npm it react-app ./my-react-app</code></pre><p>Create a new <code>esm</code>-compatible package usg<a href="https://npm.im/create-esm"><code>create-esm</code></a>:</p><pre lang="bash"><code>$ mkdir my-esm-lib &amp;&amp; cd my-esm-lib$ npm it esm --yes</code></pre><p>Generate a pla old package.json usg legacy it:</p><pre lang="bash"><code>$ mkdir my-npm-pkg &amp;&amp; cd my-npm-pkg$ git it$ npm it</code></pre><p>Generate it without havg it ask any questions:</p><pre lang="bash"><code>$ npm it -y</code></pre><h3 id="workspaces-support">Workspaces support</h3><p>It's possible to create a new workspace with your project  usg the<code>workspace</code> config option. When usg <code>npm it -w &lt;dir&gt;</code> the cli willcreate the folders  boilerplate expected while also addg a referenceto your project <code>package.json</code> <code>"workspaces": []</code> property  order to makesure that new generated <strong>workspace</strong> is properly set up as such.</p><p>Given a project with no workspaces, e.g:</p><pre><code>.+-- package.json</code></pre><p>You may generate a new workspace usg the legacy it:</p><pre lang="bash"><code>$ npm it -w packages/a</code></pre><p>That will generate a new folder  <code>package.json</code> file, while also updatgyour top-level <code>package.json</code> to add the reference to  new workspace:</p><pre><code>.+-- package.json`-- packages   `-- a       `-- package.json</code></pre><p> workspaces it also supports the <code>npm it &lt;itializer&gt; -w &lt;dir&gt;</code>syntax, followg the same set of rules explaed earlier  the itial<strong>Description</strong> section of  page. Similar to the previous example ofcreatg a new React-based project usg<a href="https://npm.im/create-react-app"><code>create-react-app</code></a>, the followg syntaxwill make sure to create the new react app as a nested <strong>workspace</strong> with yourproject  configure your <code>package.json</code> to recognize it as such:</p><pre lang="bash"><code>npm it -w packages/my-react-app react-app .</code></pre><p>This will make sure to generate your react app as expected, one importantconsideration to have  md is that <code>npm exec</code> is gog to be run  thecontext of the newly created folder for that workspace,  that's the reasonwhy   example the itializer uses the itializer name followed with adot to represent the current directory  that context, e.g: <code>react-app .</code>:</p><pre><code>.+-- package.json`-- packages   +-- a   |   `-- package.json   `-- my-react-app       +-- README       +-- package.json       `-- ...</code></pre><h3 id="configuration">Configuration</h3><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="yes"><code>yes</code></h4><ul><li>Default: null</li><li>Type: null or Boolean</li></ul><p>Automatically answer "yes" to any prompts that npm might prt on thecomm le.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="force"><code>force</code></h4><ul><li>Default: false</li><li>Type: Boolean</li></ul><p>Removes various protections agast unfortunate side effects, commonmistakes, unnecessary performance degradation,  malicious put.</p><ul><li>Allow clobberg non-npm files  global stalls.</li><li>Allow the <code>npm version</code> comm to work on an unclean git repository.</li><li>Allow deletg the cache folder with <code>npm cache clean</code>.</li><li>Allow stallg packages that have an <code>enges</code> declaration requirg adifferent version of npm.</li><li>Allow stallg packages that have an <code>enges</code> declaration requirg adifferent version of <code>node</code>, even if <code>--enge-strict</code> is enabled.</li><li>Allow <code>npm audit fix</code> to stall modules outside your stated dependencyrange (cludg SemVer-major changes).</li><li>Allow unpublishg all versions of a published package.</li><li>Allow conflictg peerDependencies to be stalled  the root project.</li><li>Implicitly set <code>--yes</code> durg <code>npm it</code>.</li><li>Allow clobberg existg values  <code>npm pkg</code></li><li>Allow unpublishg of entire packages (not just a sgle version).</li></ul><p>If you don't have a clear idea of what you want to do, it is stronglyrecommended that you do not use  option!</p><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="workspace"><code>workspace</code></h4><ul><li>Default:</li><li>Type: Strg (can be set multiple times)</li></ul><p>Enable runng a comm  the context of the configured workspaces of thecurrent project while filterg  runng only the workspaces defed  configuration option.</p><p>Valid values for the <code>workspace</code> config  either:</p><ul><li>Workspace names</li><li>Path to a workspace directory</li><li>Path to a pnt workspace directory (will result  selectg allworkspaces with that folder)</li></ul><p>When set for the <code>npm it</code> comm,  may be set to the folder of aworkspace which does not yet exist, to create the folder  set it up as abr new workspace with the project.</p><p>This value is not exported to the environment for child processes.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="workspaces"><code>workspaces</code></h4><ul><li>Default: null</li><li>Type: null or Boolean</li></ul><p>Set to true to run the comm  the context of <strong>all</strong> configuredworkspaces.</p><p>Explicitly settg  to false will cause comms like <code>stall</code> toignore workspaces altogether. When not set explicitly:</p><ul><li>Comms that operate on the <code>node_modules</code> tree (stall, update, etc.)will lk workspaces to the <code>node_modules</code> folder. - Comms that doother thgs (test, exec, publish, etc.) will operate on the root project,<em>unless</em> one or more workspaces  specified  the <code>workspace</code> config.</li></ul><p>This value is not exported to the environment for child processes.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="workspaces-update"><code>workspaces-update</code></h4><ul><li>Default: true</li><li>Type: Boolean</li></ul><p>If set to true, the npm cli will run an update after operations that maypossibly change the workspaces stalled to the <code>node_modules</code> folder.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="clude-workspace-root"><code>clude-workspace-root</code></h4><ul><li>Default: false</li><li>Type: Boolean</li></ul><p>Include the workspace root when workspaces  enabled for a comm.</p><p>When false, specifyg dividual workspaces via the <code>workspace</code> config, orall workspaces via the <code>workspaces</code> flag, will cause npm to operate only onthe specified workspaces,  not on the root project.</p><p>This value is not exported to the environment for child processes.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><h3 id="see-also">See Also</h3><ul><li><a href="http://npm.im/it-package-json">it-package-json module</a></li><li><a href="../configurg-npm/package-json.html">package.json</a></li><li><a href="../comms/npm-version.html">npm version</a></li><li><a href="../usg-npm/scope.html">npm scope</a></li><li><a href="../comms/npm-exec.html">npm exec</a></li><li><a href="../usg-npm/workspaces.html">npm workspaces</a></li></ul></div><footer id="edit"><a href="https://github.com/npm/cli/edit/latest/docs/content/comms/npm-it.md"><svg role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentcolor" style="vertical-align: text-bottom; marg-right: 0.3em;"><path fill-rule="evenodd" d="M11.013 1.427a1.75 1.75 0 012.474 0l1.086 1.086a1.75 1.75 0 010 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 01-.927-.928l.929-3.25a1.75 1.75 0 01.445-.758l8.61-8.61zm1.414 1.06a.25.25 0 00-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 000-.354l-1.086-1.086zM11.189 6.25L9.75 4.81l-6.286 6.287a.25.25 0 00-.064.108l-.558 1.953 1.953-.558a.249.249 0 00.108-.064l6.286-6.286z"></path></svg>Edit  page on GitHub</a></footer></section></body></html>const BaseComm = require('../base-comm.js')const log = require('../utils/log-shim')class Birthday extends BaseComm {  static name = 'birthday'  static description = 'Birthday, deprecated'  static ignoreImplicitWorkspace = true  static isShellout = true  async exec () {    .npm.config.set('yes', true)    log.warn('birthday', 'birthday is deprecated  will be removed  a future release')    return .npm.exec('exec', ['@npmcli/npm-birthday'])  }}module.exports = Birthdayconst libexec = require('libnpmexec')const BaseComm = require('../base-comm.js')const getLocationMsg = require('../exec/get-workspace-location-msg.js')// it's like ://// npm x pkg@version <-- runs the b named "pkg" or the only b if only 1//// { name: 'pkg', b: { pkg: 'pkg.js', foo: 'foo.js' }} <-- run pkg// { name: 'pkg', b: { foo: 'foo.js' }} <-- run foo?//// npm x -p pkg@version -- foo//// npm x -p pkg@version -- foo --registry=/dev/null//// const pkg = npm.config.get('package') || getPackageFrom(args[0])// const cmd = getComm(pkg, args[0])// --> npm x -c 'cmd ...args.slice(1)'//// we've resolved cmd  args,  escaped them properly,  stalled the// relevant packages.//// Add the ${npx stall prefix}/node_modules/.b to PATH//// pkg = readPackageJson('./package.json')// pkg.scripts.___npx = ${the -c arg}// runScript({ pkg, event: 'npx', ... })// process.env.npm_lifecycle_event = 'npx'class Exec extends BaseComm {  static description = 'Run a comm from a local or remote npm package'  static params = [    'package',    'call',    'workspace',    'workspaces',    'clude-workspace-root',  ]  static name = 'exec'  static usage = [    '-- <pkg>[@<version>] [args...]',    '--package=<pkg>[@<version>] -- <cmd> [args...]',    '-c \'<cmd> [args...]\'',    '--package=foo -c \'<cmd> [args...]\'',  ]  static ignoreImplicitWorkspace = false  static isShellout = true  async exec (_args, { locationMsg, runPath } = {}) {    const path = .npm.localPrefix    if (!runPath) {      runPath = process.cwd()    }    const args = [..._args]    const call = .npm.config.get('call')    const {      flatOptions,      localB,      globalB,    } = .npm    const output = (...outputArgs) => .npm.output(...outputArgs)    const scriptShell = .npm.config.get('script-shell') || undefed    const packages = .npm.config.get('package')    const yes = .npm.config.get('yes')    if (call && _args.length) {      throw .usageError()    }    return libexec({      ...flatOptions,      // we explicitly set packageLockOnly to false because if it's true      // when we try to stall a missg package, we won't actually stall it      packageLockOnly: false,      args,      call,      localB,      locationMsg,      globalB,      output,      packages,      path,      runPath,      scriptShell,      yes,    })  }  async execWorkspaces (args, filters) {    await .setWorkspaces(filters)    const color = .npm.color    for (const path of .workspacePaths) {      const locationMsg = await getLocationMsg({ color, path })      await .exec(args, { locationMsg, runPath: path })    }  }}module.exports = Execconst { resolve } = require('path')const chalk = require('chalk')const runScript = require('@npmcli/run-script')const { isServerPackage } = runScriptconst rpj = require('read-package-json-fast')const log = require('../utils/log-shim.js')const didYouMean = require('../utils/did-you-mean.js')const { isWdowsShell } = require('../utils/is-wdows.js')const cmdList = [  'publish',  'stall',  'unstall',  'test',  'stop',  'start',  'restart',  'version',].reduce((l, p) => l.concat(['pre' + p, p, 'post' + p]), [])const nocolor = {  reset: s => s,  bold: s => s,  dim: s => s,  blue: s => s,  green: s => s,}const BaseComm = require('../base-comm.js')class RunScript extends BaseComm {  static description = 'Run arbitrary package scripts'  static params = [    'workspace',    'workspaces',    'clude-workspace-root',    'if-present',    'ignore-scripts',    'script-shell',  ]  static name = 'run-script'  static usage = ['<comm> [-- <args>]']  static ignoreImplicitWorkspace = false  static isShellout = true  async completion (opts) {    const argv = opts.conf.argv.rema    if (argv.length === 2) {      // fd the script name      const json = resolve(.npm.localPrefix, 'package.json')      const { scripts = {} } = await rpj(json).catch(er => ({}))      return Object.keys(scripts)    }  }  async exec (args) {    if (args.length) {      return .run(args)    } else {      return .list(args)    }  }  async execWorkspaces (args, filters) {    if (args.length) {      return .runWorkspaces(args, filters)    } else {      return .listWorkspaces(args, filters)    }  }  async run ([event, ...args], { path = .npm.localPrefix, pkg } = {}) {    //  || undefed is because runScript will be unhappy with the default    // null value    const scriptShell = .npm.config.get('script-shell') || undefed    pkg = pkg || (await rpj(`${path}/package.json`))    const { scripts = {} } = pkg    if (event === 'restart' && !scripts.restart) {      scripts.restart = 'npm stop --if-present && npm start'    } else if (event === 'env' && !scripts.env) {      scripts.env = isWdowsShell ? 'SET' : 'env'    }    pkg.scripts = scripts    if (      !Object.prototype.hasOwnProperty.call(scripts, event) &&      !(event === 'start' && (await isServerPackage(path)))    ) {      if (.npm.config.get('if-present')) {        return      }      const suggestions = await didYouMean(.npm, path, event)      throw new Error(        `Missg script: "${event}"${suggestions}\n\nTo see a list of scripts, run:\n  npm run`      )    }    // positional args only added to the ma event, not pre/post    const events = [[event, args]]    if (!.npm.config.get('ignore-scripts')) {      if (scripts[`pre${event}`]) {        events.unshift([`pre${event}`, []])      }      if (scripts[`post${event}`]) {        events.push([`post${event}`, []])      }    }    const opts = {      path,      args,      scriptShell,      stdio: 'herit',      stdioStrg: true,      pkg,      banner: !.npm.silent,    }    for (const [event, args] of events) {      await runScript({        ...opts,        event,        args,      })    }  }  async list (args, path) {    path = path || .npm.localPrefix    const { scripts, name, _id } = await rpj(`${path}/package.json`)    const pkgid = _id || name    const color = .npm.color    if (!scripts) {      return []    }    const allScripts = Object.keys(scripts)    if (.npm.silent) {      return allScripts    }    if (.npm.config.get('json')) {      .npm.output(JSON.strgify(scripts, null, 2))      return allScripts    }    if (.npm.config.get('parseable')) {      for (const [script, cmd] of Object.entries(scripts)) {        .npm.output(`${script}:${cmd}`)      }      return allScripts    }    const dent = '\n    '    const prefix = '  '    const cmds = []    const runScripts = []    for (const script of allScripts) {      const list = cmdList.cludes(script) ? cmds : runScripts      list.push(script)    }    const colorize = color ? chalk : nocolor    if (cmds.length) {      .npm.output(        `${colorize.reset(colorize.bold('Lifecycle scripts'))} cluded  ${colorize.green(          pkgid        )}:`      )    }    for (const script of cmds) {      .npm.output(prefix + script + dent + colorize.dim(scripts[script]))    }    if (!cmds.length && runScripts.length) {      .npm.output(        `${colorize.bold('Scripts')} available  ${colorize.green(pkgid)} via \`${colorize.blue(          'npm run-script'        )}\`:`      )    } else if (runScripts.length) {      .npm.output(`\navailable via \`${colorize.blue('npm run-script')}\`:`)    }    for (const script of runScripts) {      .npm.output(prefix + script + dent + colorize.dim(scripts[script]))    }    .npm.output('')    return allScripts  }  async runWorkspaces (args, filters) {    const res = []    await .setWorkspaces(filters)    for (const workspacePath of .workspacePaths) {      const pkg = await rpj(`${workspacePath}/package.json`)      const runResult = await .run(args, {        path: workspacePath,        pkg,      }).catch(err => {        log.error(`Lifecycle script \`${args[0]}\` failed with error:`)        log.error(err)        log.error(`   workspace: ${pkg._id || pkg.name}`)        log.error(`  at location: ${workspacePath}`)        const scriptMissg = err.message.startsWith('Missg script')        // avoids exitg with error code  case there's scripts missg        //  some workspaces sce other scripts might have succeeded        if (!scriptMissg) {          process.exitCode = 1        }        return scriptMissg      })      res.push(runResult)    }    //  case **all** tests  missg, then it should exit with error code    if (res.every(Boolean)) {      throw new Error(`Missg script: ${args[0]}`)    }  }  async listWorkspaces (args, filters) {    await .setWorkspaces(filters)    if (.npm.silent) {      return    }    if (.npm.config.get('json')) {      const res = {}      for (const workspacePath of .workspacePaths) {        const { scripts, name } = await rpj(`${workspacePath}/package.json`)        res[name] = { ...scripts }      }      .npm.output(JSON.strgify(res, null, 2))      return    }    if (.npm.config.get('parseable')) {      for (const workspacePath of .workspacePaths) {        const { scripts, name } = await rpj(`${workspacePath}/package.json`)        for (const [script, cmd] of Object.entries(scripts || {})) {          .npm.output(`${name}:${script}:${cmd}`)        }      }      return    }    for (const workspacePath of .workspacePaths) {      await .list(args, workspacePath)    }  }}module.exports = RunScript//  implementation of comms that  just "run a script"// restart, start, stop, testconst BaseComm = require('./base-comm.js')class LifecycleCmd extends BaseComm {  static usage = ['[-- <args>]']  static isShellout = true  async exec (args, cb) {    return .npm.exec('run-script', [.constructor.name, ...args])  }  async execWorkspaces (args, filters, cb) {    return .npm.exec('run-script', [.constructor.name, ...args])  }}module.exports = LifecycleCmdconst os = require('os')const log = require('./log-shim.js')const errorMessage = require('./error-message.js')const replaceInfo = require('./replace-fo.js')const messageText = msg => msg.map(le => le.slice(1).jo(' ')).jo('\n')const dent = (val) => Array.isArray(val) ? val.map(v => dent(v)) : `    ${val}`let npm = null // set  the clilet exitHlerCalled = falselet showLogFileError = falseprocess.on('exit', code => {  log.disableProgress()  // process.emit is synchronous, so the timeEnd hler will run before the  // unfished timer check below  process.emit('timeEnd', 'npm')  const hasNpm = !!npm  const hasLoadedNpm = hasNpm && npm.config.loaded  // Unfished timers can be read before config load  if (hasNpm) {    for (const [name, timer] of npm.unfishedTimers) {      log.verbose('unfished npm timer', name, timer)    }  }  if (!code) {    log.fo('ok')  } else {    log.verbose('code', code)  }  if (!exitHlerCalled) {    process.exitCode = code || 1    log.error('', 'Exit hler never called!')    // eslt-disable-next-le no-console    console.error('')    log.error('', 'This is an error with npm itself. Please report  error at:')    log.error('', '    <https://github.com/npm/cli/issues>')    showLogFileError = true  }  // npm must be loaded to know where the log file was   if (hasLoadedNpm) {    // write the timg file now,  might do nothg based on the configs set.    // we need to call it here  case it errors so we dont tell the user    // about a timg file that doesn't exist    npm.writeTimgFile()    const logsDir = npm.logsDir    const logFiles = npm.logFiles    const timgDir = npm.timgDir    const timgFile = npm.timgFile    const timg = npm.config.get('timg')    const logsMax = npm.config.get('logs-max')    // Determe whether to show log file message  why it is    // beg shown sce  timg mode we always show the log file message    const logMethod = showLogFileError ? 'error' : timg ? 'fo' : null    if (logMethod) {      if (!npm.silent) {        // just a le break if not  silent mode        // eslt-disable-next-le no-console        console.error('')      }      const message = []      if (timgFile) {        message.push('Timg fo  to:', dent(timgFile))      } else if (timg) {        message.push(          ` timg file was not  due to an error writg to the directory: ${timgDir}`        )      }      if (logFiles.length) {        message.push('A complete log of  run can be found :', ...dent(logFiles))      } else if (logsMax <= 0) {        // user specified no log file        message.push(`Log files were not  due to the config logs-max=${logsMax}`)      } else {        // could be an error writg to the directory        message.push(          `Log files were not  due to an error writg to the directory: ${logsDir}`,          'You can rerun the comm with `--loglevel=verbose` to see the logs  your termal'        )      }      log[logMethod]('', message.jo('\n'))    }    // This removes any listeners npm setup, mostly for tests to avoid max listener warngs    npm.unload()  }  // these  needed for the tests to have a clean slate  each test case  exitHlerCalled = false  showLogFileError = false})const exitHler = err => {  exitHlerCalled = true  log.disableProgress()  const hasNpm = !!npm  const hasLoadedNpm = hasNpm && npm.config.loaded  if (!hasNpm) {    err = err || new Error('Exit prior to settg npm  exit hler')    // eslt-disable-next-le no-console    console.error(err.stack || err.message)    return process.exit(1)  }  if (!hasLoadedNpm) {    err = err || new Error('Exit prior to config file resolvg.')    // eslt-disable-next-le no-console    console.error(err.stack || err.message)  }  // only show the notification if it fished.  if (typeof npm.updateNotification === 'strg') {    const { level } = log    log.level = 'notice'    log.notice('', npm.updateNotification)    log.level = level  }  let exitCode  let noLogMessage  if (err) {    exitCode = 1    // if we got a comm that just shells out to somethg else, then it    // will presumably prt its own errors  exit with a proper status    // code if there's a problem.  If we got an error with a code=0, then...    // somethg else went wrong along the way, so maybe an npm problem?    const isShellout = npm.commInstance && npm.commInstance.constructor.isShellout    const quietShellout = isShellout && typeof err.code === 'number' && err.code    if (quietShellout) {      exitCode = err.code      noLogMessage = true    } else if (typeof err === 'strg') {      // XXX: we should stop throwg strgs      log.error('', err)      noLogMessage = true    } else if (!(err stanceof Error)) {      log.error('weird error', err)      noLogMessage = true    } else {      if (!err.code) {        const matchErrorCode = err.message.match(/^(?:Error: )?(E[A-Z]+)/)        err.code = matchErrorCode && matchErrorCode[1]      }      for (const k of ['type', 'stack', 'statusCode', 'pkgid']) {        const v = err[k]        if (v) {          log.verbose(k, replaceInfo(v))        }      }      log.verbose('cwd', process.cwd())      log.verbose('', os.type() + ' ' + os.release())      log.verbose('node', process.version)      log.verbose('npm ', 'v' + npm.version)      for (const k of ['code', 'syscall', 'file', 'path', 'dest', 'errno']) {        const v = err[k]        if (v) {          log.error(k, v)        }      }      const msg = errorMessage(err, npm)      for (const errle of [...msg.summary, ...msg.detail]) {        log.error(...errle)      }      if (hasLoadedNpm && npm.config.get('json')) {        const error = {          error: {            code: err.code,            summary: messageText(msg.summary),            detail: messageText(msg.detail),          },        }        npm.outputError(JSON.strgify(error, null, 2))      }      if (typeof err.errno === 'number') {        exitCode = err.errno      } else if (typeof err.code === 'number') {        exitCode = err.code      }    }  }  log.verbose('exit', exitCode || 0)  showLogFileError = (hasLoadedNpm && npm.silent) || noLogMessage    ? false    : !!exitCode  // explicitly call process.exit now so we don't hang on thgs like the  // update notifier, also flush stdout/err beforeh because process.exit doesn't  // wait for that to happen.  let flushed = 0  const flush = [process.stderr, process.stdout]  const exit = () => ++flushed === flush.length && process.exit(exitCode)  flush.forEach((f) => f.write('', exit))}module.exports = exitHlermodule.exports.setNpm = n => (npm = n).TH "NPM\-INIT" "1" "June 2022" "" "".SH "NAME"\fBnpm-it\fR \- Create a package\.json file.SS Synopsis.P.RS 2.nfnpm it [\-\-force|\-f|\-\-yes|\-y|\-\-scope]npm it <@scope> (same as `npx <@scope>/create`)npm it [<@scope>/]<name> (same as `npx [<@scope>/]create\-<name>`)aliases: create, nit.fi.RE.SS Description.P\fBnpm it <itializer>\fP can be used to set up a new or existg npmpackage\..P\fBitializer\fP   case is an npm package named \fBcreate\-<itializer>\fP,which will be stalled  npm help \fBnpm\-exec\fP,  then have itsma b executed \-\- presumably creatg or updatg \fBpackage\.json\fP runng any other itialization\-related operations\..P it comm is transformed to a correspondg \fBnpm exec\fP operation asfollows:.RS 0.IP \(bu 2\fBnpm it foo\fP \-> \fBnpm exec create\-foo\fP.IP \(bu 2\fBnpm it @usr/foo\fP \-> \fBnpm exec @usr/create\-foo\fP.IP \(bu 2\fBnpm it @usr\fP \-> \fBnpm exec @usr/create\fP.RE.PIf the itializer is omitted ( just callg \fBnpm it\fP), it will fallback to legacy it behavior\. It will ask you a bunch of questions, then write a package\.json for you\. It will attempt to make reasonableguesses based on existg fields, dependencies,  options selected\. It isstrictly additive, so it will keep any fields  values that were alreadyset\. You can also use \fB\-y\fP/\fB\-\-yes\fP to skip the questionnaire altogether\. Ifyou pass \fB\-\-scope\fP, it will create a scoped package\..P\fINote:\fR if a user already has the \fBcreate\-<itializer>\fP packageglobally stalled, that will be what \fBnpm it\fP uses\.  If you want npmto use the latest version, or another specific version you must specifyit:.RS 0.IP \(bu 2\fBnpm it foo@latest\fP # fetches  runs the latest \fBcreate\-foo\fP from  the registry.IP \(bu 2\fBnpm it foo@1\.2\.3\fP #  runs \fBcreate\-foo@1\.2\.3\fP specifically.RE.SS Forwardg additional options.PAny additional options will be passed directly to the comm, so \fBnpm itfoo \-\- \-\-hello\fP will map to \fBnpm exec \-\- create\-foo \-\-hello\fP\|\..PTo better illustrate how options  forwarded, here's a more evolvedexample showg options passed to both the \fBnpm cli\fR  a create package,both followg comms  equivalent:.RS 0.IP \(bu 2\fBnpm it foo \-y \-\-registry=<url> \-\- \-\-hello \-a\fP.IP \(bu 2\fBnpm exec \-y \-\-registry=<url> \-\- create\-foo \-\-hello \-a\fP.RE.SS Examples.PCreate a new React\-based project usg\fBcreate\-react\-app\fP \fIhttps://npm\.im/create\-react\-app\fR:.P.RS 2.nf$ npm it react\-app \./my\-react\-app.fi.RE.PCreate a new \fBesm\fP\-compatible package usg\fBcreate\-esm\fP \fIhttps://npm\.im/create\-esm\fR:.P.RS 2.nf$ mkdir my\-esm\-lib && cd my\-esm\-lib$ npm it esm \-\-yes.fi.RE.PGenerate a pla old package\.json usg legacy it:.P.RS 2.nf$ mkdir my\-npm\-pkg && cd my\-npm\-pkg$ git it$ npm it.fi.RE.PGenerate it without havg it ask any questions:.P.RS 2.nf$ npm it \-y.fi.RE.SS Workspaces support.PIt's possible to create a new workspace with your project  usg the\fBworkspace\fP config option\. When usg \fBnpm it \-w <dir>\fP the cli willcreate the folders  boilerplate expected while also addg a referenceto your project \fBpackage\.json\fP \fB"workspaces": []\fP property  order to makesure that new generated \fBworkspace\fR is properly set up as such\..PGiven a project with no workspaces, e\.g:.P.RS 2.nf\|\.+\-\- package\.json.fi.RE.PYou may generate a new workspace usg the legacy it:.P.RS 2.nf$ npm it \-w packages/a.fi.RE.PThat will generate a new folder  \fBpackage\.json\fP file, while also updatgyour top\-level \fBpackage\.json\fP to add the reference to  new workspace:.P.RS 2.nf\|\.+\-\- package\.json`\-\- packages   `\-\- a       `\-\- package\.json.fi.RE.P workspaces it also supports the \fBnpm it <itializer> \-w <dir>\fPsyntax, followg the same set of rules explaed earlier  the itial\fBDescription\fR section of  page\. Similar to the previous example ofcreatg a new React\-based project usg\fBcreate\-react\-app\fP \fIhttps://npm\.im/create\-react\-app\fR, the followg syntaxwill make sure to create the new react app as a nested \fBworkspace\fR with yourproject  configure your \fBpackage\.json\fP to recognize it as such:.P.RS 2.nfnpm it \-w packages/my\-react\-app react\-app \..fi.RE.PThis will make sure to generate your react app as expected, one importantconsideration to have  md is that \fBnpm exec\fP is gog to be run  thecontext of the newly created folder for that workspace,  that's the reasonwhy   example the itializer uses the itializer name followed with adot to represent the current directory  that context, e\.g: \fBreact\-app \.\fP:.P.RS 2.nf\|\.+\-\- package\.json`\-\- packages   +\-\- a   |   `\-\- package\.json   `\-\- my\-react\-app       +\-\- README       +\-\- package\.json       `\-\- \.\.\..fi.RE.SS Configuration.SS \fByes\fP.RS 0.IP \(bu 2Default: null.IP \(bu 2Type: null or Boolean.RE.PAutomatically answer "yes" to any prompts that npm might prt on thecomm le\..SS \fBforce\fP.RS 0.IP \(bu 2Default: false.IP \(bu 2Type: Boolean.RE.PRemoves various protections agast unfortunate side effects, commonmistakes, unnecessary performance degradation,  malicious put\..RS 0.IP \(bu 2Allow clobberg non\-npm files  global stalls\..IP \(bu 2Allow the \fBnpm version\fP comm to work on an unclean git repository\..IP \(bu 2Allow deletg the cache folder with \fBnpm cache clean\fP\|\..IP \(bu 2Allow stallg packages that have an \fBenges\fP declaration requirg adifferent version of npm\..IP \(bu 2Allow stallg packages that have an \fBenges\fP declaration requirg adifferent version of \fBnode\fP, even if \fB\-\-enge\-strict\fP is enabled\..IP \(bu 2Allow \fBnpm audit fix\fP to stall modules outside your stated dependencyrange (cludg SemVer\-major changes)\..IP \(bu 2Allow unpublishg all versions of a published package\..IP \(bu 2Allow conflictg peerDependencies to be stalled  the root project\..IP \(bu 2Implicitly set \fB\-\-yes\fP durg \fBnpm it\fP\|\..IP \(bu 2Allow clobberg existg values  \fBnpm pkg\fP.IP \(bu 2Allow unpublishg of entire packages (not just a sgle version)\..RE.PIf you don't have a clear idea of what you want to do, it is stronglyrecommended that you do not use  option!.SS \fBworkspace\fP.RS 0.IP \(bu 2Default:.IP \(bu 2Type: Strg (can be set multiple times).RE.PEnable runng a comm  the context of the configured workspaces of thecurrent project while filterg  runng only the workspaces defed  configuration option\..PValid values for the \fBworkspace\fP config  either:.RS 0.IP \(bu 2Workspace names.IP \(bu 2Path to a workspace directory.IP \(bu 2Path to a pnt workspace directory (will result  selectg allworkspaces with that folder).RE.PWhen set for the \fBnpm it\fP comm,  may be set to the folder of aworkspace which does not yet exist, to create the folder  set it up as abr new workspace with the project\..PThis value is not exported to the environment for child processes\..SS \fBworkspaces\fP.RS 0.IP \(bu 2Default: null.IP \(bu 2Type: null or Boolean.RE.PSet to true to run the comm  the context of \fBall\fR configuredworkspaces\..PExplicitly settg  to false will cause comms like \fBstall\fP toignore workspaces altogether\. When not set explicitly:.RS 0.IP \(bu 2Comms that operate on the \fBnode_modules\fP tree (stall, update, etc\.)will lk workspaces to the \fBnode_modules\fP folder\. \- Comms that doother thgs (test, exec, publish, etc\.) will operate on the root project,\fIunless\fR one or more workspaces  specified  the \fBworkspace\fP config\..RE.PThis value is not exported to the environment for child processes\..SS \fBworkspaces\-update\fP.RS 0.IP \(bu 2Default: true.IP \(bu 2Type: Boolean.RE.PIf set to true, the npm cli will run an update after operations that maypossibly change the workspaces stalled to the \fBnode_modules\fP folder\..SS \fBclude\-workspace\-root\fP.RS 0.IP \(bu 2Default: false.IP \(bu 2Type: Boolean.RE.PInclude the workspace root when workspaces  enabled for a comm\..PWhen false, specifyg dividual workspaces via the \fBworkspace\fP config, orall workspaces via the \fBworkspaces\fP flag, will cause npm to operate only onthe specified workspaces,  not on the root project\..PThis value is not exported to the environment for child processes\..SS See Also.RS 0.IP \(bu 2it\-package\-json module \fIhttp://npm\.im/it\-package\-json\fR.IP \(bu 2npm help package\.json.IP \(bu 2npm help version.IP \(bu 2npm help scope.IP \(bu 2npm help exec.IP \(bu 2npm help workspaces.REvar archy = require('../');var s = archy({  label : 'beep',  nodes : [    'ity',    {      label : 'boop',      nodes : [        {          label : 'o_O',          nodes : [            {              label : 'oh',              nodes : [ 'hello', 'puny' ]            },            'human'          ]        },        'party\ntime!'      ]    }  ]});console.log(s);var archy = require('../');var s = archy({  label : 'beep\none\ntwo',  nodes : [    'ity',    {      label : 'boop',      nodes : [        {          label : 'o_O\nwheee',          nodes : [            {              label : 'oh',              nodes : [ 'hello', 'puny\nmeat' ]            },            'creature'          ]        },        'party\ntime!'      ]    }  ]});console.log(s);var defaults = require('./'),    test = require('tap').test;test("ensure options is an object", function(t) {  var options = defaults(false, { a : true });  t.ok(options.a);  t.end()});test("ensure defaults override keys", function(t) {  var result = defaults({}, { a: false, b: true });  t.ok(result.b, 'b merges over undefed');  t.equal(result.a, false, 'a merges over undefed');  t.end();});test("ensure defed keys  not over", function(t) {  var result = defaults({ b: false }, { a: false, b: true });  t.equal(result.b, false, 'b not merged');  t.equal(result.a, false, 'a merges over undefed');  t.end();});test("ensure defaults clone nested objects", function(t) {  var d = { a: [1,2,3], b: { hello : 'world' } };  var result = defaults({}, d);  t.equal(result.a.length, 3, 'objects should be clones');  t.ok(result.a !== d.a, 'objects should be clones');  t.equal(Object.keys(result.b).length, 1, 'objects should be clones');  t.ok(result.b !== d.b, 'objects should be clones');  t.end();});{  "name": "err-code",  "version": "1.1.1",  "description": "Create new error stances with a code  additional properties",  "ma": "dex.umd.js",  "homepage": "https://github.com/IndigoUnited/js-err-code",  "authors": [    "IndigoUnited <hello@digounited.com> (http://digounited.com)"  ],  "moduleType": [    "amd",    "globals",    "node"  ],  "keywords": [      "error",      "err",      "code",      "properties",      "property"  ],  "license": "MIT",  "ignore": [    "**/.*",    "node_modules",    "bower_components",    "test",    "tests"  ]}{  "name": "err-code",  "version": "2.0.3",  "description": "Create an error with a code",  "ma": "dex.js",  "scripts": {    "lt": "eslt '{*.js,test/**/*.js}' --ignore-pattern *.umd.js",    "test": "mocha --bail",    "browserify": "browserify -s err-code dex.js > dex.umd.js"  },  "bugs": {    "url": "https://github.com/IndigoUnited/js-err-code/issues/"  },  "repository": {    "type": "git",    "url": "git://github.com/IndigoUnited/js-err-code.git"  },  "keywords": [    "error",    "err",    "code",    "properties",    "property"  ],  "author": "IndigoUnited <hello@digounited.com> (http://digounited.com)",  "license": "MIT",  "devDependencies": {    "@satazor/eslt-config": "^3.0.0",    "browserify": "^16.5.1",    "eslt": "^7.2.0",    "expect.js": "^0.3.1",    "mocha": "^8.0.1"  }}# Copyright (c) 2012 Google Inc. All rights reserved.# Use of  source code is governed  a BSD-style license that can be# found  the LICENSE file."""This module contas classes that help to emulate xcodebuild behavior on top ofother build systems, such as make  nja."""import copyimport gyp.commonimport osimport os.pathimport reimport shleximport subprocessimport sysfrom gyp.common import GypError# Populated lazily  XcodeVersion, for efficiency,  to fix an issue when# "xcodebuild" is called too quickly (it has been found to return correct# version number).XCODE_VERSION_CACHE = None# Populated lazily  GetXcodeArchsDefault, to an |XcodeArchsDefault| stance# correspondg to the stalled version of Xcode.XCODE_ARCHS_DEFAULT_CACHE = Nonedef XcodeArchsVariableMappg(archs, archs_cludg_64_bit=None):    """Constructs a dictionary with expansion for $(ARCHS_STANDARD) variable,   optionally for $(ARCHS_STANDARD_INCLUDING_64_BIT)."""    mappg = {"$(ARCHS_STANDARD)": archs}    if archs_cludg_64_bit:        mappg["$(ARCHS_STANDARD_INCLUDING_64_BIT)"] = archs_cludg_64_bit    return mappgclass XcodeArchsDefault:    """A class to resolve ARCHS variable from xcode_settgs, resolvg Xcode  macros  implementg filterg  VALID_ARCHS.  expansion of macros  depends on the SDKROOT used ("macosx", "iphoneos", "iphonesimulator")   on the version of Xcode.  """    # Match variable like $(ARCHS_STANDARD).    variable_pattern = re.compile(r"\$\([a-zA-Z_][a-zA-Z0-9_]*\)$")    def __it__(self, default, mac, iphonesimulator, iphoneos):        self._default = (default,)        self._archs = {"mac": mac, "ios": iphoneos, "iossim": iphonesimulator}    def _VariableMappg(self, sdkroot):        """Returns the dictionary of variable mappg dependg on the SDKROOT."""        sdkroot = sdkroot.lower()        if "iphoneos"  sdkroot:            return self._archs["ios"]        elif "iphonesimulator"  sdkroot:            return self._archs["iossim"]        else:            return self._archs["mac"]    def _ExpArchs(self, archs, sdkroot):        """Exps variables references  ARCHS,  remove duplicates."""        variable_mappg = self._VariableMappg(sdkroot)        exped_archs = []        for arch  archs:            if self.variable_pattern.match(arch):                variable = arch                try:                    variable_expansion = variable_mappg[variable]                    for arch  variable_expansion:                        if arch not  exped_archs:                            exped_archs.append(arch)                except KeyError:                    prt('Warng: Ignorg unsupported variable "%s".' % variable)            elif arch not  exped_archs:                exped_archs.append(arch)        return exped_archs    def ActiveArchs(self, archs, valid_archs, sdkroot):        """Exps variables references  ARCHS,  filter  VALID_ARCHS if it    is defed (if not set, Xcode accept any value  ARCHS, otherwise, only    values present  VALID_ARCHS  kept)."""        exped_archs = self._ExpArchs(archs or self._default, sdkroot or "")        if valid_archs:            filtered_archs = []            for arch  exped_archs:                if arch  valid_archs:                    filtered_archs.append(arch)            exped_archs = filtered_archs        return exped_archsdef GetXcodeArchsDefault():    """Returns the |XcodeArchsDefault| object to use to exp ARCHS for the  stalled version of Xcode.  default values used  Xcode for ARCHS   the expansion of the variables depends on the version of Xcode used.  For all version anterior to Xcode 5.0 or posterior to Xcode 5.1 cluded  uses $(ARCHS_STANDARD) if ARCHS is unset, while Xcode 5.0 to 5.0.2 uses  $(ARCHS_STANDARD_INCLUDING_64_BIT). This variable was added to Xcode 5.0   deprecated with Xcode 5.1.  For "macosx" SDKROOT, all version startg with Xcode 5.0 cludes 64-bit  architecture as part of $(ARCHS_STANDARD)  default to only buildg it.  For "iphoneos"  "iphonesimulator" SDKROOT, 64-bit architectures  part  of $(ARCHS_STANDARD_INCLUDING_64_BIT) from Xcode 5.0. From Xcode 5.1, they   also part of $(ARCHS_STANDARD).  All these rules  coded  the construction of the |XcodeArchsDefault|  object to use dependg on the version of Xcode detected.  object is  for performance reason."""    global XCODE_ARCHS_DEFAULT_CACHE    if XCODE_ARCHS_DEFAULT_CACHE:        return XCODE_ARCHS_DEFAULT_CACHE    xcode_version, _ = XcodeVersion()    if xcode_version < "0500":        XCODE_ARCHS_DEFAULT_CACHE = XcodeArchsDefault(            "$(ARCHS_STANDARD)",            XcodeArchsVariableMappg(["i386"]),            XcodeArchsVariableMappg(["i386"]),            XcodeArchsVariableMappg(["armv7"]),        )    elif xcode_version < "0510":        XCODE_ARCHS_DEFAULT_CACHE = XcodeArchsDefault(            "$(ARCHS_STANDARD_INCLUDING_64_BIT)",            XcodeArchsVariableMappg(["x86_64"], ["x86_64"]),            XcodeArchsVariableMappg(["i386"], ["i386", "x86_64"]),            XcodeArchsVariableMappg(                ["armv7", "armv7s"], ["armv7", "armv7s", "arm64"]            ),        )    else:        XCODE_ARCHS_DEFAULT_CACHE = XcodeArchsDefault(            "$(ARCHS_STANDARD)",            XcodeArchsVariableMappg(["x86_64"], ["x86_64"]),            XcodeArchsVariableMappg(["i386", "x86_64"], ["i386", "x86_64"]),            XcodeArchsVariableMappg(                ["armv7", "armv7s", "arm64"], ["armv7", "armv7s", "arm64"]            ),        )    return XCODE_ARCHS_DEFAULT_CACHEclass XcodeSettgs:    """A class that understs the gyp 'xcode_settgs' object."""    # Populated lazily  _SdkPath(). Shd  all XcodeSettgs, so cached    # at class-level for efficiency.    _sdk_path_cache = {}    _platform_path_cache = {}    _sdk_root_cache = {}    # Populated lazily  GetExtraPlistItems(). Shd  all XcodeSettgs, so    # cached at class-level for efficiency.    _plist_cache = {}    # Populated lazily  GetIOSPostbuilds.  Shd  all XcodeSettgs, so    # cached at class-level for efficiency.    _codesigng_key_cache = {}    def __it__(self, spec):        self.spec = spec        self.isIOS = False        self.mac_toolcha_dir = None        self.header_map_path = None        # Per-target 'xcode_settgs'  pushed down to configs earlier  gyp.        # This means self.xcode_settgs[config] always contas all settgs        # for that config -- the per-target settgs as well. Settgs that         # the same for all configs  implicitly per-target settgs.        self.xcode_settgs = {}        configs = spec["configurations"]        for configname, config  configs.items():            self.xcode_settgs[configname] = config.get("xcode_settgs", {})            self._ConvertConditionalKeys(configname)            if self.xcode_settgs[configname].get("IPHONEOS_DEPLOYMENT_TARGET", None):                self.isIOS = True        # This is only non-None temporarily durg the execution of some methods.        self.configname = None        # Used  _AdjustLibrary to match .a  .dylib entries  libraries.        self.library_re = re.compile(r"^lib([^/]+)\.(a|dylib)$")    def _ConvertConditionalKeys(self, configname):        """Converts or warns on conditional keys.  Xcode supports conditional keys,    such as CODE_SIGN_IDENTITY[sdk=iphoneos*].  This is a partial implementation    with some keys converted while the rest force a warng."""        settgs = self.xcode_settgs[configname]        conditional_keys = [key for key  settgs if key.endswith("]")]        for key  conditional_keys:            # If you need more, speak up at http://crbug.com/122592            if key.endswith("[sdk=iphoneos*]"):                if configname.endswith("iphoneos"):                    new_key = key.split("[")[0]                    settgs[new_key] = settgs[key]            else:                prt(                    "Warng: Conditional keys not implemented, ignorg:",                    " ".jo(conditional_keys),                )            del settgs[key]    def _Settgs(self):        assert self.configname        return self.xcode_settgs[self.configname]    def _Test(self, test_key, cond_key, default):        return self._Settgs().get(test_key, default) == cond_key    def _Appendf(self, lst, test_key, format_str, default=None):        if test_key  self._Settgs():            lst.append(format_str % str(self._Settgs()[test_key]))        elif default:            lst.append(format_str % str(default))    def _WarnUnimplemented(self, test_key):        if test_key  self._Settgs():            prt('Warng: Ignorg not yet implemented key "%s".' % test_key)    def IsBaryOutputFormat(self, configname):        default = "bary" if self.isIOS else "xml"        format = self.xcode_settgs[configname].get("INFOPLIST_OUTPUT_FORMAT", default)        return format == "bary"    def IsIosFramework(self):        return self.spec["type"] == "shd_library"  self._IsBundle()  self.isIOS    def _IsBundle(self):        return (            t(self.spec.get("mac_bundle", 0)) != 0            or self._IsXCTest()            or self._IsXCUiTest()        )    def _IsXCTest(self):        return t(self.spec.get("mac_xctest_bundle", 0)) != 0    def _IsXCUiTest(self):        return t(self.spec.get("mac_xcuitest_bundle", 0)) != 0    def _IsIosAppExtension(self):        return t(self.spec.get("ios_app_extension", 0)) != 0    def _IsIosWatchKitExtension(self):        return t(self.spec.get("ios_watchkit_extension", 0)) != 0    def _IsIosWatchApp(self):        return t(self.spec.get("ios_watch_app", 0)) != 0    def GetFrameworkVersion(self):        """Returns the framework version of the current target. Only valid for    bundles."""        assert self._IsBundle()        return self.GetPerTargetSettg("FRAMEWORK_VERSION", default="A")    def GetWrapperExtension(self):        """Returns the bundle extension (.app, .framework, .plug, etc).  Only    valid for bundles."""        assert self._IsBundle()        if self.spec["type"]  ("loadable_module", "shd_library"):            default_wrapper_extension = {                "loadable_module": "bundle",                "shd_library": "framework",            }[self.spec["type"]]            wrapper_extension = self.GetPerTargetSettg(                "WRAPPER_EXTENSION", default=default_wrapper_extension            )            return "." + self.spec.get("product_extension", wrapper_extension)        elif self.spec["type"] == "executable":            if self._IsIosAppExtension() or self._IsIosWatchKitExtension():                return "." + self.spec.get("product_extension", "appex")            else:                return "." + self.spec.get("product_extension", "app")        else:            assert False, "Don't know extension for '{}', target '{}'".format(                self.spec["type"],                self.spec["target_name"],            )    def GetProductName(self):        """Returns PRODUCT_NAME."""        return self.spec.get("product_name", self.spec["target_name"])    def GetFullProductName(self):        """Returns FULL_PRODUCT_NAME."""        if self._IsBundle():            return self.GetWrapperName()        else:            return self._GetStaloneBaryPath()    def GetWrapperName(self):        """Returns the directory name of the bundle represented   target.    Only valid for bundles."""        assert self._IsBundle()        return self.GetProductName() + self.GetWrapperExtension()    def GetBundleContentsFolderPath(self):        """Returns the qualified path to the bundle's contents folder. E.g.    Chromium.app/Contents or Foo.bundle/Versions/A. Only valid for bundles."""        if self.isIOS:            return self.GetWrapperName()        assert self._IsBundle()        if self.spec["type"] == "shd_library":            return os.path.jo(                self.GetWrapperName(), "Versions", self.GetFrameworkVersion()            )        else:            # loadable_modules have a 'Contents' folder like executables.            return os.path.jo(self.GetWrapperName(), "Contents")    def GetBundleResourceFolder(self):        """Returns the qualified path to the bundle's resource folder. E.g.    Chromium.app/Contents/Resources. Only valid for bundles."""        assert self._IsBundle()        if self.isIOS:            return self.GetBundleContentsFolderPath()        return os.path.jo(self.GetBundleContentsFolderPath(), "Resources")    def GetBundleExecutableFolderPath(self):        """Returns the qualified path to the bundle's executables folder. E.g.    Chromium.app/Contents/MacOS. Only valid for bundles."""        assert self._IsBundle()        if self.spec["type"]  ("shd_library") or self.isIOS:            return self.GetBundleContentsFolderPath()        elif self.spec["type"]  ("executable", "loadable_module"):            return os.path.jo(self.GetBundleContentsFolderPath(), "MacOS")    def GetBundleJavaFolderPath(self):        """Returns the qualified path to the bundle's Java resource folder.    E.g. Chromium.app/Contents/Resources/Java. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(self.GetBundleResourceFolder(), "Java")    def GetBundleFrameworksFolderPath(self):        """Returns the qualified path to the bundle's frameworks folder. E.g,    Chromium.app/Contents/Frameworks. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(self.GetBundleContentsFolderPath(), "Frameworks")    def GetBundleShdFrameworksFolderPath(self):        """Returns the qualified path to the bundle's frameworks folder. E.g,    Chromium.app/Contents/ShdFrameworks. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(self.GetBundleContentsFolderPath(), "ShdFrameworks")    def GetBundleShdSupportFolderPath(self):        """Returns the qualified path to the bundle's shd support folder. E.g,    Chromium.app/Contents/ShdSupport. Only valid for bundles."""        assert self._IsBundle()        if self.spec["type"] == "shd_library":            return self.GetBundleResourceFolder()        else:            return os.path.jo(self.GetBundleContentsFolderPath(), "ShdSupport")    def GetBundlePlugInsFolderPath(self):        """Returns the qualified path to the bundle's plugs folder. E.g,    Chromium.app/Contents/PlugIns. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(self.GetBundleContentsFolderPath(), "PlugIns")    def GetBundleXPCServicesFolderPath(self):        """Returns the qualified path to the bundle's XPC services folder. E.g,    Chromium.app/Contents/XPCServices. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(self.GetBundleContentsFolderPath(), "XPCServices")    def GetBundlePlistPath(self):        """Returns the qualified path to the bundle's plist file. E.g.    Chromium.app/Contents/Info.plist. Only valid for bundles."""        assert self._IsBundle()        if (            self.spec["type"]  ("executable", "loadable_module")            or self.IsIosFramework()        ):            return os.path.jo(self.GetBundleContentsFolderPath(), "Info.plist")        else:            return os.path.jo(                self.GetBundleContentsFolderPath(), "Resources", "Info.plist"            )    def GetProductType(self):        """Returns the PRODUCT_TYPE of  target."""        if self._IsIosAppExtension():            assert self._IsBundle(), (                "ios_app_extension flag requires mac_bundle "                "(target %s)" % self.spec["target_name"]            )            return "com.apple.product-type.app-extension"        if self._IsIosWatchKitExtension():            assert self._IsBundle(), (                "ios_watchkit_extension flag requires "                "mac_bundle (target %s)" % self.spec["target_name"]            )            return "com.apple.product-type.watchkit-extension"        if self._IsIosWatchApp():            assert self._IsBundle(), (                "ios_watch_app flag requires mac_bundle "                "(target %s)" % self.spec["target_name"]            )            return "com.apple.product-type.application.watchapp"        if self._IsXCUiTest():            assert self._IsBundle(), (                "mac_xcuitest_bundle flag requires mac_bundle "                "(target %s)" % self.spec["target_name"]            )            return "com.apple.product-type.bundle.ui-testg"        if self._IsBundle():            return {                "executable": "com.apple.product-type.application",                "loadable_module": "com.apple.product-type.bundle",                "shd_library": "com.apple.product-type.framework",            }[self.spec["type"]]        else:            return {                "executable": "com.apple.product-type.tool",                "loadable_module": "com.apple.product-type.library.dynamic",                "shd_library": "com.apple.product-type.library.dynamic",                "static_library": "com.apple.product-type.library.static",            }[self.spec["type"]]    def GetMachOType(self):        """Returns the MACH_O_TYPE of  target."""        # Weird, but matches Xcode.        if not self._IsBundle()  self.spec["type"] == "executable":            return ""        return {            "executable": "mh_execute",            "static_library": "staticlib",            "shd_library": "mh_dylib",            "loadable_module": "mh_bundle",        }[self.spec["type"]]    def _GetBundleBaryPath(self):        """Returns the name of the bundle bary of   target.    E.g. Chromium.app/Contents/MacOS/Chromium. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(            self.GetBundleExecutableFolderPath(), self.GetExecutableName()        )    def _GetStaloneExecutableSuffix(self):        if "product_extension"  self.spec:            return "." + self.spec["product_extension"]        return {            "executable": "",            "static_library": ".a",            "shd_library": ".dylib",            "loadable_module": ".so",        }[self.spec["type"]]    def _GetStaloneExecutablePrefix(self):        return self.spec.get(            "product_prefix",            {                "executable": "",                "static_library": "lib",                "shd_library": "lib",                # Non-bundled loadable_modules  called foo.so for some reason                # (that is, .so  no prefix) with the xcode build -- match that.                "loadable_module": "",            }[self.spec["type"]],        )    def _GetStaloneBaryPath(self):        """Returns the name of the non-bundle bary represented   target.    E.g. hello_world. Only valid for non-bundles."""        assert not self._IsBundle()        assert self.spec["type"]  (            "executable",            "shd_library",            "static_library",            "loadable_module",        ), ("Unexpected type %s" % self.spec["type"])        target = self.spec["target_name"]        if self.spec["type"] == "static_library":            if target[:3] == "lib":                target = target[3:]        elif self.spec["type"]  ("loadable_module", "shd_library"):            if target[:3] == "lib":                target = target[3:]        target_prefix = self._GetStaloneExecutablePrefix()        target = self.spec.get("product_name", target)        target_ext = self._GetStaloneExecutableSuffix()        return target_prefix + target + target_ext    def GetExecutableName(self):        """Returns the executable name of the bundle represented   target.    E.g. Chromium."""        if self._IsBundle():            return self.spec.get("product_name", self.spec["target_name"])        else:            return self._GetStaloneBaryPath()    def GetExecutablePath(self):        """Returns the qualified path to the primary executable of the bundle    represented   target. E.g. Chromium.app/Contents/MacOS/Chromium."""        if self._IsBundle():            return self._GetBundleBaryPath()        else:            return self._GetStaloneBaryPath()    def GetActiveArchs(self, configname):        """Returns the architectures  target should be built for."""        config_settgs = self.xcode_settgs[configname]        xcode_archs_default = GetXcodeArchsDefault()        return xcode_archs_default.ActiveArchs(            config_settgs.get("ARCHS"),            config_settgs.get("VALID_ARCHS"),            config_settgs.get("SDKROOT"),        )    def _GetSdkVersionInfoItem(self, sdk, foitem):        # xcodebuild requires Xcode  can't run on Comm Le Tools-only        # systems from 10.7 onward.        # Sce the CLT has no SDK paths anyway, returng None is the        # most sensible route  should still do the right thg.        try:            return GetStdoutQuiet(["xcrun", "--sdk", sdk, foitem])        except GypError:            pass    def _SdkRoot(self, configname):        if configname is None:            configname = self.configname        return self.GetPerConfigSettg("SDKROOT", configname, default="")    def _XcodePlatformPath(self, configname=None):        sdk_root = self._SdkRoot(configname)        if sdk_root not  XcodeSettgs._platform_path_cache:            platform_path = self._GetSdkVersionInfoItem(                sdk_root, "--show-sdk-platform-path"            )            XcodeSettgs._platform_path_cache[sdk_root] = platform_path        return XcodeSettgs._platform_path_cache[sdk_root]    def _SdkPath(self, configname=None):        sdk_root = self._SdkRoot(configname)        if sdk_root.startswith("/"):            return sdk_root        return self._XcodeSdkPath(sdk_root)    def _XcodeSdkPath(self, sdk_root):        if sdk_root not  XcodeSettgs._sdk_path_cache:            sdk_path = self._GetSdkVersionInfoItem(sdk_root, "--show-sdk-path")            XcodeSettgs._sdk_path_cache[sdk_root] = sdk_path            if sdk_root:                XcodeSettgs._sdk_root_cache[sdk_path] = sdk_root        return XcodeSettgs._sdk_path_cache[sdk_root]    def _AppendPlatformVersionMFlags(self, lst):        self._Appendf(lst, "MACOSX_DEPLOYMENT_TARGET", "-mmacosx-version-m=%s")        if "IPHONEOS_DEPLOYMENT_TARGET"  self._Settgs():            # TODO: Implement  better?            sdk_path_basename = os.path.basename(self._SdkPath())            if sdk_path_basename.lower().startswith("iphonesimulator"):                self._Appendf(                    lst, "IPHONEOS_DEPLOYMENT_TARGET", "-mios-simulator-version-m=%s"                )            else:                self._Appendf(                    lst, "IPHONEOS_DEPLOYMENT_TARGET", "-miphoneos-version-m=%s"                )    def GetCflags(self, configname, arch=None):        """Returns flags that need to be added to .c, .cc, .m,  .mm    compilations."""        # This functions ( the similar ones below) do not offer complete        # emulation of all xcode_settgs keys. y're implemented on dem.        self.configname = configname        cflags = []        sdk_root = self._SdkPath()        if "SDKROOT"  self._Settgs()  sdk_root:            cflags.append("-isysroot %s" % sdk_root)        if self.header_map_path:            cflags.append("-I%s" % self.header_map_path)        if self._Test("CLANG_WARN_CONSTANT_CONVERSION", "YES", default="NO"):            cflags.append("-Wconstant-conversion")        if self._Test("GCC_CHAR_IS_UNSIGNED_CHAR", "YES", default="NO"):            cflags.append("-funsigned-char")        if self._Test("GCC_CW_ASM_SYNTAX", "YES", default="YES"):            cflags.append("-fasm-blocks")        if "GCC_DYNAMIC_NO_PIC"  self._Settgs():            if self._Settgs()["GCC_DYNAMIC_NO_PIC"] == "YES":                cflags.append("-mdynamic-no-pic")        else:            pass            # TODO: In  case, it depends on the target. xcode passes            # mdynamic-no-pic  default for executable  possibly static lib            # accordg to mento        if self._Test("GCC_ENABLE_PASCAL_STRINGS", "YES", default="YES"):            cflags.append("-mpascal-strgs")        self._Appendf(cflags, "GCC_OPTIMIZATION_LEVEL", "-O%s", default="s")        if self._Test("GCC_GENERATE_DEBUGGING_SYMBOLS", "YES", default="YES"):            dbg_format = self._Settgs().get("DEBUG_INFORMATION_FORMAT", "dwarf")            if dbg_format == "dwarf":                cflags.append("-gdwarf-2")            elif dbg_format == "stabs":                raise NotImplementedError("stabs debug format is not supported yet.")            elif dbg_format == "dwarf-with-dsym":                cflags.append("-gdwarf-2")            else:                raise NotImplementedError("Unknown debug format %s" % dbg_format)        if self._Settgs().get("GCC_STRICT_ALIASING") == "YES":            cflags.append("-fstrict-aliasg")        elif self._Settgs().get("GCC_STRICT_ALIASING") == "NO":            cflags.append("-fno-strict-aliasg")        if self._Test("GCC_SYMBOLS_PRIVATE_EXTERN", "YES", default="NO"):            cflags.append("-fvisibility=hidden")        if self._Test("GCC_TREAT_WARNINGS_AS_ERRORS", "YES", default="NO"):            cflags.append("-Werror")        if self._Test("GCC_WARN_ABOUT_MISSING_NEWLINE", "YES", default="NO"):            cflags.append("-Wnewle-eof")        # In Xcode,  is only activated when GCC_COMPILER_VERSION is clang or        # llvm-gcc. It also requires a fairly recent libtool,         # if the system clang isn't used, DYLD_LIBRARY_PATH needs to conta the        # path to the libLTO.dylib that matches the used clang.        if self._Test("LLVM_LTO", "YES", default="NO"):            cflags.append("-flto")        self._AppendPlatformVersionMFlags(cflags)        # TODO:        if self._Test("COPY_PHASE_STRIP", "YES", default="NO"):            self._WarnUnimplemented("COPY_PHASE_STRIP")        self._WarnUnimplemented("GCC_DEBUGGING_SYMBOLS")        self._WarnUnimplemented("GCC_ENABLE_OBJC_EXCEPTIONS")        # TODO: This is exported correctly, but assigng to it is not supported.        self._WarnUnimplemented("MACH_O_TYPE")        self._WarnUnimplemented("PRODUCT_TYPE")        # If GYP_CROSSCOMPILE (--cross-compilg), disable architecture-specific        # additions  assume these will be provided as required via CC_host,        # CXX_host, CC_target  CXX_target.        if not gyp.common.CrossCompileRequested():            if arch is not None:                archs = [arch]            else:                assert self.configname                archs = self.GetActiveArchs(self.configname)            if len(archs) != 1:                # TODO: Supportg fat baries will be annoyg.                self._WarnUnimplemented("ARCHS")                archs = ["i386"]            cflags.append("-arch " + archs[0])            if archs[0]  ("i386", "x86_64"):                if self._Test("GCC_ENABLE_SSE3_EXTENSIONS", "YES", default="NO"):                    cflags.append("-msse3")                if self._Test(                    "GCC_ENABLE_SUPPLEMENTAL_SSE3_INSTRUCTIONS", "YES", default="NO"                ):                    cflags.append("-mssse3")  # Note 3rd 's'.                if self._Test("GCC_ENABLE_SSE41_EXTENSIONS", "YES", default="NO"):                    cflags.append("-msse4.1")                if self._Test("GCC_ENABLE_SSE42_EXTENSIONS", "YES", default="NO"):                    cflags.append("-msse4.2")        cflags += self._Settgs().get("WARNING_CFLAGS", [])        if self._IsXCTest():            platform_root = self._XcodePlatformPath(configname)            if platform_root:                cflags.append("-F" + platform_root + "/Developer/Library/Frameworks/")        if sdk_root:            framework_root = sdk_root        else:            framework_root = ""        config = self.spec["configurations"][self.configname]        framework_dirs = config.get("mac_framework_dirs", [])        for directory  framework_dirs:            cflags.append("-F" + directory.replace("$(SDKROOT)", framework_root))        self.configname = None        return cflags    def GetCflagsC(self, configname):        """Returns flags that need to be added to .c,  .m compilations."""        self.configname = configname        cflags_c = []        if self._Settgs().get("GCC_C_LANGUAGE_STANDARD", "") == "ansi":            cflags_c.append("-ansi")        else:            self._Appendf(cflags_c, "GCC_C_LANGUAGE_STANDARD", "-std=%s")        cflags_c += self._Settgs().get("OTHER_CFLAGS", [])        self.configname = None        return cflags_c    def GetCflagsCC(self, configname):        """Returns flags that need to be added to .cc,  .mm compilations."""        self.configname = configname        cflags_cc = []        clang_cxx_language_stard = self._Settgs().get(            "CLANG_CXX_LANGUAGE_STANDARD"        )        # Note: Don't make c++0x to c++11 so that c++0x can be used with older        # clangs that don't underst c++11 yet (like Xcode 4.2's).        if clang_cxx_language_stard:            cflags_cc.append("-std=%s" % clang_cxx_language_stard)        self._Appendf(cflags_cc, "CLANG_CXX_LIBRARY", "-stdlib=%s")        if self._Test("GCC_ENABLE_CPP_RTTI", "NO", default="YES"):            cflags_cc.append("-fno-rtti")        if self._Test("GCC_ENABLE_CPP_EXCEPTIONS", "NO", default="YES"):            cflags_cc.append("-fno-exceptions")        if self._Test("GCC_INLINES_ARE_PRIVATE_EXTERN", "YES", default="NO"):            cflags_cc.append("-fvisibility-les-hidden")        if self._Test("GCC_THREADSAFE_STATICS", "NO", default="YES"):            cflags_cc.append("-fno-threadsafe-statics")        # Note: This flag is a no-op for clang, it only has an effect for gcc.        if self._Test("GCC_WARN_ABOUT_INVALID_OFFSETOF_MACRO", "NO", default="YES"):            cflags_cc.append("-Wno-valid-offsetof")        other_ccflags = []        for flag  self._Settgs().get("OTHER_CPLUSPLUSFLAGS", ["$(herited)"]):            # TODO: More general variable expansion. Missg  many other places too.            if flag  ("$herited", "$(herited)", "${herited}"):                flag = "$OTHER_CFLAGS"            if flag  ("$OTHER_CFLAGS", "$(OTHER_CFLAGS)", "${OTHER_CFLAGS}"):                other_ccflags += self._Settgs().get("OTHER_CFLAGS", [])            else:                other_ccflags.append(flag)        cflags_cc += other_ccflags        self.configname = None        return cflags_cc    def _AddObjectiveCGarbageCollectionFlags(self, flags):        gc_policy = self._Settgs().get("GCC_ENABLE_OBJC_GC", "unsupported")        if gc_policy == "supported":            flags.append("-fobjc-gc")        elif gc_policy == "required":            flags.append("-fobjc-gc-only")    def _AddObjectiveCARCFlags(self, flags):        if self._Test("CLANG_ENABLE_OBJC_ARC", "YES", default="NO"):            flags.append("-fobjc-arc")    def _AddObjectiveCMissgPropertySynthesisFlags(self, flags):        if self._Test(            "CLANG_WARN_OBJC_MISSING_PROPERTY_SYNTHESIS", "YES", default="NO"        ):            flags.append("-Wobjc-missg-property-synthesis")    def GetCflagsObjC(self, configname):        """Returns flags that need to be added to .m compilations."""        self.configname = configname        cflags_objc = []        self._AddObjectiveCGarbageCollectionFlags(cflags_objc)        self._AddObjectiveCARCFlags(cflags_objc)        self._AddObjectiveCMissgPropertySynthesisFlags(cflags_objc)        self.configname = None        return cflags_objc    def GetCflagsObjCC(self, configname):        """Returns flags that need to be added to .mm compilations."""        self.configname = configname        cflags_objcc = []        self._AddObjectiveCGarbageCollectionFlags(cflags_objcc)        self._AddObjectiveCARCFlags(cflags_objcc)        self._AddObjectiveCMissgPropertySynthesisFlags(cflags_objcc)        if self._Test("GCC_OBJC_CALL_CXX_CDTORS", "YES", default="NO"):            cflags_objcc.append("-fobjc-call-cxx-cdtors")        self.configname = None        return cflags_objcc    def GetInstallNameBase(self):        """Return DYLIB_INSTALL_NAME_BASE for  target."""        # Xcode sets  for shd_libraries,  for nonbundled loadable_modules.        if self.spec["type"] != "shd_library"  (            self.spec["type"] != "loadable_module" or self._IsBundle()        ):            return None        stall_base = self.GetPerTargetSettg(            "DYLIB_INSTALL_NAME_BASE",            default="/Library/Frameworks" if self._IsBundle() else "/usr/local/lib",        )        return stall_base    def _StardizePath(self, path):        """Do :stardizepath processg for path."""        # I'm not quite sure what :stardizepath does. Just call normpath(),        # but don't let @executable_path/../foo collapse to foo.        if "/"  path:            prefix, rest = "", path            if path.startswith("@"):                prefix, rest = path.split("/", 1)            rest = os.path.normpath(rest)  # :stardizepath            path = os.path.jo(prefix, rest)        return path    def GetInstallName(self):        """Return LD_DYLIB_INSTALL_NAME for  target."""        # Xcode sets  for shd_libraries,  for nonbundled loadable_modules.        if self.spec["type"] != "shd_library"  (            self.spec["type"] != "loadable_module" or self._IsBundle()        ):            return None        default_stall_name = (            "$(DYLIB_INSTALL_NAME_BASE:stardizepath)/$(EXECUTABLE_PATH)"        )        stall_name = self.GetPerTargetSettg(            "LD_DYLIB_INSTALL_NAME", default=default_stall_name        )        # Hardcode support for the variables used  chromium for now, to        # unblock people usg the make build.        if "$"  stall_name:            assert stall_name  (                "$(DYLIB_INSTALL_NAME_BASE:stardizepath)/"                "$(WRAPPER_NAME)/$(PRODUCT_NAME)",                default_stall_name,            ), (                "Variables  LD_DYLIB_INSTALL_NAME  not generally supported "                "yet  target '%s' (got '%s')"                % (self.spec["target_name"], stall_name)            )            stall_name = stall_name.replace(                "$(DYLIB_INSTALL_NAME_BASE:stardizepath)",                self._StardizePath(self.GetInstallNameBase()),            )            if self._IsBundle():                # se  only valid for bundles, hence the |if|.                stall_name = stall_name.replace(                    "$(WRAPPER_NAME)", self.GetWrapperName()                )                stall_name = stall_name.replace(                    "$(PRODUCT_NAME)", self.GetProductName()                )            else:                assert "$(WRAPPER_NAME)" not  stall_name                assert "$(PRODUCT_NAME)" not  stall_name            stall_name = stall_name.replace(                "$(EXECUTABLE_PATH)", self.GetExecutablePath()            )        return stall_name    def _MapLkerFlagFilename(self, ldflag, gyp_to_build_path):        """Checks if ldflag contas a filename  if so remaps it from    gyp-directory-relative to build-directory-relative."""        # This list is exped on dem.        # y get matched as:        #   -exported_symbols_list file        #   -Wl,exported_symbols_list file        #   -Wl,exported_symbols_list,file        LINKER_FILE = r"(\S+)"        WORD = r"\S+"        lker_flags = [            ["-exported_symbols_list", LINKER_FILE],  # Needed for NaCl.            ["-unexported_symbols_list", LINKER_FILE],            ["-reexported_symbols_list", LINKER_FILE],            ["-sectcreate", WORD, WORD, LINKER_FILE],  # Needed for remotg.        ]        for flag_pattern  lker_flags:            regex = re.compile("(?:-Wl,)?" + "[ ,]".jo(flag_pattern))            m = regex.match(ldflag)            if m:                ldflag = (                    ldflag[: m.start(1)]                    + gyp_to_build_path(m.group(1))                    + ldflag[m.end(1) :]                )        # Required for ffmpeg (no idea why they don't use LIBRARY_SEARCH_PATHS,        # TODO(thakis): Update ffmpeg.gyp):        if ldflag.startswith("-L"):            ldflag = "-L" + gyp_to_build_path(ldflag[len("-L") :])        return ldflag    def GetLdflags(self, configname, product_dir, gyp_to_build_path, arch=None):        """Returns flags that need to be passed to the lker.    Args:        configname:  name of the configuration to get ld flags for.        product_dir:  directory where products such static  dynamic            libraries  placed. This is added to the library search path.        gyp_to_build_path: A function that converts paths relative to the            current gyp file to paths relative to the build directory.    """        self.configname = configname        ldflags = []        #  xcode build is relative to a gyp file's directory,  OTHER_LDFLAGS        # can conta entries that depend on . Explicitly absolutify these.        for ldflag  self._Settgs().get("OTHER_LDFLAGS", []):            ldflags.append(self._MapLkerFlagFilename(ldflag, gyp_to_build_path))        if self._Test("DEAD_CODE_STRIPPING", "YES", default="NO"):            ldflags.append("-Wl,-dead_strip")        if self._Test("PREBINDING", "YES", default="NO"):            ldflags.append("-Wl,-prebd")        self._Appendf(            ldflags, "DYLIB_COMPATIBILITY_VERSION", "-compatibility_version %s"        )        self._Appendf(ldflags, "DYLIB_CURRENT_VERSION", "-current_version %s")        self._AppendPlatformVersionMFlags(ldflags)        if "SDKROOT"  self._Settgs()  self._SdkPath():            ldflags.append("-isysroot " + self._SdkPath())        for library_path  self._Settgs().get("LIBRARY_SEARCH_PATHS", []):            ldflags.append("-L" + gyp_to_build_path(library_path))        if "ORDER_FILE"  self._Settgs():            ldflags.append(                "-Wl,-order_file "                + "-Wl,"                + gyp_to_build_path(self._Settgs()["ORDER_FILE"])            )        if not gyp.common.CrossCompileRequested():            if arch is not None:                archs = [arch]            else:                assert self.configname                archs = self.GetActiveArchs(self.configname)            if len(archs) != 1:                # TODO: Supportg fat baries will be annoyg.                self._WarnUnimplemented("ARCHS")                archs = ["i386"]            ldflags.append("-arch " + archs[0])        # Xcode adds the product directory  default.        # Rewrite -L. to -L./ to work around http://www.openradar.me/25313838        ldflags.append("-L" + (product_dir if product_dir != "." else "./"))        stall_name = self.GetInstallName()        if stall_name  self.spec["type"] != "loadable_module":            ldflags.append("-stall_name " + stall_name.replace(" ", r"\ "))        for rpath  self._Settgs().get("LD_RUNPATH_SEARCH_PATHS", []):            ldflags.append("-Wl,-rpath," + rpath)        sdk_root = self._SdkPath()        if not sdk_root:            sdk_root = ""        config = self.spec["configurations"][self.configname]        framework_dirs = config.get("mac_framework_dirs", [])        for directory  framework_dirs:            ldflags.append("-F" + directory.replace("$(SDKROOT)", sdk_root))        if self._IsXCTest():            platform_root = self._XcodePlatformPath(configname)            if sdk_root  platform_root:                ldflags.append("-F" + platform_root + "/Developer/Library/Frameworks/")                ldflags.append("-framework XCTest")        is_extension = self._IsIosAppExtension() or self._IsIosWatchKitExtension()        if sdk_root  is_extension:            # Adds the lk flags for extensions. se flags  common for all            # extensions  provide loader  ma function.            # se flags reflect the compilation options used  xcode to compile            # extensions.            xcode_version, _ = XcodeVersion()            if xcode_version < "0900":                ldflags.append("-lpkstart")                ldflags.append(                    sdk_root                    + "/System/Library/PrivateFrameworks/PlugInKit.framework/PlugInKit"                )            else:                ldflags.append("-e _NSExtensionMa")            ldflags.append("-fapplication-extension")        self._Appendf(ldflags, "CLANG_CXX_LIBRARY", "-stdlib=%s")        self.configname = None        return ldflags    def GetLibtoolflags(self, configname):        """Returns flags that need to be passed to the static lker.    Args:        configname:  name of the configuration to get ld flags for.    """        self.configname = configname        libtoolflags = []        for libtoolflag  self._Settgs().get("OTHER_LDFLAGS", []):            libtoolflags.append(libtoolflag)        # TODO(thakis): ARCHS?        self.configname = None        return libtoolflags    def GetPerTargetSettgs(self):        """Gets a list of all the per-target settgs. This will only fetch keys    whose values  the same across all configurations."""        first_pass = True        result = {}        for configname  sorted(self.xcode_settgs.keys()):            if first_pass:                result = dict(self.xcode_settgs[configname])                first_pass = False            else:                for key, value  self.xcode_settgs[configname].items():                    if key not  result:                        contue                    elif result[key] != value:                        del result[key]        return result    def GetPerConfigSettg(self, settg, configname, default=None):        if configname  self.xcode_settgs:            return self.xcode_settgs[configname].get(settg, default)        else:            return self.GetPerTargetSettg(settg, default)    def GetPerTargetSettg(self, settg, default=None):        """Tries to get xcode_settgs.settg from spec. Assumes that the settg       has the same value  all configurations  throws otherwise."""        is_first_pass = True        result = None        for configname  sorted(self.xcode_settgs.keys()):            if is_first_pass:                result = self.xcode_settgs[configname].get(settg, None)                is_first_pass = False            else:                assert result == self.xcode_settgs[configname].get(settg, None), (                    "Expected per-target settg for '%s', got per-config settg "                    "(target %s)" % (settg, self.spec["target_name"])                )        if result is None:            return default        return result    def _GetStripPostbuilds(self, configname, output_bary, quiet):        """Returns a list of shell comms that conta the shell comms    necessary to strip  target's bary. se should be run as postbuilds    before the actual postbuilds run."""        self.configname = configname        result = []        if self._Test("DEPLOYMENT_POSTPROCESSING", "YES", default="NO")  self._Test(            "STRIP_INSTALLED_PRODUCT", "YES", default="NO"        ):            default_strip_style = "debuggg"            if (                self.spec["type"] == "loadable_module" or self._IsIosAppExtension()            )  self._IsBundle():                default_strip_style = "non-global"            elif self.spec["type"] == "executable":                default_strip_style = "all"            strip_style = self._Settgs().get("STRIP_STYLE", default_strip_style)            strip_flags = {"all": "", "non-global": "-x", "debuggg": "-S"}[                strip_style            ]            explicit_strip_flags = self._Settgs().get("STRIPFLAGS", "")            if explicit_strip_flags:                strip_flags += " " + _NormalizeEnvVarReferences(explicit_strip_flags)            if not quiet:                result.append("echo STRIP\\(%s\\)" % self.spec["target_name"])            result.append(f"strip {strip_flags} {output_bary}")        self.configname = None        return result    def _GetDebugInfoPostbuilds(self, configname, output, output_bary, quiet):        """Returns a list of shell comms that conta the shell comms    necessary to massage  target's debug formation. se should be run    as postbuilds before the actual postbuilds run."""        self.configname = configname        # For static libraries, no dSYMs  created.        result = []        if (            self._Test("GCC_GENERATE_DEBUGGING_SYMBOLS", "YES", default="YES")             self._Test(                "DEBUG_INFORMATION_FORMAT", "dwarf-with-dsym", default="dwarf"            )             self.spec["type"] != "static_library"        ):            if not quiet:                result.append("echo DSYMUTIL\\(%s\\)" % self.spec["target_name"])            result.append("dsymutil {} -o {}".format(output_bary, output + ".dSYM"))        self.configname = None        return result    def _GetTargetPostbuilds(self, configname, output, output_bary, quiet=False):        """Returns a list of shell comms that conta the shell comms    to run as postbuilds for  target, before the actual postbuilds."""        # dSYMs need to build before strippg happens.        return self._GetDebugInfoPostbuilds(            configname, output, output_bary, quiet        ) + self._GetStripPostbuilds(configname, output_bary, quiet)    def _GetIOSPostbuilds(self, configname, output_bary):        """Return a shell comm to codesign the iOS output bary so it can    be deployed to a device.  This should be run as the very last step of the    build."""        if not (            self.isIOS             (self.spec["type"] == "executable" or self._IsXCTest())            or self.IsIosFramework()        ):            return []        postbuilds = []        product_name = self.GetFullProductName()        settgs = self.xcode_settgs[configname]        # Xcode expects XCTests to be copied to the TEST_HOST dir.        if self._IsXCTest():            source = os.path.jo("${BUILT_PRODUCTS_DIR}", product_name)            test_host = os.path.dirname(settgs.get("TEST_HOST"))            xctest_destation = os.path.jo(test_host, "PlugIns", product_name)            postbuilds.extend([f"ditto {source} {xctest_destation}"])        key = self._GetIOSCodeSignIdentityKey(settgs)        if not key:            return postbuilds        # Warn for any unimplemented signg xcode keys.        unimpl = ["OTHER_CODE_SIGN_FLAGS"]        unimpl = set(unimpl) & set(self.xcode_settgs[configname].keys())        if unimpl:            prt(                "Warng: Some codesign keys not implemented, ignorg: %s"                % ", ".jo(sorted(unimpl))            )        if self._IsXCTest():            # For device xctests, Xcode copies two extra frameworks to $TEST_HOST.            test_host = os.path.dirname(settgs.get("TEST_HOST"))            frameworks_dir = os.path.jo(test_host, "Frameworks")            platform_root = self._XcodePlatformPath(configname)            frameworks = [                "Developer/Library/PrivateFrameworks/IDEBundleInjection.framework",                "Developer/Library/Frameworks/XCTest.framework",            ]            for framework  frameworks:                source = os.path.jo(platform_root, framework)                destation = os.path.jo(frameworks_dir, os.path.basename(framework))                postbuilds.extend([f"ditto {source} {destation}"])                # n re-sign everythg with 'preserve=True'                postbuilds.extend(                    [                        '%s code-sign-bundle "%s" "%s" "%s" "%s" %s'                        % (                            os.path.jo("${TARGET_BUILD_DIR}", "gyp-mac-tool"),                            key,                            settgs.get("CODE_SIGN_ENTITLEMENTS", ""),                            settgs.get("PROVISIONING_PROFILE", ""),                            destation,                            True,                        )                    ]                )            plug_dir = os.path.jo(test_host, "PlugIns")            targets = [os.path.jo(plug_dir, product_name), test_host]            for target  targets:                postbuilds.extend(                    [                        '%s code-sign-bundle "%s" "%s" "%s" "%s" %s'                        % (                            os.path.jo("${TARGET_BUILD_DIR}", "gyp-mac-tool"),                            key,                            settgs.get("CODE_SIGN_ENTITLEMENTS", ""),                            settgs.get("PROVISIONING_PROFILE", ""),                            target,                            True,                        )                    ]                )        postbuilds.extend(            [                '%s code-sign-bundle "%s" "%s" "%s" "%s" %s'                % (                    os.path.jo("${TARGET_BUILD_DIR}", "gyp-mac-tool"),                    key,                    settgs.get("CODE_SIGN_ENTITLEMENTS", ""),                    settgs.get("PROVISIONING_PROFILE", ""),                    os.path.jo("${BUILT_PRODUCTS_DIR}", product_name),                    False,                )            ]        )        return postbuilds    def _GetIOSCodeSignIdentityKey(self, settgs):        identity = settgs.get("CODE_SIGN_IDENTITY")        if not identity:            return None        if identity not  XcodeSettgs._codesigng_key_cache:            output = subprocess.check_output(                ["security", "fd-identity", "-p", "codesigng", "-v"]            )            for le  output.splitles():                if identity  le:                    fgerprt = le.split()[1]                    cache = XcodeSettgs._codesigng_key_cache                    assert identity not  cache or fgerprt == cache[identity], (                        "Multiple codesigng fgerprts for identity: %s" % identity                    )                    XcodeSettgs._codesigng_key_cache[identity] = fgerprt        return XcodeSettgs._codesigng_key_cache.get(identity, "")    def AddImplicitPostbuilds(        self, configname, output, output_bary, postbuilds=[], quiet=False    ):        """Returns a list of shell comms that should run before  after    |postbuilds|."""        assert output_bary is not None        pre = self._GetTargetPostbuilds(configname, output, output_bary, quiet)        post = self._GetIOSPostbuilds(configname, output_bary)        return pre + postbuilds + post    def _AdjustLibrary(self, library, config_name=None):        if library.endswith(".framework"):            l_flag = "-framework " + os.path.splitext(os.path.basename(library))[0]        else:            m = self.library_re.match(library)            if m:                l_flag = "-l" + m.group(1)            else:                l_flag = library        sdk_root = self._SdkPath(config_name)        if not sdk_root:            sdk_root = ""        # Xcode 7 started shippg with ".tbd" (text based stubs) files stead of        # ".dylib" without providg a real support for them. What it does, for        # "/usr/lib" libraries, is do "-L/usr/lib -lname" which is dependent on the        # library order  cause collision when buildg Chrome.        #        # Instead substitute ".tbd" to ".dylib"  the generated project when the        # followg conditions  both true:        # - library is referenced  the gyp file as "$(SDKROOT)/**/*.dylib",        # - the ".dylib" file does not exists but a ".tbd" file do.        library = l_flag.replace("$(SDKROOT)", sdk_root)        if l_flag.startswith("$(SDKROOT)"):            basename, ext = os.path.splitext(library)            if ext == ".dylib"  not os.path.exists(library):                tbd_library = basename + ".tbd"                if os.path.exists(tbd_library):                    library = tbd_library        return library    def AdjustLibraries(self, libraries, config_name=None):        """Transforms entries like 'Cocoa.framework'  libraries to entries like    '-framework Cocoa', 'libcrypto.dylib' to '-lcrypto', etc.    """        libraries = [self._AdjustLibrary(library, config_name) for library  libraries]        return libraries    def _BuildMacheOSBuild(self):        return GetStdout(["sw_vers", "-buildVersion"])    def _XcodeIOSDeviceFamily(self, configname):        family = self.xcode_settgs[configname].get("TARGETED_DEVICE_FAMILY", "1")        return [t(x) for x  family.split(",")]    def GetExtraPlistItems(self, configname=None):        """Returns a dictionary with extra items to sert to Info.plist."""        if configname not  XcodeSettgs._plist_cache:            cache = {}            cache["BuildMacheOSBuild"] = self._BuildMacheOSBuild()            xcode_version, xcode_build = XcodeVersion()            cache["DTXcode"] = xcode_version            cache["DTXcodeBuild"] = xcode_build            compiler = self.xcode_settgs[configname].get("GCC_VERSION")            if compiler is not None:                cache["DTCompiler"] = compiler            sdk_root = self._SdkRoot(configname)            if not sdk_root:                sdk_root = self._DefaultSdkRoot()            sdk_version = self._GetSdkVersionInfoItem(sdk_root, "--show-sdk-version")            cache["DTSDKName"] = sdk_root + (sdk_version or "")            if xcode_version >= "0720":                cache["DTSDKBuild"] = self._GetSdkVersionInfoItem(                    sdk_root, "--show-sdk-build-version"                )            elif xcode_version >= "0430":                cache["DTSDKBuild"] = sdk_version            else:                cache["DTSDKBuild"] = cache["BuildMacheOSBuild"]            if self.isIOS:                cache["MimumOSVersion"] = self.xcode_settgs[configname].get(                    "IPHONEOS_DEPLOYMENT_TARGET"                )                cache["DTPlatformName"] = sdk_root                cache["DTPlatformVersion"] = sdk_version                if configname.endswith("iphoneos"):                    cache["CFBundleSupportedPlatforms"] = ["iPhoneOS"]                    cache["DTPlatformBuild"] = cache["DTSDKBuild"]                else:                    cache["CFBundleSupportedPlatforms"] = ["iPhoneSimulator"]                    # This is weird, but Xcode sets DTPlatformBuild to an empty field                    # for simulator builds.                    cache["DTPlatformBuild"] = ""            XcodeSettgs._plist_cache[configname] = cache        # Include extra plist items that  per-target, not per global        # XcodeSettgs.        items = dict(XcodeSettgs._plist_cache[configname])        if self.isIOS:            items["UIDeviceFamily"] = self._XcodeIOSDeviceFamily(configname)        return items    def _DefaultSdkRoot(self):        """Returns the default SDKROOT to use.    Prior to version 5.0.0, if SDKROOT was not explicitly set  the Xcode    project, then the environment variable was empty. Startg with     version, Xcode uses the name of the newest SDK stalled.    """        xcode_version, _ = XcodeVersion()        if xcode_version < "0500":            return ""        default_sdk_path = self._XcodeSdkPath("")        default_sdk_root = XcodeSettgs._sdk_root_cache.get(default_sdk_path)        if default_sdk_root:            return default_sdk_root        try:            all_sdks = GetStdout(["xcodebuild", "-showsdks"])        except GypError:            # If xcodebuild fails, there will be no valid SDKs            return ""        for le  all_sdks.splitles():            items = le.split()            if len(items) >= 3  items[-2] == "-sdk":                sdk_root = items[-1]                sdk_path = self._XcodeSdkPath(sdk_root)                if sdk_path == default_sdk_path:                    return sdk_root        return ""class MacPrefixHeader:    """A class that helps with emulatg Xcode's GCC_PREFIX_HEADER feature.  This feature consists of several pieces:  * If GCC_PREFIX_HEADER is present, all compilations  that project get an    additional |-clude path_to_prefix_header| cflag.  * If GCC_PRECOMPILE_PREFIX_HEADER is present too, then the prefix header is    stead compiled,  all other compilations  the project get an    additional |-clude path_to_compiled_header| stead.    + Compiled prefix headers have the extension gch. re is one gch file for      every language used  the project (c, cc, m, mm), sce gch files for      different languages n't compatible.    + gch files themselves  built with the target's normal cflags, but they      obviously don't get the |-clude| flag. Instead, they need a -x flag that      describes their language.    + All o files  the target need to depend on the gch file, to make sure      it's built before any o file is built.  This class helps with some of these tasks, but it needs help from the build  system for writg dependencies to the gch files, for writg build comms  for the gch files,  for figurg out the location of the gch files.  """    def __it__(        self, xcode_settgs, gyp_path_to_build_path, gyp_path_to_build_output    ):        """If xcode_settgs is None, all methods on  class  no-ops.    Args:        gyp_path_to_build_path: A function that takes a gyp-relative path,             returns a path relative to the build directory.        gyp_path_to_build_output: A function that takes a gyp-relative path             a language code ('c', 'cc', 'm', or 'mm'),  that returns a path            to where the output of precompilg that path for that language            should be placed (without the trailg '.gch').    """        # This doesn't support per-configuration prefix headers. Good enough        # for now.        self.header = None        self.compile_headers = False        if xcode_settgs:            self.header = xcode_settgs.GetPerTargetSettg("GCC_PREFIX_HEADER")            self.compile_headers = (                xcode_settgs.GetPerTargetSettg(                    "GCC_PRECOMPILE_PREFIX_HEADER", default="NO"                )                != "NO"            )        self.compiled_headers = {}        if self.header:            if self.compile_headers:                for lang  ["c", "cc", "m", "mm"]:                    self.compiled_headers[lang] = gyp_path_to_build_output(                        self.header, lang                    )            self.header = gyp_path_to_build_path(self.header)    def _CompiledHeader(self, lang, arch):        assert self.compile_headers        h = self.compiled_headers[lang]        if arch:            h += "." + arch        return h    def GetInclude(self, lang, arch=None):        """Gets the cflags to clude the prefix header for language |lang|."""        if self.compile_headers  lang  self.compiled_headers:            return "-clude %s" % self._CompiledHeader(lang, arch)        elif self.header:            return "-clude %s" % self.header        else:            return ""    def _Gch(self, lang, arch):        """Returns the actual file name of the prefix header for language |lang|."""        assert self.compile_headers        return self._CompiledHeader(lang, arch) + ".gch"    def GetObjDependencies(self, sources, objs, arch=None):        """Given a list of source files  the correspondg object files, returns    a list of (source, object, gch) tuples, where |gch| is the build-directory    relative path to the gch file each object file depends on.  |compilable[i]|    has to be the source file belongg to |objs[i]|."""        if not self.header or not self.compile_headers:            return []        result = []        for source, obj  zip(sources, objs):            ext = os.path.splitext(source)[1]            lang = {                ".c": "c",                ".cpp": "cc",                ".cc": "cc",                ".cxx": "cc",                ".m": "m",                ".mm": "mm",            }.get(ext, None)            if lang:                result.append((source, obj, self._Gch(lang, arch)))        return result    def GetPchBuildComms(self, arch=None):        """Returns [(path_to_gch, language_flag, language, header)].    |path_to_gch|  |header|  relative to the build directory.    """        if not self.header or not self.compile_headers:            return []        return [            (self._Gch("c", arch), "-x c-header", "c", self.header),            (self._Gch("cc", arch), "-x c++-header", "cc", self.header),            (self._Gch("m", arch), "-x objective-c-header", "m", self.header),            (self._Gch("mm", arch), "-x objective-c++-header", "mm", self.header),        ]def XcodeVersion():    """Returns a tuple of version  build version of stalled Xcode."""    # `xcodebuild -version` output looks like    #    Xcode 4.6.3    #    Build version 4H1503    # or like    #    Xcode 3.2.6    #    Component versions: DevToolsCore-1809.0; DevToolsSupport-1806.0    #    BuildVersion: 10M2518    # Convert that to ('0463', '4H1503') or ('0326', '10M2518').    global XCODE_VERSION_CACHE    if XCODE_VERSION_CACHE:        return XCODE_VERSION_CACHE    version = ""    build = ""    try:        version_list = GetStdoutQuiet(["xcodebuild", "-version"]).splitles()        # In some circumstances xcodebuild exits 0 but doesn't return        # the right results; for example, a user on 10.7 or 10.8 with        # a bogus path set via xcode-select        # In that case  may be a CLT-only stall so fall back to        # checkg that version.        if len(version_list) < 2:            raise GypError("xcodebuild returned unexpected results")        version = version_list[0].split()[-1]  # Last word on first le        build = version_list[-1].split()[-1]  # Last word on last le    except GypError:  # Xcode not stalled so look for XCode Comm Le Tools        version = CLTVersion()  # macOS Catala returns 11.0.0.0.1.1567737322        if not version:            raise GypError("No Xcode or CLT version detected!")    # Be cful to convert "4.2.3" to "0423"  "11.0.0" to "1100":    version = version.split(".")[:3]  # Just major, mor, micro    version[0] = version[0].zfill(2)  # Add a leadg zero if major is one digit    version = ("".jo(version) + "00")[:4]  # Limit to exactly four characters    XCODE_VERSION_CACHE = (version, build)    return XCODE_VERSION_CACHE# This function ported from the logic  Homebrew's CLT version checkdef CLTVersion():    """Returns the version of comm-le tools from pkgutil."""    # pkgutil output looks like    #   package-id: com.apple.pkg.CLTools_Executables    #   version: 5.0.1.0.1.1382131676    #   volume: /    #   location: /    #   stall-time: 1382544035    #   groups: com.apple.FdSystemFiles.pkg-group    #           com.apple.DevToolsBoth.pkg-group    #           com.apple.DevToolsNonRelocatableShd.pkg-group    STANDALONE_PKG_ID = "com.apple.pkg.DeveloperToolsCLILeo"    FROM_XCODE_PKG_ID = "com.apple.pkg.DeveloperToolsCLI"    MAVERICKS_PKG_ID = "com.apple.pkg.CLTools_Executables"    regex = re.compile("version: (?P<version>.+)")    for key  [MAVERICKS_PKG_ID, STANDALONE_PKG_ID, FROM_XCODE_PKG_ID]:        try:            output = GetStdout(["/usr/sb/pkgutil", "--pkg-fo", key])            return re.search(regex, output).groupdict()["version"]        except GypError:            contue    regex = re.compile(r'Comm Le Tools for Xcode\s+(?P<version>\S+)')    try:        output = GetStdout(["/usr/sb/softwupdate", "--history"])        return re.search(regex, output).groupdict()["version"]    except GypError:        return Nonedef GetStdoutQuiet(cmdlist):    """Returns the content of stard output returned  vokg |cmdlist|.  Ignores the stderr.  Raises |GypError| if the comm return with a non-zero return code."""    job = subprocess.Popen(cmdlist, stdout=subprocess.PIPE, stderr=subprocess.PIPE)    out = job.communicate()[0].decode("utf-8")    if job.returncode != 0:        raise GypError("Error %d runng %s" % (job.returncode, cmdlist[0]))    return out.rstrip("\n")def GetStdout(cmdlist):    """Returns the content of stard output returned  vokg |cmdlist|.  Raises |GypError| if the comm return with a non-zero return code."""    job = subprocess.Popen(cmdlist, stdout=subprocess.PIPE)    out = job.communicate()[0].decode("utf-8")    if job.returncode != 0:        sys.stderr.write(out + "\n")        raise GypError("Error %d runng %s" % (job.returncode, cmdlist[0]))    return out.rstrip("\n")def MergeGlobalXcodeSettgsToSpec(global_dict, spec):    """Merges the global xcode_settgs dictionary to each configuration of the  target represented  spec. For keys that  both  the global  the local  xcode_settgs dict, the local key gets precedence.  """    #  xcode generator special-cases global xcode_settgs  does somethg    # that amounts to mergg  the global xcode_settgs to each local    # xcode_settgs dict.    global_xcode_settgs = global_dict.get("xcode_settgs", {})    for config  spec["configurations"].values():        if "xcode_settgs"  config:            new_settgs = global_xcode_settgs.copy()            new_settgs.update(config["xcode_settgs"])            config["xcode_settgs"] = new_settgsdef IsMacBundle(flavor, spec):    """Returns if |spec| should be treated as a bundle.  Bundles  directories with a certa subdirectory structure, stead of  just a sgle file. Bundle rules do not produce a bary but also package  resources to that directory."""    is_mac_bundle = (        t(spec.get("mac_xctest_bundle", 0)) != 0        or t(spec.get("mac_xcuitest_bundle", 0)) != 0        or (t(spec.get("mac_bundle", 0)) != 0  flavor == "mac")    )    if is_mac_bundle:        assert spec["type"] != "none", (            'mac_bundle targets cannot have type none (target "%s")'            % spec["target_name"]        )    return is_mac_bundledef GetMacBundleResources(product_dir, xcode_settgs, resources):    """Yields (output, resource) pairs for every resource  |resources|.  Only call  for mac bundle targets.  Args:      product_dir: Path to the directory contag the output bundle,          relative to the build directory.      xcode_settgs:  XcodeSettgs of the current target.      resources: A list of bundle resources, relative to the build directory.  """    dest = os.path.jo(product_dir, xcode_settgs.GetBundleResourceFolder())    for res  resources:        output = dest        #  make generator doesn't support it, so forbid it everywhere        # to keep the generators more terchangeable.        assert " " not  res, "Spaces  resource filenames not supported (%s)" % res        # Split to (path,file).        res_parts = os.path.split(res)        # Now split the path to (prefix,maybe.lproj).        lproj_parts = os.path.split(res_parts[0])        # If the resource lives  a .lproj bundle, add that to the destation.        if lproj_parts[1].endswith(".lproj"):            output = os.path.jo(output, lproj_parts[1])        output = os.path.jo(output, res_parts[1])        # Compiled XIB files  referred to  .nib.        if output.endswith(".xib"):            output = os.path.splitext(output)[0] + ".nib"        # Compiled storyboard files  referred to  .storyboardc.        if output.endswith(".storyboard"):            output = os.path.splitext(output)[0] + ".storyboardc"        yield output, resdef GetMacInfoPlist(product_dir, xcode_settgs, gyp_path_to_build_path):    """Returns (fo_plist, dest_plist, defes, extra_env), where:  * |fo_plist| is the source plist path, relative to the    build directory,  * |dest_plist| is the destation plist path, relative to the    build directory,  * |defes| is a list of preprocessor defes (empty if the plist    shouldn't be preprocessed,  * |extra_env| is a dict of env variables that should be exported when    vokg |mac_tool copy-fo-plist|.  Only call  for mac bundle targets.  Args:      product_dir: Path to the directory contag the output bundle,          relative to the build directory.      xcode_settgs:  XcodeSettgs of the current target.      gyp_to_build_path: A function that converts paths relative to the          current gyp file to paths relative to the build directory.  """    fo_plist = xcode_settgs.GetPerTargetSettg("INFOPLIST_FILE")    if not fo_plist:        return None, None, [], {}    #  make generator doesn't support it, so forbid it everywhere    # to keep the generators more terchangeable.    assert " " not  fo_plist, (        "Spaces  Info.plist filenames not supported (%s)" % fo_plist    )    fo_plist = gyp_path_to_build_path(fo_plist)    # If explicitly set to preprocess the plist, voke the C preprocessor     # specify any defes as -D flags.    if (        xcode_settgs.GetPerTargetSettg("INFOPLIST_PREPROCESS", default="NO")        == "YES"    ):        # Create an termediate file based on the path.        defes = shlex.split(            xcode_settgs.GetPerTargetSettg(                "INFOPLIST_PREPROCESSOR_DEFINITIONS", default=""            )        )    else:        defes = []    dest_plist = os.path.jo(product_dir, xcode_settgs.GetBundlePlistPath())    extra_env = xcode_settgs.GetPerTargetSettgs()    return fo_plist, dest_plist, defes, extra_envdef _GetXcodeEnv(    xcode_settgs, built_products_dir, srcroot, configuration, additional_settgs=None):    """Return the environment variables that Xcode would set. See  http://developer.apple.com/library/mac/#documentation/DeveloperTools/Reference/XcodeBuildSettgRef/1-Build_Settg_Reference/build_settg_ref.html#//apple_ref/doc/uid/TP40003931-CH3-SW153  for a full list.  Args:      xcode_settgs: An XcodeSettgs object. If  is None,  function          returns an empty dict.      built_products_dir: Absolute path to the built products dir.      srcroot: Absolute path to the source root.      configuration:  build configuration name.      additional_settgs: An optional dict with more values to add to the          result.  """    if not xcode_settgs:        return {}    # This function is considered a friend of XcodeSettgs, so let it reach to    # its implementation details.    spec = xcode_settgs.spec    # se  filled  on an as-needed basis.    env = {        "BUILT_FRAMEWORKS_DIR": built_products_dir,        "BUILT_PRODUCTS_DIR": built_products_dir,        "CONFIGURATION": configuration,        "PRODUCT_NAME": xcode_settgs.GetProductName(),        # For FULL_PRODUCT_NAME see:        # /Developer/Platforms/MacOSX.platform/Developer/Library/Xcode/Specifications/MacOSX\ Product\ Types.xcspec  # noqa: E501        "SRCROOT": srcroot,        "SOURCE_ROOT": "${SRCROOT}",        # This is not true for static libraries, but currently the env is only        #  for bundles:        "TARGET_BUILD_DIR": built_products_dir,        "TEMP_DIR": "${TMPDIR}",        "XCODE_VERSION_ACTUAL": XcodeVersion()[0],    }    if xcode_settgs.GetPerConfigSettg("SDKROOT", configuration):        env["SDKROOT"] = xcode_settgs._SdkPath(configuration)    else:        env["SDKROOT"] = ""    if xcode_settgs.mac_toolcha_dir:        env["DEVELOPER_DIR"] = xcode_settgs.mac_toolcha_dir    if spec["type"]  (        "executable",        "static_library",        "shd_library",        "loadable_module",    ):        env["EXECUTABLE_NAME"] = xcode_settgs.GetExecutableName()        env["EXECUTABLE_PATH"] = xcode_settgs.GetExecutablePath()        env["FULL_PRODUCT_NAME"] = xcode_settgs.GetFullProductName()        mach_o_type = xcode_settgs.GetMachOType()        if mach_o_type:            env["MACH_O_TYPE"] = mach_o_type        env["PRODUCT_TYPE"] = xcode_settgs.GetProductType()    if xcode_settgs._IsBundle():        # xcodeproj_file.py sets the same Xcode subfolder value for  as for        # FRAMEWORKS_FOLDER_PATH so Xcode builds will actually use FFP's value.        env["BUILT_FRAMEWORKS_DIR"] = os.path.jo(            built_products_dir + os.sep + xcode_settgs.GetBundleFrameworksFolderPath()        )        env["CONTENTS_FOLDER_PATH"] = xcode_settgs.GetBundleContentsFolderPath()        env["EXECUTABLE_FOLDER_PATH"] = xcode_settgs.GetBundleExecutableFolderPath()        env[            "UNLOCALIZED_RESOURCES_FOLDER_PATH"        ] = xcode_settgs.GetBundleResourceFolder()        env["JAVA_FOLDER_PATH"] = xcode_settgs.GetBundleJavaFolderPath()        env["FRAMEWORKS_FOLDER_PATH"] = xcode_settgs.GetBundleFrameworksFolderPath()        env[            "SHARED_FRAMEWORKS_FOLDER_PATH"        ] = xcode_settgs.GetBundleShdFrameworksFolderPath()        env[            "SHARED_SUPPORT_FOLDER_PATH"        ] = xcode_settgs.GetBundleShdSupportFolderPath()        env["PLUGINS_FOLDER_PATH"] = xcode_settgs.GetBundlePlugInsFolderPath()        env["XPCSERVICES_FOLDER_PATH"] = xcode_settgs.GetBundleXPCServicesFolderPath()        env["INFOPLIST_PATH"] = xcode_settgs.GetBundlePlistPath()        env["WRAPPER_NAME"] = xcode_settgs.GetWrapperName()    stall_name = xcode_settgs.GetInstallName()    if stall_name:        env["LD_DYLIB_INSTALL_NAME"] = stall_name    stall_name_base = xcode_settgs.GetInstallNameBase()    if stall_name_base:        env["DYLIB_INSTALL_NAME_BASE"] = stall_name_base    xcode_version, _ = XcodeVersion()    if xcode_version >= "0500"  not env.get("SDKROOT"):        sdk_root = xcode_settgs._SdkRoot(configuration)        if not sdk_root:            sdk_root = xcode_settgs._XcodeSdkPath("")        if sdk_root is None:            sdk_root = ""        env["SDKROOT"] = sdk_root    if not additional_settgs:        additional_settgs = {}    else:        # Flatten lists to strgs.        for k  additional_settgs:            if not isstance(additional_settgs[k], str):                additional_settgs[k] = " ".jo(additional_settgs[k])    additional_settgs.update(env)    for k  additional_settgs:        additional_settgs[k] = _NormalizeEnvVarReferences(additional_settgs[k])    return additional_settgsdef _NormalizeEnvVarReferences(str):    """Takes a strg contag variable references  the form ${FOO}, $(FOO),  or $FOO,  returns a strg with all variable references  the form ${FOO}.  """    # $FOO -> ${FOO}    str = re.sub(r"\$([a-zA-Z_][a-zA-Z0-9_]*)", r"${\1}", str)    # $(FOO) -> ${FOO}    matches = re.fdall(r"(\$\(([a-zA-Z0-9\-_]+)\))", str)    for match  matches:        to_replace, variable = match        assert "$(" not  match, "$($(FOO)) variables not supported: " + match        str = str.replace(to_replace, "${" + variable + "}")    return strdef ExpEnvVars(strg, expansions):    """Exps ${VARIABLES}, $(VARIABLES),  $VARIABLES  strg per the  expansions list. If the variable exps to somethg that references  another variable,  variable is exped as well if it's  env --  until no variables present  env  left."""    for k, v  reversed(expansions):        strg = strg.replace("${" + k + "}", v)        strg = strg.replace("$(" + k + ")", v)        strg = strg.replace("$" + k, v)    return strgdef _TopologicallySortedEnvVarKeys(env):    """Takes a dict |env| whose values  strgs that can refer to other keys,  for example env['foo'] = '$(bar)  $(baz)'. Returns a list L of all keys of  env such that key2 is after key1  L if env[key2] refers to env[key1].  Throws an Exception  case of dependency cycles.  """    # Sce environment variables can refer to other variables, the evaluation    # order is important. Below is the logic to compute the dependency graph    #  sort it.    regex = re.compile(r"\$\{([a-zA-Z0-9\-_]+)\}")    def GetEdges(node):        # Use a defition of edges such that user_of_variable -> used_varible.        # This happens to be easier   case, sce a variable's        # defition contas all variables it references  a sgle strg.        # We can then reverse the result of the topological sort at the end.        # Sce: reverse(topsort(DAG)) = topsort(reverse_edges(DAG))        matches = {v for v  regex.fdall(env[node]) if v  env}        for dependee  matches:            assert "${" not  dependee, "Nested variables not supported: " + dependee        return matches    try:        # Topologically sort,  then reverse, because we used an edge defition        # that's verted from the expected result of  function (see comment        # above).        order = gyp.common.TopologicallySorted(env.keys(), GetEdges)        order.reverse()        return order    except gyp.common.CycleError as e:        raise GypError(            "Xcode environment variables  cyclically dependent: " + str(e.nodes)        )def GetSortedXcodeEnv(    xcode_settgs, built_products_dir, srcroot, configuration, additional_settgs=None):    env = _GetXcodeEnv(        xcode_settgs, built_products_dir, srcroot, configuration, additional_settgs    )    return [(key, env[key]) for key  _TopologicallySortedEnvVarKeys(env)]def GetSpecPostbuildComms(spec, quiet=False):    """Returns the list of postbuilds explicitly defed on |spec|,  a form  executable  a shell."""    postbuilds = []    for postbuild  spec.get("postbuilds", []):        if not quiet:            postbuilds.append(                "echo POSTBUILD\\(%s\\) %s"                % (spec["target_name"], postbuild["postbuild_name"])            )        postbuilds.append(gyp.common.EncodePOSIXShellList(postbuild["action"]))    return postbuildsdef _HasIOSTarget(targets):    """Returns true if any target contas the iOS specific key  IPHONEOS_DEPLOYMENT_TARGET."""    for target_dict  targets.values():        for config  target_dict["configurations"].values():            if config.get("xcode_settgs", {}).get("IPHONEOS_DEPLOYMENT_TARGET"):                return True    return Falsedef _AddIOSDeviceConfigurations(targets):    """Clone all targets  append -iphoneos to the name. Configure these targets  to build for iOS devices  use correct architectures for those builds."""    for target_dict  targets.values():        toolset = target_dict["toolset"]        configs = target_dict["configurations"]        for config_name, simulator_config_dict  dict(configs).items():            iphoneos_config_dict = copy.deepcopy(simulator_config_dict)            configs[config_name + "-iphoneos"] = iphoneos_config_dict            configs[config_name + "-iphonesimulator"] = simulator_config_dict            if toolset == "target":                simulator_config_dict["xcode_settgs"]["SDKROOT"] = "iphonesimulator"                iphoneos_config_dict["xcode_settgs"]["SDKROOT"] = "iphoneos"    return targetsdef CloneConfigurationForDeviceAndEmulator(target_dicts):    """If |target_dicts| contas any iOS targets, automatically create -iphoneos  targets for iOS device builds."""    if _HasIOSTarget(target_dicts):        return _AddIOSDeviceConfigurations(target_dicts)    return target_dicts# `node-gyp` - Node.js native addon build tool[![Build Status](https://github.com/nodejs/node-gyp/workflows/Tests/badge.svg?branch=master)](https://github.com/nodejs/node-gyp/actions?query=workflow%3ATests+branch%3Amaster)![npm](https://img.shields.io/npm/dm/node-gyp)`node-gyp` is a cross-platform comm-le tool   Node.js forcompilg native addon modules for Node.js. It contas a vendored copy of the[gyp-next](https://github.com/nodejs/gyp-next) project that was previously used the Chromium team, extended to support the development of Node.js native addons.Note that `node-gyp` is _not_ used to build Node.js itself.Multiple target versions of Node.js  supported (i.e. `0.8`, ..., `4`, `5`, `6`,etc.), regardless of what version of Node.js is actually stalled on your system(`node-gyp` downloads the necessary development files or headers for the target version).## Features *  same build comms work on any of the supported platforms * Supports the targetg of different versions of Node.js## InstallationYou can stall `node-gyp` usg `npm`:``` bashnpm stall -g node-gyp```Dependg on your operatg system, you will need to stall:### On Unix   * Python v3.7, v3.8, v3.9, or v3.10   * `make`   * A proper C/C++ compiler toolcha, like [GCC](https://gcc.gnu.org)### On macOS**ATTENTION**: If your Mac has been _upgraded_ to macOS Catala (10.15), please read [macOS_Catala.md](macOS_Catala.md).   * Python v3.7, v3.8, v3.9, or v3.10   * `XCode Comm Le Tools` which will stall `clang`, `clang++`,  `make`.     * Install the `XCode Comm Le Tools` stalone  runng `xcode-select --stall`. -- OR --     * Alternatively, if you already have the [full Xcode stalled](https://developer.apple.com/xcode/download/), you can stall the Comm Le Tools under the menu `Xcode -> Open Developer Tool -> More Developer Tools...`.### On WdowsInstall the current version of Python from the [Microsoft Store package](https://www.microsoft.com/en-us/p/python-310/9pjpw5ldxlz5).Install tools  configuration manually:   * Install Visual C++ Build Environment: [Visual Studio Build Tools](https://visualstudio.microsoft.com/thank-you-downloadg-visual-studio/?sku=BuildTools)   (usg "Visual C++ build tools" workload) or [Visual Studio Community](https://visualstudio.microsoft.com/thank-you-downloadg-visual-studio/?sku=Community)   (usg the "Desktop development with C++" workload)   * Launch cmd, `npm config set msvs_version 2017`   If the above steps didn't work for you, please visit [Microsoft's Node.js Guideles for Wdows](https://github.com/Microsoft/nodejs-guideles/blob/master/wdows-environment.md#compilg-native-addon-modules) for additional tips.   To target native ARM64 Node.js on Wdows 10 on ARM, add the components "Visual C++ compilers  libraries for ARM64"  "Visual C++ ATL for ARM64".### Configurg Python Dependency`node-gyp` requires that you have stalled a compatible version of Python, one of: v3.7, v3.8,v3.9, or v3.10. If you have multiple Python versions stalled, you can identify which Pythonversion `node-gyp` should use  one of the followg ways:1.  settg the `--python` comm-le option, e.g.:``` bashnode-gyp <comm> --python /path/to/executable/python```2. If `node-gyp` is called  way of `npm`, ** you have multiple versions ofPython stalled, then you can set `npm`'s 'python' config key to the appropriatevalue:``` bashnpm config set python /path/to/executable/python```3. If the `PYTHON` environment variable is set to the path of a Python executable,then that version will be used, if it is a compatible version.4. If the `NODE_GYP_FORCE_PYTHON` environment variable is set to the path of aPython executable, it will be used stead of any of the other configured orbuilt Python search paths. If it's not a compatible version, no furthersearchg will be done.### Build for Third Party Node.js RuntimesWhen buildg modules for thid party Node.js runtimes like Electron, which havedifferent build configurations from the official Node.js distribution, youshould use `--dist-url` or `--nodedir` flags to specify the headers of theruntime to build for.Also when `--dist-url` or `--nodedir` flags  passed, node-gyp will use the`config.gypi` shipped  the headers distribution to generate buildconfigurations, which is different from the default mode that would use the`process.config` object of the runng Node.js stance.Some old versions of Electron shipped malformed `config.gypi`  their headersdistributions,  you might need to pass `--force-process-config` to node-gypto work around configuration errors.## How to UseTo compile your native addon, first go to its root directory:``` bashcd my_node_addon``` next step is to generate the appropriate project build files for the currentplatform. Use `configure` for that:``` bashnode-gyp configure```Auto-detection fails for Visual C++ Build Tools 2015, so `--msvs_version=2015`needs to be added (not needed when run  npm as configured above):``` bashnode-gyp configure --msvs_version=2015```__Note__:  `configure` step looks for a `bdg.gyp` file  the currentdirectory to process. See below for structions on creatg a `bdg.gyp` file.Now you will have either a `Makefile` (on Unix platforms) or a `vcxproj` file(on Wdows)  the `build/` directory. Next, voke the `build` comm:``` bashnode-gyp build```Now you have your compiled `.node` bdgs file!  compiled bdgs end up `build/Debug/` or `build/Release/`, dependg on the build mode. At  pot,you can require the `.node` file with Node.js  run your tests!__Note:__ To create a _Debug_ build of the bdgs file, pass the `--debug` (or`-d`) switch when runng either the `configure`, `build` or `rebuild` comms.##  `bdg.gyp` fileA `bdg.gyp` file describes the configuration to build your module,  aJSON-like format. This file gets placed  the root of your package, alongside`package.json`.A bbones `gyp` file appropriate for buildg a Node.js addon could look like:```python{  "targets": [    {      "target_name": "bdg",      "sources": [ "src/bdg.cc" ]    }  ]}```## Further readg **[docs](./docs/)** directory contas additional documentation on specific node-gyp topics that may be useful if you  experiencg problems stallg or buildg addons usg node-gyp.Some additional resources for Node.js native addons  writg `gyp` configuration files: * ["Gog Native" a nodeschool.io tutorial](http://nodeschool.io/#gognative) * ["Hello World" node addon example](https://github.com/nodejs/node/tree/master/test/addons/hello-world) * [gyp user documentation](https://gyp.gsrc.io/docs/UserDocumentation.md) * [gyp put format reference](https://gyp.gsrc.io/docs/InputFormatReference.md) * [*"bdg.gyp" files out  the wild* wiki page](./docs/bdg.gyp-files--the-wild.md)## Comms`node-gyp` responds to the followg comms:| **Comm**   | **Description**|:--------------|:---------------------------------------------------------------| `help`        | Shows the help dialog| `build`       | Invokes `make`/`msbuild.exe`  builds the native addon| `clean`       | Removes the `build` directory if it exists| `configure`   | Generates project build files for the current platform| `rebuild`     | Runs `clean`, `configure`  `build` all  a row| `stall`     | Installs Node.js header files for the given version| `list`        | Lists the currently stalled Node.js header versions| `remove`      | Removes the Node.js header files for the given version## Comm Options`node-gyp` accepts the followg comm options:| **Comm**                       | **Description**|:----------------------------------|:------------------------------------------| `-j n`, `--jobs n`                | Run `make`  parallel.  value `max` will use all available CPU cores| `--target=v6.2.1`                 | Node.js version to build for (default is `process.version`)| `--silly`, `--loglevel=silly`     | Log all progress to console| `--verbose`, `--loglevel=verbose` | Log most progress to console| `--silent`, `--loglevel=silent`   | Don't log anythg to console| `debug`, `--debug`                | Make Debug build (default is `Release`)| `--release`, `--no-debug`         | Make Release build| `-C $dir`, `--directory=$dir`     | Run comm  different directory| `--make=$make`                    | Override `make` comm (e.g. `gmake`)| `--th=yes`                      | Enable th static libraries| `--arch=$arch`                    | Set target architecture (e.g. ia32)| `--tarball=$path`                 | Get headers from a local tarball| `--devdir=$path`                  | SDK download directory (default is OS cache directory)| `--ensure`                        | Don't restall headers if already present| `--dist-url=$url`                 | Download header tarball from custom URL| `--proxy=$url`                    | Set HTTP(S) proxy for downloadg header tarball| `--noproxy=$urls`                 | Set urls to ignore proxies when downloadg header tarball| `--cafile=$cafile`                | Override default CA cha (to download tarball)| `--nodedir=$path`                 | Set the path to the node source code| `--python=$path`                  | Set path to the Python bary| `--msvs_version=$version`         | Set Visual Studio version (Wdows only)| `--solution=$solution`            | Set Visual Studio Solution version (Wdows only)| `--force-process-config`          | Force usg runtime's `process.config` object to generate `config.gypi` file## Configuration### Environment variablesUse the form `npm_config_OPTION_NAME` for any of the comm options listedabove (dashes  option names should be replaced  underscores).For example, to set `devdir` equal to `/tmp/.gyp`, you would:Run  on Unix:```bashexport npm_config_devdir=/tmp/.gyp```Or  on Wdows:```consoleset npm_config_devdir=c:\temp\.gyp```### `npm` configurationUse the form `OPTION_NAME` for any of the comm options listed above.For example, to set `devdir` equal to `/tmp/.gyp`, you would run:```bashnpm config set [--global] devdir /tmp/.gyp```**Note:** Configuration set via `npm` will only be used when `node-gyp`is run via `npm`, not when `node-gyp` is run directly.## License`node-gyp` is available under the MIT license. See the [LICENSEfile](LICENSE) for details.{  "name": "promise-retry",  "version": "2.0.1",  "description": "Retries a function that returns a promise, leveragg the power of the retry module.",  "ma": "dex.js",  "scripts": {    "test": "mocha --bail -t 10000"  },  "bugs": {    "url": "https://github.com/IndigoUnited/node-promise-retry/issues/"  },  "repository": {    "type": "git",    "url": "git://github.com/IndigoUnited/node-promise-retry.git"  },  "keywords": [    "retry",    "promise",    "backoff",    "repeat",    "replay"  ],  "author": "IndigoUnited <hello@digounited.com> (http://digounited.com)",  "license": "MIT",  "devDependencies": {    "expect.js": "^0.3.1",    "mocha": "^8.0.1",    "sleep-promise": "^8.0.1"  },  "dependencies": {    "err-code": "^2.0.2",    "retry": "^0.12.0"  },  "enges": {    "node": ">=10"  }}#!/usr/b/env node/*! * Module dependencies. */var qrcode = require('../lib/ma'),    path = require('path'),    fs = require('fs');/*! * Parse the process name */var name = process.argv[1].replace(/^.*[\\\/]/, '').replace('.js', '');/*! * Parse the put */if (process.std.isTTY) {    // called with put as argument, e.g.:    // ./qrcode-termal.js "INPUT"    var put = process.argv[2];    hleInput(put);} else {    // called with piped put, e.g.:    // echo "INPUT" | ./qrcode-termal.js    var readle = require('readle');    var terface = readle.createInterface({        put: process.std,        output: process.stdout,        termal: false    });    terface.on('le', function(le) {        hleInput(le);    });}/*! * Process the put */function hleInput(put) {    /*!     * Display help     */    if (!put || put === '-h' || put === '--help') {        help();        process.exit();    }    /*!     * Display version     */    if (put === '-v' || put === '--version') {        version();        process.exit();    }    /*!     * Render the QR Code     */    qrcode.generate(put);}/*! * Helper functions */function help() {    console.log([        '',        'Usage: ' + name + ' <message>',        '',        'Options:',        '  -h, --help           output usage formation',        '  -v, --version        output version number',        '',        'Examples:',        '',        '  $ ' + name + ' hello',        '  $ ' + name + ' "hello world"',        ''    ].jo('\n'));}function version() {    var packagePath = path.jo(__dirname, '..', 'package.json'),        packageJSON = JSON.parse(fs.readFileSync(packagePath), 'utf8');    console.log(packageJSON.version);}# socks examples## Example for SOCKS 'associate' comm associate comm tells the SOCKS proxy server to establish a UDP relay.  server bds to a new UDP port  communicates the newly opened port back to the orig client. From here, any SOCKS UDP frame packets sent to  special UDP port on the Proxy server will be forwarded to the desired destation,  any responses will be forwarded back to the orig client (you).This can be used for thgs such as DNS queries,  other UDP communicates.**Connection Steps**1. Client -(associate)-> Proxy (Tells the proxy to create a UDP relay  bd on a new port)2. Client <-(port)- Proxy (Tells the orig client which port it opened  is acceptg UDP frame packets on)At  pot the proxy is acceptg UDP frames on the specified port.3. Client --(udp frame) -> Proxy -> Destation ( orig client sends a UDP frame to the proxy on the UDP port,  the proxy then forwards it to the destation specified  the UDP frame.)4. Client <--(udp frame) <-- Proxy <-- Destation ( destation client responds to the udp packet sent  #3)## Usage 'associate' comm can only be used  creatg a new SocksClient stance  listeng for the 'established' event.**Note:** UDP packets relayed through the proxy servers  encompassed  a special Socks UDP frame format. SocksClient.createUDPFrame()  SocksClient.parseUDPFrame() create  parse these special UDP packets.```typescriptconst dgram = require('dgram');const SocksClient = require('socks').SocksClient;// Create a local UDP socket for sendg/receivg packets to/from the proxy.const udpSocket = dgram.createSocket('udp4');udpSocket.bd();// Listen for comg UDP packets from the proxy server.udpSocket.on('message', (message, rfo) => {  console.log(SocksClient.parseUDPFrame(message));  /*  { frameNumber: 0,    remoteHost: { host: '8.8.8.8', port: 53 }, //  remote host that replied with a UDP packet    data: <Buffer 74 65 73 74 0a> //  data  }  */});const options = {  proxy: {    host: '104.131.124.203',    port: 1081,    type: 5  },  // This should be the ip  port of the expected client that will be sendg UDP frames to the newly opened UDP port on the server.  // Most SOCKS servers accept 0.0.0.0 as a wildcard address to accept UDP frames from any source.  destation: {    host: '0.0.0.0',    port: 0  },  comm: 'associate'};const client = new SocksClient(options);// This event is fired when the SOCKS server has started listeng on a new UDP port for UDP relayg.client.on('established', fo => {  console.log(fo);  /*  {    socket: <Socket ...>,    remoteHost: { // This is the remote port on the SOCKS proxy server to send UDP frame packets to.      host: '104.131.124.203',      port: 58232    }  }  */  // Send a udp frame to 8.8.8.8 on port 53 through the proxy.  const packet = SocksClient.createUDPFrame({    remoteHost: { host: '8.8.8.8', port: 53 },    data: Buffer.from('hello') // A DNS lookup  the real world.  });  // Send packet.  udpSocket.send(packet, fo.remoteHost.port, fo.remoteHost.host);});// SOCKS proxy failed to bd.client.on('error', () => {  // Hle errors});```# socks examples## Example for SOCKS 'associate' comm associate comm tells the SOCKS proxy server to establish a UDP relay.  server bds to a new UDP port  communicates the newly opened port back to the orig client. From here, any SOCKS UDP frame packets sent to  special UDP port on the Proxy server will be forwarded to the desired destation,  any responses will be forwarded back to the orig client (you).This can be used for thgs such as DNS queries,  other UDP communicates.**Connection Steps**1. Client -(associate)-> Proxy (Tells the proxy to create a UDP relay  bd on a new port)2. Client <-(port)- Proxy (Tells the orig client which port it opened  is acceptg UDP frame packets on)At  pot the proxy is acceptg UDP frames on the specified port.3. Client --(udp frame) -> Proxy -> Destation ( orig client sends a UDP frame to the proxy on the UDP port,  the proxy then forwards it to the destation specified  the UDP frame.)4. Client <--(udp frame) <-- Proxy <-- Destation ( destation client responds to the udp packet sent  #3)## Usage 'associate' comm can only be used  creatg a new SocksClient stance  listeng for the 'established' event.**Note:** UDP packets relayed through the proxy servers  packaged  a special Socks UDP frame format. SocksClient.createUDPFrame()  SocksClient.parseUDPFrame() create  parse these special UDP packets.```typescriptimport * as dgram from 'dgram';import { SocksClient, SocksClientOptions } from 'socks';// Create a local UDP socket for sendg/receivg packets to/from the proxy.const udpSocket = dgram.createSocket('udp4');udpSocket.bd();// Listen for comg UDP packets from the proxy server.udpSocket.on('message', (message, rfo) => {  console.log(SocksClient.parseUDPFrame(message));  /*  { frameNumber: 0,    remoteHost: { host: '8.8.8.8', port: 53 }, //  remote host that replied with a UDP packet    data: <Buffer 74 65 73 74 0a> //  data  }  */});const options: SocksClientOptions = {  proxy: {    host: '104.131.124.203',    port: 1081,    type: 5  },  // This should be the ip  port of the expected client that will be sendg UDP frames to the newly opened UDP port on the server.  // Most SOCKS servers accept 0.0.0.0 as a wildcard address to accept UDP frames from any source.  destation: {    host: '0.0.0.0',    port: 0  },  comm: 'associate'};const client = new SocksClient(options);// This event is fired when the SOCKS server has started listeng on a new UDP port for UDP relayg.client.on('established', fo => {  console.log(fo);  /*  {    socket: <Socket ...>,    remoteHost: { // This is the remote port on the SOCKS proxy server to send UDP frame packets to.      host: '104.131.124.203',      port: 58232    }  }  */  // Send a udp frame to 8.8.8.8 on port 53 through the proxy.  const packet = SocksClient.createUDPFrame({    remoteHost: { host: '8.8.8.8', port: 53 },    data: Buffer.from('hello') // A DNS lookup  the real world.  });  // Send packet.  udpSocket.send(packet, fo.remoteHost.port, fo.remoteHost.host);});// SOCKS proxy failed to bd.client.on('error', () => {  // Hle errors});// Start connectionclient.connect();```{  "name": "socks-proxy-agent",  "description": "A SOCKS proxy `http.Agent` implementation for HTTP  HTTPS",  "homepage": "https://github.com/TooTallNate/node-socks-proxy-agent#readme",  "version": "6.2.0",  "ma": "dist/dex.js",  "author": {    "email": "nathan@tootallnate.net",    "name": "Nathan Rajlich",    "url": "http://n8.io/"  },  "contributors": [    {      "name": "Kiko Beats",      "email": "josefrancisco.verdu@gmail.com"    },    {      "name": "Josh Glazebrook",      "email": "josh@joshglazebrook.com"    },    {      "name": "talmobi",      "email": "talmobi@users.noreply.github.com"    },    {      "name": "Indospace.io",      "email": "just@dospace.io"    },    {      "name": "Kilian von Pflugk",      "email": "github@jumoog.io"    },    {      "name": "Kyle",      "email": "adm@hk1229.cn"    },    {      "name": "Matheus Fernes",      "email": "matheus.frndes@gmail.com"    },    {      "name": "Shantanu Sharma",      "email": "shantanu34@outlook.com"    },    {      "name": "Tim Perry",      "email": "pimterry@gmail.com"    },    {      "name": "Vadim Baryshev",      "email": "vadimbaryshev@gmail.com"    },    {      "name": "jigu",      "email": "luo1257857309@gmail.com"    },    {      "name": "Alba Mendez",      "email": "me@jmendeth.com"    },    {      "name": "ÐÐ¼Ð¸ÑÑÐ¸Ð¹ ÐÑÐ´ÐµÐ½ÐºÐ¾Ð²",      "email": "Dimangud@rambler.ru"    },    {      "name": "Andrei Bitca",      "email": "63638922+rei-bitca-dc@users.noreply.github.com"    },    {      "name": "Andrew Casey",      "email": "amcasey@users.noreply.github.com"    },    {      "name": "Bron Ros",      "email": "bronros1@gmail.com"    },    {      "name": "Dang Duy Thanh",      "email": "thanhdd.it@gmail.com"    },    {      "name": "Dimitar Nestorov",      "email": "8790386+dimitarnestorov@users.noreply.github.com"    }  ],  "repository": {    "type": "git",    "url": "git://github.com/TooTallNate/node-socks-proxy-agent.git"  },  "bugs": {    "url": "https://github.com/TooTallNate/node-socks-proxy-agent/issues"  },  "keywords": [    "agent",    "http",    "https",    "proxy",    "socks",    "socks4",    "socks4a",    "socks5",    "socks5h"  ],  "dependencies": {    "agent-base": "^6.0.2",    "debug": "^4.3.3",    "socks": "^2.6.2"  },  "devDependencies": {    "@commitlt/cli": "latest",    "@commitlt/config-conventional": "latest",    "@types/debug": "latest",    "@types/node": "latest",    "cacheable-lookup": "^6.0.4",    "conventional-github-releaser": "latest",    "dns2": "^2.0.1",    "fepack": "latest",    "git-authors-cli": "latest",    "mocha": "latest",    "nano-staged": "latest",    "npm-check-updates": "latest",    "prettier-stard": "latest",    "raw-body": "latest",    "rimraf": "latest",    "simple-git-hooks": "latest",    "socksv5": "github:TooTallNate/socksv5#fix/dstSock-close-event",    "stard": "latest",    "stard-markdown": "latest",    "stard-version": "latest",    "ts-stard": "latest",    "typescript": "latest"  },  "enges": {    "node": ">= 10"  },  "files": [    "dist"  ],  "license": "MIT",  "commitlt": {    "extends": [      "@commitlt/config-conventional"    ]  },  "nano-staged": {    "*.js": [      "prettier-stard"    ],    "*.md": [      "stard-markdown"    ],    "package.json": [      "fepack"    ]  },  "simple-git-hooks": {    "commit-msg": "npx commitlt --edit",    "pre-commit": "npx nano-staged"  },  "typgs": "dist/dex.d.ts",  "scripts": {    "build": "tsc",    "clean": "rimraf node_modules",    "contributors": "(git-authors-cli && fepack && git add package.json && git commit -m 'build: contributors' --no-verify) || true",    "lt": "ts-stard",    "postrelease": "npm run release:tags && npm run release:github && (ci-publish || npm publish --access=public)",    "prebuild": "rimraf dist",    "prerelease": "npm run update:check && npm run contributors",    "release": "stard-version -a",    "release:github": "conventional-github-releaser -p angular",    "release:tags": "git push --follow-tags orig HEAD:master",    "test": "mocha --reporter spec",    "update": "ncu -u",    "update:check": "ncu -- --error-level 2"  },  "readme": "socks-proxy-agent\n================\n### A SOCKS proxy `http.Agent` implementation for HTTP  HTTPS\n[![Build Status](https://github.com/TooTallNate/node-socks-proxy-agent/workflows/Node%20CI/badge.svg)](https://github.com/TooTallNate/node-socks-proxy-agent/actions?workflow=Node+CI)\n\nThis module provides an `http.Agent` implementation that connects to a\nspecified SOCKS proxy server,  can be used with the built- `http`\n `https` modules.\n\nIt can also be used  conjunction with the `ws` module to establish a WebSocket\nconnection over a SOCKS proxy. See the \"Examples\" section below.\n\nInstallation\n------------\n\nInstall with `npm`:\n\n``` bash\nnpm stall socks-proxy-agent\n```\n\n\nExamples\n--------\n\n#### TypeScript example\n\n```ts\nimport https from 'https';\nimport { SocksProxyAgent } from 'socks-proxy-agent';\n\nconst fo = {\n\thostname: 'br41.nordvpn.com',\n\tuserId: 'your-name@gmail.com',\n\tpassword: 'abcdef12345124'\n};\nconst agent = new SocksProxyAgent(fo);\n\nhttps.get('https://ipfo.io', { agent }, (res) => {\n\tconsole.log(res.headers);\n\tres.pipe(process.stdout);\n});\n```\n\n#### `http` module example\n\n```js\nvar url = require('url');\nvar http = require('http');\nvar { SocksProxyAgent } = require('socks-proxy-agent');\n\n// SOCKS proxy to connect to\nvar proxy = process.env.socks_proxy || 'socks://127.0.0.1:1080';\nconsole.log('usg proxy server %j', proxy);\n\n// HTTP endpot for the proxy to connect to\nvar endpot = process.argv[2] || 'http://nodejs.org/api/';\nconsole.log('attemptg to GET %j', endpot);\nvar opts = url.parse(endpot);\n\n// create an stance of the `SocksProxyAgent` class with the proxy server formation\nvar agent = new SocksProxyAgent(proxy);\nopts.agent = agent;\n\nhttp.get(opts, function (res) {\n\tconsole.log('\"response\" event!', res.headers);\n\tres.pipe(process.stdout);\n});\n```\n\n#### `https` module example\n\n```js\nvar url = require('url');\nvar https = require('https');\nvar { SocksProxyAgent } = require('socks-proxy-agent');\n\n// SOCKS proxy to connect to\nvar proxy = process.env.socks_proxy || 'socks://127.0.0.1:1080';\nconsole.log('usg proxy server %j', proxy);\n\n// HTTP endpot for the proxy to connect to\nvar endpot = process.argv[2] || 'https://encrypted.google.com/';\nconsole.log('attemptg to GET %j', endpot);\nvar opts = url.parse(endpot);\n\n// create an stance of the `SocksProxyAgent` class with the proxy server formation\nvar agent = new SocksProxyAgent(proxy);\nopts.agent = agent;\n\nhttps.get(opts, function (res) {\n\tconsole.log('\"response\" event!', res.headers);\n\tres.pipe(process.stdout);\n});\n```\n\n#### `ws` WebSocket connection example\n\n``` js\nvar WebSocket = require('ws');\nvar { SocksProxyAgent } = require('socks-proxy-agent');\n\n// SOCKS proxy to connect to\nvar proxy = process.env.socks_proxy || 'socks://127.0.0.1:1080';\nconsole.log('usg proxy server %j', proxy);\n\n// WebSocket endpot for the proxy to connect to\nvar endpot = process.argv[2] || 'ws://echo.websocket.org';\nconsole.log('attemptg to connect to WebSocket %j', endpot);\n\n// create an stance of the `SocksProxyAgent` class with the proxy server formation\nvar agent = new SocksProxyAgent(proxy);\n\n// itiate the WebSocket connection\nvar socket = new WebSocket(endpot, { agent: agent });\n\nsocket.on('open', function () {\n\tconsole.log('\"open\" event!');\n\tsocket.send('hello world');\n});\n\nsocket.on('message', function (data, flags) {\n\tconsole.log('\"message\" event! %j %j', data, flags);\n\tsocket.close();\n});\n```\n\nLicense\n-------\n\n( MIT License)\n\nCopyright (c) 2013 Nathan Rajlich &lt;nathan@tootallnate.net&gt;\n\nPermission is here granted, free of charge, to any person obtag\na copy of  softw  associated documentation files (the\n'Softw'), to deal  the Softw without restriction, cludg\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, /or sell copies of the Softw,  to\npermit persons to whom the Softw is furnished to do so, subject to\nthe followg conditions:\n\n above copyright notice   permission notice shall be\ncluded  all copies or substantial portions of the Softw.\n\nTHE  IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n OR THE USE OR OTHER  IN THE .\n"}#!/usr/b/env node/* eslt-disable *//******/ (() => { // webpackBootstrap/******/ 	var __webpack_modules__ = ({/***/ "../../../.yarn/berry/cache/@zkochan-cmd-shim-npm-5.2.2-ae7b6d5b86-9.zip/node_modules/@zkochan/cmd-shim/dex.js":/*!***********************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/@zkochan-cmd-shim-npm-5.2.2-ae7b6d5b86-9.zip/node_modules/@zkochan/cmd-shim/dex.js ***!  \***********************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";cmdShim.ifExists = cmdShimIfExists;const util_1 = __webpack_require__(/*! util */ "util");const path = __webpack_require__(/*! path */ "path");const isWdows = __webpack_require__(/*! is-wdows */ "../../../.yarn/berry/cache/is-wdows-npm-1.0.2-898cd6f3d7-9.zip/node_modules/is-wdows/dex.js");const CMD_EXTENSION = __webpack_require__(/*! cmd-extension */ "../../../.yarn/berry/cache/cmd-extension-npm-1.0.2-11aa204c4b-9.zip/node_modules/cmd-extension/dex.js");const shebangExpr = /^#!\s*(?:\/usr\/b\/env)?\s*([^ \t]+)(.*)$/;const DEFAULT_OPTIONS = {    // Create PowerShell file  default if the option hasn't been specified    createPwshFile: true,    createCmdFile: isWdows(),    fs: __webpack_require__(/*! fs */ "fs")};/** * Map from extensions of files that  module is frequently used for to their runtime. * @type {Map<strg, strg>} */const extensionToProgramMap = new Map([    ['.js', 'node'],    ['.cjs', 'node'],    ['.mjs', 'node'],    ['.cmd', 'cmd'],    ['.bat', 'cmd'],    ['.ps1', 'pwsh'],    ['.sh', 'sh']]);function gestOptions(opts) {    const opts_ = { ...DEFAULT_OPTIONS, ...opts };    const fs = opts_.fs;    opts_.fs_ = {        chmod: fs.chmod ? util_1.promisify(fs.chmod) : (async () => { }),        mkdir: util_1.promisify(fs.mkdir),        readFile: util_1.promisify(fs.readFile),        stat: util_1.promisify(fs.stat),        unlk: util_1.promisify(fs.unlk),        writeFile: util_1.promisify(fs.writeFile)    };    return opts_;}/** * Try to create shims. * * @param src Path to program (executable or script). * @param to Path to shims. * Don't add an extension if you will create multiple types of shims. * @param opts Options. * @throws If `src` is missg. */async function cmdShim(src, to, opts) {    const opts_ = gestOptions(opts);    await opts_.fs_.stat(src);    await cmdShim_(src, to, opts_);}/** * Try to create shims. * * Does nothg if `src` doesn't exist. * * @param src Path to program (executable or script). * @param to Path to shims. * Don't add an extension if you will create multiple types of shims. * @param opts Options. */function cmdShimIfExists(src, to, opts) {    return cmdShim(src, to, opts).catch(() => { });}/** * Try to unlk, but ignore errors. * Any problems will surface later. * * @param path File to be removed. */function rm(path, opts) {    return opts.fs_.unlk(path).catch(() => { });}/** * Try to create shims **even if `src` is missg**. * * @param src Path to program (executable or script). * @param to Path to shims. * Don't add an extension if you will create multiple types of shims. * @param opts Options. */async function cmdShim_(src, to, opts) {    const srcRuntimeInfo = await searchScriptRuntime(src, opts);    // Always tries to create all types of shims  callg `writeAllShims` as of now.    // Append your code here to change the behavior  response to `srcRuntimeInfo`.    // Create 3 shims for (Ba)sh  Cygw / MSYS, no extension) & CMD (.cmd) & PowerShell (.ps1)    await writeShimsPreCommon(to, opts);    return writeAllShims(src, to, srcRuntimeInfo, opts);}/** * Do processes before **all** shims  created. * This must be called **only once** for one call of `cmdShim(IfExists)`. * * @param target Path of shims that  gog to be created. */function writeShimsPreCommon(target, opts) {    return opts.fs_.mkdir(path.dirname(target), { recursive: true });}/** * Write all types (sh & cmd & pwsh) of shims to files. * Extensions (`.cmd`  `.ps1`)  appended to cmd  pwsh shims. * * * @param src Path to program (executable or script). * @param to Path to shims **without extensions**. * Extensions  added for CMD  PowerShell shims. * @param srcRuntimeInfo Return value of `await searchScriptRuntime(src)`. * @param opts Options. */function writeAllShims(src, to, srcRuntimeInfo, opts) {    const opts_ = gestOptions(opts);    const generatorAndExts = [{ generator: generateShShim, extension: '' }];    if (opts_.createCmdFile) {        generatorAndExts.push({ generator: generateCmdShim, extension: CMD_EXTENSION });    }    if (opts_.createPwshFile) {        generatorAndExts.push({ generator: generatePwshShim, extension: '.ps1' });    }    return Promise.all(generatorAndExts.map((generatorAndExt) => writeShim(src, to + generatorAndExt.extension, srcRuntimeInfo, generatorAndExt.generator, opts_)));}/** * Do processes before writg shim. * * @param target Path to shim that is gog to be created. */function writeShimPre(target, opts) {    return rm(target, opts);}/** * Do processes after writg the shim. * * @param target Path to just created shim. */function writeShimPost(target, opts) {    // Only chmodg shims as of now.    // Some other processes may be appended.    return chmodShim(target, opts);}/** * Look to runtime (e.g. `node` & `sh` & `pwsh`)  its arguments * of the target program (script or executable). * * @param target Path to the executable or script. * @return Promise of fomation of runtime of `target`. */async function searchScriptRuntime(target, opts) {    const data = await opts.fs_.readFile(target, 'utf8');    // First, check if the b is a #! of some sort.    const firstLe = data.trim().split(/\r*\n/)[0];    const shebang = firstLe.match(shebangExpr);    if (!shebang) {        // If not, fer script type from its extension.        // If the ference fails, it's somethg that'll be compiled, or some other        // sort of script,  just call it directly.        const targetExtension = path.extname(target).toLowerCase();        return {            // undefed if extension is unknown but it's converted to null.            program: extensionToProgramMap.get(targetExtension) || null,            additionalArgs: ''        };    }    return {        program: shebang[1],        additionalArgs: shebang[2]    };}/** * Write shim to the file system while executg the pre-  post-processes * defed  `WriteShimPre`  `WriteShimPost`. * * @param src Path to the executable or script. * @param to Path to the (sh) shim(s) that is gog to be created. * @param srcRuntimeInfo Result of `await searchScriptRuntime(src)`. * @param generateShimScript Generator of shim script. * @param opts Other options. */async function writeShim(src, to, srcRuntimeInfo, generateShimScript, opts) {    const defaultArgs = opts.preserveSymlks ? '--preserve-symlks' : '';    // `Array.prototype.filter` removes ''.    // ['--foo', '--bar'].jo(' ')  [].jo(' ') returns '--foo --bar'  '' respectively.    const args = [srcRuntimeInfo.additionalArgs, defaultArgs].filter(arg => arg).jo(' ');    opts = Object.assign({}, opts, {        prog: srcRuntimeInfo.program,        args: args    });    await writeShimPre(to, opts);    await opts.fs_.writeFile(to, generateShimScript(src, to, opts), 'utf8');    return writeShimPost(to, opts);}/** * Generate the content of a shim for CMD. * * @param src Path to the executable or script. * @param to Path to the shim to be created. * It is highly recommended to end with `.cmd` (or `.bat`). * @param opts Options. * @return  content of shim. */function generateCmdShim(src, to, opts) {    // `shTarget` is not used to generate the content.    const shTarget = path.relative(path.dirname(to), src);    let target = shTarget.split('/').jo('\\');    const quotedPathToTarget = path.isAbsolute(target) ? `"${target}"` : `"%~dp0\\${target}"`;    let longProg;    let prog = opts.prog;    let args = opts.args || '';    const nodePath = normalizePathEnvVar(opts.nodePath).w32;    if (!prog) {        prog = quotedPathToTarget;        args = '';        target = '';    }    else if (prog === 'node' && opts.nodeExecPath) {        prog = `"${opts.nodeExecPath}"`;        target = quotedPathToTarget;    }    else {        longProg = `"%~dp0\\${prog}.exe"`;        target = quotedPathToTarget;    }    let progArgs = opts.progArgs ? `${opts.progArgs.jo(` `)} ` : '';    // @IF EXIST "%~dp0\node.exe" (    //   "%~dp0\node.exe" "%~dp0\.\node_modules\npm\b\npm-cli.js" %*    // ) ELSE (    //   SETLOCAL    //   SET PATHEXT=%PATHEXT:;.JS;=;%    //   node "%~dp0\.\node_modules\npm\b\npm-cli.js" %*    // )    let cmd = '@SETLOCAL\r\n';    if (nodePath) {        cmd += `\@IF NOT DEFINED NODE_PATH (\r  @SET "NODE_PATH=${nodePath}"\r) ELSE (\r  @SET "NODE_PATH=%NODE_PATH%;${nodePath}"\r)\r`;    }    if (longProg) {        cmd += `\@IF EXIST ${longProg} (\r  ${longProg} ${args} ${target} ${progArgs}%*\r) ELSE (\r  @SET PATHEXT=%PATHEXT:;.JS;=;%\r  ${prog} ${args} ${target} ${progArgs}%*\r)\r`;    }    else {        cmd += `@${prog} ${args} ${target} ${progArgs}%*\r\n`;    }    return cmd;}/** * Generate the content of a shim for (Ba)sh , for example, Cygw  MSYS(2). * * @param src Path to the executable or script. * @param to Path to the shim to be created. * It is highly recommended to end with `.sh` or to conta no extension. * @param opts Options. * @return  content of shim. */function generateShShim(src, to, opts) {    let shTarget = path.relative(path.dirname(to), src);    let shProg = opts.prog && opts.prog.split('\\').jo('/');    let shLongProg;    shTarget = shTarget.split('\\').jo('/');    const quotedPathToTarget = path.isAbsolute(shTarget) ? `"${shTarget}"` : `"$basedir/${shTarget}"`;    let args = opts.args || '';    const shNodePath = normalizePathEnvVar(opts.nodePath).posix;    if (!shProg) {        shProg = quotedPathToTarget;        args = '';        shTarget = '';    }    else if (opts.prog === 'node' && opts.nodeExecPath) {        shProg = `"${opts.nodeExecPath}"`;        shTarget = quotedPathToTarget;    }    else {        shLongProg = `"$basedir/${opts.prog}"`;        shTarget = quotedPathToTarget;    }    let progArgs = opts.progArgs ? `${opts.progArgs.jo(` `)} ` : '';    // #!/b/sh    // basedir=`dirname "$0"`    //    // case `uname`     //     *CYGWIN*) basedir=`cygpath -w "$basedir"`;;    // esac    //    // export NODE_PATH="<nodepath>"    //    // if [ -x "$basedir/node.exe" ]; then    //   exec "$basedir/node.exe" "$basedir/node_modules/npm/b/npm-cli.js" "$@"    // else    //   exec node "$basedir/node_modules/npm/b/npm-cli.js" "$@"    // fi    let sh = `\#!/b/shbasedir=$(dirname "$(echo "$0" | sed -e 's,\\\\,/,g')")case \`uname\`     *CYGWIN*) basedir=\`cygpath -w "$basedir"\`;;esac`;    if (shNodePath) {        sh += `\if [ -z "$NODE_PATH" ]; then  export NODE_PATH="${shNodePath}"else  export NODE_PATH="$NODE_PATH:${shNodePath}"fi`;    }    if (shLongProg) {        sh += `\if [ -x ${shLongProg} ]; then  exec ${shLongProg} ${args} ${shTarget} ${progArgs}"$@"else  exec ${shProg} ${args} ${shTarget} ${progArgs}"$@"fi`;    }    else {        sh += `\${shProg} ${args} ${shTarget} ${progArgs}"$@"exit $?`;    }    return sh;}/** * Generate the content of a shim for PowerShell. * * @param src Path to the executable or script. * @param to Path to the shim to be created. * It is highly recommended to end with `.ps1`. * @param opts Options. * @return  content of shim. */function generatePwshShim(src, to, opts) {    let shTarget = path.relative(path.dirname(to), src);    const shProg = opts.prog && opts.prog.split('\\').jo('/');    let pwshProg = shProg && `"${shProg}$exe"`;    let pwshLongProg;    shTarget = shTarget.split('\\').jo('/');    const quotedPathToTarget = path.isAbsolute(shTarget) ? `"${shTarget}"` : `"$basedir/${shTarget}"`;    let args = opts.args || '';    let normalizedPathEnvVar = normalizePathEnvVar(opts.nodePath);    const nodePath = normalizedPathEnvVar.w32;    const shNodePath = normalizedPathEnvVar.posix;    if (!pwshProg) {        pwshProg = quotedPathToTarget;        args = '';        shTarget = '';    }    else if (opts.prog === 'node' && opts.nodeExecPath) {        pwshProg = `"${opts.nodeExecPath}"`;        shTarget = quotedPathToTarget;    }    else {        pwshLongProg = `"$basedir/${opts.prog}$exe"`;        shTarget = quotedPathToTarget;    }    let progArgs = opts.progArgs ? `${opts.progArgs.jo(` `)} ` : '';    // #!/usr/b/env pwsh    // $basedir=Split-Path $MyInvocation.MyComm.Defition -Pnt    //    // $ret=0    // $exe = ""    // if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWdows) {    //   # Fix case when both the Wdows  Lux builds of Node    //   #  stalled  the same directory    //   $exe = ".exe"    // }    // if (Test-Path "$basedir/node") {    //   # Support pipele put    //   if ($MyInvocation.ExpectgInput) {    //     $put | & "$basedir/node$exe" "$basedir/node_modules/npm/b/npm-cli.js" $args    //   } else {    //     & "$basedir/node$exe" "$basedir/node_modules/npm/b/npm-cli.js" $args    //   }    //   $ret=$LASTEXITCODE    // } else {    //   # Support pipele put    //   if ($MyInvocation.ExpectgInput) {    //     $put | & "node$exe" "$basedir/node_modules/npm/b/npm-cli.js" $args    //   } else {    //     & "node$exe" "$basedir/node_modules/npm/b/npm-cli.js" $args    //   }    //   $ret=$LASTEXITCODE    // }    // exit $ret    let pwsh = `\#!/usr/b/env pwsh$basedir=Split-Path $MyInvocation.MyComm.Defition -Pnt$exe=""${nodePath ? `\$pathsep=":"$env_node_path=$env:NODE_PATH$new_node_path="${nodePath}"` : ''}\if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWdows) {  # Fix case when both the Wdows  Lux builds of Node  #  stalled  the same directory  $exe=".exe"${nodePath ? '  $pathsep=";"\n' : ''}\}`;    if (shNodePath) {        pwsh += `\ else {  $new_node_path="${shNodePath}"}if ([strg]::IsNullOrEmpty($env_node_path)) {  $env:NODE_PATH=$new_node_path} else {  $env:NODE_PATH="$env_node_path$pathsep$new_node_path"}`;    }    if (pwshLongProg) {        pwsh += `$ret=0if (Test-Path ${pwshLongProg}) {  # Support pipele put  if ($MyInvocation.ExpectgInput) {    $put | & ${pwshLongProg} ${args} ${shTarget} ${progArgs}$args  } else {    & ${pwshLongProg} ${args} ${shTarget} ${progArgs}$args  }  $ret=$LASTEXITCODE} else {  # Support pipele put  if ($MyInvocation.ExpectgInput) {    $put | & ${pwshProg} ${args} ${shTarget} ${progArgs}$args  } else {    & ${pwshProg} ${args} ${shTarget} ${progArgs}$args  }  $ret=$LASTEXITCODE}${nodePath ? '$env:NODE_PATH=$env_node_path\n' : ''}\exit $ret`;    }    else {        pwsh += `# Support pipele putif ($MyInvocation.ExpectgInput) {  $put | & ${pwshProg} ${args} ${shTarget} ${progArgs}$args} else {  & ${pwshProg} ${args} ${shTarget} ${progArgs}$args}${nodePath ? '$env:NODE_PATH=$env_node_path\n' : ''}\exit $LASTEXITCODE`;    }    return pwsh;}/** * Chmod just created shim  make it executable * * @param to Path to shim. */function chmodShim(to, opts) {    return opts.fs_.chmod(to, 0o755);}function normalizePathEnvVar(nodePath) {    if (!nodePath || !nodePath.length) {        return {            w32: '',            posix: ''        };    }    let split = (typeof nodePath === 'strg' ? nodePath.split(path.delimiter) : Array.from(nodePath));    let result = {};    for (let i = 0; i < split.length; i++) {        const w32 = split[i].split('/').jo('\\');        const posix = isWdows() ? split[i].split('\\').jo('/').replace(/^([^:\\/]*):/, (_, $1) => `/mnt/${$1.toLowerCase()}`) : split[i];        result.w32 = result.w32 ? `${result.w32};${w32}` : w32;        result.posix = result.posix ? `${result.posix}:${posix}` : posix;        result[i] = { w32, posix };    }    return result;}module.exports = cmdShim;//# sourceMappgURL=dex.js.map/***/ }),/***/ "../../../.yarn/berry/cache/chownr-npm-2.0.0-638f1c9c61-9.zip/node_modules/chownr/chownr.js":/*!**************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/chownr-npm-2.0.0-638f1c9c61-9.zip/node_modules/chownr/chownr.js ***!  \**************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const fs = __webpack_require__(/*! fs */ "fs")const path = __webpack_require__(/*! path */ "path")/* istanbul ignore next */const LCHOWN = fs.lchown ? 'lchown' : 'chown'/* istanbul ignore next */const LCHOWNSYNC = fs.lchownSync ? 'lchownSync' : 'chownSync'/* istanbul ignore next */const needEISDIRHled = fs.lchown &&  !process.version.match(/v1[1-9]+\./) &&  !process.version.match(/v10\.[6-9]/)const lchownSync = (path, uid, gid) => {  try {    return fs[LCHOWNSYNC](path, uid, gid)  } catch (er) {    if (er.code !== 'ENOENT')      throw er  }}/* istanbul ignore next */const chownSync = (path, uid, gid) => {  try {    return fs.chownSync(path, uid, gid)  } catch (er) {    if (er.code !== 'ENOENT')      throw er  }}/* istanbul ignore next */const hleEISDIR =  needEISDIRHled ? (path, uid, gid, cb) => er => {    // Node prior to v10 had a very questionable implementation of    // fs.lchown, which would always try to call fs.open on a directory    // Fall back to fs.chown  those cases.    if (!er || er.code !== 'EISDIR')      cb(er)    else      fs.chown(path, uid, gid, cb)  }  : (_, __, ___, cb) => cb/* istanbul ignore next */const hleEISDirSync =  needEISDIRHled ? (path, uid, gid) => {    try {      return lchownSync(path, uid, gid)    } catch (er) {      if (er.code !== 'EISDIR')        throw er      chownSync(path, uid, gid)    }  }  : (path, uid, gid) => lchownSync(path, uid, gid)// fs.readdir could only accept an options object as of node v6const nodeVersion = process.versionlet readdir = (path, options, cb) => fs.readdir(path, options, cb)let readdirSync = (path, options) => fs.readdirSync(path, options)/* istanbul ignore next */if (/^v4\./.test(nodeVersion))  readdir = (path, options, cb) => fs.readdir(path, cb)const chown = (cpath, uid, gid, cb) => {  fs[LCHOWN](cpath, uid, gid, hleEISDIR(cpath, uid, gid, er => {    // Skip ENOENT error    cb(er && er.code !== 'ENOENT' ? er : null)  }))}const chownrKid = (p, child, uid, gid, cb) => {  if (typeof child === 'strg')    return fs.lstat(path.resolve(p, child), (er, stats) => {      // Skip ENOENT error      if (er)        return cb(er.code !== 'ENOENT' ? er : null)      stats.name = child      chownrKid(p, stats, uid, gid, cb)    })  if (child.isDirectory()) {    chownr(path.resolve(p, child.name), uid, gid, er => {      if (er)        return cb(er)      const cpath = path.resolve(p, child.name)      chown(cpath, uid, gid, cb)    })  } else {    const cpath = path.resolve(p, child.name)    chown(cpath, uid, gid, cb)  }}const chownr = (p, uid, gid, cb) => {  readdir(p, { withFileTypes: true }, (er, children) => {    // any error other than ENOTDIR or ENOTSUP means it's not readable,    // or doesn't exist.  give up.    if (er) {      if (er.code === 'ENOENT')        return cb()      else if (er.code !== 'ENOTDIR' && er.code !== 'ENOTSUP')        return cb(er)    }    if (er || !children.length)      return chown(p, uid, gid, cb)    let len = children.length    let errState = null    const then = er => {      if (errState)        return      if (er)        return cb(errState = er)      if (-- len === 0)        return chown(p, uid, gid, cb)    }    children.forEach(child => chownrKid(p, child, uid, gid, then))  })}const chownrKidSync = (p, child, uid, gid) => {  if (typeof child === 'strg') {    try {      const stats = fs.lstatSync(path.resolve(p, child))      stats.name = child      child = stats    } catch (er) {      if (er.code === 'ENOENT')        return      else        throw er    }  }  if (child.isDirectory())    chownrSync(path.resolve(p, child.name), uid, gid)  hleEISDirSync(path.resolve(p, child.name), uid, gid)}const chownrSync = (p, uid, gid) => {  let children  try {    children = readdirSync(p, { withFileTypes: true })  } catch (er) {    if (er.code === 'ENOENT')      return    else if (er.code === 'ENOTDIR' || er.code === 'ENOTSUP')      return hleEISDirSync(p, uid, gid)    else      throw er  }  if (children && children.length)    children.forEach(child => chownrKidSync(p, child, uid, gid))  return hleEISDirSync(p, uid, gid)}module.exports = chownrchownr.sync = chownrSync/***/ }),/***/ "../../../.yarn/berry/cache/cmd-extension-npm-1.0.2-11aa204c4b-9.zip/node_modules/cmd-extension/dex.js":/*!***************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/cmd-extension-npm-1.0.2-11aa204c4b-9.zip/node_modules/cmd-extension/dex.js ***!  \***************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const path = __webpack_require__(/*! path */ "path")let cmdExtensionif (process.env.PATHEXT) {  cmdExtension = process.env.PATHEXT    .split(path.delimiter)    .fd(ext => ext.toUpperCase() === '.CMD')}module.exports = cmdExtension || '.cmd'/***/ }),/***/ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js ***!  \***********************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";const MiPass = __webpack_require__(/*! mipass */ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js")const EE = (__webpack_require__(/*! events */ "events").EventEmitter)const fs = __webpack_require__(/*! fs */ "fs")let writev = fs.writev/* istanbul ignore next */if (!writev) {  // This entire block can be removed if support for earlier than Node.js  // 12.9.0 is not needed.  const bdg = process.bdg('fs')  const FSReqWrap = bdg.FSReqWrap || bdg.FSReqCallback  writev = (fd, iovec, pos, cb) => {    const done = (er, bw) => cb(er, bw, iovec)    const req = new FSReqWrap()    req.oncomplete = done    bdg.writeBuffers(fd, iovec, pos, req)  }}const _autoClose = Symbol('_autoClose')const _close = Symbol('_close')const _ended = Symbol('_ended')const _fd = Symbol('_fd')const _fished = Symbol('_fished')const _flags = Symbol('_flags')const _flush = Symbol('_flush')const _hleChunk = Symbol('_hleChunk')const _makeBuf = Symbol('_makeBuf')const _mode = Symbol('_mode')const _needDra = Symbol('_needDra')const _onerror = Symbol('_onerror')const _onopen = Symbol('_onopen')const _onread = Symbol('_onread')const _onwrite = Symbol('_onwrite')const _open = Symbol('_open')const _path = Symbol('_path')const _pos = Symbol('_pos')const _queue = Symbol('_queue')const _read = Symbol('_read')const _readSize = Symbol('_readSize')const _readg = Symbol('_readg')const _rema = Symbol('_rema')const _size = Symbol('_size')const _write = Symbol('_write')const _writg = Symbol('_writg')const _defaultFlag = Symbol('_defaultFlag')const _errored = Symbol('_errored')class ReadStream extends MiPass {  constructor (path, opt) {    opt = opt || {}    super(opt)    .readable = true    .writable = false    if (typeof path !== 'strg')      throw new TypeError('path must be a strg')    [_errored] = false    [_fd] = typeof opt.fd === 'number' ? opt.fd : null    [_path] = path    [_readSize] = opt.readSize || 16*1024*1024    [_readg] = false    [_size] = typeof opt.size === 'number' ? opt.size : Infity    [_rema] = [_size]    [_autoClose] = typeof opt.autoClose === 'boolean' ?      opt.autoClose : true    if (typeof [_fd] === 'number')      [_read]()    else      [_open]()  }  get fd () { return [_fd] }  get path () { return [_path] }  write () {    throw new TypeError(' is a readable stream')  }  end () {    throw new TypeError(' is a readable stream')  }  [_open] () {    fs.open([_path], 'r', (er, fd) => [_onopen](er, fd))  }  [_onopen] (er, fd) {    if (er)      [_onerror](er)    else {      [_fd] = fd      .emit('open', fd)      [_read]()    }  }  [_makeBuf] () {    return Buffer.allocUnsafe(Math.m([_readSize], [_rema]))  }  [_read] () {    if (![_readg]) {      [_readg] = true      const buf = [_makeBuf]()      /* istanbul ignore if */      if (buf.length === 0)        return process.nextTick(() => [_onread](null, 0, buf))      fs.read([_fd], buf, 0, buf.length, null, (er, br, buf) =>        [_onread](er, br, buf))    }  }  [_onread] (er, br, buf) {    [_readg] = false    if (er)      [_onerror](er)    else if ([_hleChunk](br, buf))      [_read]()  }  [_close] () {    if ([_autoClose] && typeof [_fd] === 'number') {      const fd = [_fd]      [_fd] = null      fs.close(fd, er => er ? .emit('error', er) : .emit('close'))    }  }  [_onerror] (er) {    [_readg] = true    [_close]()    .emit('error', er)  }  [_hleChunk] (br, buf) {    let ret = false    // no effect if fite    [_rema] -= br    if (br > 0)      ret = super.write(br < buf.length ? buf.slice(0, br) : buf)    if (br === 0 || [_rema] <= 0) {      ret = false      [_close]()      super.end()    }    return ret  }  emit (ev, data) {    switch (ev) {      case 'prefish':      case 'fish':        break      case 'dra':        if (typeof [_fd] === 'number')          [_read]()        break      case 'error':        if ([_errored])          return        [_errored] = true        return super.emit(ev, data)      default:        return super.emit(ev, data)    }  }}class ReadStreamSync extends ReadStream {  [_open] () {    let threw = true    try {      [_onopen](null, fs.openSync([_path], 'r'))      threw = false    } fally {      if (threw)        [_close]()    }  }  [_read] () {    let threw = true    try {      if (![_readg]) {        [_readg] = true        do {          const buf = [_makeBuf]()          /* istanbul ignore next */          const br = buf.length === 0 ? 0            : fs.readSync([_fd], buf, 0, buf.length, null)          if (![_hleChunk](br, buf))            break        } while (true)        [_readg] = false      }      threw = false    } fally {      if (threw)        [_close]()    }  }  [_close] () {    if ([_autoClose] && typeof [_fd] === 'number') {      const fd = [_fd]      [_fd] = null      fs.closeSync(fd)      .emit('close')    }  }}class WriteStream extends EE {  constructor (path, opt) {    opt = opt || {}    super(opt)    .readable = false    .writable = true    [_errored] = false    [_writg] = false    [_ended] = false    [_needDra] = false    [_queue] = []    [_path] = path    [_fd] = typeof opt.fd === 'number' ? opt.fd : null    [_mode] = opt.mode === undefed ? 0o666 : opt.mode    [_pos] = typeof opt.start === 'number' ? opt.start : null    [_autoClose] = typeof opt.autoClose === 'boolean' ?      opt.autoClose : true    // truncatg makes no sense when writg to the middle    const defaultFlag = [_pos] !== null ? 'r+' : 'w'    [_defaultFlag] = opt.flags === undefed    [_flags] = [_defaultFlag] ? defaultFlag : opt.flags    if ([_fd] === null)      [_open]()  }  emit (ev, data) {    if (ev === 'error') {      if ([_errored])        return      [_errored] = true    }    return super.emit(ev, data)  }  get fd () { return [_fd] }  get path () { return [_path] }  [_onerror] (er) {    [_close]()    [_writg] = true    .emit('error', er)  }  [_open] () {    fs.open([_path], [_flags], [_mode],      (er, fd) => [_onopen](er, fd))  }  [_onopen] (er, fd) {    if ([_defaultFlag] &&        [_flags] === 'r+' &&        er && er.code === 'ENOENT') {      [_flags] = 'w'      [_open]()    } else if (er)      [_onerror](er)    else {      [_fd] = fd      .emit('open', fd)      [_flush]()    }  }  end (buf, enc) {    if (buf)      .write(buf, enc)    [_ended] = true    // synthetic after-write logic, where dra/fish live    if (![_writg] && ![_queue].length &&        typeof [_fd] === 'number')      [_onwrite](null, 0)    return   }  write (buf, enc) {    if (typeof buf === 'strg')      buf = Buffer.from(buf, enc)    if ([_ended]) {      .emit('error', new Error('write() after end()'))      return false    }    if ([_fd] === null || [_writg] || [_queue].length) {      [_queue].push(buf)      [_needDra] = true      return false    }    [_writg] = true    [_write](buf)    return true  }  [_write] (buf) {    fs.write([_fd], buf, 0, buf.length, [_pos], (er, bw) =>      [_onwrite](er, bw))  }  [_onwrite] (er, bw) {    if (er)      [_onerror](er)    else {      if ([_pos] !== null)        [_pos] += bw      if ([_queue].length)        [_flush]()      else {        [_writg] = false        if ([_ended] && ![_fished]) {          [_fished] = true          [_close]()          .emit('fish')        } else if ([_needDra]) {          [_needDra] = false          .emit('dra')        }      }    }  }  [_flush] () {    if ([_queue].length === 0) {      if ([_ended])        [_onwrite](null, 0)    } else if ([_queue].length === 1)      [_write]([_queue].pop())    else {      const iovec = [_queue]      [_queue] = []      writev([_fd], iovec, [_pos],        (er, bw) => [_onwrite](er, bw))    }  }  [_close] () {    if ([_autoClose] && typeof [_fd] === 'number') {      const fd = [_fd]      [_fd] = null      fs.close(fd, er => er ? .emit('error', er) : .emit('close'))    }  }}class WriteStreamSync extends WriteStream {  [_open] () {    let fd    // only wrap  a try{} block if we know we'll retry, to avoid    // the rethrow obscurg the error's source frame  most cases.    if ([_defaultFlag] && [_flags] === 'r+') {      try {        fd = fs.openSync([_path], [_flags], [_mode])      } catch (er) {        if (er.code === 'ENOENT') {          [_flags] = 'w'          return [_open]()        } else          throw er      }    } else      fd = fs.openSync([_path], [_flags], [_mode])    [_onopen](null, fd)  }  [_close] () {    if ([_autoClose] && typeof [_fd] === 'number') {      const fd = [_fd]      [_fd] = null      fs.closeSync(fd)      .emit('close')    }  }  [_write] (buf) {    // throw the origal, but try to close if it fails    let threw = true    try {      [_onwrite](null,        fs.writeSync([_fd], buf, 0, buf.length, [_pos]))      threw = false    } fally {      if (threw)        try { [_close]() } catch (_) {}    }  }}exports.ReadStream = ReadStreamexports.ReadStreamSync = ReadStreamSyncexports.WriteStream = WriteStreamexports.WriteStreamSync = WriteStreamSync/***/ }),/***/ "../../../.yarn/berry/cache/is-wdows-npm-1.0.2-898cd6f3d7-9.zip/node_modules/is-wdows/dex.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/is-wdows-npm-1.0.2-898cd6f3d7-9.zip/node_modules/is-wdows/dex.js ***!  \*********************************************************************************************************//***/ ((module, exports) => {var __WEBPACK_AMD_DEFINE_FACTORY__, __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;/*! * is-wdows <https://github.com/jonschlkert/is-wdows> * * Copyright Â© 2015-2018, Jon Schlkert. * Released under the MIT License. */(function(factory) {  if (exports && typeof exports === 'object' && "object" !== 'undefed') {    module.exports = factory();  } else if (true) {    !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_FACTORY__ = (factory),		__WEBPACK_AMD_DEFINE_RESULT__ = (typeof __WEBPACK_AMD_DEFINE_FACTORY__ === 'function' ?		(__WEBPACK_AMD_DEFINE_FACTORY__.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__)) : __WEBPACK_AMD_DEFINE_FACTORY__),		__WEBPACK_AMD_DEFINE_RESULT__ !== undefed && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));  } else {}})(function() {  'use strict';  return function isWdows() {    return process && (process.platform === 'w32' || /^(msys|cygw)$/.test(process.env.OSTYPE));  };});/***/ }),/***/ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/dex.js":/*!***********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/dex.js ***!  \***********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {var fs = __webpack_require__(/*! fs */ "fs")var coreif (process.platform === 'w32' || global.TESTING_WINDOWS) {  core = __webpack_require__(/*! ./wdows.js */ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/wdows.js")} else {  core = __webpack_require__(/*! ./mode.js */ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/mode.js")}module.exports = isexeisexe.sync = syncfunction isexe (path, options, cb) {  if (typeof options === 'function') {    cb = options    options = {}  }  if (!cb) {    if (typeof Promise !== 'function') {      throw new TypeError('callback not provided')    }    return new Promise(function (resolve, reject) {      isexe(path, options || {}, function (er, is) {        if (er) {          reject(er)        } else {          resolve(is)        }      })    })  }  core(path, options || {}, function (er, is) {    // ignore EACCES because that just means we n't allowed to run it    if (er) {      if (er.code === 'EACCES' || options && options.ignoreErrors) {        er = null        is = false      }    }    cb(er, is)  })}function sync (path, options) {  // my kgdom for a filtered catch  try {    return core.sync(path, options || {})  } catch (er) {    if (options && options.ignoreErrors || er.code === 'EACCES') {      return false    } else {      throw er    }  }}/***/ }),/***/ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/mode.js":/*!**********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/mode.js ***!  \**********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {module.exports = isexeisexe.sync = syncvar fs = __webpack_require__(/*! fs */ "fs")function isexe (path, options, cb) {  fs.stat(path, function (er, stat) {    cb(er, er ? false : checkStat(stat, options))  })}function sync (path, options) {  return checkStat(fs.statSync(path), options)}function checkStat (stat, options) {  return stat.isFile() && checkMode(stat, options)}function checkMode (stat, options) {  var mod = stat.mode  var uid = stat.uid  var gid = stat.gid  var myUid = options.uid !== undefed ?    options.uid : process.getuid && process.getuid()  var myGid = options.gid !== undefed ?    options.gid : process.getgid && process.getgid()  var u = parseInt('100', 8)  var g = parseInt('010', 8)  var o = parseInt('001', 8)  var ug = u | g  var ret = (mod & o) ||    (mod & g) && gid === myGid ||    (mod & u) && uid === myUid ||    (mod & ug) && myUid === 0  return ret}/***/ }),/***/ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/wdows.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/wdows.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {module.exports = isexeisexe.sync = syncvar fs = __webpack_require__(/*! fs */ "fs")function checkPathExt (path, options) {  var pathext = options.pathExt !== undefed ?    options.pathExt : process.env.PATHEXT  if (!pathext) {    return true  }  pathext = pathext.split(';')  if (pathext.dexOf('') !== -1) {    return true  }  for (var i = 0; i < pathext.length; i++) {    var p = pathext[i].toLowerCase()    if (p && path.substr(-p.length).toLowerCase() === p) {      return true    }  }  return false}function checkStat (stat, path, options) {  if (!stat.isSymbolicLk() && !stat.isFile()) {    return false  }  return checkPathExt(path, options)}function isexe (path, options, cb) {  fs.stat(path, function (er, stat) {    cb(er, er ? false : checkStat(stat, path, options))  })}function sync (path, options) {  return checkStat(fs.statSync(path), path, options)}/***/ }),/***/ "../../../.yarn/berry/cache/lru-cache-npm-6.0.0-b4c8668fe1-9.zip/node_modules/lru-cache/dex.js":/*!*******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/lru-cache-npm-6.0.0-b4c8668fe1-9.zip/node_modules/lru-cache/dex.js ***!  \*******************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// A lked list to keep track of recently-used-nessconst Yallist = __webpack_require__(/*! yallist */ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js")const MAX = Symbol('max')const LENGTH = Symbol('length')const LENGTH_CALCULATOR = Symbol('lengthCalculator')const ALLOW_STALE = Symbol('allowStale')const MAX_AGE = Symbol('maxAge')const DISPOSE = Symbol('dispose')const NO_DISPOSE_ON_SET = Symbol('noDisposeOnSet')const LRU_LIST = Symbol('lruList')const CACHE = Symbol('cache')const UPDATE_AGE_ON_GET = Symbol('updateAgeOnGet')const naiveLength = () => 1// lruList is a yallist where the head is the youngest// item,  the tail is the oldest.  the list contas the Hit// objects as the entries.// Each Hit object has a reference to its Yallist.Node.  This// never changes.//// cache is a Map (or PseudoMap) that matches the keys to// the Yallist.Node object.class LRUCache {  constructor (options) {    if (typeof options === 'number')      options = { max: options }    if (!options)      options = {}    if (options.max && (typeof options.max !== 'number' || options.max < 0))      throw new TypeError('max must be a non-negative number')    // Kd of weird to have a default max of Infity, but oh well.    const max = [MAX] = options.max || Infity    const lc = options.length || naiveLength    [LENGTH_CALCULATOR] = (typeof lc !== 'function') ? naiveLength : lc    [ALLOW_STALE] = options.stale || false    if (options.maxAge && typeof options.maxAge !== 'number')      throw new TypeError('maxAge must be a number')    [MAX_AGE] = options.maxAge || 0    [DISPOSE] = options.dispose    [NO_DISPOSE_ON_SET] = options.noDisposeOnSet || false    [UPDATE_AGE_ON_GET] = options.updateAgeOnGet || false    .reset()  }  // resize the cache when the max changes.  set max (mL) {    if (typeof mL !== 'number' || mL < 0)      throw new TypeError('max must be a non-negative number')    [MAX] = mL || Infity    trim()  }  get max () {    return [MAX]  }  set allowStale (allowStale) {    [ALLOW_STALE] = !!allowStale  }  get allowStale () {    return [ALLOW_STALE]  }  set maxAge (mA) {    if (typeof mA !== 'number')      throw new TypeError('maxAge must be a non-negative number')    [MAX_AGE] = mA    trim()  }  get maxAge () {    return [MAX_AGE]  }  // resize the cache when the lengthCalculator changes.  set lengthCalculator (lC) {    if (typeof lC !== 'function')      lC = naiveLength    if (lC !== [LENGTH_CALCULATOR]) {      [LENGTH_CALCULATOR] = lC      [LENGTH] = 0      [LRU_LIST].forEach(hit => {        hit.length = [LENGTH_CALCULATOR](hit.value, hit.key)        [LENGTH] += hit.length      })    }    trim()  }  get lengthCalculator () { return [LENGTH_CALCULATOR] }  get length () { return [LENGTH] }  get itemCount () { return [LRU_LIST].length }  rforEach (fn, p) {    p = p ||     for (let walker = [LRU_LIST].tail; walker !== null;) {      const prev = walker.prev      forEachStep(, fn, walker, p)      walker = prev    }  }  forEach (fn, p) {    p = p ||     for (let walker = [LRU_LIST].head; walker !== null;) {      const next = walker.next      forEachStep(, fn, walker, p)      walker = next    }  }  keys () {    return [LRU_LIST].toArray().map(k => k.key)  }  values () {    return [LRU_LIST].toArray().map(k => k.value)  }  reset () {    if ([DISPOSE] &&        [LRU_LIST] &&        [LRU_LIST].length) {      [LRU_LIST].forEach(hit => [DISPOSE](hit.key, hit.value))    }    [CACHE] = new Map() // hash of items  key    [LRU_LIST] = new Yallist() // list of items  order of use recency    [LENGTH] = 0 // length of items  the list  }  dump () {    return [LRU_LIST].map(hit =>      isStale(, hit) ? false : {        k: hit.key,        v: hit.value,        e: hit.now + (hit.maxAge || 0)      }).toArray().filter(h => h)  }  dumpLru () {    return [LRU_LIST]  }  set (key, value, maxAge) {    maxAge = maxAge || [MAX_AGE]    if (maxAge && typeof maxAge !== 'number')      throw new TypeError('maxAge must be a number')    const now = maxAge ? Date.now() : 0    const len = [LENGTH_CALCULATOR](value, key)    if ([CACHE].has(key)) {      if (len > [MAX]) {        del(, [CACHE].get(key))        return false      }      const node = [CACHE].get(key)      const item = node.value      // dispose of the old one before overwritg      // split out to 2 ifs for better coverage trackg      if ([DISPOSE]) {        if (![NO_DISPOSE_ON_SET])          [DISPOSE](key, item.value)      }      item.now = now      item.maxAge = maxAge      item.value = value      [LENGTH] += len - item.length      item.length = len      .get(key)      trim()      return true    }    const hit = new Entry(key, value, len, now, maxAge)    // oversized objects fall out of cache automatically.    if (hit.length > [MAX]) {      if ([DISPOSE])        [DISPOSE](key, value)      return false    }    [LENGTH] += hit.length    [LRU_LIST].unshift(hit)    [CACHE].set(key, [LRU_LIST].head)    trim()    return true  }  has (key) {    if (![CACHE].has(key)) return false    const hit = [CACHE].get(key).value    return !isStale(, hit)  }  get (key) {    return get(, key, true)  }  peek (key) {    return get(, key, false)  }  pop () {    const node = [LRU_LIST].tail    if (!node)      return null    del(, node)    return node.value  }  del (key) {    del(, [CACHE].get(key))  }  load (arr) {    // reset the cache    .reset()    const now = Date.now()    // A previous serialized cache has the most recent items first    for (let l = arr.length - 1; l >= 0; l--) {      const hit = arr[l]      const expiresAt = hit.e || 0      if (expiresAt === 0)        // the item was created without expiration  a non aged cache        .set(hit.k, hit.v)      else {        const maxAge = expiresAt - now        // dont add already expired items        if (maxAge > 0) {          .set(hit.k, hit.v, maxAge)        }      }    }  }  prune () {    [CACHE].forEach((value, key) => get(, key, false))  }}const get = (self, key, doUse) => {  const node = self[CACHE].get(key)  if (node) {    const hit = node.value    if (isStale(self, hit)) {      del(self, node)      if (!self[ALLOW_STALE])        return undefed    } else {      if (doUse) {        if (self[UPDATE_AGE_ON_GET])          node.value.now = Date.now()        self[LRU_LIST].unshiftNode(node)      }    }    return hit.value  }}const isStale = (self, hit) => {  if (!hit || (!hit.maxAge && !self[MAX_AGE]))    return false  const diff = Date.now() - hit.now  return hit.maxAge ? diff > hit.maxAge    : self[MAX_AGE] && (diff > self[MAX_AGE])}const trim = self => {  if (self[LENGTH] > self[MAX]) {    for (let walker = self[LRU_LIST].tail;      self[LENGTH] > self[MAX] && walker !== null;) {      // We know that we're about to delete  one,  also      // what the next least recently used key will be, so just      // go ahead  set it now.      const prev = walker.prev      del(self, walker)      walker = prev    }  }}const del = (self, node) => {  if (node) {    const hit = node.value    if (self[DISPOSE])      self[DISPOSE](hit.key, hit.value)    self[LENGTH] -= hit.length    self[CACHE].delete(hit.key)    self[LRU_LIST].removeNode(node)  }}class Entry {  constructor (key, value, length, now, maxAge) {    .key = key    .value = value    .length = length    .now = now    .maxAge = maxAge || 0  }}const forEachStep = (self, fn, node, p) => {  let hit = node.value  if (isStale(self, hit)) {    del(self, node)    if (!self[ALLOW_STALE])      hit = undefed  }  if (hit)    fn.call(p, hit.value, hit.key, self)}module.exports = LRUCache/***/ }),/***/ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js":/*!*****************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js ***!  \*****************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const proc = typeof process === 'object' && process ? process : {  stdout: null,  stderr: null,}const EE = __webpack_require__(/*! events */ "events")const Stream = __webpack_require__(/*! stream */ "stream")const Yallist = __webpack_require__(/*! yallist */ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js")const SD = (__webpack_require__(/*! strg_decoder */ "strg_decoder").StrgDecoder)const EOF = Symbol('EOF')const MAYBE_EMIT_END = Symbol('maybeEmitEnd')const EMITTED_END = Symbol('emittedEnd')const EMITTING_END = Symbol('emittgEnd')const EMITTED_ERROR = Symbol('emittedError')const CLOSED = Symbol('closed')const READ = Symbol('read')const FLUSH = Symbol('flush')const FLUSHCHUNK = Symbol('flushChunk')const ENCODING = Symbol('encodg')const DECODER = Symbol('decoder')const FLOWING = Symbol('flowg')const PAUSED = Symbol('paused')const RESUME = Symbol('resume')const BUFFERLENGTH = Symbol('bufferLength')const BUFFERPUSH = Symbol('bufferPush')const BUFFERSHIFT = Symbol('bufferShift')const OBJECTMODE = Symbol('objectMode')const DESTROYED = Symbol('destroyed')// TODO remove when Node v8 support dropsconst doIter = global._MP_NO_ITERATOR_SYMBOLS_  !== '1'const ASYNCITERATOR = doIter && Symbol.asyncIterator  || Symbol('asyncIterator not implemented')const ITERATOR = doIter && Symbol.iterator  || Symbol('iterator not implemented')// events that mean 'the stream is over'// these  treated specially,  re-emitted// if they  listened for after emittg.const isEndish = ev =>  ev === 'end' ||  ev === 'fish' ||  ev === 'prefish'const isArrayBuffer = b => b stanceof ArrayBuffer ||  typeof b === 'object' &&  b.constructor &&  b.constructor.name === 'ArrayBuffer' &&  b.teLength >= 0const isArrayBufferView = b => !Buffer.isBuffer(b) && ArrayBuffer.isView(b)module.exports = class Mipass extends Stream {  constructor (options) {    super()    [FLOWING] = false    // whether we're explicitly paused    [PAUSED] = false    .pipes = new Yallist()    .buffer = new Yallist()    [OBJECTMODE] = options && options.objectMode || false    if ([OBJECTMODE])      [ENCODING] = null    else      [ENCODING] = options && options.encodg || null    if ([ENCODING] === 'buffer')      [ENCODING] = null    [DECODER] = [ENCODING] ? new SD([ENCODING]) : null    [EOF] = false    [EMITTED_END] = false    [EMITTING_END] = false    [CLOSED] = false    [EMITTED_ERROR] = null    .writable = true    .readable = true    [BUFFERLENGTH] = 0    [DESTROYED] = false  }  get bufferLength () { return [BUFFERLENGTH] }  get encodg () { return [ENCODING] }  set encodg (enc) {    if ([OBJECTMODE])      throw new Error('cannot set encodg  objectMode')    if ([ENCODING] && enc !== [ENCODING] &&        ([DECODER] && [DECODER].lastNeed || [BUFFERLENGTH]))      throw new Error('cannot change encodg')    if ([ENCODING] !== enc) {      [DECODER] = enc ? new SD(enc) : null      if (.buffer.length)        .buffer = .buffer.map(chunk => [DECODER].write(chunk))    }    [ENCODING] = enc  }  setEncodg (enc) {    .encodg = enc  }  get objectMode () { return [OBJECTMODE] }  set objectMode (om) { [OBJECTMODE] = [OBJECTMODE] || !!om }  write (chunk, encodg, cb) {    if ([EOF])      throw new Error('write after end')    if ([DESTROYED]) {      .emit('error', Object.assign(        new Error('Cannot call write after a stream was destroyed'),        { code: 'ERR_STREAM_DESTROYED' }      ))      return true    }    if (typeof encodg === 'function')      cb = encodg, encodg = 'utf8'    if (!encodg)      encodg = 'utf8'    // convert array buffers  typed array views to buffers    // at some pot  the future, we may want to do the opposite!    // leave strgs  buffers as-is    // anythg else switches us to object mode    if (![OBJECTMODE] && !Buffer.isBuffer(chunk)) {      if (isArrayBufferView(chunk))        chunk = Buffer.from(chunk.buffer, chunk.teOffset, chunk.teLength)      else if (isArrayBuffer(chunk))        chunk = Buffer.from(chunk)      else if (typeof chunk !== 'strg')        // use the setter so we throw if we have encodg set        .objectMode = true    }    //  ensures at  pot that the chunk is a buffer or strg    // don't buffer it up or send it to the decoder    if (!.objectMode && !chunk.length) {      if ([BUFFERLENGTH] !== 0)        .emit('readable')      if (cb)        cb()      return .flowg    }    // fast-path writg strgs of same encodg to a stream with    // an empty buffer, skippg the buffer/decoder dance    if (typeof chunk === 'strg' && ![OBJECTMODE] &&        // unless it is a strg already ready for us to use        !(encodg === [ENCODING] && ![DECODER].lastNeed)) {      chunk = Buffer.from(chunk, encodg)    }    if (Buffer.isBuffer(chunk) && [ENCODING])      chunk = [DECODER].write(chunk)    if (.flowg) {      // if we somehow have somethg  the buffer, but we thk we're      // flowg, then we need to flush all that out first, or we get      // chunks comg  out of order.  Can't emit 'dra' here though,      // because we're mid-write, so that'd be bad.      if ([BUFFERLENGTH] !== 0)        [FLUSH](true)      // if we  still flowg after flushg the buffer we can emit the      // chunk otherwise we have to buffer it.      .flowg        ? .emit('data', chunk)        : [BUFFERPUSH](chunk)    } else      [BUFFERPUSH](chunk)    if ([BUFFERLENGTH] !== 0)      .emit('readable')    if (cb)      cb()    return .flowg  }  read (n) {    if ([DESTROYED])      return null    try {      if ([BUFFERLENGTH] === 0 || n === 0 || n > [BUFFERLENGTH])        return null      if ([OBJECTMODE])        n = null      if (.buffer.length > 1 && ![OBJECTMODE]) {        if (.encodg)          .buffer = new Yallist([            Array.from(.buffer).jo('')          ])        else          .buffer = new Yallist([            Buffer.concat(Array.from(.buffer), [BUFFERLENGTH])          ])      }      return [READ](n || null, .buffer.head.value)    } fally {      [MAYBE_EMIT_END]()    }  }  [READ] (n, chunk) {    if (n === chunk.length || n === null)      [BUFFERSHIFT]()    else {      .buffer.head.value = chunk.slice(n)      chunk = chunk.slice(0, n)      [BUFFERLENGTH] -= n    }    .emit('data', chunk)    if (!.buffer.length && ![EOF])      .emit('dra')    return chunk  }  end (chunk, encodg, cb) {    if (typeof chunk === 'function')      cb = chunk, chunk = null    if (typeof encodg === 'function')      cb = encodg, encodg = 'utf8'    if (chunk)      .write(chunk, encodg)    if (cb)      .once('end', cb)    [EOF] = true    .writable = false    // if we haven't  anythg, then go ahead  emit,    // even if we're not readg.    // we'll re-emit if a new 'end' listener is added anyway.    // This makes MP more suitable to write-only use cases.    if (.flowg || ![PAUSED])      [MAYBE_EMIT_END]()    return   }  // don't let the ternal resume be over  [RESUME] () {    if ([DESTROYED])      return    [PAUSED] = false    [FLOWING] = true    .emit('resume')    if (.buffer.length)      [FLUSH]()    else if ([EOF])      [MAYBE_EMIT_END]()    else      .emit('dra')  }  resume () {    return [RESUME]()  }  pause () {    [FLOWING] = false    [PAUSED] = true  }  get destroyed () {    return [DESTROYED]  }  get flowg () {    return [FLOWING]  }  get paused () {    return [PAUSED]  }  [BUFFERPUSH] (chunk) {    if ([OBJECTMODE])      [BUFFERLENGTH] += 1    else      [BUFFERLENGTH] += chunk.length    return .buffer.push(chunk)  }  [BUFFERSHIFT] () {    if (.buffer.length) {      if ([OBJECTMODE])        [BUFFERLENGTH] -= 1      else        [BUFFERLENGTH] -= .buffer.head.value.length    }    return .buffer.shift()  }  [FLUSH] (noDra) {    do {} while ([FLUSHCHUNK]([BUFFERSHIFT]()))    if (!noDra && !.buffer.length && ![EOF])      .emit('dra')  }  [FLUSHCHUNK] (chunk) {    return chunk ? (.emit('data', chunk), .flowg) : false  }  pipe (dest, opts) {    if ([DESTROYED])      return    const ended = [EMITTED_END]    opts = opts || {}    if (dest === proc.stdout || dest === proc.stderr)      opts.end = false    else      opts.end = opts.end !== false    const p = { dest: dest, opts: opts, ondra: _ => [RESUME]() }    .pipes.push(p)    dest.on('dra', p.ondra)    [RESUME]()    // pipg an ended stream ends immediately    if (ended && p.opts.end)      p.dest.end()    return dest  }  addListener (ev, fn) {    return .on(ev, fn)  }  on (ev, fn) {    try {      return super.on(ev, fn)    } fally {      if (ev === 'data' && !.pipes.length && !.flowg)        [RESUME]()      else if (isEndish(ev) && [EMITTED_END]) {        super.emit(ev)        .removeAllListeners(ev)      } else if (ev === 'error' && [EMITTED_ERROR]) {        fn.call(, [EMITTED_ERROR])      }    }  }  get emittedEnd () {    return [EMITTED_END]  }  [MAYBE_EMIT_END] () {    if (![EMITTING_END] &&        ![EMITTED_END] &&        ![DESTROYED] &&        .buffer.length === 0 &&        [EOF]) {      [EMITTING_END] = true      .emit('end')      .emit('prefish')      .emit('fish')      if ([CLOSED])        .emit('close')      [EMITTING_END] = false    }  }  emit (ev, data) {    // error  close  only events allowed after callg destroy()    if (ev !== 'error' && ev !== 'close' && ev !== DESTROYED && [DESTROYED])      return    else if (ev === 'data') {      if (!data)        return      if (.pipes.length)        .pipes.forEach(p =>          p.dest.write(data) === false && .pause())    } else if (ev === 'end') {      // only actual end gets  treatment      if ([EMITTED_END] === true)        return      [EMITTED_END] = true      .readable = false      if ([DECODER]) {        data = [DECODER].end()        if (data) {          .pipes.forEach(p => p.dest.write(data))          super.emit('data', data)        }      }      .pipes.forEach(p => {        p.dest.removeListener('dra', p.ondra)        if (p.opts.end)          p.dest.end()      })    } else if (ev === 'close') {      [CLOSED] = true      // don't emit close before 'end'  'fish'      if (![EMITTED_END] && ![DESTROYED])        return    } else if (ev === 'error') {      [EMITTED_ERROR] = data    }    // TODO: replace with a spread operator when Node v4 support drops    const args = new Array(arguments.length)    args[0] = ev    args[1] = data    if (arguments.length > 2) {      for (let i = 2; i < arguments.length; i++) {        args[i] = arguments[i]      }    }    try {      return super.emit.apply(, args)    } fally {      if (!isEndish(ev))        [MAYBE_EMIT_END]()      else        .removeAllListeners(ev)    }  }  // const all = await stream.collect()  collect () {    const buf = []    if (![OBJECTMODE])      buf.dataLength = 0    // set the promise first,  case an error is raised    //  triggerg the flow here.    const p = .promise()    .on('data', c => {      buf.push(c)      if (![OBJECTMODE])        buf.dataLength += c.length    })    return p.then(() => buf)  }  // const data = await stream.concat()  concat () {    return [OBJECTMODE]      ? Promise.reject(new Error('cannot concat  objectMode'))      : .collect().then(buf =>          [OBJECTMODE]            ? Promise.reject(new Error('cannot concat  objectMode'))            : [ENCODING] ? buf.jo('') : Buffer.concat(buf, buf.dataLength))  }  // stream.promise().then(() => done, er => emitted error)  promise () {    return new Promise((resolve, reject) => {      .on(DESTROYED, () => reject(new Error('stream destroyed')))      .on('error', er => reject(er))      .on('end', () => resolve())    })  }  // for await (let chunk of stream)  [ASYNCITERATOR] () {    const next = () => {      const res = .read()      if (res !== null)        return Promise.resolve({ done: false, value: res })      if ([EOF])        return Promise.resolve({ done: true })      let resolve = null      let reject = null      const onerr = er => {        .removeListener('data', ondata)        .removeListener('end', onend)        reject(er)      }      const ondata = value => {        .removeListener('error', onerr)        .removeListener('end', onend)        .pause()        resolve({ value: value, done: !![EOF] })      }      const onend = () => {        .removeListener('error', onerr)        .removeListener('data', ondata)        resolve({ done: true })      }      const ondestroy = () => onerr(new Error('stream destroyed'))      return new Promise((res, rej) => {        reject = rej        resolve = res        .once(DESTROYED, ondestroy)        .once('error', onerr)        .once('end', onend)        .once('data', ondata)      })    }    return { next }  }  // for (let chunk of stream)  [ITERATOR] () {    const next = () => {      const value = .read()      const done = value === null      return { value, done }    }    return { next }  }  destroy (er) {    if ([DESTROYED]) {      if (er)        .emit('error', er)      else        .emit(DESTROYED)      return     }    [DESTROYED] = true    // throw away all buffered data, it's never comg out    .buffer = new Yallist()    [BUFFERLENGTH] = 0    if (typeof .close === 'function' && ![CLOSED])      .close()    if (er)      .emit('error', er)    else // if no error to emit, still reject pendg promises      .emit(DESTROYED)    return   }  static isStream (s) {    return !!s && (s stanceof Mipass || s stanceof Stream ||      s stanceof EE && (        typeof s.pipe === 'function' || // readable        (typeof s.write === 'function' && typeof s.end === 'function') // writable      ))  }}/***/ }),/***/ "../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/constants.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/constants.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// Update with any zlib constants that  added or changed  the future.// Node v6 didn't export , so we just hard code the version  rely// on all the other hard-coded values from zlib v4736.  When node v6// support drops, we can just export the realZlibConstants object.const realZlibConstants = (__webpack_require__(/*! zlib */ "zlib").constants) ||  /* istanbul ignore next */ { ZLIB_VERNUM: 4736 }module.exports = Object.freeze(Object.assign(Object.create(null), {  Z_NO_FLUSH: 0,  Z_PARTIAL_FLUSH: 1,  Z_SYNC_FLUSH: 2,  Z_FULL_FLUSH: 3,  Z_FINISH: 4,  Z_BLOCK: 5,  Z_OK: 0,  Z_STREAM_END: 1,  Z_NEED_DICT: 2,  Z_ERRNO: -1,  Z_STREAM_ERROR: -2,  Z_DATA_ERROR: -3,  Z_MEM_ERROR: -4,  Z_BUF_ERROR: -5,  Z_VERSION_ERROR: -6,  Z_NO_COMPRESSION: 0,  Z_BEST_SPEED: 1,  Z_BEST_COMPRESSION: 9,  Z_DEFAULT_COMPRESSION: -1,  Z_FILTERED: 1,  Z_HUFFMAN_ONLY: 2,  Z_RLE: 3,  Z_FIXED: 4,  Z_DEFAULT_STRATEGY: 0,  DEFLATE: 1,  INFLATE: 2,  GZIP: 3,  GUNZIP: 4,  DEFLATERAW: 5,  INFLATERAW: 6,  UNZIP: 7,  BROTLI_DECODE: 8,  BROTLI_ENCODE: 9,  Z_MIN_WINDOWBITS: 8,  Z_MAX_WINDOWBITS: 15,  Z_DEFAULT_WINDOWBITS: 15,  Z_MIN_CHUNK: 64,  Z_MAX_CHUNK: Infity,  Z_DEFAULT_CHUNK: 16384,  Z_MIN_MEMLEVEL: 1,  Z_MAX_MEMLEVEL: 9,  Z_DEFAULT_MEMLEVEL: 8,  Z_MIN_LEVEL: -1,  Z_MAX_LEVEL: 9,  Z_DEFAULT_LEVEL: -1,  BROTLI_OPERATION_PROCESS: 0,  BROTLI_OPERATION_FLUSH: 1,  BROTLI_OPERATION_FINISH: 2,  BROTLI_OPERATION_EMIT_METADATA: 3,  BROTLI_MODE_GENERIC: 0,  BROTLI_MODE_TEXT: 1,  BROTLI_MODE_FONT: 2,  BROTLI_DEFAULT_MODE: 0,  BROTLI_MIN_QUALITY: 0,  BROTLI_MAX_QUALITY: 11,  BROTLI_DEFAULT_QUALITY: 11,  BROTLI_MIN_WINDOW_BITS: 10,  BROTLI_MAX_WINDOW_BITS: 24,  BROTLI_LARGE_MAX_WINDOW_BITS: 30,  BROTLI_DEFAULT_WINDOW: 22,  BROTLI_MIN_INPUT_BLOCK_BITS: 16,  BROTLI_MAX_INPUT_BLOCK_BITS: 24,  BROTLI_PARAM_MODE: 0,  BROTLI_PARAM_QUALITY: 1,  BROTLI_PARAM_LGWIN: 2,  BROTLI_PARAM_LGBLOCK: 3,  BROTLI_PARAM_DISABLE_LITERAL_CONTEXT_MODELING: 4,  BROTLI_PARAM_SIZE_HINT: 5,  BROTLI_PARAM_LARGE_WINDOW: 6,  BROTLI_PARAM_NPOSTFIX: 7,  BROTLI_PARAM_NDIRECT: 8,  BROTLI_DECODER_RESULT_ERROR: 0,  BROTLI_DECODER_RESULT_SUCCESS: 1,  BROTLI_DECODER_RESULT_NEEDS_MORE_INPUT: 2,  BROTLI_DECODER_RESULT_NEEDS_MORE_OUTPUT: 3,  BROTLI_DECODER_PARAM_DISABLE_RING_BUFFER_REALLOCATION: 0,  BROTLI_DECODER_PARAM_LARGE_WINDOW: 1,  BROTLI_DECODER_NO_ERROR: 0,  BROTLI_DECODER_SUCCESS: 1,  BROTLI_DECODER_NEEDS_MORE_INPUT: 2,  BROTLI_DECODER_NEEDS_MORE_OUTPUT: 3,  BROTLI_DECODER_ERROR_FORMAT_EXUBERANT_NIBBLE: -1,  BROTLI_DECODER_ERROR_FORMAT_RESERVED: -2,  BROTLI_DECODER_ERROR_FORMAT_EXUBERANT_META_NIBBLE: -3,  BROTLI_DECODER_ERROR_FORMAT_SIMPLE_HUFFMAN_ALPHABET: -4,  BROTLI_DECODER_ERROR_FORMAT_SIMPLE_HUFFMAN_SAME: -5,  BROTLI_DECODER_ERROR_FORMAT_CL_SPACE: -6,  BROTLI_DECODER_ERROR_FORMAT_HUFFMAN_SPACE: -7,  BROTLI_DECODER_ERROR_FORMAT_CONTEXT_MAP_REPEAT: -8,  BROTLI_DECODER_ERROR_FORMAT_BLOCK_LENGTH_1: -9,  BROTLI_DECODER_ERROR_FORMAT_BLOCK_LENGTH_2: -10,  BROTLI_DECODER_ERROR_FORMAT_TRANSFORM: -11,  BROTLI_DECODER_ERROR_FORMAT_DICTIONARY: -12,  BROTLI_DECODER_ERROR_FORMAT_WINDOW_BITS: -13,  BROTLI_DECODER_ERROR_FORMAT_PADDING_1: -14,  BROTLI_DECODER_ERROR_FORMAT_PADDING_2: -15,  BROTLI_DECODER_ERROR_FORMAT_DISTANCE: -16,  BROTLI_DECODER_ERROR_DICTIONARY_NOT_SET: -19,  BROTLI_DECODER_ERROR_INVALID_ARGUMENTS: -20,  BROTLI_DECODER_ERROR_ALLOC_CONTEXT_MODES: -21,  BROTLI_DECODER_ERROR_ALLOC_TREE_GROUPS: -22,  BROTLI_DECODER_ERROR_ALLOC_CONTEXT_MAP: -25,  BROTLI_DECODER_ERROR_ALLOC_RING_BUFFER_1: -26,  BROTLI_DECODER_ERROR_ALLOC_RING_BUFFER_2: -27,  BROTLI_DECODER_ERROR_ALLOC_BLOCK_TYPE_TREES: -30,  BROTLI_DECODER_ERROR_UNREACHABLE: -31,}, realZlibConstants))/***/ }),/***/ "../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/dex.js":/*!*****************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/dex.js ***!  \*****************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";const assert = __webpack_require__(/*! assert */ "assert")const Buffer = (__webpack_require__(/*! buffer */ "buffer").Buffer)const realZlib = __webpack_require__(/*! zlib */ "zlib")const constants = exports.constants = __webpack_require__(/*! ./constants.js */ "../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/constants.js")const Mipass = __webpack_require__(/*! mipass */ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js")const OrigalBufferConcat = Buffer.concatconst _superWrite = Symbol('_superWrite')class ZlibError extends Error {  constructor (err) {    super('zlib: ' + err.message)    .code = err.code    .errno = err.errno    /* istanbul ignore if */    if (!.code)      .code = 'ZLIB_ERROR'    .message = 'zlib: ' + err.message    Error.captureStackTrace(, .constructor)  }  get name () {    return 'ZlibError'  }}// the Zlib class they all herit from// This thg manages the queue of requests,  returns// true or false if there is anythg  the queue when// you call the .write() method.const _opts = Symbol('opts')const _flushFlag = Symbol('flushFlag')const _fishFlushFlag = Symbol('fishFlushFlag')const _fullFlushFlag = Symbol('fullFlushFlag')const _hle = Symbol('hle')const _onError = Symbol('onError')const _sawError = Symbol('sawError')const _level = Symbol('level')const _strategy = Symbol('strategy')const _ended = Symbol('ended')const _defaultFullFlush = Symbol('_defaultFullFlush')class ZlibBase extends Mipass {  constructor (opts, mode) {    if (!opts || typeof opts !== 'object')      throw new TypeError('valid options for ZlibBase constructor')    super(opts)    [_sawError] = false    [_ended] = false    [_opts] = opts    [_flushFlag] = opts.flush    [_fishFlushFlag] = opts.fishFlush    //  will throw if any options  valid for the class selected    try {      [_hle] = new realZlib[mode](opts)    } catch (er) {      // make sure that all errors get decorated properly      throw new ZlibError(er)    }    [_onError] = (err) => {      // no sense raisg multiple errors, sce we abort on the first one.      if ([_sawError])        return      [_sawError] = true      // there is no way to cleanly recover.      // contug only obscures problems.      .close()      .emit('error', err)    }    [_hle].on('error', er => [_onError](new ZlibError(er)))    .once('end', () => .close)  }  close () {    if ([_hle]) {      [_hle].close()      [_hle] = null      .emit('close')    }  }  reset () {    if (![_sawError]) {      assert([_hle], 'zlib bdg closed')      return [_hle].reset()    }  }  flush (flushFlag) {    if (.ended)      return    if (typeof flushFlag !== 'number')      flushFlag = [_fullFlushFlag]    .write(Object.assign(Buffer.alloc(0), { [_flushFlag]: flushFlag }))  }  end (chunk, encodg, cb) {    if (chunk)      .write(chunk, encodg)    .flush([_fishFlushFlag])    [_ended] = true    return super.end(null, null, cb)  }  get ended () {    return [_ended]  }  write (chunk, encodg, cb) {    // process the chunk usg the sync process    // then super.write() all the outputted chunks    if (typeof encodg === 'function')      cb = encodg, encodg = 'utf8'    if (typeof chunk === 'strg')      chunk = Buffer.from(chunk, encodg)    if ([_sawError])      return    assert([_hle], 'zlib bdg closed')    // _processChunk tries to .close() the native hle after it's done, so we    // tercept that  temporarily makg it a no-op.    const nativeHle = [_hle]._hle    const origalNativeClose = nativeHle.close    nativeHle.close = () => {}    const origalClose = [_hle].close    [_hle].close = () => {}    // It also calls `Buffer.concat()` at the end, which may be convenient    // for some, but which we  not terested  as it slows us down.    Buffer.concat = (args) => args    let result    try {      const flushFlag = typeof chunk[_flushFlag] === 'number'        ? chunk[_flushFlag] : [_flushFlag]      result = [_hle]._processChunk(chunk, flushFlag)      // if we don't throw, reset it back how it was      Buffer.concat = OrigalBufferConcat    } catch (err) {      // or if we do, put Buffer.concat() back before we emit error      // Error events call to user code, which may call Buffer.concat()      Buffer.concat = OrigalBufferConcat      [_onError](new ZlibError(err))    } fally {      if ([_hle]) {        // Core zlib resets `_hle` to null after attemptg to close the        // native hle. Our no-op hler prevented actual closure, but we        // need to restore the `._hle` property.        [_hle]._hle = nativeHle        nativeHle.close = origalNativeClose        [_hle].close = origalClose        // `_processChunk()` adds an 'error' listener. If we don't remove it        // after each call, these hlers start pilg up.        [_hle].removeAllListeners('error')        // make sure OUR error listener is still attached tho      }    }    if ([_hle])      [_hle].on('error', er => [_onError](new ZlibError(er)))    let writeReturn    if (result) {      if (Array.isArray(result) && result.length > 0) {        //  first buffer is always `hle._outBuffer`, which would be        // re-used for later vocations; so, we always have to copy that one.        writeReturn = [_superWrite](Buffer.from(result[0]))        for (let i = 1; i < result.length; i++) {          writeReturn = [_superWrite](result[i])        }      } else {        writeReturn = [_superWrite](Buffer.from(result))      }    }    if (cb)      cb()    return writeReturn  }  [_superWrite] (data) {    return super.write(data)  }}class Zlib extends ZlibBase {  constructor (opts, mode) {    opts = opts || {}    opts.flush = opts.flush || constants.Z_NO_FLUSH    opts.fishFlush = opts.fishFlush || constants.Z_FINISH    super(opts, mode)    [_fullFlushFlag] = constants.Z_FULL_FLUSH    [_level] = opts.level    [_strategy] = opts.strategy  }  params (level, strategy) {    if ([_sawError])      return    if (![_hle])      throw new Error('cannot switch params when bdg is closed')    // no way to test  without also not supportg params at all    /* istanbul ignore if */    if (![_hle].params)      throw new Error('not supported   implementation')    if ([_level] !== level || [_strategy] !== strategy) {      .flush(constants.Z_SYNC_FLUSH)      assert([_hle], 'zlib bdg closed')      // .params() calls .flush(), but the latter is always async  the      // core zlib. We override .flush() temporarily to tercept that       // flush synchronously.      const origFlush = [_hle].flush      [_hle].flush = (flushFlag, cb) => {        .flush(flushFlag)        cb()      }      try {        [_hle].params(level, strategy)      } fally {        [_hle].flush = origFlush      }      /* istanbul ignore else */      if ([_hle]) {        [_level] = level        [_strategy] = strategy      }    }  }}// mimal 2-te headerclass Deflate extends Zlib {  constructor (opts) {    super(opts, 'Deflate')  }}class Inflate extends Zlib {  constructor (opts) {    super(opts, 'Inflate')  }}// gzip - bigger header, same deflate compressionconst _portable = Symbol('_portable')class Gzip extends Zlib {  constructor (opts) {    super(opts, 'Gzip')    [_portable] = opts && !!opts.portable  }  [_superWrite] (data) {    if (![_portable])      return super[_superWrite](data)    // we'll always get the header emitted  one first chunk    // overwrite the OS dicator te with 0xFF    [_portable] = false    data[9] = 255    return super[_superWrite](data)  }}class Gunzip extends Zlib {  constructor (opts) {    super(opts, 'Gunzip')  }}// raw - no headerclass DeflateRaw extends Zlib {  constructor (opts) {    super(opts, 'DeflateRaw')  }}class InflateRaw extends Zlib {  constructor (opts) {    super(opts, 'InflateRaw')  }}// auto-detect header.class Unzip extends Zlib {  constructor (opts) {    super(opts, 'Unzip')  }}class Brotli extends ZlibBase {  constructor (opts, mode) {    opts = opts || {}    opts.flush = opts.flush || constants.BROTLI_OPERATION_PROCESS    opts.fishFlush = opts.fishFlush || constants.BROTLI_OPERATION_FINISH    super(opts, mode)    [_fullFlushFlag] = constants.BROTLI_OPERATION_FLUSH  }}class BrotliCompress extends Brotli {  constructor (opts) {    super(opts, 'BrotliCompress')  }}class BrotliDecompress extends Brotli {  constructor (opts) {    super(opts, 'BrotliDecompress')  }}exports.Deflate = Deflateexports.Inflate = Inflateexports.Gzip = Gzipexports.Gunzip = Gunzipexports.DeflateRaw = DeflateRawexports.InflateRaw = InflateRawexports.Unzip = Unzip/* istanbul ignore else */if (typeof realZlib.BrotliCompress === 'function') {  exports.BrotliCompress = BrotliCompress  exports.BrotliDecompress = BrotliDecompress} else {  exports.BrotliCompress = exports.BrotliDecompress = class {    constructor () {      throw new Error('Brotli is not supported   version of Node.js')    }  }}/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/dex.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/dex.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const optsArg = __webpack_require__(/*! ./lib/opts-arg.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/opts-arg.js")const pathArg = __webpack_require__(/*! ./lib/path-arg.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/path-arg.js")const {mkdirpNative, mkdirpNativeSync} = __webpack_require__(/*! ./lib/mkdirp-native.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-native.js")const {mkdirpManual, mkdirpManualSync} = __webpack_require__(/*! ./lib/mkdirp-manual.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-manual.js")const {useNative, useNativeSync} = __webpack_require__(/*! ./lib/use-native.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/use-native.js")const mkdirp = (path, opts) => {  path = pathArg(path)  opts = optsArg(opts)  return useNative(opts)    ? mkdirpNative(path, opts)    : mkdirpManual(path, opts)}const mkdirpSync = (path, opts) => {  path = pathArg(path)  opts = optsArg(opts)  return useNativeSync(opts)    ? mkdirpNativeSync(path, opts)    : mkdirpManualSync(path, opts)}mkdirp.sync = mkdirpSyncmkdirp.native = (path, opts) => mkdirpNative(pathArg(path), optsArg(opts))mkdirp.manual = (path, opts) => mkdirpManual(pathArg(path), optsArg(opts))mkdirp.nativeSync = (path, opts) => mkdirpNativeSync(pathArg(path), optsArg(opts))mkdirp.manualSync = (path, opts) => mkdirpManualSync(pathArg(path), optsArg(opts))module.exports = mkdirp/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/fd-made.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/fd-made.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const {dirname} = __webpack_require__(/*! path */ "path")const fdMade = (opts, pnt, path = undefed) => {  // we never want the 'made' return value to be a root directory  if (path === pnt)    return Promise.resolve()  return opts.statAsync(pnt).then(    st => st.isDirectory() ? path : undefed, // will fail later    er => er.code === 'ENOENT'      ? fdMade(opts, dirname(pnt), pnt)      : undefed  )}const fdMadeSync = (opts, pnt, path = undefed) => {  if (path === pnt)    return undefed  try {    return opts.statSync(pnt).isDirectory() ? path : undefed  } catch (er) {    return er.code === 'ENOENT'      ? fdMadeSync(opts, dirname(pnt), pnt)      : undefed  }}module.exports = {fdMade, fdMadeSync}/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-manual.js":/*!*************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-manual.js ***!  \*************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const {dirname} = __webpack_require__(/*! path */ "path")const mkdirpManual = (path, opts, made) => {  opts.recursive = false  const pnt = dirname(path)  if (pnt === path) {    return opts.mkdirAsync(path, opts).catch(er => {      // swallowed  recursive implementation on posix systems      // any other error is a failure      if (er.code !== 'EISDIR')        throw er    })  }  return opts.mkdirAsync(path, opts).then(() => made || path, er => {    if (er.code === 'ENOENT')      return mkdirpManual(pnt, opts)        .then(made => mkdirpManual(path, opts, made))    if (er.code !== 'EEXIST' && er.code !== 'EROFS')      throw er    return opts.statAsync(path).then(st => {      if (st.isDirectory())        return made      else        throw er    }, () => { throw er })  })}const mkdirpManualSync = (path, opts, made) => {  const pnt = dirname(path)  opts.recursive = false  if (pnt === path) {    try {      return opts.mkdirSync(path, opts)    } catch (er) {      // swallowed  recursive implementation on posix systems      // any other error is a failure      if (er.code !== 'EISDIR')        throw er      else        return    }  }  try {    opts.mkdirSync(path, opts)    return made || path  } catch (er) {    if (er.code === 'ENOENT')      return mkdirpManualSync(path, opts, mkdirpManualSync(pnt, opts, made))    if (er.code !== 'EEXIST' && er.code !== 'EROFS')      throw er    try {      if (!opts.statSync(path).isDirectory())        throw er    } catch (_) {      throw er    }  }}module.exports = {mkdirpManual, mkdirpManualSync}/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-native.js":/*!*************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-native.js ***!  \*************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const {dirname} = __webpack_require__(/*! path */ "path")const {fdMade, fdMadeSync} = __webpack_require__(/*! ./fd-made.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/fd-made.js")const {mkdirpManual, mkdirpManualSync} = __webpack_require__(/*! ./mkdirp-manual.js */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/mkdirp-manual.js")const mkdirpNative = (path, opts) => {  opts.recursive = true  const pnt = dirname(path)  if (pnt === path)    return opts.mkdirAsync(path, opts)  return fdMade(opts, path).then(made =>    opts.mkdirAsync(path, opts).then(() => made)    .catch(er => {      if (er.code === 'ENOENT')        return mkdirpManual(path, opts)      else        throw er    }))}const mkdirpNativeSync = (path, opts) => {  opts.recursive = true  const pnt = dirname(path)  if (pnt === path)    return opts.mkdirSync(path, opts)  const made = fdMadeSync(opts, path)  try {    opts.mkdirSync(path, opts)    return made  } catch (er) {    if (er.code === 'ENOENT')      return mkdirpManualSync(path, opts)    else      throw er  }}module.exports = {mkdirpNative, mkdirpNativeSync}/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/opts-arg.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/opts-arg.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const { promisify } = __webpack_require__(/*! util */ "util")const fs = __webpack_require__(/*! fs */ "fs")const optsArg = opts => {  if (!opts)    opts = { mode: 0o777, fs }  else if (typeof opts === 'object')    opts = { mode: 0o777, fs, ...opts }  else if (typeof opts === 'number')    opts = { mode: opts, fs }  else if (typeof opts === 'strg')    opts = { mode: parseInt(opts, 8), fs }  else    throw new TypeError('valid options argument')  opts.mkdir = opts.mkdir || opts.fs.mkdir || fs.mkdir  opts.mkdirAsync = promisify(opts.mkdir)  opts.stat = opts.stat || opts.fs.stat || fs.stat  opts.statAsync = promisify(opts.stat)  opts.statSync = opts.statSync || opts.fs.statSync || fs.statSync  opts.mkdirSync = opts.mkdirSync || opts.fs.mkdirSync || fs.mkdirSync  return opts}module.exports = optsArg/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/path-arg.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/path-arg.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const platform = process.env.__TESTING_MKDIRP_PLATFORM__ || process.platformconst { resolve, parse } = __webpack_require__(/*! path */ "path")const pathArg = path => {  if (/\0/.test(path)) {    // simulate same failure that node raises    throw Object.assign(      new TypeError('path must be a strg without null tes'),      {        path,        code: 'ERR_INVALID_ARG_VALUE',      }    )  }  path = resolve(path)  if (platform === 'w32') {    const badWChars = /[*|"<>?:]/    const {root} = parse(path)    if (badWChars.test(path.substr(root.length))) {      throw Object.assign(new Error('Illegal characters  path.'), {        path,        code: 'EINVAL',      })    }  }  return path}module.exports = pathArg/***/ }),/***/ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/use-native.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/lib/use-native.js ***!  \**********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const fs = __webpack_require__(/*! fs */ "fs")const version = process.env.__TESTING_MKDIRP_NODE_VERSION__ || process.versionconst versArr = version.replace(/^v/, '').split('.')const hasNative = +versArr[0] > 10 || +versArr[0] === 10 && +versArr[1] >= 12const useNative = !hasNative ? () => false : opts => opts.mkdir === fs.mkdirconst useNativeSync = !hasNative ? () => false : opts => opts.mkdirSync === fs.mkdirSyncmodule.exports = {useNative, useNativeSync}/***/ }),/***/ "../../../.yarn/berry/cache/ms-npm-2.1.2-ec0c1512ff-9.zip/node_modules/ms/dex.js":/*!*****************************************************************************************!*\  !*** ../../../.yarn/berry/cache/ms-npm-2.1.2-ec0c1512ff-9.zip/node_modules/ms/dex.js ***!  \*****************************************************************************************//***/ ((module) => {/** * Helpers. */var s = 1000;var m = s * 60;var h = m * 60;var d = h * 24;var w = d * 7;var y = d * 365.25;/** * Parse or format the given `val`. * * Options: * *  - `long` verbose formattg [false] * * @param {Strg|Number} val * @param {Object} [options] * @throws {Error} throw an error if val is not a non-empty strg or a number * @return {Strg|Number} * @api public */module.exports = function(val, options) {  options = options || {};  var type = typeof val;  if (type === 'strg' && val.length > 0) {    return parse(val);  } else if (type === 'number' && isFite(val)) {    return options.long ? fmtLong(val) : fmtShort(val);  }  throw new Error(    'val is not a non-empty strg or a valid number. val=' +      JSON.strgify(val)  );};/** * Parse the given `str`  return milliseconds. * * @param {Strg} str * @return {Number} * @api private */function parse(str) {  str = Strg(str);  if (str.length > 100) {    return;  }  var match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|mutes?|ms?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(    str  );  if (!match) {    return;  }  var n = parseFloat(match[1]);  var type = (match[2] || 'ms').toLowerCase();  switch (type) {    case 'years':    case 'year':    case 'yrs':    case 'yr':    case 'y':      return n * y;    case 'weeks':    case 'week':    case 'w':      return n * w;    case 'days':    case 'day':    case 'd':      return n * d;    case 'hours':    case 'hour':    case 'hrs':    case 'hr':    case 'h':      return n * h;    case 'mutes':    case 'mute':    case 'ms':    case 'm':    case 'm':      return n * m;    case 'seconds':    case 'second':    case 'secs':    case 'sec':    case 's':      return n * s;    case 'milliseconds':    case 'millisecond':    case 'msecs':    case 'msec':    case 'ms':      return n;    default:      return undefed;  }}/** * Short format for `ms`. * * @param {Number} ms * @return {Strg} * @api private */function fmtShort(ms) {  var msAbs = Math.abs(ms);  if (msAbs >= d) {    return Math.round(ms / d) + 'd';  }  if (msAbs >= h) {    return Math.round(ms / h) + 'h';  }  if (msAbs >= m) {    return Math.round(ms / m) + 'm';  }  if (msAbs >= s) {    return Math.round(ms / s) + 's';  }  return ms + 'ms';}/** * Long format for `ms`. * * @param {Number} ms * @return {Strg} * @api private */function fmtLong(ms) {  var msAbs = Math.abs(ms);  if (msAbs >= d) {    return plural(ms, msAbs, d, 'day');  }  if (msAbs >= h) {    return plural(ms, msAbs, h, 'hour');  }  if (msAbs >= m) {    return plural(ms, msAbs, m, 'mute');  }  if (msAbs >= s) {    return plural(ms, msAbs, s, 'second');  }  return ms + ' ms';}/** * Pluralization helper. */function plural(ms, msAbs, n, name) {  var isPlural = msAbs >= n * 1.5;  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js":/*!**************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js ***!  \**************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const ANY = Symbol('SemVer ANY')// hoisted class for cyclic dependencyclass Comparator {  static get ANY () {    return ANY  }  constructor (comp, options) {    options = parseOptions(options)    if (comp stanceof Comparator) {      if (comp.loose === !!options.loose) {        return comp      } else {        comp = comp.value      }    }    debug('comparator', comp, options)    .options = options    .loose = !!options.loose    .parse(comp)    if (.semver === ANY) {      .value = ''    } else {      .value = .operator + .semver.version    }    debug('comp', )  }  parse (comp) {    const r = .options.loose ? re[t.COMPARATORLOOSE] : re[t.COMPARATOR]    const m = comp.match(r)    if (!m) {      throw new TypeError(`Invalid comparator: ${comp}`)    }    .operator = m[1] !== undefed ? m[1] : ''    if (.operator === '=') {      .operator = ''    }    // if it literally is just '>' or '' then allow anythg.    if (!m[2]) {      .semver = ANY    } else {      .semver = new SemVer(m[2], .options.loose)    }  }  toStrg () {    return .value  }  test (version) {    debug('Comparator.test', version, .options.loose)    if (.semver === ANY || version === ANY) {      return true    }    if (typeof version === 'strg') {      try {        version = new SemVer(version, .options)      } catch (er) {        return false      }    }    return cmp(version, .operator, .semver, .options)  }  tersects (comp, options) {    if (!(comp stanceof Comparator)) {      throw new TypeError('a Comparator is required')    }    if (!options || typeof options !== 'object') {      options = {        loose: !!options,        cludePrerelease: false,      }    }    if (.operator === '') {      if (.value === '') {        return true      }      return new Range(comp.value, options).test(.value)    } else if (comp.operator === '') {      if (comp.value === '') {        return true      }      return new Range(.value, options).test(comp.semver)    }    const sameDirectionIncreasg =      (.operator === '>=' || .operator === '>') &&      (comp.operator === '>=' || comp.operator === '>')    const sameDirectionDecreasg =      (.operator === '<=' || .operator === '<') &&      (comp.operator === '<=' || comp.operator === '<')    const sameSemVer = .semver.version === comp.semver.version    const differentDirectionsInclusive =      (.operator === '>=' || .operator === '<=') &&      (comp.operator === '>=' || comp.operator === '<=')    const oppositeDirectionsLessThan =      cmp(.semver, '<', comp.semver, options) &&      (.operator === '>=' || .operator === '>') &&        (comp.operator === '<=' || comp.operator === '<')    const oppositeDirectionsGreaterThan =      cmp(.semver, '>', comp.semver, options) &&      (.operator === '<=' || .operator === '<') &&        (comp.operator === '>=' || comp.operator === '>')    return (      sameDirectionIncreasg ||      sameDirectionDecreasg ||      (sameSemVer && differentDirectionsInclusive) ||      oppositeDirectionsLessThan ||      oppositeDirectionsGreaterThan    )  }}module.exports = Comparatorconst parseOptions = __webpack_require__(/*! ../ternal/parse-options */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js")const { re, t } = __webpack_require__(/*! ../ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")const cmp = __webpack_require__(/*! ../functions/cmp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/cmp.js")const debug = __webpack_require__(/*! ../ternal/debug */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js")const SemVer = __webpack_require__(/*! ./semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const Range = __webpack_require__(/*! ./range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// hoisted class for cyclic dependencyclass Range {  constructor (range, options) {    options = parseOptions(options)    if (range stanceof Range) {      if (        range.loose === !!options.loose &&        range.cludePrerelease === !!options.cludePrerelease      ) {        return range      } else {        return new Range(range.raw, options)      }    }    if (range stanceof Comparator) {      // just put it  the set  return      .raw = range.value      .set = [[range]]      .format()      return     }    .options = options    .loose = !!options.loose    .cludePrerelease = !!options.cludePrerelease    // First, split based on boolean or ||    .raw = range    .set = range      .split('||')      // map the range to a 2d array of comparators      .map(r => .parseRange(r.trim()))      // throw out any comparator lists that  empty      //  generally means that it was not a valid range, which is allowed      //  loose mode, but will still throw if the WHOLE range is valid.      .filter(c => c.length)    if (!.set.length) {      throw new TypeError(`Invalid SemVer Range: ${range}`)    }    // if we have any that  not the null set, throw out null sets.    if (.set.length > 1) {      // keep the first one,  case they're all null sets      const first = .set[0]      .set = .set.filter(c => !isNullSet(c[0]))      if (.set.length === 0) {        .set = [first]      } else if (.set.length > 1) {        // if we have any that  *, then the range is just *        for (const c of .set) {          if (c.length === 1 && isAny(c[0])) {            .set = [c]            break          }        }      }    }    .format()  }  format () {    .range = .set      .map((comps) => {        return comps.jo(' ').trim()      })      .jo('||')      .trim()    return .range  }  toStrg () {    return .range  }  parseRange (range) {    range = range.trim()    // memoize range parsg for performance.    //  is a very hot path,  fully determistic.    const memoOpts = Object.keys(.options).jo(',')    const memoKey = `parseRange:${memoOpts}:${range}`    const cached = cache.get(memoKey)    if (cached) {      return cached    }    const loose = .options.loose    // `1.2.3 - 1.2.4` => `>=1.2.3 <=1.2.4`    const hr = loose ? re[t.HYPHENRANGELOOSE] : re[t.HYPHENRANGE]    range = range.replace(hr, hyphenReplace(.options.cludePrerelease))    debug('hyphen replace', range)    // `> 1.2.3 < 1.2.5` => `>1.2.3 <1.2.5`    range = range.replace(re[t.COMPARATORTRIM], comparatorTrimReplace)    debug('comparator trim', range)    // `~ 1.2.3` => `~1.2.3`    range = range.replace(re[t.TILDETRIM], tildeTrimReplace)    // `^ 1.2.3` => `^1.2.3`    range = range.replace(re[t.CARETTRIM], ctTrimReplace)    // normalize spaces    range = range.split(/\s+/).jo(' ')    // At  pot, the range is completely trimmed     // ready to be split to comparators.    let rangeList = range      .split(' ')      .map(comp => parseComparator(comp, .options))      .jo(' ')      .split(/\s+/)      // >=0.0.0 is equivalent to *      .map(comp => replaceGTE0(comp, .options))    if (loose) {      //  loose mode, throw out any that  not valid comparators      rangeList = rangeList.filter(comp => {        debug('loose valid filter', comp, .options)        return !!comp.match(re[t.COMPARATORLOOSE])      })    }    debug('range list', rangeList)    // if any comparators  the null set, then replace with JUST null set    // if more than one comparator, remove any * comparators    // also, don't clude the same comparator more than once    const rangeMap = new Map()    const comparators = rangeList.map(comp => new Comparator(comp, .options))    for (const comp of comparators) {      if (isNullSet(comp)) {        return [comp]      }      rangeMap.set(comp.value, comp)    }    if (rangeMap.size > 1 && rangeMap.has('')) {      rangeMap.delete('')    }    const result = [...rangeMap.values()]    cache.set(memoKey, result)    return result  }  tersects (range, options) {    if (!(range stanceof Range)) {      throw new TypeError('a Range is required')    }    return .set.some((Comparators) => {      return (        isSatisfiable(Comparators, options) &&        range.set.some((rangeComparators) => {          return (            isSatisfiable(rangeComparators, options) &&            Comparators.every((Comparator) => {              return rangeComparators.every((rangeComparator) => {                return Comparator.tersects(rangeComparator, options)              })            })          )        })      )    })  }  // if ANY of the sets match ALL of its comparators, then pass  test (version) {    if (!version) {      return false    }    if (typeof version === 'strg') {      try {        version = new SemVer(version, .options)      } catch (er) {        return false      }    }    for (let i = 0; i < .set.length; i++) {      if (testSet(.set[i], version, .options)) {        return true      }    }    return false  }}module.exports = Rangeconst LRU = __webpack_require__(/*! lru-cache */ "../../../.yarn/berry/cache/lru-cache-npm-6.0.0-b4c8668fe1-9.zip/node_modules/lru-cache/dex.js")const cache = new LRU({ max: 1000 })const parseOptions = __webpack_require__(/*! ../ternal/parse-options */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js")const Comparator = __webpack_require__(/*! ./comparator */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js")const debug = __webpack_require__(/*! ../ternal/debug */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js")const SemVer = __webpack_require__(/*! ./semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const {  re,  t,  comparatorTrimReplace,  tildeTrimReplace,  ctTrimReplace,} = __webpack_require__(/*! ../ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")const isNullSet = c => c.value === '<0.0.0-0'const isAny = c => c.value === ''// take a set of comparators  determe whether there// exists a version which can satisfy itconst isSatisfiable = (comparators, options) => {  let result = true  const remagComparators = comparators.slice()  let testComparator = remagComparators.pop()  while (result && remagComparators.length) {    result = remagComparators.every((otherComparator) => {      return testComparator.tersects(otherComparator, options)    })    testComparator = remagComparators.pop()  }  return result}// comprised of xranges, tildes, stars,  gtlt's at  pot.// already replaced the hyphen ranges// turn to a set of JUST comparators.const parseComparator = (comp, options) => {  debug('comp', comp, options)  comp = replaceCts(comp, options)  debug('ct', comp)  comp = replaceTildes(comp, options)  debug('tildes', comp)  comp = replaceXRanges(comp, options)  debug('xrange', comp)  comp = replaceStars(comp, options)  debug('stars', comp)  return comp}const isX = id => !id || id.toLowerCase() === 'x' || id === '*'// ~, ~> --> * (any, kda silly)// ~2, ~2.x, ~2.x.x, ~>2, ~>2.x ~>2.x.x --> >=2.0.0 <3.0.0-0// ~2.0, ~2.0.x, ~>2.0, ~>2.0.x --> >=2.0.0 <2.1.0-0// ~1.2, ~1.2.x, ~>1.2, ~>1.2.x --> >=1.2.0 <1.3.0-0// ~1.2.3, ~>1.2.3 --> >=1.2.3 <1.3.0-0// ~1.2.0, ~>1.2.0 --> >=1.2.0 <1.3.0-0const replaceTildes = (comp, options) =>  comp.trim().split(/\s+/).map((c) => {    return replaceTilde(c, options)  }).jo(' ')const replaceTilde = (comp, options) => {  const r = options.loose ? re[t.TILDELOOSE] : re[t.TILDE]  return comp.replace(r, (_, M, m, p, pr) => {    debug('tilde', comp, _, M, m, p, pr)    let ret    if (isX(M)) {      ret = ''    } else if (isX(m)) {      ret = `>=${M}.0.0 <${+M + 1}.0.0-0`    } else if (isX(p)) {      // ~1.2 == >=1.2.0 <1.3.0-0      ret = `>=${M}.${m}.0 <${M}.${+m + 1}.0-0`    } else if (pr) {      debug('replaceTilde pr', pr)      ret = `>=${M}.${m}.${p}-${pr      } <${M}.${+m + 1}.0-0`    } else {      // ~1.2.3 == >=1.2.3 <1.3.0-0      ret = `>=${M}.${m}.${p      } <${M}.${+m + 1}.0-0`    }    debug('tilde return', ret)    return ret  })}// ^ --> * (any, kda silly)// ^2, ^2.x, ^2.x.x --> >=2.0.0 <3.0.0-0// ^2.0, ^2.0.x --> >=2.0.0 <3.0.0-0// ^1.2, ^1.2.x --> >=1.2.0 <2.0.0-0// ^1.2.3 --> >=1.2.3 <2.0.0-0// ^1.2.0 --> >=1.2.0 <2.0.0-0const replaceCts = (comp, options) =>  comp.trim().split(/\s+/).map((c) => {    return replaceCt(c, options)  }).jo(' ')const replaceCt = (comp, options) => {  debug('ct', comp, options)  const r = options.loose ? re[t.CARETLOOSE] : re[t.CARET]  const z = options.cludePrerelease ? '-0' : ''  return comp.replace(r, (_, M, m, p, pr) => {    debug('ct', comp, _, M, m, p, pr)    let ret    if (isX(M)) {      ret = ''    } else if (isX(m)) {      ret = `>=${M}.0.0${z} <${+M + 1}.0.0-0`    } else if (isX(p)) {      if (M === '0') {        ret = `>=${M}.${m}.0${z} <${M}.${+m + 1}.0-0`      } else {        ret = `>=${M}.${m}.0${z} <${+M + 1}.0.0-0`      }    } else if (pr) {      debug('replaceCt pr', pr)      if (M === '0') {        if (m === '0') {          ret = `>=${M}.${m}.${p}-${pr          } <${M}.${m}.${+p + 1}-0`        } else {          ret = `>=${M}.${m}.${p}-${pr          } <${M}.${+m + 1}.0-0`        }      } else {        ret = `>=${M}.${m}.${p}-${pr        } <${+M + 1}.0.0-0`      }    } else {      debug('no pr')      if (M === '0') {        if (m === '0') {          ret = `>=${M}.${m}.${p          }${z} <${M}.${m}.${+p + 1}-0`        } else {          ret = `>=${M}.${m}.${p          }${z} <${M}.${+m + 1}.0-0`        }      } else {        ret = `>=${M}.${m}.${p        } <${+M + 1}.0.0-0`      }    }    debug('ct return', ret)    return ret  })}const replaceXRanges = (comp, options) => {  debug('replaceXRanges', comp, options)  return comp.split(/\s+/).map((c) => {    return replaceXRange(c, options)  }).jo(' ')}const replaceXRange = (comp, options) => {  comp = comp.trim()  const r = options.loose ? re[t.XRANGELOOSE] : re[t.XRANGE]  return comp.replace(r, (ret, gtlt, M, m, p, pr) => {    debug('xRange', comp, ret, gtlt, M, m, p, pr)    const xM = isX(M)    const xm = xM || isX(m)    const xp = xm || isX(p)    const anyX = xp    if (gtlt === '=' && anyX) {      gtlt = ''    }    // if we're cludg prereleases  the match, then we need    // to fix  to -0, the lowest possible prerelease value    pr = options.cludePrerelease ? '-0' : ''    if (xM) {      if (gtlt === '>' || gtlt === '<') {        // nothg is allowed        ret = '<0.0.0-0'      } else {        // nothg is forbidden        ret = '*'      }    } else if (gtlt && anyX) {      // we know patch is an x, because we have any x at all.      // replace X with 0      if (xm) {        m = 0      }      p = 0      if (gtlt === '>') {        // >1 => >=2.0.0        // >1.2 => >=1.3.0        gtlt = '>='        if (xm) {          M = +M + 1          m = 0          p = 0        } else {          m = +m + 1          p = 0        }      } else if (gtlt === '<=') {        // <=0.7.x is actually <0.8.0, sce any 0.7.x should        // pass.  Similarly, <=7.x is actually <8.0.0, etc.        gtlt = '<'        if (xm) {          M = +M + 1        } else {          m = +m + 1        }      }      if (gtlt === '<') {        pr = '-0'      }      ret = `${gtlt + M}.${m}.${p}${pr}`    } else if (xm) {      ret = `>=${M}.0.0${pr} <${+M + 1}.0.0-0`    } else if (xp) {      ret = `>=${M}.${m}.0${pr      } <${M}.${+m + 1}.0-0`    }    debug('xRange return', ret)    return ret  })}// Because * is AND-ed with everythg else  the comparator,//  '' means "any version", just remove the *s entirely.const replaceStars = (comp, options) => {  debug('replaceStars', comp, options)  // Looseness is ignored here.  star is always as loose as it gets!  return comp.trim().replace(re[t.STAR], '')}const replaceGTE0 = (comp, options) => {  debug('replaceGTE0', comp, options)  return comp.trim()    .replace(re[options.cludePrerelease ? t.GTE0PRE : t.GTE0], '')}// This function is passed to strg.replace(re[t.HYPHENRANGE])// M, m, patch, prerelease, build// 1.2 - 3.4.5 => >=1.2.0 <=3.4.5// 1.2.3 - 3.4 => >=1.2.0 <3.5.0-0 Any 3.4.x will do// 1.2 - 3.4 => >=1.2.0 <3.5.0-0const hyphenReplace = cPr => ($0,  from, fM, fm, fp, fpr, fb,  to, tM, tm, tp, tpr, tb) => {  if (isX(fM)) {    from = ''  } else if (isX(fm)) {    from = `>=${fM}.0.0${cPr ? '-0' : ''}`  } else if (isX(fp)) {    from = `>=${fM}.${fm}.0${cPr ? '-0' : ''}`  } else if (fpr) {    from = `>=${from}`  } else {    from = `>=${from}${cPr ? '-0' : ''}`  }  if (isX(tM)) {    to = ''  } else if (isX(tm)) {    to = `<${+tM + 1}.0.0-0`  } else if (isX(tp)) {    to = `<${tM}.${+tm + 1}.0-0`  } else if (tpr) {    to = `<=${tM}.${tm}.${tp}-${tpr}`  } else if (cPr) {    to = `<${tM}.${tm}.${+tp + 1}-0`  } else {    to = `<=${to}`  }  return (`${from} ${to}`).trim()}const testSet = (set, version, options) => {  for (let i = 0; i < set.length; i++) {    if (!set[i].test(version)) {      return false    }  }  if (version.prerelease.length && !options.cludePrerelease) {    // Fd the set of versions that  allowed to have prereleases    // For example, ^1.2.3-pr.1 desugars to >=1.2.3-pr.1 <2.0.0    // That should allow `1.2.3-pr.2` to pass.    // However, `1.2.4-alpha.notready` should NOT be allowed,    // even though it's with the range set  the comparators.    for (let i = 0; i < set.length; i++) {      debug(set[i].semver)      if (set[i].semver === Comparator.ANY) {        contue      }      if (set[i].semver.prerelease.length > 0) {        const allowed = set[i].semver        if (allowed.major === version.major &&            allowed.mor === version.mor &&            allowed.patch === version.patch) {          return true        }      }    }    // Version has a -pre, but it's not one of the ones we like.    return false  }  return true}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js ***!  \**********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const debug = __webpack_require__(/*! ../ternal/debug */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js")const { MAX_LENGTH, MAX_SAFE_INTEGER } = __webpack_require__(/*! ../ternal/constants */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js")const { re, t } = __webpack_require__(/*! ../ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")const parseOptions = __webpack_require__(/*! ../ternal/parse-options */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js")const { compIdentifiers } = __webpack_require__(/*! ../ternal/identifiers */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/identifiers.js")class SemVer {  constructor (version, options) {    options = parseOptions(options)    if (version stanceof SemVer) {      if (version.loose === !!options.loose &&          version.cludePrerelease === !!options.cludePrerelease) {        return version      } else {        version = version.version      }    } else if (typeof version !== 'strg') {      throw new TypeError(`Invalid Version: ${version}`)    }    if (version.length > MAX_LENGTH) {      throw new TypeError(        `version is longer than ${MAX_LENGTH} characters`      )    }    debug('SemVer', version, options)    .options = options    .loose = !!options.loose    //  isn't actually relevant for versions, but keep it so that we    // don't run to trouble passg .options around.    .cludePrerelease = !!options.cludePrerelease    const m = version.trim().match(options.loose ? re[t.LOOSE] : re[t.FULL])    if (!m) {      throw new TypeError(`Invalid Version: ${version}`)    }    .raw = version    // these  actually numbers    .major = +m[1]    .mor = +m[2]    .patch = +m[3]    if (.major > MAX_SAFE_INTEGER || .major < 0) {      throw new TypeError('Invalid major version')    }    if (.mor > MAX_SAFE_INTEGER || .mor < 0) {      throw new TypeError('Invalid mor version')    }    if (.patch > MAX_SAFE_INTEGER || .patch < 0) {      throw new TypeError('Invalid patch version')    }    // numberify any prerelease numeric ids    if (!m[4]) {      .prerelease = []    } else {      .prerelease = m[4].split('.').map((id) => {        if (/^[0-9]+$/.test(id)) {          const num = +id          if (num >= 0 && num < MAX_SAFE_INTEGER) {            return num          }        }        return id      })    }    .build = m[5] ? m[5].split('.') : []    .format()  }  format () {    .version = `${.major}.${.mor}.${.patch}`    if (.prerelease.length) {      .version += `-${.prerelease.jo('.')}`    }    return .version  }  toStrg () {    return .version  }  comp (other) {    debug('SemVer.comp', .version, .options, other)    if (!(other stanceof SemVer)) {      if (typeof other === 'strg' && other === .version) {        return 0      }      other = new SemVer(other, .options)    }    if (other.version === .version) {      return 0    }    return .compMa(other) || .compPre(other)  }  compMa (other) {    if (!(other stanceof SemVer)) {      other = new SemVer(other, .options)    }    return (      compIdentifiers(.major, other.major) ||      compIdentifiers(.mor, other.mor) ||      compIdentifiers(.patch, other.patch)    )  }  compPre (other) {    if (!(other stanceof SemVer)) {      other = new SemVer(other, .options)    }    // NOT havg a prerelease is > havg one    if (.prerelease.length && !other.prerelease.length) {      return -1    } else if (!.prerelease.length && other.prerelease.length) {      return 1    } else if (!.prerelease.length && !other.prerelease.length) {      return 0    }    let i = 0    do {      const a = .prerelease[i]      const b = other.prerelease[i]      debug('prerelease comp', i, a, b)      if (a === undefed && b === undefed) {        return 0      } else if (b === undefed) {        return 1      } else if (a === undefed) {        return -1      } else if (a === b) {        contue      } else {        return compIdentifiers(a, b)      }    } while (++i)  }  compBuild (other) {    if (!(other stanceof SemVer)) {      other = new SemVer(other, .options)    }    let i = 0    do {      const a = .build[i]      const b = other.build[i]      debug('prerelease comp', i, a, b)      if (a === undefed && b === undefed) {        return 0      } else if (b === undefed) {        return 1      } else if (a === undefed) {        return -1      } else if (a === b) {        contue      } else {        return compIdentifiers(a, b)      }    } while (++i)  }  // premor will bump the version up to the next mor release,  immediately  // down to pre-release. premajor  prepatch work the same way.  c (release, identifier) {    switch (release) {      case 'premajor':        .prerelease.length = 0        .patch = 0        .mor = 0        .major++        .c('pre', identifier)        break      case 'premor':        .prerelease.length = 0        .patch = 0        .mor++        .c('pre', identifier)        break      case 'prepatch':        // If  is already a prerelease, it will bump to the next version        // drop any prereleases that might already exist, sce they  not        // relevant at  pot.        .prerelease.length = 0        .c('patch', identifier)        .c('pre', identifier)        break      // If the put is a non-prerelease version,  acts the same as      // prepatch.      case 'prerelease':        if (.prerelease.length === 0) {          .c('patch', identifier)        }        .c('pre', identifier)        break      case 'major':        // If  is a pre-major version, bump up to the same major version.        // Otherwise crement major.        // 1.0.0-5 bumps to 1.0.0        // 1.1.0 bumps to 2.0.0        if (          .mor !== 0 ||          .patch !== 0 ||          .prerelease.length === 0        ) {          .major++        }        .mor = 0        .patch = 0        .prerelease = []        break      case 'mor':        // If  is a pre-mor version, bump up to the same mor version.        // Otherwise crement mor.        // 1.2.0-5 bumps to 1.2.0        // 1.2.1 bumps to 1.3.0        if (.patch !== 0 || .prerelease.length === 0) {          .mor++        }        .patch = 0        .prerelease = []        break      case 'patch':        // If  is not a pre-release version, it will crement the patch.        // If it is a pre-release it will bump up to the same patch version.        // 1.2.0-5 patches to 1.2.0        // 1.2.0 patches to 1.2.1        if (.prerelease.length === 0) {          .patch++        }        .prerelease = []        break      // This probably shouldn't be used publicly.      // 1.0.0 'pre' would become 1.0.0-0 which is the wrong direction.      case 'pre':        if (.prerelease.length === 0) {          .prerelease = [0]        } else {          let i = .prerelease.length          while (--i >= 0) {            if (typeof .prerelease[i] === 'number') {              .prerelease[i]++              i = -2            }          }          if (i === -1) {            // didn't crement anythg            .prerelease.push(0)          }        }        if (identifier) {          // 1.2.0-beta.1 bumps to 1.2.0-beta.2,          // 1.2.0-beta.fooblz or 1.2.0-beta bumps to 1.2.0-beta.0          if (compIdentifiers(.prerelease[0], identifier) === 0) {            if (isNaN(.prerelease[1])) {              .prerelease = [identifier, 0]            }          } else {            .prerelease = [identifier, 0]          }        }        break      default:        throw new Error(`valid crement argument: ${release}`)    }    .format()    .raw = .version    return   }}module.exports = SemVer/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/clean.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/clean.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const parse = __webpack_require__(/*! ./parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js")const clean = (version, options) => {  const s = parse(version.trim().replace(/^[=v]+/, ''), options)  return s ? s.version : null}module.exports = clean/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/cmp.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/cmp.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const eq = __webpack_require__(/*! ./eq */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/eq.js")const neq = __webpack_require__(/*! ./neq */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/neq.js")const gt = __webpack_require__(/*! ./gt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js")const gte = __webpack_require__(/*! ./gte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gte.js")const lt = __webpack_require__(/*! ./lt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lt.js")const lte = __webpack_require__(/*! ./lte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lte.js")const cmp = (a, op, b, loose) => {  switch (op) {    case '===':      if (typeof a === 'object') {        a = a.version      }      if (typeof b === 'object') {        b = b.version      }      return a === b    case '!==':      if (typeof a === 'object') {        a = a.version      }      if (typeof b === 'object') {        b = b.version      }      return a !== b    case '':    case '=':    case '==':      return eq(a, b, loose)    case '!=':      return neq(a, b, loose)    case '>':      return gt(a, b, loose)    case '>=':      return gte(a, b, loose)    case '<':      return lt(a, b, loose)    case '<=':      return lte(a, b, loose)    default:      throw new TypeError(`Invalid operator: ${op}`)  }}module.exports = cmp/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/coerce.js":/*!************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/coerce.js ***!  \************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const parse = __webpack_require__(/*! ./parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js")const { re, t } = __webpack_require__(/*! ../ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")const coerce = (version, options) => {  if (version stanceof SemVer) {    return version  }  if (typeof version === 'number') {    version = Strg(version)  }  if (typeof version !== 'strg') {    return null  }  options = options || {}  let match = null  if (!options.rtl) {    match = version.match(re[t.COERCE])  } else {    // Fd the right-most coercible strg that does not sh    // a termus with a more left-ward coercible strg.    // Eg, '1.2.3.4' wants to coerce '2.3.4', not '3.4' or '4'    //    // Walk through the strg checkg with a /g regexp    // Manually set the dex so as to pick up overlappg matches.    // Stop when we get a match that ends at the strg end, sce no    // coercible strg can be more right-ward without the same termus.    let next    while ((next = re[t.COERCERTL].exec(version)) &&        (!match || match.dex + match[0].length !== version.length)    ) {      if (!match ||            next.dex + next[0].length !== match.dex + match[0].length) {        match = next      }      re[t.COERCERTL].lastIndex = next.dex + next[1].length + next[2].length    }    // leave it  a clean state    re[t.COERCERTL].lastIndex = -1  }  if (match === null) {    return null  }  return parse(`${match[2]}.${match[3] || '0'}.${match[4] || '0'}`, options)}module.exports = coerce/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-build.js":/*!*******************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-build.js ***!  \*******************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const compBuild = (a, b, loose) => {  const versionA = new SemVer(a, loose)  const versionB = new SemVer(b, loose)  return versionA.comp(versionB) || versionA.compBuild(versionB)}module.exports = compBuild/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-loose.js":/*!*******************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-loose.js ***!  \*******************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const compLoose = (a, b) => comp(a, b, true)module.exports = compLoose/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js":/*!*************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js ***!  \*************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const comp = (a, b, loose) =>  new SemVer(a, loose).comp(new SemVer(b, loose))module.exports = comp/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/diff.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/diff.js ***!  \**********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const parse = __webpack_require__(/*! ./parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js")const eq = __webpack_require__(/*! ./eq */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/eq.js")const diff = (version1, version2) => {  if (eq(version1, version2)) {    return null  } else {    const v1 = parse(version1)    const v2 = parse(version2)    const hasPre = v1.prerelease.length || v2.prerelease.length    const prefix = hasPre ? 'pre' : ''    const defaultResult = hasPre ? 'prerelease' : ''    for (const key  v1) {      if (key === 'major' || key === 'mor' || key === 'patch') {        if (v1[key] !== v2[key]) {          return prefix + key        }      }    }    return defaultResult // may be undefed  }}module.exports = diff/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/eq.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/eq.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const eq = (a, b, loose) => comp(a, b, loose) === 0module.exports = eq/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const gt = (a, b, loose) => comp(a, b, loose) > 0module.exports = gt/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gte.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gte.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const gte = (a, b, loose) => comp(a, b, loose) >= 0module.exports = gte/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/c.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/c.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const c = (version, release, options, identifier) => {  if (typeof (options) === 'strg') {    identifier = options    options = undefed  }  try {    return new SemVer(      version stanceof SemVer ? version.version : version,      options    ).c(release, identifier).version  } catch (er) {    return null  }}module.exports = c/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lt.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lt.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const lt = (a, b, loose) => comp(a, b, loose) < 0module.exports = lt/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lte.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lte.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const lte = (a, b, loose) => comp(a, b, loose) <= 0module.exports = lte/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/major.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/major.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const major = (a, loose) => new SemVer(a, loose).majormodule.exports = major/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/mor.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/mor.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const mor = (a, loose) => new SemVer(a, loose).mormodule.exports = mor/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/neq.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/neq.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const neq = (a, b, loose) => comp(a, b, loose) !== 0module.exports = neq/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const { MAX_LENGTH } = __webpack_require__(/*! ../ternal/constants */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js")const { re, t } = __webpack_require__(/*! ../ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const parseOptions = __webpack_require__(/*! ../ternal/parse-options */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js")const parse = (version, options) => {  options = parseOptions(options)  if (version stanceof SemVer) {    return version  }  if (typeof version !== 'strg') {    return null  }  if (version.length > MAX_LENGTH) {    return null  }  const r = options.loose ? re[t.LOOSE] : re[t.FULL]  if (!r.test(version)) {    return null  }  try {    return new SemVer(version, options)  } catch (er) {    return null  }}module.exports = parse/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/patch.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/patch.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const patch = (a, loose) => new SemVer(a, loose).patchmodule.exports = patch/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/prerelease.js":/*!****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/prerelease.js ***!  \****************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const parse = __webpack_require__(/*! ./parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js")const prerelease = (version, options) => {  const parsed = parse(version, options)  return (parsed && parsed.prerelease.length) ? parsed.prerelease : null}module.exports = prerelease/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rcomp.js":/*!**************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rcomp.js ***!  \**************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const comp = __webpack_require__(/*! ./comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")const rcomp = (a, b, loose) => comp(b, a, loose)module.exports = rcomp/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rsort.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rsort.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const compBuild = __webpack_require__(/*! ./comp-build */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-build.js")const rsort = (list, loose) => list.sort((a, b) => compBuild(b, a, loose))module.exports = rsort/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js":/*!***************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js ***!  \***************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const satisfies = (version, range, options) => {  try {    range = new Range(range, options)  } catch (er) {    return false  }  return range.test(version)}module.exports = satisfies/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/sort.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/sort.js ***!  \**********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const compBuild = __webpack_require__(/*! ./comp-build */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-build.js")const sort = (list, loose) => list.sort((a, b) => compBuild(a, b, loose))module.exports = sort/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/valid.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/valid.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const parse = __webpack_require__(/*! ./parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js")const valid = (version, options) => {  const v = parse(version, options)  return v ? v.version : null}module.exports = valid/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// just pre-load all the stuff that dex.js lazily exportsconst ternalRe = __webpack_require__(/*! ./ternal/re */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js")module.exports = {  re: ternalRe.re,  src: ternalRe.src,  tokens: ternalRe.t,  SEMVER_SPEC_VERSION: (__webpack_require__(/*! ./ternal/constants */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js").SEMVER_SPEC_VERSION),  SemVer: __webpack_require__(/*! ./classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js"),  compIdentifiers: (__webpack_require__(/*! ./ternal/identifiers */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/identifiers.js").compIdentifiers),  rcompIdentifiers: (__webpack_require__(/*! ./ternal/identifiers */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/identifiers.js").rcompIdentifiers),  parse: __webpack_require__(/*! ./functions/parse */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/parse.js"),  valid: __webpack_require__(/*! ./functions/valid */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/valid.js"),  clean: __webpack_require__(/*! ./functions/clean */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/clean.js"),  c: __webpack_require__(/*! ./functions/c */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/c.js"),  diff: __webpack_require__(/*! ./functions/diff */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/diff.js"),  major: __webpack_require__(/*! ./functions/major */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/major.js"),  mor: __webpack_require__(/*! ./functions/mor */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/mor.js"),  patch: __webpack_require__(/*! ./functions/patch */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/patch.js"),  prerelease: __webpack_require__(/*! ./functions/prerelease */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/prerelease.js"),  comp: __webpack_require__(/*! ./functions/comp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js"),  rcomp: __webpack_require__(/*! ./functions/rcomp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rcomp.js"),  compLoose: __webpack_require__(/*! ./functions/comp-loose */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-loose.js"),  compBuild: __webpack_require__(/*! ./functions/comp-build */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp-build.js"),  sort: __webpack_require__(/*! ./functions/sort */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/sort.js"),  rsort: __webpack_require__(/*! ./functions/rsort */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/rsort.js"),  gt: __webpack_require__(/*! ./functions/gt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js"),  lt: __webpack_require__(/*! ./functions/lt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lt.js"),  eq: __webpack_require__(/*! ./functions/eq */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/eq.js"),  neq: __webpack_require__(/*! ./functions/neq */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/neq.js"),  gte: __webpack_require__(/*! ./functions/gte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gte.js"),  lte: __webpack_require__(/*! ./functions/lte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lte.js"),  cmp: __webpack_require__(/*! ./functions/cmp */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/cmp.js"),  coerce: __webpack_require__(/*! ./functions/coerce */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/coerce.js"),  Comparator: __webpack_require__(/*! ./classes/comparator */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js"),  Range: __webpack_require__(/*! ./classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js"),  satisfies: __webpack_require__(/*! ./functions/satisfies */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js"),  toComparators: __webpack_require__(/*! ./ranges/to-comparators */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/to-comparators.js"),  maxSatisfyg: __webpack_require__(/*! ./ranges/max-satisfyg */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/max-satisfyg.js"),  mSatisfyg: __webpack_require__(/*! ./ranges/m-satisfyg */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-satisfyg.js"),  mVersion: __webpack_require__(/*! ./ranges/m-version */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-version.js"),  validRange: __webpack_require__(/*! ./ranges/valid */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/valid.js"),  outside: __webpack_require__(/*! ./ranges/outside */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/outside.js"),  gtr: __webpack_require__(/*! ./ranges/gtr */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/gtr.js"),  ltr: __webpack_require__(/*! ./ranges/ltr */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/ltr.js"),  tersects: __webpack_require__(/*! ./ranges/tersects */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/tersects.js"),  simplifyRange: __webpack_require__(/*! ./ranges/simplify */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/simplify.js"),  subset: __webpack_require__(/*! ./ranges/subset */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/subset.js"),}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js":/*!**************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js ***!  \**************************************************************************************************************//***/ ((module) => {// Note:  is the semver.org version of the spec that it implements// Not necessarily the package version of  code.const SEMVER_SPEC_VERSION = '2.0.0'const MAX_LENGTH = 256const MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER ||/* istanbul ignore next */ 9007199254740991// Max safe segment length for coercion.const MAX_SAFE_COMPONENT_LENGTH = 16module.exports = {  SEMVER_SPEC_VERSION,  MAX_LENGTH,  MAX_SAFE_INTEGER,  MAX_SAFE_COMPONENT_LENGTH,}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js ***!  \**********************************************************************************************************//***/ ((module) => {const debug = (  typeof process === 'object' &&  process.env &&  process.env.NODE_DEBUG &&  /\bsemver\b/i.test(process.env.NODE_DEBUG)) ? (...args) => console.error('SEMVER', ...args)  : () => {}module.exports = debug/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/identifiers.js":/*!****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/identifiers.js ***!  \****************************************************************************************************************//***/ ((module) => {const numeric = /^[0-9]+$/const compIdentifiers = (a, b) => {  const anum = numeric.test(a)  const bnum = numeric.test(b)  if (anum && bnum) {    a = +a    b = +b  }  return a === b ? 0    : (anum && !bnum) ? -1    : (bnum && !anum) ? 1    : a < b ? -1    : 1}const rcompIdentifiers = (a, b) => compIdentifiers(b, a)module.exports = {  compIdentifiers,  rcompIdentifiers,}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js":/*!******************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/parse-options.js ***!  \******************************************************************************************************************//***/ ((module) => {// parse out just the options we c about so we always get a consistent// obj with keys  a consistent order.const opts = ['cludePrerelease', 'loose', 'rtl']const parseOptions = options =>  !options ? {}  : typeof options !== 'object' ? { loose: true }  : opts.filter(k => options[k]).reduce((o, k) => {    o[k] = true    return o  }, {})module.exports = parseOptions/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js":/*!*******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/re.js ***!  \*******************************************************************************************************//***/ ((module, exports, __webpack_require__) => {const { MAX_SAFE_COMPONENT_LENGTH } = __webpack_require__(/*! ./constants */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/constants.js")const debug = __webpack_require__(/*! ./debug */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ternal/debug.js")exports = module.exports = {}//  actual regexps go on exports.reconst re = exports.re = []const src = exports.src = []const t = exports.t = {}let R = 0const createToken = (name, value, isGlobal) => {  const dex = R++  debug(name, dex, value)  t[name] = dex  src[dex] = value  re[dex] = new RegExp(value, isGlobal ? 'g' : undefed)}//  followg Regular Expressions can be used for tokenizg,// validatg,  parsg SemVer version strgs.// ## Numeric Identifier// A sgle `0`, or a non-zero digit followed  zero or more digits.createToken('NUMERICIDENTIFIER', '0|[1-9]\\d*')createToken('NUMERICIDENTIFIERLOOSE', '[0-9]+')// ## Non-numeric Identifier// Zero or more digits, followed  a letter or hyphen,  then zero or// more letters, digits, or hyphens.createToken('NONNUMERICIDENTIFIER', '\\d*[a-zA-Z-][a-zA-Z0-9-]*')// ## Ma Version// Three dot-separated numeric identifiers.createToken('MAINVERSION', `(${src[t.NUMERICIDENTIFIER]})\\.` +                   `(${src[t.NUMERICIDENTIFIER]})\\.` +                   `(${src[t.NUMERICIDENTIFIER]})`)createToken('MAINVERSIONLOOSE', `(${src[t.NUMERICIDENTIFIERLOOSE]})\\.` +                        `(${src[t.NUMERICIDENTIFIERLOOSE]})\\.` +                        `(${src[t.NUMERICIDENTIFIERLOOSE]})`)// ## Pre-release Version Identifier// A numeric identifier, or a non-numeric identifier.createToken('PRERELEASEIDENTIFIER', `(?:${src[t.NUMERICIDENTIFIER]}|${src[t.NONNUMERICIDENTIFIER]})`)createToken('PRERELEASEIDENTIFIERLOOSE', `(?:${src[t.NUMERICIDENTIFIERLOOSE]}|${src[t.NONNUMERICIDENTIFIER]})`)// ## Pre-release Version// Hyphen, followed  one or more dot-separated pre-release version// identifiers.createToken('PRERELEASE', `(?:-(${src[t.PRERELEASEIDENTIFIER]}(?:\\.${src[t.PRERELEASEIDENTIFIER]})*))`)createToken('PRERELEASELOOSE', `(?:-?(${src[t.PRERELEASEIDENTIFIERLOOSE]}(?:\\.${src[t.PRERELEASEIDENTIFIERLOOSE]})*))`)// ## Build Metadata Identifier// Any combation of digits, letters, or hyphens.createToken('BUILDIDENTIFIER', '[0-9A-Za-z-]+')// ## Build Metadata// Plus sign, followed  one or more period-separated build metadata// identifiers.createToken('BUILD', `(?:\\+(${src[t.BUILDIDENTIFIER]}(?:\\.${src[t.BUILDIDENTIFIER]})*))`)// ## Full Version Strg// A ma version, followed optionally  a pre-release version // build metadata.// Note that the only major, mor, patch,  pre-release sections of// the version strg  capturg groups.   build metadata is not a// capturg group, because it should not ever be used  version// comparison.createToken('FULLPLAIN', `v?${src[t.MAINVERSION]}${src[t.PRERELEASE]}?${  src[t.BUILD]}?`)createToken('FULL', `^${src[t.FULLPLAIN]}$`)// like full, but allows v1.2.3  =1.2.3, which people do sometimes.// also, 1.0.0alpha1 (prerelease without the hyphen) which is pretty// common  the npm registry.createToken('LOOSEPLAIN', `[v=\\s]*${src[t.MAINVERSIONLOOSE]}${src[t.PRERELEASELOOSE]}?${  src[t.BUILD]}?`)createToken('LOOSE', `^${src[t.LOOSEPLAIN]}$`)createToken('GTLT', '((?:<|>)?=?)')// Somethg like "2.*" or "1.2.x".// Note that "x.x" is a valid xRange identifer, meang "any version"// Only the first item is strictly required.createToken('XRANGEIDENTIFIERLOOSE', `${src[t.NUMERICIDENTIFIERLOOSE]}|x|X|\\*`)createToken('XRANGEIDENTIFIER', `${src[t.NUMERICIDENTIFIER]}|x|X|\\*`)createToken('XRANGEPLAIN', `[v=\\s]*(${src[t.XRANGEIDENTIFIER]})` +                   `(?:\\.(${src[t.XRANGEIDENTIFIER]})` +                   `(?:\\.(${src[t.XRANGEIDENTIFIER]})` +                   `(?:${src[t.PRERELEASE]})?${                     src[t.BUILD]}?` +                   `)?)?`)createToken('XRANGEPLAINLOOSE', `[v=\\s]*(${src[t.XRANGEIDENTIFIERLOOSE]})` +                        `(?:\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +                        `(?:\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +                        `(?:${src[t.PRERELEASELOOSE]})?${                          src[t.BUILD]}?` +                        `)?)?`)createToken('XRANGE', `^${src[t.GTLT]}\\s*${src[t.XRANGEPLAIN]}$`)createToken('XRANGELOOSE', `^${src[t.GTLT]}\\s*${src[t.XRANGEPLAINLOOSE]}$`)// Coercion.// Extract anythg that could conceivably be a part of a valid semvercreateToken('COERCE', `${'(^|[^\\d])' +              '(\\d{1,'}${MAX_SAFE_COMPONENT_LENGTH}})` +              `(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +              `(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +              `(?:$|[^\\d])`)createToken('COERCERTL', src[t.COERCE], true)// Tilde ranges.// Meang is "reasonably at or greater than"createToken('LONETILDE', '(?:~>?)')createToken('TILDETRIM', `(\\s*)${src[t.LONETILDE]}\\s+`, true)exports.tildeTrimReplace = '$1~'createToken('TILDE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAIN]}$`)createToken('TILDELOOSE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAINLOOSE]}$`)// Ct ranges.// Meang is "at least  backwards compatible with"createToken('LONECARET', '(?:\\^)')createToken('CARETTRIM', `(\\s*)${src[t.LONECARET]}\\s+`, true)exports.ctTrimReplace = '$1^'createToken('CARET', `^${src[t.LONECARET]}${src[t.XRANGEPLAIN]}$`)createToken('CARETLOOSE', `^${src[t.LONECARET]}${src[t.XRANGEPLAINLOOSE]}$`)// A simple gt/lt/eq thg, or just "" to dicate "any version"createToken('COMPARATORLOOSE', `^${src[t.GTLT]}\\s*(${src[t.LOOSEPLAIN]})$|^$`)createToken('COMPARATOR', `^${src[t.GTLT]}\\s*(${src[t.FULLPLAIN]})$|^$`)// An expression to strip any whitespace between the gtlt  the thg// it modifies, so that `> 1.2.3` ==> `>1.2.3`createToken('COMPARATORTRIM', `(\\s*)${src[t.GTLT]}\\s*(${src[t.LOOSEPLAIN]}|${src[t.XRANGEPLAIN]})`, true)exports.comparatorTrimReplace = '$1$2$3'// Somethg like `1.2.3 - 1.2.4`// Note that these all use the loose form, because they'll be// checked agast either the strict or loose comparator form// later.createToken('HYPHENRANGE', `^\\s*(${src[t.XRANGEPLAIN]})` +                   `\\s+-\\s+` +                   `(${src[t.XRANGEPLAIN]})` +                   `\\s*$`)createToken('HYPHENRANGELOOSE', `^\\s*(${src[t.XRANGEPLAINLOOSE]})` +                        `\\s+-\\s+` +                        `(${src[t.XRANGEPLAINLOOSE]})` +                        `\\s*$`)// Star ranges basically just allow anythg at all.createToken('STAR', '(<|>)?=?\\s*\\*')// >=0.0.0 is like a starcreateToken('GTE0', '^\\s*>=\\s*0\\.0\\.0\\s*$')createToken('GTE0PRE', '^\\s*>=\\s*0\\.0\\.0-0\\s*$')/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/gtr.js":/*!******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/gtr.js ***!  \******************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// Determe if version is greater than all the versions possible  the range.const outside = __webpack_require__(/*! ./outside */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/outside.js")const gtr = (version, range, options) => outside(version, range, '>', options)module.exports = gtr/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/tersects.js":/*!*************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/tersects.js ***!  \*************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const tersects = (r1, r2, options) => {  r1 = new Range(r1, options)  r2 = new Range(r2, options)  return r1.tersects(r2)}module.exports = tersects/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/ltr.js":/*!******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/ltr.js ***!  \******************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const outside = __webpack_require__(/*! ./outside */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/outside.js")// Determe if version is less than all the versions possible  the rangeconst ltr = (version, range, options) => outside(version, range, '<', options)module.exports = ltr/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/max-satisfyg.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/max-satisfyg.js ***!  \*****************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const maxSatisfyg = (versions, range, options) => {  let max = null  let maxSV = null  let rangeObj = null  try {    rangeObj = new Range(range, options)  } catch (er) {    return null  }  versions.forEach((v) => {    if (rangeObj.test(v)) {      // satisfies(v, range, options)      if (!max || maxSV.comp(v) === -1) {        // comp(max, v, true)        max = v        maxSV = new SemVer(max, options)      }    }  })  return max}module.exports = maxSatisfyg/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-satisfyg.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-satisfyg.js ***!  \*****************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const mSatisfyg = (versions, range, options) => {  let m = null  let mSV = null  let rangeObj = null  try {    rangeObj = new Range(range, options)  } catch (er) {    return null  }  versions.forEach((v) => {    if (rangeObj.test(v)) {      // satisfies(v, range, options)      if (!m || mSV.comp(v) === 1) {        // comp(m, v, true)        m = v        mSV = new SemVer(m, options)      }    }  })  return m}module.exports = mSatisfyg/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-version.js":/*!**************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/m-version.js ***!  \**************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const gt = __webpack_require__(/*! ../functions/gt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js")const mVersion = (range, loose) => {  range = new Range(range, loose)  let mver = new SemVer('0.0.0')  if (range.test(mver)) {    return mver  }  mver = new SemVer('0.0.0-0')  if (range.test(mver)) {    return mver  }  mver = null  for (let i = 0; i < range.set.length; ++i) {    const comparators = range.set[i]    let setM = null    comparators.forEach((comparator) => {      // Clone to avoid manipulatg the comparator's semver object.      const compver = new SemVer(comparator.semver.version)      switch (comparator.operator) {        case '>':          if (compver.prerelease.length === 0) {            compver.patch++          } else {            compver.prerelease.push(0)          }          compver.raw = compver.format()          /* fallthrough */        case '':        case '>=':          if (!setM || gt(compver, setM)) {            setM = compver          }          break        case '<':        case '<=':          /* Ignore maximum versions */          break        /* istanbul ignore next */        default:          throw new Error(`Unexpected operation: ${comparator.operator}`)      }    })    if (setM && (!mver || gt(mver, setM))) {      mver = setM    }  }  if (mver && range.test(mver)) {    return mver  }  return null}module.exports = mVersion/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/outside.js":/*!**********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/outside.js ***!  \**********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const SemVer = __webpack_require__(/*! ../classes/semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/semver.js")const Comparator = __webpack_require__(/*! ../classes/comparator */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js")const { ANY } = Comparatorconst Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const satisfies = __webpack_require__(/*! ../functions/satisfies */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js")const gt = __webpack_require__(/*! ../functions/gt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gt.js")const lt = __webpack_require__(/*! ../functions/lt */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lt.js")const lte = __webpack_require__(/*! ../functions/lte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/lte.js")const gte = __webpack_require__(/*! ../functions/gte */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/gte.js")const outside = (version, range, hilo, options) => {  version = new SemVer(version, options)  range = new Range(range, options)  let gtfn, ltefn, ltfn, comp, ecomp  switch (hilo) {    case '>':      gtfn = gt      ltefn = lte      ltfn = lt      comp = '>'      ecomp = '>='      break    case '<':      gtfn = lt      ltefn = gte      ltfn = gt      comp = '<'      ecomp = '<='      break    default:      throw new TypeError('Must provide a hilo val of "<" or ">"')  }  // If it satisfies the range it is not outside  if (satisfies(version, range, options)) {    return false  }  // From now on, variable terms  as if we're  "gtr" mode.  // but note that everythg is flipped for the "ltr" function.  for (let i = 0; i < range.set.length; ++i) {    const comparators = range.set[i]    let high = null    let low = null    comparators.forEach((comparator) => {      if (comparator.semver === ANY) {        comparator = new Comparator('>=0.0.0')      }      high = high || comparator      low = low || comparator      if (gtfn(comparator.semver, high.semver, options)) {        high = comparator      } else if (ltfn(comparator.semver, low.semver, options)) {        low = comparator      }    })    // If the edge version comparator has a operator then our version    // isn't outside it    if (high.operator === comp || high.operator === ecomp) {      return false    }    // If the lowest version comparator has an operator  our version    // is less than it then it isn't higher than the range    if ((!low.operator || low.operator === comp) &&        ltefn(version, low.semver)) {      return false    } else if (low.operator === ecomp && ltfn(version, low.semver)) {      return false    }  }  return true}module.exports = outside/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/simplify.js":/*!***********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/simplify.js ***!  \***********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// given a set of versions  a range, create a "simplified" range// that cludes the same versions that the origal range does// If the origal range is shorter than the simplified one, return that.const satisfies = __webpack_require__(/*! ../functions/satisfies.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js")const comp = __webpack_require__(/*! ../functions/comp.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")module.exports = (versions, range, options) => {  const set = []  let first = null  let prev = null  const v = versions.sort((a, b) => comp(a, b, options))  for (const version of v) {    const cluded = satisfies(version, range, options)    if (cluded) {      prev = version      if (!first) {        first = version      }    } else {      if (prev) {        set.push([first, prev])      }      prev = null      first = null    }  }  if (first) {    set.push([first, null])  }  const ranges = []  for (const [m, max] of set) {    if (m === max) {      ranges.push(m)    } else if (!max && m === v[0]) {      ranges.push('*')    } else if (!max) {      ranges.push(`>=${m}`)    } else if (m === v[0]) {      ranges.push(`<=${max}`)    } else {      ranges.push(`${m} - ${max}`)    }  }  const simplified = ranges.jo(' || ')  const origal = typeof range.raw === 'strg' ? range.raw : Strg(range)  return simplified.length < origal.length ? simplified : range}/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/subset.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/subset.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const Range = __webpack_require__(/*! ../classes/range.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const Comparator = __webpack_require__(/*! ../classes/comparator.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/comparator.js")const { ANY } = Comparatorconst satisfies = __webpack_require__(/*! ../functions/satisfies.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/satisfies.js")const comp = __webpack_require__(/*! ../functions/comp.js */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/functions/comp.js")// Complex range `r1 || r2 || ...` is a subset of `R1 || R2 || ...` iff:// - Every simple range `r1, r2, ...` is a null set, OR// - Every simple range `r1, r2, ...` which is not a null set is a subset of//   some `R1, R2, ...`//// Simple range `c1 c2 ...` is a subset of simple range `C1 C2 ...` iff:// - If c is only the ANY comparator//   - If C is only the ANY comparator, return true//   - Else if  prerelease mode, return false//   - else replace c with `[>=0.0.0]`// - If C is only the ANY comparator//   - if  prerelease mode, return true//   - else replace C with `[>=0.0.0]`// - Let EQ be the set of = comparators  c// - If EQ is more than one, return true (null set)// - Let GT be the highest > or >= comparator  c// - Let LT be the lowest < or <= comparator  c// - If GT  LT,  GT.semver > LT.semver, return true (null set)// - If any C is a = range,  GT or LT  set, return false// - If EQ//   - If GT,  EQ does not satisfy GT, return true (null set)//   - If LT,  EQ does not satisfy LT, return true (null set)//   - If EQ satisfies every C, return true//   - Else return false// - If GT//   - If GT.semver is lower than any > or >= comp  C, return false//   - If GT is >=,  GT.semver does not satisfy every C, return false//   - If GT.semver has a prerelease,  not  prerelease mode//     - If no C has a prerelease  the GT.semver tuple, return false// - If LT//   - If LT.semver is greater than any < or <= comp  C, return false//   - If LT is <=,  LT.semver does not satisfy every C, return false//   - If GT.semver has a prerelease,  not  prerelease mode//     - If no C has a prerelease  the LT.semver tuple, return false// - Else return trueconst subset = (sub, dom, options = {}) => {  if (sub === dom) {    return true  }  sub = new Range(sub, options)  dom = new Range(dom, options)  let sawNonNull = false  OUTER: for (const simpleSub of sub.set) {    for (const simpleDom of dom.set) {      const isSub = simpleSubset(simpleSub, simpleDom, options)      sawNonNull = sawNonNull || isSub !== null      if (isSub) {        contue OUTER      }    }    // the null set is a subset of everythg, but null simple ranges     // a complex range should be ignored.  so if we saw a non-null range,    // then we know  isn't a subset, but if EVERY simple range was null,    // then it is a subset.    if (sawNonNull) {      return false    }  }  return true}const simpleSubset = (sub, dom, options) => {  if (sub === dom) {    return true  }  if (sub.length === 1 && sub[0].semver === ANY) {    if (dom.length === 1 && dom[0].semver === ANY) {      return true    } else if (options.cludePrerelease) {      sub = [new Comparator('>=0.0.0-0')]    } else {      sub = [new Comparator('>=0.0.0')]    }  }  if (dom.length === 1 && dom[0].semver === ANY) {    if (options.cludePrerelease) {      return true    } else {      dom = [new Comparator('>=0.0.0')]    }  }  const eqSet = new Set()  let gt, lt  for (const c of sub) {    if (c.operator === '>' || c.operator === '>=') {      gt = higherGT(gt, c, options)    } else if (c.operator === '<' || c.operator === '<=') {      lt = lowerLT(lt, c, options)    } else {      eqSet.add(c.semver)    }  }  if (eqSet.size > 1) {    return null  }  let gtltComp  if (gt && lt) {    gtltComp = comp(gt.semver, lt.semver, options)    if (gtltComp > 0) {      return null    } else if (gtltComp === 0 && (gt.operator !== '>=' || lt.operator !== '<=')) {      return null    }  }  // will iterate one or zero times  for (const eq of eqSet) {    if (gt && !satisfies(eq, Strg(gt), options)) {      return null    }    if (lt && !satisfies(eq, Strg(lt), options)) {      return null    }    for (const c of dom) {      if (!satisfies(eq, Strg(c), options)) {        return false      }    }    return true  }  let higher, lower  let hasDomLT, hasDomGT  // if the subset has a prerelease, we need a comparator  the superset  // with the same tuple  a prerelease, or it's not a subset  let needDomLTPre = lt &&    !options.cludePrerelease &&    lt.semver.prerelease.length ? lt.semver : false  let needDomGTPre = gt &&    !options.cludePrerelease &&    gt.semver.prerelease.length ? gt.semver : false  // exception: <1.2.3-0 is the same as <1.2.3  if (needDomLTPre && needDomLTPre.prerelease.length === 1 &&      lt.operator === '<' && needDomLTPre.prerelease[0] === 0) {    needDomLTPre = false  }  for (const c of dom) {    hasDomGT = hasDomGT || c.operator === '>' || c.operator === '>='    hasDomLT = hasDomLT || c.operator === '<' || c.operator === '<='    if (gt) {      if (needDomGTPre) {        if (c.semver.prerelease && c.semver.prerelease.length &&            c.semver.major === needDomGTPre.major &&            c.semver.mor === needDomGTPre.mor &&            c.semver.patch === needDomGTPre.patch) {          needDomGTPre = false        }      }      if (c.operator === '>' || c.operator === '>=') {        higher = higherGT(gt, c, options)        if (higher === c && higher !== gt) {          return false        }      } else if (gt.operator === '>=' && !satisfies(gt.semver, Strg(c), options)) {        return false      }    }    if (lt) {      if (needDomLTPre) {        if (c.semver.prerelease && c.semver.prerelease.length &&            c.semver.major === needDomLTPre.major &&            c.semver.mor === needDomLTPre.mor &&            c.semver.patch === needDomLTPre.patch) {          needDomLTPre = false        }      }      if (c.operator === '<' || c.operator === '<=') {        lower = lowerLT(lt, c, options)        if (lower === c && lower !== lt) {          return false        }      } else if (lt.operator === '<=' && !satisfies(lt.semver, Strg(c), options)) {        return false      }    }    if (!c.operator && (lt || gt) && gtltComp !== 0) {      return false    }  }  // if there was a < or >,  nothg  the dom, then must be false  // UNLESS it was limited  another range  the other direction.  // Eg, >1.0.0 <1.0.1 is still a subset of <2.0.0  if (gt && hasDomLT && !lt && gtltComp !== 0) {    return false  }  if (lt && hasDomGT && !gt && gtltComp !== 0) {    return false  }  // we needed a prerelease range  a specific tuple, but didn't get one  // then  isn't a subset.  eg >=1.2.3-pre is not a subset of >=1.0.0,  // because it cludes prereleases  the 1.2.3 tuple  if (needDomGTPre || needDomLTPre) {    return false  }  return true}// >=1.2.3 is lower than >1.2.3const higherGT = (a, b, options) => {  if (!a) {    return b  }  const comp = comp(a.semver, b.semver, options)  return comp > 0 ? a    : comp < 0 ? b    : b.operator === '>' && a.operator === '>=' ? b    : a}// <=1.2.3 is higher than <1.2.3const lowerLT = (a, b, options) => {  if (!a) {    return b  }  const comp = comp(a.semver, b.semver, options)  return comp < 0 ? a    : comp > 0 ? b    : b.operator === '<' && a.operator === '<=' ? b    : a}module.exports = subset/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/to-comparators.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/to-comparators.js ***!  \*****************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")// Mostly just for testg  legacy API reasonsconst toComparators = (range, options) =>  new Range(range, options).set    .map(comp => comp.map(c => c.value).jo(' ').trim().split(' '))module.exports = toComparators/***/ }),/***/ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/valid.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/ranges/valid.js ***!  \********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const Range = __webpack_require__(/*! ../classes/range */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/classes/range.js")const validRange = (range, options) => {  try {    // Return '*' stead of '' so that truthess works.    // This will throw if it's valid anyway    return new Range(range, options).range || '*'  } catch (er) {    return null  }}module.exports = validRange/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/dex.js":/*!********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/dex.js ***!  \********************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";// high-level commsexports.c = exports.create = __webpack_require__(/*! ./lib/create.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/create.js")exports.r = exports.replace = __webpack_require__(/*! ./lib/replace.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/replace.js")exports.t = exports.list = __webpack_require__(/*! ./lib/list.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/list.js")exports.u = exports.update = __webpack_require__(/*! ./lib/update.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/update.js")exports.x = exports.extract = __webpack_require__(/*! ./lib/extract.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/extract.js")// classesexports.Pack = __webpack_require__(/*! ./lib/pack.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pack.js")exports.Unpack = __webpack_require__(/*! ./lib/unpack.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/unpack.js")exports.Parse = __webpack_require__(/*! ./lib/parse.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/parse.js")exports.ReadEntry = __webpack_require__(/*! ./lib/read-entry.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/read-entry.js")exports.WriteEntry = __webpack_require__(/*! ./lib/write-entry.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/write-entry.js")exports.Header = __webpack_require__(/*! ./lib/header.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js")exports.Pax = __webpack_require__(/*! ./lib/pax.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pax.js")exports.types = __webpack_require__(/*! ./lib/types.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/types.js")/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/create.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/create.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// tar -cconst hlo = __webpack_require__(/*! ./high-level-opt.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js")const Pack = __webpack_require__(/*! ./pack.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pack.js")const fsm = __webpack_require__(/*! fs-mipass */ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js")const t = __webpack_require__(/*! ./list.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/list.js")const path = __webpack_require__(/*! path */ "path")module.exports = (opt_, files, cb) => {  if (typeof files === 'function')    cb = files  if (Array.isArray(opt_))    files = opt_, opt_ = {}  if (!files || !Array.isArray(files) || !files.length)    throw new TypeError('no files or directories specified')  files = Array.from(files)  const opt = hlo(opt_)  if (opt.sync && typeof cb === 'function')    throw new TypeError('callback not supported for sync tar functions')  if (!opt.file && typeof cb === 'function')    throw new TypeError('callback only supported with file option')  return opt.file && opt.sync ? createFileSync(opt, files)    : opt.file ? createFile(opt, files, cb)    : opt.sync ? createSync(opt, files)    : create(opt, files)}const createFileSync = (opt, files) => {  const p = new Pack.Sync(opt)  const stream = new fsm.WriteStreamSync(opt.file, {    mode: opt.mode || 0o666,  })  p.pipe(stream)  addFilesSync(p, files)}const createFile = (opt, files, cb) => {  const p = new Pack(opt)  const stream = new fsm.WriteStream(opt.file, {    mode: opt.mode || 0o666,  })  p.pipe(stream)  const promise = new Promise((res, rej) => {    stream.on('error', rej)    stream.on('close', res)    p.on('error', rej)  })  addFilesAsync(p, files)  return cb ? promise.then(cb, cb) : promise}const addFilesSync = (p, files) => {  files.forEach(file => {    if (file.charAt(0) === '@') {      t({        file: path.resolve(p.cwd, file.substr(1)),        sync: true,        noResume: true,        onentry: entry => p.add(entry),      })    } else      p.add(file)  })  p.end()}const addFilesAsync = (p, files) => {  while (files.length) {    const file = files.shift()    if (file.charAt(0) === '@') {      return t({        file: path.resolve(p.cwd, file.substr(1)),        noResume: true,        onentry: entry => p.add(entry),      }).then(_ => addFilesAsync(p, files))    } else      p.add(file)  }  p.end()}const createSync = (opt, files) => {  const p = new Pack.Sync(opt)  addFilesSync(p, files)  return p}const create = (opt, files) => {  const p = new Pack(opt)  addFilesAsync(p, files)  return p}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/extract.js":/*!**************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/extract.js ***!  \**************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// tar -xconst hlo = __webpack_require__(/*! ./high-level-opt.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js")const Unpack = __webpack_require__(/*! ./unpack.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/unpack.js")const fs = __webpack_require__(/*! fs */ "fs")const fsm = __webpack_require__(/*! fs-mipass */ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js")const path = __webpack_require__(/*! path */ "path")const stripSlash = __webpack_require__(/*! ./strip-trailg-slashes.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js")module.exports = (opt_, files, cb) => {  if (typeof opt_ === 'function')    cb = opt_, files = null, opt_ = {}  else if (Array.isArray(opt_))    files = opt_, opt_ = {}  if (typeof files === 'function')    cb = files, files = null  if (!files)    files = []  else    files = Array.from(files)  const opt = hlo(opt_)  if (opt.sync && typeof cb === 'function')    throw new TypeError('callback not supported for sync tar functions')  if (!opt.file && typeof cb === 'function')    throw new TypeError('callback only supported with file option')  if (files.length)    filesFilter(opt, files)  return opt.file && opt.sync ? extractFileSync(opt)    : opt.file ? extractFile(opt, cb)    : opt.sync ? extractSync(opt)    : extract(opt)}// construct a filter that limits the file entries listed// clude child entries if a dir is cludedconst filesFilter = (opt, files) => {  const map = new Map(files.map(f => [stripSlash(f), true]))  const filter = opt.filter  const mapHas = (file, r) => {    const root = r || path.parse(file).root || '.'    const ret = file === root ? false      : map.has(file) ? map.get(file)      : mapHas(path.dirname(file), root)    map.set(file, ret)    return ret  }  opt.filter = filter    ? (file, entry) => filter(file, entry) && mapHas(stripSlash(file))    : file => mapHas(stripSlash(file))}const extractFileSync = opt => {  const u = new Unpack.Sync(opt)  const file = opt.file  const stat = fs.statSync(file)  // This trades a zero-te read() syscall for a stat  // However, it will usually result  less memory allocation  const readSize = opt.maxReadSize || 16 * 1024 * 1024  const stream = new fsm.ReadStreamSync(file, {    readSize: readSize,    size: stat.size,  })  stream.pipe(u)}const extractFile = (opt, cb) => {  const u = new Unpack(opt)  const readSize = opt.maxReadSize || 16 * 1024 * 1024  const file = opt.file  const p = new Promise((resolve, reject) => {    u.on('error', reject)    u.on('close', resolve)    // This trades a zero-te read() syscall for a stat    // However, it will usually result  less memory allocation    fs.stat(file, (er, stat) => {      if (er)        reject(er)      else {        const stream = new fsm.ReadStream(file, {          readSize: readSize,          size: stat.size,        })        stream.on('error', reject)        stream.pipe(u)      }    })  })  return cb ? p.then(cb, cb) : p}const extractSync = opt => new Unpack.Sync(opt)const extract = opt => new Unpack(opt)/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/get-write-flag.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/get-write-flag.js ***!  \*********************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// Get the appropriate flag to use for creatg files// We use fmap on Wdows platforms for files less than// 512kb.  This is a fairly low limit, but avoids makg// thgs slower  some cases.  Sce most of what // library is used for is extractg tarballs of many// relatively small files  npm packages  the like,// it can be a big boost on Wdows platforms.// Only supported  Node v12.9.0  above.const platform = process.env.__FAKE_PLATFORM__ || process.platformconst isWdows = platform === 'w32'const fs = global.__FAKE_TESTING_FS__ || __webpack_require__(/*! fs */ "fs")/* istanbul ignore next */const { O_CREAT, O_TRUNC, O_WRONLY, UV_FS_O_FILEMAP = 0 } = fs.constantsconst fMapEnabled = isWdows && !!UV_FS_O_FILEMAPconst fMapLimit = 512 * 1024const fMapFlag = UV_FS_O_FILEMAP | O_TRUNC | O_CREAT | O_WRONLYmodule.exports = !fMapEnabled ? () => 'w'  : size => size < fMapLimit ? fMapFlag : 'w'/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// parse a 512-te header block to a data object, or vice-versa// encode returns `true` if a pax extended header is needed, because// the data could not be faithfully encoded  a simple header.// (Also, check header.needPax to see if it needs a pax header.)const types = __webpack_require__(/*! ./types.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/types.js")const pathModule = (__webpack_require__(/*! path */ "path").posix)const large = __webpack_require__(/*! ./large-numbers.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/large-numbers.js")const SLURP = Symbol('slurp')const TYPE = Symbol('type')class Header {  constructor (data, off, ex, gex) {    .cksumValid = false    .needPax = false    .nullBlock = false    .block = null    .path = null    .mode = null    .uid = null    .gid = null    .size = null    .mtime = null    .cksum = null    [TYPE] = '0'    .lkpath = null    .uname = null    .gname = null    .devmaj = 0    .devm = 0    .atime = null    .ctime = null    if (Buffer.isBuffer(data))      .decode(data, off || 0, ex, gex)    else if (data)      .set(data)  }  decode (buf, off, ex, gex) {    if (!off)      off = 0    if (!buf || !(buf.length >= off + 512))      throw new Error('need 512 tes for header')    .path = decStrg(buf, off, 100)    .mode = decNumber(buf, off + 100, 8)    .uid = decNumber(buf, off + 108, 8)    .gid = decNumber(buf, off + 116, 8)    .size = decNumber(buf, off + 124, 12)    .mtime = decDate(buf, off + 136, 12)    .cksum = decNumber(buf, off + 148, 12)    // if we have extended or global extended headers, apply them now    // See https://github.com/npm/node-tar/pull/187    [SLURP](ex)    [SLURP](gex, true)    // old tar versions marked dirs as a file with a trailg /    [TYPE] = decStrg(buf, off + 156, 1)    if ([TYPE] === '')      [TYPE] = '0'    if ([TYPE] === '0' && .path.substr(-1) === '/')      [TYPE] = '5'    // tar implementations sometimes correctly put the stat(dir).size    // as the size  the tarball, even though Directory entries     // not able to have any body at all.  In the very r chance that    // it actually DOES have a body, we weren't gog to do anythg with    // it anyway,  it'll just be a warng about an valid header.    if ([TYPE] === '5')      .size = 0    .lkpath = decStrg(buf, off + 157, 100)    if (buf.slice(off + 257, off + 265).toStrg() === 'ustar\u000000') {      .uname = decStrg(buf, off + 265, 32)      .gname = decStrg(buf, off + 297, 32)      .devmaj = decNumber(buf, off + 329, 8)      .devm = decNumber(buf, off + 337, 8)      if (buf[off + 475] !== 0) {        // defitely a prefix, defitely >130 chars.        const prefix = decStrg(buf, off + 345, 155)        .path = prefix + '/' + .path      } else {        const prefix = decStrg(buf, off + 345, 130)        if (prefix)          .path = prefix + '/' + .path        .atime = decDate(buf, off + 476, 12)        .ctime = decDate(buf, off + 488, 12)      }    }    let sum = 8 * 0x20    for (let i = off; i < off + 148; i++)      sum += buf[i]    for (let i = off + 156; i < off + 512; i++)      sum += buf[i]    .cksumValid = sum === .cksum    if (.cksum === null && sum === 8 * 0x20)      .nullBlock = true  }  [SLURP] (ex, global) {    for (const k  ex) {      // we slurp  everythg except for the path attribute       // a global extended header, because that's weird.      if (ex[k] !== null && ex[k] !== undefed &&          !(global && k === 'path'))        [k] = ex[k]    }  }  encode (buf, off) {    if (!buf) {      buf = .block = Buffer.alloc(512)      off = 0    }    if (!off)      off = 0    if (!(buf.length >= off + 512))      throw new Error('need 512 tes for header')    const prefixSize = .ctime || .atime ? 130 : 155    const split = splitPrefix(.path || '', prefixSize)    const path = split[0]    const prefix = split[1]    .needPax = split[2]    .needPax = encStrg(buf, off, 100, path) || .needPax    .needPax = encNumber(buf, off + 100, 8, .mode) || .needPax    .needPax = encNumber(buf, off + 108, 8, .uid) || .needPax    .needPax = encNumber(buf, off + 116, 8, .gid) || .needPax    .needPax = encNumber(buf, off + 124, 12, .size) || .needPax    .needPax = encDate(buf, off + 136, 12, .mtime) || .needPax    buf[off + 156] = [TYPE].charCodeAt(0)    .needPax = encStrg(buf, off + 157, 100, .lkpath) || .needPax    buf.write('ustar\u000000', off + 257, 8)    .needPax = encStrg(buf, off + 265, 32, .uname) || .needPax    .needPax = encStrg(buf, off + 297, 32, .gname) || .needPax    .needPax = encNumber(buf, off + 329, 8, .devmaj) || .needPax    .needPax = encNumber(buf, off + 337, 8, .devm) || .needPax    .needPax = encStrg(buf, off + 345, prefixSize, prefix) || .needPax    if (buf[off + 475] !== 0)      .needPax = encStrg(buf, off + 345, 155, prefix) || .needPax    else {      .needPax = encStrg(buf, off + 345, 130, prefix) || .needPax      .needPax = encDate(buf, off + 476, 12, .atime) || .needPax      .needPax = encDate(buf, off + 488, 12, .ctime) || .needPax    }    let sum = 8 * 0x20    for (let i = off; i < off + 148; i++)      sum += buf[i]    for (let i = off + 156; i < off + 512; i++)      sum += buf[i]    .cksum = sum    encNumber(buf, off + 148, 8, .cksum)    .cksumValid = true    return .needPax  }  set (data) {    for (const i  data) {      if (data[i] !== null && data[i] !== undefed)        [i] = data[i]    }  }  get type () {    return types.name.get([TYPE]) || [TYPE]  }  get typeKey () {    return [TYPE]  }  set type (type) {    if (types.code.has(type))      [TYPE] = types.code.get(type)    else      [TYPE] = type  }}const splitPrefix = (p, prefixSize) => {  const pathSize = 100  let pp = p  let prefix = ''  let ret  const root = pathModule.parse(p).root || '.'  if (Buffer.teLength(pp) < pathSize)    ret = [pp, prefix, false]  else {    // first set prefix to the dir,  path to the base    prefix = pathModule.dirname(pp)    pp = pathModule.basename(pp)    do {      // both fit!      if (Buffer.teLength(pp) <= pathSize &&          Buffer.teLength(prefix) <= prefixSize)        ret = [pp, prefix, false]      // prefix fits  prefix, but path doesn't fit  path      else if (Buffer.teLength(pp) > pathSize &&          Buffer.teLength(prefix) <= prefixSize)        ret = [pp.substr(0, pathSize - 1), prefix, true]      else {        // make path take a bit from prefix        pp = pathModule.jo(pathModule.basename(prefix), pp)        prefix = pathModule.dirname(prefix)      }    } while (prefix !== root && !ret)    // at  pot, found no resolution, just truncate    if (!ret)      ret = [p.substr(0, pathSize - 1), '', true]  }  return ret}const decStrg = (buf, off, size) =>  buf.slice(off, off + size).toStrg('utf8').replace(/\0.*/, '')const decDate = (buf, off, size) =>  numToDate(decNumber(buf, off, size))const numToDate = num => num === null ? null : new Date(num * 1000)const decNumber = (buf, off, size) =>  buf[off] & 0x80 ? large.parse(buf.slice(off, off + size))  : decSmallNumber(buf, off, size)const nanNull = value => isNaN(value) ? null : valueconst decSmallNumber = (buf, off, size) =>  nanNull(parseInt(    buf.slice(off, off + size)      .toStrg('utf8').replace(/\0.*$/, '').trim(), 8))// the maximum encodable as a null-termated octal,  field sizeconst MAXNUM = {  12: 0o77777777777,  8: 0o7777777,}const encNumber = (buf, off, size, number) =>  number === null ? false :  number > MAXNUM[size] || number < 0    ? (large.encode(number, buf.slice(off, off + size)), true)    : (encSmallNumber(buf, off, size, number), false)const encSmallNumber = (buf, off, size, number) =>  buf.write(octalStrg(number, size), off, size, 'ascii')const octalStrg = (number, size) =>  padOctal(Math.floor(number).toStrg(8), size)const padOctal = (strg, size) =>  (strg.length === size - 1 ? strg  : new Array(size - strg.length - 1).jo('0') + strg + ' ') + '\0'const encDate = (buf, off, size, date) =>  date === null ? false :  encNumber(buf, off, size, date.getTime() / 1000)// enough to fill the longest strg we've gotconst NULLS = new Array(156).jo('\0')// pad with nulls, return true if it's longer or non-asciiconst encStrg = (buf, off, size, strg) =>  strg === null ? false :  (buf.write(strg + NULLS, off, size, 'utf8'),  strg.length !== Buffer.teLength(strg) || strg.length > size)module.exports = Header/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js ***!  \*********************************************************************************************************//***/ ((module) => {"use strict";// turn tar(1) style args like `C` to the more verbose thgs like `cwd`const argmap = new Map([  ['C', 'cwd'],  ['f', 'file'],  ['z', 'gzip'],  ['P', 'preservePaths'],  ['U', 'unlk'],  ['strip-components', 'strip'],  ['stripComponents', 'strip'],  ['keep-newer', 'newer'],  ['keepNewer', 'newer'],  ['keep-newer-files', 'newer'],  ['keepNewerFiles', 'newer'],  ['k', 'keep'],  ['keep-existg', 'keep'],  ['keepExistg', 'keep'],  ['m', 'noMtime'],  ['no-mtime', 'noMtime'],  ['p', 'preserveOwner'],  ['L', 'follow'],  ['h', 'follow'],])module.exports = opt => opt ? Object.keys(opt).map(k => [  argmap.has(k) ? argmap.get(k) : k, opt[k],]).reduce((set, kv) => (set[kv[0]] = kv[1], set), Object.create(null)) : {}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/large-numbers.js":/*!********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/large-numbers.js ***!  \********************************************************************************************************//***/ ((module) => {"use strict";// Tar can encode large  negative numbers usg a leadg te of// 0xff for negative,  0x80 for positive.const encode = (num, buf) => {  if (!Number.isSafeInteger(num))    //  number is so large that javascript cannot represent it with teger    // precision.    throw Error('cannot encode number outside of javascript safe teger range')  else if (num < 0)    encodeNegative(num, buf)  else    encodePositive(num, buf)  return buf}const encodePositive = (num, buf) => {  buf[0] = 0x80  for (var i = buf.length; i > 1; i--) {    buf[i - 1] = num & 0xff    num = Math.floor(num / 0x100)  }}const encodeNegative = (num, buf) => {  buf[0] = 0xff  var flipped = false  num = num * -1  for (var i = buf.length; i > 1; i--) {    var te = num & 0xff    num = Math.floor(num / 0x100)    if (flipped)      buf[i - 1] = onesComp(te)    else if (te === 0)      buf[i - 1] = 0    else {      flipped = true      buf[i - 1] = twosComp(te)    }  }}const parse = (buf) => {  const pre = buf[0]  const value = pre === 0x80 ? pos(buf.slice(1, buf.length))    : pre === 0xff ? twos(buf)    : null  if (value === null)    throw Error('valid base256 encodg')  if (!Number.isSafeInteger(value))    //  number is so large that javascript cannot represent it with teger    // precision.    throw Error('parsed number outside of javascript safe teger range')  return value}const twos = (buf) => {  var len = buf.length  var sum = 0  var flipped = false  for (var i = len - 1; i > -1; i--) {    var te = buf[i]    var f    if (flipped)      f = onesComp(te)    else if (te === 0)      f = te    else {      flipped = true      f = twosComp(te)    }    if (f !== 0)      sum -= f * Math.pow(256, len - i - 1)  }  return sum}const pos = (buf) => {  var len = buf.length  var sum = 0  for (var i = len - 1; i > -1; i--) {    var te = buf[i]    if (te !== 0)      sum += te * Math.pow(256, len - i - 1)  }  return sum}const onesComp = te => (0xff ^ te) & 0xffconst twosComp = te => ((0xff ^ te) + 1) & 0xffmodule.exports = {  encode,  parse,}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/list.js":/*!***********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/list.js ***!  \***********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// XXX: This shs a lot  common with extract.js// maybe some DRY opportunity here?// tar -tconst hlo = __webpack_require__(/*! ./high-level-opt.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js")const Parser = __webpack_require__(/*! ./parse.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/parse.js")const fs = __webpack_require__(/*! fs */ "fs")const fsm = __webpack_require__(/*! fs-mipass */ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js")const path = __webpack_require__(/*! path */ "path")const stripSlash = __webpack_require__(/*! ./strip-trailg-slashes.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js")module.exports = (opt_, files, cb) => {  if (typeof opt_ === 'function')    cb = opt_, files = null, opt_ = {}  else if (Array.isArray(opt_))    files = opt_, opt_ = {}  if (typeof files === 'function')    cb = files, files = null  if (!files)    files = []  else    files = Array.from(files)  const opt = hlo(opt_)  if (opt.sync && typeof cb === 'function')    throw new TypeError('callback not supported for sync tar functions')  if (!opt.file && typeof cb === 'function')    throw new TypeError('callback only supported with file option')  if (files.length)    filesFilter(opt, files)  if (!opt.noResume)    onentryFunction(opt)  return opt.file && opt.sync ? listFileSync(opt)    : opt.file ? listFile(opt, cb)    : list(opt)}const onentryFunction = opt => {  const onentry = opt.onentry  opt.onentry = onentry ? e => {    onentry(e)    e.resume()  } : e => e.resume()}// construct a filter that limits the file entries listed// clude child entries if a dir is cludedconst filesFilter = (opt, files) => {  const map = new Map(files.map(f => [stripSlash(f), true]))  const filter = opt.filter  const mapHas = (file, r) => {    const root = r || path.parse(file).root || '.'    const ret = file === root ? false      : map.has(file) ? map.get(file)      : mapHas(path.dirname(file), root)    map.set(file, ret)    return ret  }  opt.filter = filter    ? (file, entry) => filter(file, entry) && mapHas(stripSlash(file))    : file => mapHas(stripSlash(file))}const listFileSync = opt => {  const p = list(opt)  const file = opt.file  let threw = true  let fd  try {    const stat = fs.statSync(file)    const readSize = opt.maxReadSize || 16 * 1024 * 1024    if (stat.size < readSize)      p.end(fs.readFileSync(file))    else {      let pos = 0      const buf = Buffer.allocUnsafe(readSize)      fd = fs.openSync(file, 'r')      while (pos < stat.size) {        const tesRead = fs.readSync(fd, buf, 0, readSize, pos)        pos += tesRead        p.write(buf.slice(0, tesRead))      }      p.end()    }    threw = false  } fally {    if (threw && fd) {      try {        fs.closeSync(fd)      } catch (er) {}    }  }}const listFile = (opt, cb) => {  const parse = new Parser(opt)  const readSize = opt.maxReadSize || 16 * 1024 * 1024  const file = opt.file  const p = new Promise((resolve, reject) => {    parse.on('error', reject)    parse.on('end', resolve)    fs.stat(file, (er, stat) => {      if (er)        reject(er)      else {        const stream = new fsm.ReadStream(file, {          readSize: readSize,          size: stat.size,        })        stream.on('error', reject)        stream.pipe(parse)      }    })  })  return cb ? p.then(cb, cb) : p}const list = opt => new Parser(opt)/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mkdir.js":/*!************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mkdir.js ***!  \************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// wrapper around mkdirp for tar's needs.// TODO: This should probably be a class, not functionally// passg around state  a gazillion args.const mkdirp = __webpack_require__(/*! mkdirp */ "../../../.yarn/berry/cache/mkdirp-npm-1.0.4-37f6ef56b9-9.zip/node_modules/mkdirp/dex.js")const fs = __webpack_require__(/*! fs */ "fs")const path = __webpack_require__(/*! path */ "path")const chownr = __webpack_require__(/*! chownr */ "../../../.yarn/berry/cache/chownr-npm-2.0.0-638f1c9c61-9.zip/node_modules/chownr/chownr.js")const normPath = __webpack_require__(/*! ./normalize-wdows-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js")class SymlkError extends Error {  constructor (symlk, path) {    super('Cannot extract through symbolic lk')    .path = path    .symlk = symlk  }  get name () {    return 'SylkError'  }}class CwdError extends Error {  constructor (path, code) {    super(code + ': Cannot cd to \'' + path + '\'')    .path = path    .code = code  }  get name () {    return 'CwdError'  }}const cGet = (cache, key) => cache.get(normPath(key))const cSet = (cache, key, val) => cache.set(normPath(key), val)const checkCwd = (dir, cb) => {  fs.stat(dir, (er, st) => {    if (er || !st.isDirectory())      er = new CwdError(dir, er && er.code || 'ENOTDIR')    cb(er)  })}module.exports = (dir, opt, cb) => {  dir = normPath(dir)  // if there's any overlap between mask  mode,  // then we'll need an explicit chmod  const umask = opt.umask  const mode = opt.mode | 0o0700  const needChmod = (mode & umask) !== 0  const uid = opt.uid  const gid = opt.gid  const doChown = typeof uid === 'number' &&    typeof gid === 'number' &&    (uid !== opt.processUid || gid !== opt.processGid)  const preserve = opt.preserve  const unlk = opt.unlk  const cache = opt.cache  const cwd = normPath(opt.cwd)  const done = (er, created) => {    if (er)      cb(er)    else {      cSet(cache, dir, true)      if (created && doChown)        chownr(created, uid, gid, er => done(er))      else if (needChmod)        fs.chmod(dir, mode, cb)      else        cb()    }  }  if (cache && cGet(cache, dir) === true)    return done()  if (dir === cwd)    return checkCwd(dir, done)  if (preserve)    return mkdirp(dir, {mode}).then(made => done(null, made), done)  const sub = normPath(path.relative(cwd, dir))  const parts = sub.split('/')  mkdir_(cwd, parts, mode, cache, unlk, cwd, null, done)}const mkdir_ = (base, parts, mode, cache, unlk, cwd, created, cb) => {  if (!parts.length)    return cb(null, created)  const p = parts.shift()  const part = normPath(path.resolve(base + '/' + p))  if (cGet(cache, part))    return mkdir_(part, parts, mode, cache, unlk, cwd, created, cb)  fs.mkdir(part, mode, onmkdir(part, parts, mode, cache, unlk, cwd, created, cb))}const onmkdir = (part, parts, mode, cache, unlk, cwd, created, cb) => er => {  if (er) {    fs.lstat(part, (statEr, st) => {      if (statEr) {        statEr.path = statEr.path && normPath(statEr.path)        cb(statEr)      } else if (st.isDirectory())        mkdir_(part, parts, mode, cache, unlk, cwd, created, cb)      else if (unlk) {        fs.unlk(part, er => {          if (er)            return cb(er)          fs.mkdir(part, mode, onmkdir(part, parts, mode, cache, unlk, cwd, created, cb))        })      } else if (st.isSymbolicLk())        return cb(new SymlkError(part, part + '/' + parts.jo('/')))      else        cb(er)    })  } else {    created = created || part    mkdir_(part, parts, mode, cache, unlk, cwd, created, cb)  }}const checkCwdSync = dir => {  let ok = false  let code = 'ENOTDIR'  try {    ok = fs.statSync(dir).isDirectory()  } catch (er) {    code = er.code  } fally {    if (!ok)      throw new CwdError(dir, code)  }}module.exports.sync = (dir, opt) => {  dir = normPath(dir)  // if there's any overlap between mask  mode,  // then we'll need an explicit chmod  const umask = opt.umask  const mode = opt.mode | 0o0700  const needChmod = (mode & umask) !== 0  const uid = opt.uid  const gid = opt.gid  const doChown = typeof uid === 'number' &&    typeof gid === 'number' &&    (uid !== opt.processUid || gid !== opt.processGid)  const preserve = opt.preserve  const unlk = opt.unlk  const cache = opt.cache  const cwd = normPath(opt.cwd)  const done = (created) => {    cSet(cache, dir, true)    if (created && doChown)      chownr.sync(created, uid, gid)    if (needChmod)      fs.chmodSync(dir, mode)  }  if (cache && cGet(cache, dir) === true)    return done()  if (dir === cwd) {    checkCwdSync(cwd)    return done()  }  if (preserve)    return done(mkdirp.sync(dir, mode))  const sub = normPath(path.relative(cwd, dir))  const parts = sub.split('/')  let created = null  for (let p = parts.shift(), part = cwd;    p && (part += '/' + p);    p = parts.shift()) {    part = normPath(path.resolve(part))    if (cGet(cache, part))      contue    try {      fs.mkdirSync(part, mode)      created = created || part      cSet(cache, part, true)    } catch (er) {      const st = fs.lstatSync(part)      if (st.isDirectory()) {        cSet(cache, part, true)        contue      } else if (unlk) {        fs.unlkSync(part)        fs.mkdirSync(part, mode)        created = created || part        cSet(cache, part, true)        contue      } else if (st.isSymbolicLk())        return new SymlkError(part, part + '/' + parts.jo('/'))    }  }  return done(created)}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mode-fix.js":/*!***************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mode-fix.js ***!  \***************************************************************************************************//***/ ((module) => {"use strict";module.exports = (mode, isDir, portable) => {  mode &= 0o7777  //  portable mode, use the mimum reasonable umask  // if  system creates files with 0o664  default  // (as some lux distros do), then we'll write the  // archive with 0o644 stead.  Also, don't ever create  // a file that is not readable/writable  the owner.  if (portable)    mode = (mode | 0o600) & ~0o22  // if dirs  readable, then they should be listable  if (isDir) {    if (mode & 0o400)      mode |= 0o100    if (mode & 0o40)      mode |= 0o10    if (mode & 0o4)      mode |= 0o1  }  return mode}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-unicode.js":/*!************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-unicode.js ***!  \************************************************************************************************************//***/ ((module) => {// warng: extremely hot code path.// This has been meticulously optimized for use// with npm stall on large package trees.// Do not edit without cful benchmarkg.const normalizeCache = Object.create(null)const {hasOwnProperty} = Object.prototypemodule.exports = s => {  if (!hasOwnProperty.call(normalizeCache, s))    normalizeCache[s] = s.normalize('NFKD')  return normalizeCache[s]}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js ***!  \*****************************************************************************************************************//***/ ((module) => {// on wdows, either \ or /  valid directory separators.// on unix, \ is a valid character  filenames.// so, on wdows,  only on wdows, we replace all \ chars with /,// so that we can use / as our one  only directory separator char.const platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platformmodule.exports = platform !== 'w32' ? p => p  : p => p && p.replace(/\\/g, '/')/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pack.js":/*!***********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pack.js ***!  \***********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// A readable tar stream creator// Technically,  is a transform stream that you write paths to,//  tar format comes out of.//  `add()` method is like `write()` but returns ,//  end() return `` as well, so you can// do `new Pack(opt).add('files').add('dir').end().pipe(output)// You could also do somethg like:// streamOfPaths().pipe(new Pack()).pipe(new fs.WriteStream('out.tar'))class PackJob {  constructor (path, absolute) {    .path = path || './'    .absolute = absolute    .entry = null    .stat = null    .readdir = null    .pendg = false    .ignore = false    .piped = false  }}const MiPass = __webpack_require__(/*! mipass */ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js")const zlib = __webpack_require__(/*! mizlib */ "../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/dex.js")const ReadEntry = __webpack_require__(/*! ./read-entry.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/read-entry.js")const WriteEntry = __webpack_require__(/*! ./write-entry.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/write-entry.js")const WriteEntrySync = WriteEntry.Syncconst WriteEntryTar = WriteEntry.Tarconst Yallist = __webpack_require__(/*! yallist */ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js")const EOF = Buffer.alloc(1024)const ONSTAT = Symbol('onStat')const ENDED = Symbol('ended')const QUEUE = Symbol('queue')const CURRENT = Symbol('current')const PROCESS = Symbol('process')const PROCESSING = Symbol('processg')const PROCESSJOB = Symbol('processJob')const JOBS = Symbol('jobs')const JOBDONE = Symbol('jobDone')const ADDFSENTRY = Symbol('addFSEntry')const ADDTARENTRY = Symbol('addTarEntry')const STAT = Symbol('stat')const READDIR = Symbol('readdir')const ONREADDIR = Symbol('onreaddir')const PIPE = Symbol('pipe')const ENTRY = Symbol('entry')const ENTRYOPT = Symbol('entryOpt')const WRITEENTRYCLASS = Symbol('writeEntryClass')const WRITE = Symbol('write')const ONDRAIN = Symbol('ondra')const fs = __webpack_require__(/*! fs */ "fs")const path = __webpack_require__(/*! path */ "path")const warner = __webpack_require__(/*! ./warn-mix.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/warn-mix.js")const normPath = __webpack_require__(/*! ./normalize-wdows-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js")const Pack = warner(class Pack extends MiPass {  constructor (opt) {    super(opt)    opt = opt || Object.create(null)    .opt = opt    .file = opt.file || ''    .cwd = opt.cwd || process.cwd()    .maxReadSize = opt.maxReadSize    .preservePaths = !!opt.preservePaths    .strict = !!opt.strict    .noPax = !!opt.noPax    .prefix = normPath(opt.prefix || '')    .lkCache = opt.lkCache || new Map()    .statCache = opt.statCache || new Map()    .readdirCache = opt.readdirCache || new Map()    [WRITEENTRYCLASS] = WriteEntry    if (typeof opt.onwarn === 'function')      .on('warn', opt.onwarn)    .portable = !!opt.portable    .zip = null    if (opt.gzip) {      if (typeof opt.gzip !== 'object')        opt.gzip = {}      if (.portable)        opt.gzip.portable = true      .zip = new zlib.Gzip(opt.gzip)      .zip.on('data', chunk => super.write(chunk))      .zip.on('end', _ => super.end())      .zip.on('dra', _ => [ONDRAIN]())      .on('resume', _ => .zip.resume())    } else      .on('dra', [ONDRAIN])    .noDirRecurse = !!opt.noDirRecurse    .follow = !!opt.follow    .noMtime = !!opt.noMtime    .mtime = opt.mtime || null    .filter = typeof opt.filter === 'function' ? opt.filter : _ => true    [QUEUE] = new Yallist()    [JOBS] = 0    .jobs = +opt.jobs || 4    [PROCESSING] = false    [ENDED] = false  }  [WRITE] (chunk) {    return super.write(chunk)  }  add (path) {    .write(path)    return   }  end (path) {    if (path)      .write(path)    [ENDED] = true    [PROCESS]()    return   }  write (path) {    if ([ENDED])      throw new Error('write after end')    if (path stanceof ReadEntry)      [ADDTARENTRY](path)    else      [ADDFSENTRY](path)    return .flowg  }  [ADDTARENTRY] (p) {    const absolute = normPath(path.resolve(.cwd, p.path))    //   case, we don't have to wait for the stat    if (!.filter(p.path, p))      p.resume()    else {      const job = new PackJob(p.path, absolute, false)      job.entry = new WriteEntryTar(p, [ENTRYOPT](job))      job.entry.on('end', _ => [JOBDONE](job))      [JOBS] += 1      [QUEUE].push(job)    }    [PROCESS]()  }  [ADDFSENTRY] (p) {    const absolute = normPath(path.resolve(.cwd, p))    [QUEUE].push(new PackJob(p, absolute))    [PROCESS]()  }  [STAT] (job) {    job.pendg = true    [JOBS] += 1    const stat = .follow ? 'stat' : 'lstat'    fs[stat](job.absolute, (er, stat) => {      job.pendg = false      [JOBS] -= 1      if (er)        .emit('error', er)      else        [ONSTAT](job, stat)    })  }  [ONSTAT] (job, stat) {    .statCache.set(job.absolute, stat)    job.stat = stat    // now we have the stat, we can filter it.    if (!.filter(job.path, stat))      job.ignore = true    [PROCESS]()  }  [READDIR] (job) {    job.pendg = true    [JOBS] += 1    fs.readdir(job.absolute, (er, entries) => {      job.pendg = false      [JOBS] -= 1      if (er)        return .emit('error', er)      [ONREADDIR](job, entries)    })  }  [ONREADDIR] (job, entries) {    .readdirCache.set(job.absolute, entries)    job.readdir = entries    [PROCESS]()  }  [PROCESS] () {    if ([PROCESSING])      return    [PROCESSING] = true    for (let w = [QUEUE].head;      w !== null && [JOBS] < .jobs;      w = w.next) {      [PROCESSJOB](w.value)      if (w.value.ignore) {        const p = w.next        [QUEUE].removeNode(w)        w.next = p      }    }    [PROCESSING] = false    if ([ENDED] && ![QUEUE].length && [JOBS] === 0) {      if (.zip)        .zip.end(EOF)      else {        super.write(EOF)        super.end()      }    }  }  get [CURRENT] () {    return [QUEUE] && [QUEUE].head && [QUEUE].head.value  }  [JOBDONE] (job) {    [QUEUE].shift()    [JOBS] -= 1    [PROCESS]()  }  [PROCESSJOB] (job) {    if (job.pendg)      return    if (job.entry) {      if (job === [CURRENT] && !job.piped)        [PIPE](job)      return    }    if (!job.stat) {      if (.statCache.has(job.absolute))        [ONSTAT](job, .statCache.get(job.absolute))      else        [STAT](job)    }    if (!job.stat)      return    // filtered out!    if (job.ignore)      return    if (!.noDirRecurse && job.stat.isDirectory() && !job.readdir) {      if (.readdirCache.has(job.absolute))        [ONREADDIR](job, .readdirCache.get(job.absolute))      else        [READDIR](job)      if (!job.readdir)        return    }    // we know it doesn't have an entry, because that got checked above    job.entry = [ENTRY](job)    if (!job.entry) {      job.ignore = true      return    }    if (job === [CURRENT] && !job.piped)      [PIPE](job)  }  [ENTRYOPT] (job) {    return {      onwarn: (code, msg, data) => .warn(code, msg, data),      noPax: .noPax,      cwd: .cwd,      absolute: job.absolute,      preservePaths: .preservePaths,      maxReadSize: .maxReadSize,      strict: .strict,      portable: .portable,      lkCache: .lkCache,      statCache: .statCache,      noMtime: .noMtime,      mtime: .mtime,      prefix: .prefix,    }  }  [ENTRY] (job) {    [JOBS] += 1    try {      return new [WRITEENTRYCLASS](job.path, [ENTRYOPT](job))        .on('end', () => [JOBDONE](job))        .on('error', er => .emit('error', er))    } catch (er) {      .emit('error', er)    }  }  [ONDRAIN] () {    if ([CURRENT] && [CURRENT].entry)      [CURRENT].entry.resume()  }  // like .pipe() but usg super, because our write() is special  [PIPE] (job) {    job.piped = true    if (job.readdir) {      job.readdir.forEach(entry => {        const p = job.path        const base = p === './' ? '' : p.replace(/\/*$/, '/')        [ADDFSENTRY](base + entry)      })    }    const source = job.entry    const zip = .zip    if (zip) {      source.on('data', chunk => {        if (!zip.write(chunk))          source.pause()      })    } else {      source.on('data', chunk => {        if (!super.write(chunk))          source.pause()      })    }  }  pause () {    if (.zip)      .zip.pause()    return super.pause()  }})class PackSync extends Pack {  constructor (opt) {    super(opt)    [WRITEENTRYCLASS] = WriteEntrySync  }  // pause/resume  no-ops  sync streams.  pause () {}  resume () {}  [STAT] (job) {    const stat = .follow ? 'statSync' : 'lstatSync'    [ONSTAT](job, fs[stat](job.absolute))  }  [READDIR] (job, stat) {    [ONREADDIR](job, fs.readdirSync(job.absolute))  }  // gotta get it all   tick  [PIPE] (job) {    const source = job.entry    const zip = .zip    if (job.readdir) {      job.readdir.forEach(entry => {        const p = job.path        const base = p === './' ? '' : p.replace(/\/*$/, '/')        [ADDFSENTRY](base + entry)      })    }    if (zip) {      source.on('data', chunk => {        zip.write(chunk)      })    } else {      source.on('data', chunk => {        super[WRITE](chunk)      })    }  }}Pack.Sync = PackSyncmodule.exports = Pack/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/parse.js":/*!************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/parse.js ***!  \************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// [BUFFER] is the remader of a chunk if we're waitg for// the full 512 tes of a header to come .  We will Buffer.concat()// it to the next write(), which is a mem copy, but a small one.//// [QUEUE] is a Yallist of entries that haven't been emitted// yet  can only get filled up if the user keeps write()g after// a write() returns false, or does a write() with more than one entry//// We don't buffer chunks, we always parse them  either create an// entry, or push it to the active entry.   ReadEntry class knows// to throw data away if .ignore=true//// Shift entry off the buffer when it emits 'end',  emit 'entry' for// the next one  the list.//// At any time, we're pushg body chunks to the entry at WRITEENTRY,//  waitg for 'end' on the entry at READENTRY//// ignored entries get .resume() called on them straight awayconst warner = __webpack_require__(/*! ./warn-mix.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/warn-mix.js")const Header = __webpack_require__(/*! ./header.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js")const EE = __webpack_require__(/*! events */ "events")const Yallist = __webpack_require__(/*! yallist */ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js")const maxMetaEntrySize = 1024 * 1024const Entry = __webpack_require__(/*! ./read-entry.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/read-entry.js")const Pax = __webpack_require__(/*! ./pax.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pax.js")const zlib = __webpack_require__(/*! mizlib */ "../../../.yarn/berry/cache/mizlib-npm-2.1.2-ea89cd0cfb-9.zip/node_modules/mizlib/dex.js")const gzipHeader = Buffer.from([0x1f, 0x8b])const STATE = Symbol('state')const WRITEENTRY = Symbol('writeEntry')const READENTRY = Symbol('readEntry')const NEXTENTRY = Symbol('nextEntry')const PROCESSENTRY = Symbol('processEntry')const EX = Symbol('extendedHeader')const GEX = Symbol('globalExtendedHeader')const META = Symbol('meta')const EMITMETA = Symbol('emitMeta')const BUFFER = Symbol('buffer')const QUEUE = Symbol('queue')const ENDED = Symbol('ended')const EMITTEDEND = Symbol('emittedEnd')const EMIT = Symbol('emit')const UNZIP = Symbol('unzip')const CONSUMECHUNK = Symbol('consumeChunk')const CONSUMECHUNKSUB = Symbol('consumeChunkSub')const CONSUMEBODY = Symbol('consumeBody')const CONSUMEMETA = Symbol('consumeMeta')const CONSUMEHEADER = Symbol('consumeHeader')const CONSUMING = Symbol('consumg')const BUFFERCONCAT = Symbol('bufferConcat')const MAYBEEND = Symbol('maybeEnd')const WRITING = Symbol('writg')const ABORTED = Symbol('aborted')const DONE = Symbol('onDone')const SAW_VALID_ENTRY = Symbol('sawValidEntry')const SAW_NULL_BLOCK = Symbol('sawNullBlock')const SAW_EOF = Symbol('sawEOF')const noop = _ => truemodule.exports = warner(class Parser extends EE {  constructor (opt) {    opt = opt || {}    super(opt)    .file = opt.file || ''    // set to boolean false when an entry starts.  1024 tes of \0    // is technically a valid tarball, albeit a borg one.    [SAW_VALID_ENTRY] = null    // these BADARCHIVE errors can't be detected early. listen on DONE.    .on(DONE, _ => {      if ([STATE] === 'beg' || [SAW_VALID_ENTRY] === false) {        // either less than 1 block of data, or all entries were valid.        // Either way, probably not even a tarball.        .warn('TAR_BAD_ARCHIVE', 'Unrecognized archive format')      }    })    if (opt.ondone)      .on(DONE, opt.ondone)    else {      .on(DONE, _ => {        .emit('prefish')        .emit('fish')        .emit('end')        .emit('close')      })    }    .strict = !!opt.strict    .maxMetaEntrySize = opt.maxMetaEntrySize || maxMetaEntrySize    .filter = typeof opt.filter === 'function' ? opt.filter : noop    // have to set  so that streams  ok pipg to it    .writable = true    .readable = false    [QUEUE] = new Yallist()    [BUFFER] = null    [READENTRY] = null    [WRITEENTRY] = null    [STATE] = 'beg'    [META] = ''    [EX] = null    [GEX] = null    [ENDED] = false    [UNZIP] = null    [ABORTED] = false    [SAW_NULL_BLOCK] = false    [SAW_EOF] = false    if (typeof opt.onwarn === 'function')      .on('warn', opt.onwarn)    if (typeof opt.onentry === 'function')      .on('entry', opt.onentry)  }  [CONSUMEHEADER] (chunk, position) {    if ([SAW_VALID_ENTRY] === null)      [SAW_VALID_ENTRY] = false    let header    try {      header = new Header(chunk, position, [EX], [GEX])    } catch (er) {      return .warn('TAR_ENTRY_INVALID', er)    }    if (header.nullBlock) {      if ([SAW_NULL_BLOCK]) {        [SAW_EOF] = true        // endg an archive with no entries.  potless, but legal.        if ([STATE] === 'beg')          [STATE] = 'header'        [EMIT]('eof')      } else {        [SAW_NULL_BLOCK] = true        [EMIT]('nullBlock')      }    } else {      [SAW_NULL_BLOCK] = false      if (!header.cksumValid)        .warn('TAR_ENTRY_INVALID', 'checksum failure', {header})      else if (!header.path)        .warn('TAR_ENTRY_INVALID', 'path is required', {header})      else {        const type = header.type        if (/^(Symbolic)?Lk$/.test(type) && !header.lkpath)          .warn('TAR_ENTRY_INVALID', 'lkpath required', {header})        else if (!/^(Symbolic)?Lk$/.test(type) && header.lkpath)          .warn('TAR_ENTRY_INVALID', 'lkpath forbidden', {header})        else {          const entry = [WRITEENTRY] = new Entry(header, [EX], [GEX])          // we do  for meta & ignored entries as well, because they          //  still valid tar, or else we wouldn't know to ignore them          if (![SAW_VALID_ENTRY]) {            if (entry.rema) {              //  might be the one!              const onend = () => {                if (!entry.valid)                  [SAW_VALID_ENTRY] = true              }              entry.on('end', onend)            } else              [SAW_VALID_ENTRY] = true          }          if (entry.meta) {            if (entry.size > .maxMetaEntrySize) {              entry.ignore = true              [EMIT]('ignoredEntry', entry)              [STATE] = 'ignore'              entry.resume()            } else if (entry.size > 0) {              [META] = ''              entry.on('data', c => [META] += c)              [STATE] = 'meta'            }          } else {            [EX] = null            entry.ignore = entry.ignore || !.filter(entry.path, entry)            if (entry.ignore) {              // probably valid, just not somethg we c about              [EMIT]('ignoredEntry', entry)              [STATE] = entry.rema ? 'ignore' : 'header'              entry.resume()            } else {              if (entry.rema)                [STATE] = 'body'              else {                [STATE] = 'header'                entry.end()              }              if (![READENTRY]) {                [QUEUE].push(entry)                [NEXTENTRY]()              } else                [QUEUE].push(entry)            }          }        }      }    }  }  [PROCESSENTRY] (entry) {    let go = true    if (!entry) {      [READENTRY] = null      go = false    } else if (Array.isArray(entry))      .emit.apply(, entry)    else {      [READENTRY] = entry      .emit('entry', entry)      if (!entry.emittedEnd) {        entry.on('end', _ => [NEXTENTRY]())        go = false      }    }    return go  }  [NEXTENTRY] () {    do {} while ([PROCESSENTRY]([QUEUE].shift()))    if (![QUEUE].length) {      // At  pot, there's nothg  the queue, but we may have an      // entry which is beg consumed (readEntry).      // If we don't, then we defitely can hle more data.      // If we do,  either it's flowg, or it has never had any data      //  to it, then it needs more.      //  only other possibility is that it has returned false from a      // write() call, so we wait for the next dra to contue.      const re = [READENTRY]      const draNow = !re || re.flowg || re.size === re.rema      if (draNow) {        if (![WRITING])          .emit('dra')      } else        re.once('dra', _ => .emit('dra'))    }  }  [CONSUMEBODY] (chunk, position) {    // write up to but no  more than writeEntry.blockRema    const entry = [WRITEENTRY]    const br = entry.blockRema    const c = (br >= chunk.length && position === 0) ? chunk      : chunk.slice(position, position + br)    entry.write(c)    if (!entry.blockRema) {      [STATE] = 'header'      [WRITEENTRY] = null      entry.end()    }    return c.length  }  [CONSUMEMETA] (chunk, position) {    const entry = [WRITEENTRY]    const ret = [CONSUMEBODY](chunk, position)    // if we fished, then the entry is reset    if (![WRITEENTRY])      [EMITMETA](entry)    return ret  }  [EMIT] (ev, data, extra) {    if (![QUEUE].length && ![READENTRY])      .emit(ev, data, extra)    else      [QUEUE].push([ev, data, extra])  }  [EMITMETA] (entry) {    [EMIT]('meta', [META])    switch (entry.type) {      case 'ExtendedHeader':      case 'OldExtendedHeader':        [EX] = Pax.parse([META], [EX], false)        break      case 'GlobalExtendedHeader':        [GEX] = Pax.parse([META], [GEX], true)        break      case 'NextFileHasLongPath':      case 'OldGnuLongPath':        [EX] = [EX] || Object.create(null)        [EX].path = [META].replace(/\0.*/, '')        break      case 'NextFileHasLongLkpath':        [EX] = [EX] || Object.create(null)        [EX].lkpath = [META].replace(/\0.*/, '')        break      /* istanbul ignore next */      default: throw new Error('unknown meta: ' + entry.type)    }  }  abort (error) {    [ABORTED] = true    .emit('abort', error)    // always throws, even  non-strict mode    .warn('TAR_ABORT', error, { recoverable: false })  }  write (chunk) {    if ([ABORTED])      return    // first write, might be gzipped    if ([UNZIP] === null && chunk) {      if ([BUFFER]) {        chunk = Buffer.concat([[BUFFER], chunk])        [BUFFER] = null      }      if (chunk.length < gzipHeader.length) {        [BUFFER] = chunk        return true      }      for (let i = 0; [UNZIP] === null && i < gzipHeader.length; i++) {        if (chunk[i] !== gzipHeader[i])          [UNZIP] = false      }      if ([UNZIP] === null) {        const ended = [ENDED]        [ENDED] = false        [UNZIP] = new zlib.Unzip()        [UNZIP].on('data', chunk => [CONSUMECHUNK](chunk))        [UNZIP].on('error', er => .abort(er))        [UNZIP].on('end', _ => {          [ENDED] = true          [CONSUMECHUNK]()        })        [WRITING] = true        const ret = [UNZIP][ended ? 'end' : 'write'](chunk)        [WRITING] = false        return ret      }    }    [WRITING] = true    if ([UNZIP])      [UNZIP].write(chunk)    else      [CONSUMECHUNK](chunk)    [WRITING] = false    // return false if there's a queue, or if the current entry isn't flowg    const ret =      [QUEUE].length ? false :      [READENTRY] ? [READENTRY].flowg :      true    // if we have no queue, then that means a clogged READENTRY    if (!ret && ![QUEUE].length)      [READENTRY].once('dra', _ => .emit('dra'))    return ret  }  [BUFFERCONCAT] (c) {    if (c && ![ABORTED])      [BUFFER] = [BUFFER] ? Buffer.concat([[BUFFER], c]) : c  }  [MAYBEEND] () {    if ([ENDED] &&        ![EMITTEDEND] &&        ![ABORTED] &&        ![CONSUMING]) {      [EMITTEDEND] = true      const entry = [WRITEENTRY]      if (entry && entry.blockRema) {        // truncated, likely a damaged file        const have = [BUFFER] ? [BUFFER].length : 0        .warn('TAR_BAD_ARCHIVE', `Truncated put (needed ${          entry.blockRema} more tes, only ${have} available)`, {entry})        if ([BUFFER])          entry.write([BUFFER])        entry.end()      }      [EMIT](DONE)    }  }  [CONSUMECHUNK] (chunk) {    if ([CONSUMING])      [BUFFERCONCAT](chunk)    else if (!chunk && ![BUFFER])      [MAYBEEND]()    else {      [CONSUMING] = true      if ([BUFFER]) {        [BUFFERCONCAT](chunk)        const c = [BUFFER]        [BUFFER] = null        [CONSUMECHUNKSUB](c)      } else        [CONSUMECHUNKSUB](chunk)      while ([BUFFER] &&          [BUFFER].length >= 512 &&          ![ABORTED] &&          ![SAW_EOF]) {        const c = [BUFFER]        [BUFFER] = null        [CONSUMECHUNKSUB](c)      }      [CONSUMING] = false    }    if (![BUFFER] || [ENDED])      [MAYBEEND]()  }  [CONSUMECHUNKSUB] (chunk) {    // we know that we   CONSUMING mode, so anythg  goes to    // the buffer.  Advance the position  put any remader  the buffer.    let position = 0    const length = chunk.length    while (position + 512 <= length && ![ABORTED] && ![SAW_EOF]) {      switch ([STATE]) {        case 'beg':        case 'header':          [CONSUMEHEADER](chunk, position)          position += 512          break        case 'ignore':        case 'body':          position += [CONSUMEBODY](chunk, position)          break        case 'meta':          position += [CONSUMEMETA](chunk, position)          break        /* istanbul ignore next */        default:          throw new Error('valid state: ' + [STATE])      }    }    if (position < length) {      if ([BUFFER])        [BUFFER] = Buffer.concat([chunk.slice(position), [BUFFER]])      else        [BUFFER] = chunk.slice(position)    }  }  end (chunk) {    if (![ABORTED]) {      if ([UNZIP])        [UNZIP].end(chunk)      else {        [ENDED] = true        .write(chunk)      }    }  }})/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/path-reservations.js":/*!************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/path-reservations.js ***!  \************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// A path exclusive reservation system// reserve([list, of, paths], fn)// When the fn is first  le for all its paths, it// is called with a cb that clears the reservation.//// Used  async unpack to avoid clobberg paths  use,// while still allowg maximal safe parallelization.const assert = __webpack_require__(/*! assert */ "assert")const normalize = __webpack_require__(/*! ./normalize-unicode.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-unicode.js")const stripSlashes = __webpack_require__(/*! ./strip-trailg-slashes.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js")const { jo } = __webpack_require__(/*! path */ "path")const platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platformconst isWdows = platform === 'w32'module.exports = () => {  // path => [function or Set]  // A Set object means a directory reservation  // A fn is a direct reservation on that path  const queues = new Map()  // fn => {paths:[path,...], dirs:[path, ...]}  const reservations = new Map()  // return a set of pnt dirs for a given path  // '/a/b/c/d' -> ['/', '/a', '/a/b', '/a/b/c', '/a/b/c/d']  const getDirs = path => {    const dirs = path.split('/').slice(0, -1).reduce((set, path) => {      if (set.length)        path = jo(set[set.length - 1], path)      set.push(path || '/')      return set    }, [])    return dirs  }  // functions currently runng  const runng = new Set()  // return the queues for each path the function cs about  // fn => {paths, dirs}  const getQueues = fn => {    const res = reservations.get(fn)    /* istanbul ignore if - unpossible */    if (!res)      throw new Error('function does not have any path reservations')    return {      paths: res.paths.map(path => queues.get(path)),      dirs: [...res.dirs].map(path => queues.get(path)),    }  }  // check if fn is first  le for all its paths,  is  // cluded  the first set for all its dir queues  const check = fn => {    const {paths, dirs} = getQueues(fn)    return paths.every(q => q[0] === fn) &&      dirs.every(q => q[0] stanceof Set && q[0].has(fn))  }  // run the function if it's first  le  not already runng  const run = fn => {    if (runng.has(fn) || !check(fn))      return false    runng.add(fn)    fn(() => clear(fn))    return true  }  const clear = fn => {    if (!runng.has(fn))      return false    const { paths, dirs } = reservations.get(fn)    const next = new Set()    paths.forEach(path => {      const q = queues.get(path)      assert.equal(q[0], fn)      if (q.length === 1)        queues.delete(path)      else {        q.shift()        if (typeof q[0] === 'function')          next.add(q[0])        else          q[0].forEach(fn => next.add(fn))      }    })    dirs.forEach(dir => {      const q = queues.get(dir)      assert(q[0] stanceof Set)      if (q[0].size === 1 && q.length === 1)        queues.delete(dir)      else if (q[0].size === 1) {        q.shift()        // must be a function or else the Set would've been reused        next.add(q[0])      } else        q[0].delete(fn)    })    runng.delete(fn)    next.forEach(fn => run(fn))    return true  }  const reserve = (paths, fn) => {    // collide on matches across case  unicode normalization    // On wdows, thanks to the magic of 8.3 shortnames, it is fundamentally    // impossible to determe whether two paths refer to the same thg on    // disk, without askg the kernel for a shortname.    // So, we just pretend that every path matches every other path here,    // effectively removg all parallelization on wdows.    paths = isWdows ? ['w32 parallelization disabled'] : paths.map(p => {      // don't need normPath, because we skip  entirely for wdows      return normalize(stripSlashes(jo(p))).toLowerCase()    })    const dirs = new Set(      paths.map(path => getDirs(path)).reduce((a, b) => a.concat(b))    )    reservations.set(fn, {dirs, paths})    paths.forEach(path => {      const q = queues.get(path)      if (!q)        queues.set(path, [fn])      else        q.push(fn)    })    dirs.forEach(dir => {      const q = queues.get(dir)      if (!q)        queues.set(dir, [new Set([fn])])      else if (q[q.length - 1] stanceof Set)        q[q.length - 1].add(fn)      else        q.push(new Set([fn]))    })    return run(fn)  }  return { check, reserve }}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pax.js":/*!**********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pax.js ***!  \**********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const Header = __webpack_require__(/*! ./header.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js")const path = __webpack_require__(/*! path */ "path")class Pax {  constructor (obj, global) {    .atime = obj.atime || null    .charset = obj.charset || null    .comment = obj.comment || null    .ctime = obj.ctime || null    .gid = obj.gid || null    .gname = obj.gname || null    .lkpath = obj.lkpath || null    .mtime = obj.mtime || null    .path = obj.path || null    .size = obj.size || null    .uid = obj.uid || null    .uname = obj.uname || null    .dev = obj.dev || null    .o = obj.o || null    .nlk = obj.nlk || null    .global = global || false  }  encode () {    const body = .encodeBody()    if (body === '')      return null    const bodyLen = Buffer.teLength(body)    // round up to 512 tes    // add 512 for header    const bufLen = 512 * Math.ceil(1 + bodyLen / 512)    const buf = Buffer.allocUnsafe(bufLen)    // 0-fill the header section, it might not hit every field    for (let i = 0; i < 512; i++)      buf[i] = 0    new Header({      // XXX split the path      // then the path should be PaxHeader + basename, but less than 99,      // prepend with the dirname      path: ('PaxHeader/' + path.basename(.path)).slice(0, 99),      mode: .mode || 0o644,      uid: .uid || null,      gid: .gid || null,      size: bodyLen,      mtime: .mtime || null,      type: .global ? 'GlobalExtendedHeader' : 'ExtendedHeader',      lkpath: '',      uname: .uname || '',      gname: .gname || '',      devmaj: 0,      devm: 0,      atime: .atime || null,      ctime: .ctime || null,    }).encode(buf)    buf.write(body, 512, bodyLen, 'utf8')    // null pad after the body    for (let i = bodyLen + 512; i < buf.length; i++)      buf[i] = 0    return buf  }  encodeBody () {    return (      .encodeField('path') +      .encodeField('ctime') +      .encodeField('atime') +      .encodeField('dev') +      .encodeField('o') +      .encodeField('nlk') +      .encodeField('charset') +      .encodeField('comment') +      .encodeField('gid') +      .encodeField('gname') +      .encodeField('lkpath') +      .encodeField('mtime') +      .encodeField('size') +      .encodeField('uid') +      .encodeField('uname')    )  }  encodeField (field) {    if ([field] === null || [field] === undefed)      return ''    const v = [field] stanceof Date ? [field].getTime() / 1000      : [field]    const s = ' ' +      (field === 'dev' || field === 'o' || field === 'nlk'        ? 'SCHILY.' : '') +      field + '=' + v + '\n'    const teLen = Buffer.teLength(s)    // the digits cludes the length of the digits  ascii base-10    // so if it's 9 characters, then addg 1 for the 9 makes it 10    // which makes it 11 chars.    let digits = Math.floor(Math.log(teLen) / Math.log(10)) + 1    if (teLen + digits >= Math.pow(10, digits))      digits += 1    const len = digits + teLen    return len + s  }}Pax.parse = (strg, ex, g) => new Pax(merge(parseKV(strg), ex), g)const merge = (a, b) =>  b ? Object.keys(a).reduce((s, k) => (s[k] = a[k], s), b) : aconst parseKV = strg =>  strg    .replace(/\n$/, '')    .split('\n')    .reduce(parseKVLe, Object.create(null))const parseKVLe = (set, le) => {  const n = parseInt(le, 10)  // XXX Values with \n  them will fail .  // Refactor to not be a naive le--le parse.  if (n !== Buffer.teLength(le) + 1)    return set  le = le.substr((n + ' ').length)  const kv = le.split('=')  const k = kv.shift().replace(/^SCHILY\.(dev|o|nlk)/, '$1')  if (!k)    return set  const v = kv.jo('=')  set[k] = /^([A-Z]+\.)?([mac]|birth|creation)time$/.test(k)    ? new Date(v * 1000)    : /^[0-9]+$/.test(v) ? +v    : v  return set}module.exports = Pax/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/read-entry.js":/*!*****************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/read-entry.js ***!  \*****************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const MiPass = __webpack_require__(/*! mipass */ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js")const normPath = __webpack_require__(/*! ./normalize-wdows-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js")const SLURP = Symbol('slurp')module.exports = class ReadEntry extends MiPass {  constructor (header, ex, gex) {    super()    // read entries always start life paused.   is to avoid the    // situation where Mipass's auto-endg empty streams results    //  an entry endg before we're ready for it.    .pause()    .extended = ex    .globalExtended = gex    .header = header    .startBlockSize = 512 * Math.ceil(header.size / 512)    .blockRema = .startBlockSize    .rema = header.size    .type = header.type    .meta = false    .ignore = false    switch (.type) {      case 'File':      case 'OldFile':      case 'Lk':      case 'SymbolicLk':      case 'CharacterDevice':      case 'BlockDevice':      case 'Directory':      case 'FIFO':      case 'ContiguousFile':      case 'GNUDumpDir':        break      case 'NextFileHasLongLkpath':      case 'NextFileHasLongPath':      case 'OldGnuLongPath':      case 'GlobalExtendedHeader':      case 'ExtendedHeader':      case 'OldExtendedHeader':        .meta = true        break      // NOTE: gnutar  bsdtar treat unrecognized types as 'File'      // it may be worth dog the same, but with a warng.      default:        .ignore = true    }    .path = normPath(header.path)    .mode = header.mode    if (.mode)      .mode = .mode & 0o7777    .uid = header.uid    .gid = header.gid    .uname = header.uname    .gname = header.gname    .size = header.size    .mtime = header.mtime    .atime = header.atime    .ctime = header.ctime    .lkpath = normPath(header.lkpath)    .uname = header.uname    .gname = header.gname    if (ex)      [SLURP](ex)    if (gex)      [SLURP](gex, true)  }  write (data) {    const writeLen = data.length    if (writeLen > .blockRema)      throw new Error('writg more to entry than is appropriate')    const r = .rema    const br = .blockRema    .rema = Math.max(0, r - writeLen)    .blockRema = Math.max(0, br - writeLen)    if (.ignore)      return true    if (r >= writeLen)      return super.write(data)    // r < writeLen    return super.write(data.slice(0, r))  }  [SLURP] (ex, global) {    for (const k  ex) {      // we slurp  everythg except for the path attribute       // a global extended header, because that's weird.      if (ex[k] !== null && ex[k] !== undefed &&          !(global && k === 'path'))        [k] = k === 'path' || k === 'lkpath' ? normPath(ex[k]) : ex[k]    }  }}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/replace.js":/*!**************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/replace.js ***!  \**************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// tar -rconst hlo = __webpack_require__(/*! ./high-level-opt.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js")const Pack = __webpack_require__(/*! ./pack.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pack.js")const fs = __webpack_require__(/*! fs */ "fs")const fsm = __webpack_require__(/*! fs-mipass */ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js")const t = __webpack_require__(/*! ./list.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/list.js")const path = __webpack_require__(/*! path */ "path")// startg at the head of the file, read a Header// If the checksum is valid, that's our position to start writg// If it is, jump forward  the specified size (round up to 512)//  try aga.// Write the new Pack stream startg there.const Header = __webpack_require__(/*! ./header.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js")module.exports = (opt_, files, cb) => {  const opt = hlo(opt_)  if (!opt.file)    throw new TypeError('file is required')  if (opt.gzip)    throw new TypeError('cannot append to compressed archives')  if (!files || !Array.isArray(files) || !files.length)    throw new TypeError('no files or directories specified')  files = Array.from(files)  return opt.sync ? replaceSync(opt, files)    : replace(opt, files, cb)}const replaceSync = (opt, files) => {  const p = new Pack.Sync(opt)  let threw = true  let fd  let position  try {    try {      fd = fs.openSync(opt.file, 'r+')    } catch (er) {      if (er.code === 'ENOENT')        fd = fs.openSync(opt.file, 'w+')      else        throw er    }    const st = fs.fstatSync(fd)    const headBuf = Buffer.alloc(512)    POSITION: for (position = 0; position < st.size; position += 512) {      for (let bufPos = 0, tes = 0; bufPos < 512; bufPos += tes) {        tes = fs.readSync(          fd, headBuf, bufPos, headBuf.length - bufPos, position + bufPos        )        if (position === 0 && headBuf[0] === 0x1f && headBuf[1] === 0x8b)          throw new Error('cannot append to compressed archives')        if (!tes)          break POSITION      }      const h = new Header(headBuf)      if (!h.cksumValid)        break      const entryBlockSize = 512 * Math.ceil(h.size / 512)      if (position + entryBlockSize + 512 > st.size)        break      // the 512 for the header we just parsed will be added as well      // also jump ahead all the blocks for the body      position += entryBlockSize      if (opt.mtimeCache)        opt.mtimeCache.set(h.path, h.mtime)    }    threw = false    streamSync(opt, p, position, fd, files)  } fally {    if (threw) {      try {        fs.closeSync(fd)      } catch (er) {}    }  }}const streamSync = (opt, p, position, fd, files) => {  const stream = new fsm.WriteStreamSync(opt.file, {    fd: fd,    start: position,  })  p.pipe(stream)  addFilesSync(p, files)}const replace = (opt, files, cb) => {  files = Array.from(files)  const p = new Pack(opt)  const getPos = (fd, size, cb_) => {    const cb = (er, pos) => {      if (er)        fs.close(fd, _ => cb_(er))      else        cb_(null, pos)    }    let position = 0    if (size === 0)      return cb(null, 0)    let bufPos = 0    const headBuf = Buffer.alloc(512)    const onread = (er, tes) => {      if (er)        return cb(er)      bufPos += tes      if (bufPos < 512 && tes) {        return fs.read(          fd, headBuf, bufPos, headBuf.length - bufPos,          position + bufPos, onread        )      }      if (position === 0 && headBuf[0] === 0x1f && headBuf[1] === 0x8b)        return cb(new Error('cannot append to compressed archives'))      // truncated header      if (bufPos < 512)        return cb(null, position)      const h = new Header(headBuf)      if (!h.cksumValid)        return cb(null, position)      const entryBlockSize = 512 * Math.ceil(h.size / 512)      if (position + entryBlockSize + 512 > size)        return cb(null, position)      position += entryBlockSize + 512      if (position >= size)        return cb(null, position)      if (opt.mtimeCache)        opt.mtimeCache.set(h.path, h.mtime)      bufPos = 0      fs.read(fd, headBuf, 0, 512, position, onread)    }    fs.read(fd, headBuf, 0, 512, position, onread)  }  const promise = new Promise((resolve, reject) => {    p.on('error', reject)    let flag = 'r+'    const onopen = (er, fd) => {      if (er && er.code === 'ENOENT' && flag === 'r+') {        flag = 'w+'        return fs.open(opt.file, flag, onopen)      }      if (er)        return reject(er)      fs.fstat(fd, (er, st) => {        if (er)          return fs.close(fd, () => reject(er))        getPos(fd, st.size, (er, position) => {          if (er)            return reject(er)          const stream = new fsm.WriteStream(opt.file, {            fd: fd,            start: position,          })          p.pipe(stream)          stream.on('error', reject)          stream.on('close', resolve)          addFilesAsync(p, files)        })      })    }    fs.open(opt.file, flag, onopen)  })  return cb ? promise.then(cb, cb) : promise}const addFilesSync = (p, files) => {  files.forEach(file => {    if (file.charAt(0) === '@') {      t({        file: path.resolve(p.cwd, file.substr(1)),        sync: true,        noResume: true,        onentry: entry => p.add(entry),      })    } else      p.add(file)  })  p.end()}const addFilesAsync = (p, files) => {  while (files.length) {    const file = files.shift()    if (file.charAt(0) === '@') {      return t({        file: path.resolve(p.cwd, file.substr(1)),        noResume: true,        onentry: entry => p.add(entry),      }).then(_ => addFilesAsync(p, files))    } else      p.add(file)  }  p.end()}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-absolute-path.js":/*!**************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-absolute-path.js ***!  \**************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {// unix absolute paths  also absolute on w32, so we use  for bothconst { isAbsolute, parse } = (__webpack_require__(/*! path */ "path").w32)// returns [root, stripped]// Note that wdows will thk that //x/y/z/a has a "root" of //x/y,  // those cases, we want to sanitize it to x/y/z/a, not z/a, so we strip /// explicitly if it's the first character.// drive-specific relative paths on Wdows get their root stripped off even// though they  not absolute, so `c:../foo` becomes ['c:', '../foo']module.exports = path => {  let r = ''  let parsed = parse(path)  while (isAbsolute(path) || parsed.root) {    // wdows will thk that //x/y/z has a "root" of //x/y/    // but strip the //?/C:/ off of //?/C:/path    const root = path.charAt(0) === '/' && path.slice(0, 4) !== '//?/' ? '/'      : parsed.root    path = path.substr(root.length)    r += root    parsed = parse(path)  }  return [r, path]}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js ***!  \*****************************************************************************************************************//***/ ((module) => {// warng: extremely hot code path.// This has been meticulously optimized for use// with npm stall on large package trees.// Do not edit without cful benchmarkg.module.exports = str => {  let i = str.length - 1  let slashesStart = -1  while (i > -1 && str.charAt(i) === '/') {    slashesStart = i    i--  }  return slashesStart === -1 ? str : str.slice(0, slashesStart)}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/types.js":/*!************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/types.js ***!  \************************************************************************************************//***/ ((__unused_webpack_module, exports) => {"use strict";// map types from key to human-friendly nameexports.name = new Map([  ['0', 'File'],  // same as File  ['', 'OldFile'],  ['1', 'Lk'],  ['2', 'SymbolicLk'],  // Devices  FIFOs n't fully supported  // they  parsed, but skipped when unpackg  ['3', 'CharacterDevice'],  ['4', 'BlockDevice'],  ['5', 'Directory'],  ['6', 'FIFO'],  // same as File  ['7', 'ContiguousFile'],  // pax headers  ['g', 'GlobalExtendedHeader'],  ['x', 'ExtendedHeader'],  // vendor-specific stuff  // skip  ['A', 'SolarisACL'],  // like 5, but with data, which should be skipped  ['D', 'GNUDumpDir'],  // metadata only, skip  ['I', 'Inode'],  // data = lk path of next file  ['K', 'NextFileHasLongLkpath'],  // data = path of next file  ['L', 'NextFileHasLongPath'],  // skip  ['M', 'ContuationFile'],  // like L  ['N', 'OldGnuLongPath'],  // skip  ['S', 'SparseFile'],  // skip  ['V', 'TapeVolumeHeader'],  // like x  ['X', 'OldExtendedHeader'],])// map the other directionexports.code = new Map(Array.from(exports.name).map(kv => [kv[1], kv[0]]))/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/unpack.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/unpack.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// the PEND/UNPEND stuff tracks whether we're ready to emit end/close yet.// but the path reservations  required to avoid race conditions where// parallelized unpack ops may mess with one another, due to dependencies// (like a Lk dependg on its target) or destructive operations (like// clobberg an fs object to create one of a different type.)const assert = __webpack_require__(/*! assert */ "assert")const Parser = __webpack_require__(/*! ./parse.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/parse.js")const fs = __webpack_require__(/*! fs */ "fs")const fsm = __webpack_require__(/*! fs-mipass */ "../../../.yarn/berry/cache/fs-mipass-npm-2.1.0-501ef87306-9.zip/node_modules/fs-mipass/dex.js")const path = __webpack_require__(/*! path */ "path")const mkdir = __webpack_require__(/*! ./mkdir.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mkdir.js")const wc = __webpack_require__(/*! ./wchars.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/wchars.js")const pathReservations = __webpack_require__(/*! ./path-reservations.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/path-reservations.js")const stripAbsolutePath = __webpack_require__(/*! ./strip-absolute-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-absolute-path.js")const normPath = __webpack_require__(/*! ./normalize-wdows-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js")const stripSlash = __webpack_require__(/*! ./strip-trailg-slashes.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js")const normalize = __webpack_require__(/*! ./normalize-unicode.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-unicode.js")const ONENTRY = Symbol('onEntry')const CHECKFS = Symbol('checkFs')const CHECKFS2 = Symbol('checkFs2')const PRUNECACHE = Symbol('pruneCache')const ISREUSABLE = Symbol('isReusable')const MAKEFS = Symbol('makeFs')const FILE = Symbol('file')const DIRECTORY = Symbol('directory')const LINK = Symbol('lk')const SYMLINK = Symbol('symlk')const HARDLINK = Symbol('hardlk')const UNSUPPORTED = Symbol('unsupported')const CHECKPATH = Symbol('checkPath')const MKDIR = Symbol('mkdir')const ONERROR = Symbol('onError')const PENDING = Symbol('pendg')const PEND = Symbol('pend')const UNPEND = Symbol('unpend')const ENDED = Symbol('ended')const MAYBECLOSE = Symbol('maybeClose')const SKIP = Symbol('skip')const DOCHOWN = Symbol('doChown')const UID = Symbol('uid')const GID = Symbol('gid')const CHECKED_CWD = Symbol('checkedCwd')const crypto = __webpack_require__(/*! crypto */ "crypto")const getFlag = __webpack_require__(/*! ./get-write-flag.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/get-write-flag.js")const platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platformconst isWdows = platform === 'w32'// Unlks on Wdows  not atomic.//// This means that if you have a file entry, followed  another// file entry with an identical name,  you cannot re-use the file// (because it's a hardlk, or because unlk:true is set, or it's// Wdows, which does not have useful nlk values), then the unlk// will be committed to the disk AFTER the new file has been // over the old one, deletg the new file.//// To work around , on Wdows systems, we rename the file  then// delete the renamed file.  It's a sloppy kludge, but frankly, I do not// know of a better way to do , given wdows' non-atomic unlk// semantics.//// See: https://github.com/npm/node-tar/issues/183/* istanbul ignore next */const unlkFile = (path, cb) => {  if (!isWdows)    return fs.unlk(path, cb)  const name = path + '.DELETE.' + crypto.romBytes(16).toStrg('hex')  fs.rename(path, name, er => {    if (er)      return cb(er)    fs.unlk(name, cb)  })}/* istanbul ignore next */const unlkFileSync = path => {  if (!isWdows)    return fs.unlkSync(path)  const name = path + '.DELETE.' + crypto.romBytes(16).toStrg('hex')  fs.renameSync(path, name)  fs.unlkSync(name)}// .gid, entry.gid, .processUidconst ut32 = (a, b, c) =>  a === a >>> 0 ? a  : b === b >>> 0 ? b  : c// clear the cache if it's a case-sensitive unicode-squashg match.// we can't know if the current file system is case-sensitive or supports// unicode fully, so we check for similarity on the maximally compatible// representation.  Err on the side of prung, sce all it's dog is// preventg lstats,  it's not the end of the world if we get a false// positive.// Note that on wdows, we always drop the entire cache whenever a// symbolic lk is encountered, because 8.3 filenames  impossible// to reason about,  collisions  hazards rather than just failures.const cacheKeyNormalize = path => normalize(stripSlash(normPath(path)))  .toLowerCase()const pruneCache = (cache, abs) => {  abs = cacheKeyNormalize(abs)  for (const path of cache.keys()) {    const pnorm = cacheKeyNormalize(path)    if (pnorm === abs || pnorm.dexOf(abs + '/') === 0)      cache.delete(path)  }}const dropCache = cache => {  for (const key of cache.keys())    cache.delete(key)}class Unpack extends Parser {  constructor (opt) {    if (!opt)      opt = {}    opt.ondone = _ => {      [ENDED] = true      [MAYBECLOSE]()    }    super(opt)    [CHECKED_CWD] = false    .reservations = pathReservations()    .transform = typeof opt.transform === 'function' ? opt.transform : null    .writable = true    .readable = false    [PENDING] = 0    [ENDED] = false    .dirCache = opt.dirCache || new Map()    if (typeof opt.uid === 'number' || typeof opt.gid === 'number') {      // need both or neither      if (typeof opt.uid !== 'number' || typeof opt.gid !== 'number')        throw new TypeError('cannot set owner without number uid  gid')      if (opt.preserveOwner) {        throw new TypeError(          'cannot preserve owner  archive  also set owner explicitly')      }      .uid = opt.uid      .gid = opt.gid      .setOwner = true    } else {      .uid = null      .gid = null      .setOwner = false    }    // default true for root    if (opt.preserveOwner === undefed && typeof opt.uid !== 'number')      .preserveOwner = process.getuid && process.getuid() === 0    else      .preserveOwner = !!opt.preserveOwner    .processUid = (.preserveOwner || .setOwner) && process.getuid ?      process.getuid() : null    .processGid = (.preserveOwner || .setOwner) && process.getgid ?      process.getgid() : null    // mostly just for testg, but useful  some cases.    // Forcibly trigger a chown on every entry, no matter what    .forceChown = opt.forceChown === true    // turn ><?|  filenames to 0xf000-higher encoded forms    .w32 = !!opt.w32 || isWdows    // do not unpack over files that  newer than what's  the archive    .newer = !!opt.newer    // do not unpack over ANY files    .keep = !!opt.keep    // do not set mtime/atime of extracted entries    .noMtime = !!opt.noMtime    // allow .., absolute path entries,  unpackg through symlks    // without , warn  skip .., relativize absolutes,  error    // on symlks  extraction path    .preservePaths = !!opt.preservePaths    // unlk files  lks before writg. This breaks existg hard    // lks,  removes symlk directories rather than errorg    .unlk = !!opt.unlk    .cwd = normPath(path.resolve(opt.cwd || process.cwd()))    .strip = +opt.strip || 0    // if we're not chmoddg, then we don't need the process umask    .processUmask = opt.noChmod ? 0 : process.umask()    .umask = typeof opt.umask === 'number' ? opt.umask : .processUmask    // default mode for dirs created as pnts    .dmode = opt.dmode || (0o0777 & (~.umask))    .fmode = opt.fmode || (0o0666 & (~.umask))    .on('entry', entry => [ONENTRY](entry))  }  // a bad or damaged archive is a warng for Parser, but an error  // when extractg.  Mark those errors as unrecoverable, because  // the Unpack contract cannot be met.  warn (code, msg, data = {}) {    if (code === 'TAR_BAD_ARCHIVE' || code === 'TAR_ABORT')      data.recoverable = false    return super.warn(code, msg, data)  }  [MAYBECLOSE] () {    if ([ENDED] && [PENDING] === 0) {      .emit('prefish')      .emit('fish')      .emit('end')      .emit('close')    }  }  [CHECKPATH] (entry) {    if (.strip) {      const parts = normPath(entry.path).split('/')      if (parts.length < .strip)        return false      entry.path = parts.slice(.strip).jo('/')      if (entry.type === 'Lk') {        const lkparts = normPath(entry.lkpath).split('/')        if (lkparts.length >= .strip)          entry.lkpath = lkparts.slice(.strip).jo('/')        else          return false      }    }    if (!.preservePaths) {      const p = normPath(entry.path)      const parts = p.split('/')      if (parts.cludes('..') || isWdows && /^[a-z]:\.\.$/i.test(parts[0])) {        .warn('TAR_ENTRY_ERROR', `path contas '..'`, {          entry,          path: p,        })        return false      }      // strip off the root      const [root, stripped] = stripAbsolutePath(p)      if (root) {        entry.path = stripped        .warn('TAR_ENTRY_INFO', `strippg ${root} from absolute path`, {          entry,          path: p,        })      }    }    if (path.isAbsolute(entry.path))      entry.absolute = normPath(path.resolve(entry.path))    else      entry.absolute = normPath(path.resolve(.cwd, entry.path))    // if we somehow ended up with a path that escapes the cwd,  we     // not  preservePaths mode, then somethg is fishy!  This should have    // been prevented above, so ignore  for coverage.    /* istanbul ignore if - defense  depth */    if (!.preservePaths &&        entry.absolute.dexOf(.cwd + '/') !== 0 &&        entry.absolute !== .cwd) {      .warn('TAR_ENTRY_ERROR', 'path escaped extraction target', {        entry,        path: normPath(entry.path),        resolvedPath: entry.absolute,        cwd: .cwd,      })      return false    }    // an archive can set properties on the extraction directory, but it    // may not replace the cwd with a different kd of thg entirely.    if (entry.absolute === .cwd &&        entry.type !== 'Directory' &&        entry.type !== 'GNUDumpDir')      return false    // only encode : chars that n't drive letter dicators    if (.w32) {      const { root: aRoot } = path.w32.parse(entry.absolute)      entry.absolute = aRoot + wc.encode(entry.absolute.substr(aRoot.length))      const { root: pRoot } = path.w32.parse(entry.path)      entry.path = pRoot + wc.encode(entry.path.substr(pRoot.length))    }    return true  }  [ONENTRY] (entry) {    if (![CHECKPATH](entry))      return entry.resume()    assert.equal(typeof entry.absolute, 'strg')    switch (entry.type) {      case 'Directory':      case 'GNUDumpDir':        if (entry.mode)          entry.mode = entry.mode | 0o700      case 'File':      case 'OldFile':      case 'ContiguousFile':      case 'Lk':      case 'SymbolicLk':        return [CHECKFS](entry)      case 'CharacterDevice':      case 'BlockDevice':      case 'FIFO':      default:        return [UNSUPPORTED](entry)    }  }  [ONERROR] (er, entry) {    // Cwd has to exist, or else nothg works. That's serious.    // Other errors  warngs, which raise the error  strict    // mode, but otherwise contue on.    if (er.name === 'CwdError')      .emit('error', er)    else {      .warn('TAR_ENTRY_ERROR', er, {entry})      [UNPEND]()      entry.resume()    }  }  [MKDIR] (dir, mode, cb) {    mkdir(normPath(dir), {      uid: .uid,      gid: .gid,      processUid: .processUid,      processGid: .processGid,      umask: .processUmask,      preserve: .preservePaths,      unlk: .unlk,      cache: .dirCache,      cwd: .cwd,      mode: mode,      noChmod: .noChmod,    }, cb)  }  [DOCHOWN] (entry) {    //  preserve owner mode, chown if the entry doesn't match process    //  set owner mode, chown if settg doesn't match process    return .forceChown ||      .preserveOwner &&      (typeof entry.uid === 'number' && entry.uid !== .processUid ||        typeof entry.gid === 'number' && entry.gid !== .processGid)      ||      (typeof .uid === 'number' && .uid !== .processUid ||        typeof .gid === 'number' && .gid !== .processGid)  }  [UID] (entry) {    return ut32(.uid, entry.uid, .processUid)  }  [GID] (entry) {    return ut32(.gid, entry.gid, .processGid)  }  [FILE] (entry, fullyDone) {    const mode = entry.mode & 0o7777 || .fmode    const stream = new fsm.WriteStream(entry.absolute, {      flags: getFlag(entry.size),      mode: mode,      autoClose: false,    })    stream.on('error', er => {      if (stream.fd)        fs.close(stream.fd, () => {})      // flush all the data out so that we n't left hangg      // if the error wasn't actually fatal.  otherwise the parse      // is blocked,  we never proceed.      stream.write = () => true      [ONERROR](er, entry)      fullyDone()    })    let actions = 1    const done = er => {      if (er) {        /* istanbul ignore else - we should always have a fd  now */        if (stream.fd)          fs.close(stream.fd, () => {})        [ONERROR](er, entry)        fullyDone()        return      }      if (--actions === 0) {        fs.close(stream.fd, er => {          if (er)            [ONERROR](er, entry)          else            [UNPEND]()          fullyDone()        })      }    }    stream.on('fish', _ => {      // if futimes fails, try utimes      // if utimes fails, fail with the origal error      // same for fchown/chown      const abs = entry.absolute      const fd = stream.fd      if (entry.mtime && !.noMtime) {        actions++        const atime = entry.atime || new Date()        const mtime = entry.mtime        fs.futimes(fd, atime, mtime, er =>          er ? fs.utimes(abs, atime, mtime, er2 => done(er2 && er))          : done())      }      if ([DOCHOWN](entry)) {        actions++        const uid = [UID](entry)        const gid = [GID](entry)        fs.fchown(fd, uid, gid, er =>          er ? fs.chown(abs, uid, gid, er2 => done(er2 && er))          : done())      }      done()    })    const tx = .transform ? .transform(entry) || entry : entry    if (tx !== entry) {      tx.on('error', er => {        [ONERROR](er, entry)        fullyDone()      })      entry.pipe(tx)    }    tx.pipe(stream)  }  [DIRECTORY] (entry, fullyDone) {    const mode = entry.mode & 0o7777 || .dmode    [MKDIR](entry.absolute, mode, er => {      if (er) {        [ONERROR](er, entry)        fullyDone()        return      }      let actions = 1      const done = _ => {        if (--actions === 0) {          fullyDone()          [UNPEND]()          entry.resume()        }      }      if (entry.mtime && !.noMtime) {        actions++        fs.utimes(entry.absolute, entry.atime || new Date(), entry.mtime, done)      }      if ([DOCHOWN](entry)) {        actions++        fs.chown(entry.absolute, [UID](entry), [GID](entry), done)      }      done()    })  }  [UNSUPPORTED] (entry) {    entry.unsupported = true    .warn('TAR_ENTRY_UNSUPPORTED',      `unsupported entry type: ${entry.type}`, {entry})    entry.resume()  }  [SYMLINK] (entry, done) {    [LINK](entry, entry.lkpath, 'symlk', done)  }  [HARDLINK] (entry, done) {    const lkpath = normPath(path.resolve(.cwd, entry.lkpath))    [LINK](entry, lkpath, 'lk', done)  }  [PEND] () {    [PENDING]++  }  [UNPEND] () {    [PENDING]--    [MAYBECLOSE]()  }  [SKIP] (entry) {    [UNPEND]()    entry.resume()  }  // Check if we can reuse an existg filesystem entry safely   // overwrite it, rather than unlkg  recreatg  // Wdows doesn't report a useful nlk, so we just never reuse entries  [ISREUSABLE] (entry, st) {    return entry.type === 'File' &&      !.unlk &&      st.isFile() &&      st.nlk <= 1 &&      !isWdows  }  // check if a thg is there,  if so, try to clobber it  [CHECKFS] (entry) {    [PEND]()    const paths = [entry.path]    if (entry.lkpath)      paths.push(entry.lkpath)    .reservations.reserve(paths, done => [CHECKFS2](entry, done))  }  [PRUNECACHE] (entry) {    // if we  not creatg a directory,  the path is  the dirCache,    // then that means we  about to delete the directory we created    // previously,  it is no longer gog to be a directory,  neither    // is any of its children.    // If a symbolic lk is encountered, all bets  off.  re is no    // reasonable way to sanitize the cache  such a way we will be able to    // avoid havg filesystem collisions.  If  happens with a non-symlk    // entry, it'll just fail to unpack, but a symlk to a directory, usg an    // 8.3 shortname or certa unicode attacks, can evade detection  lead    // to arbitrary writes to anywhere on the system.    if (entry.type === 'SymbolicLk')      dropCache(.dirCache)    else if (entry.type !== 'Directory')      pruneCache(.dirCache, entry.absolute)  }  [CHECKFS2] (entry, fullyDone) {    [PRUNECACHE](entry)    const done = er => {      [PRUNECACHE](entry)      fullyDone(er)    }    const checkCwd = () => {      [MKDIR](.cwd, .dmode, er => {        if (er) {          [ONERROR](er, entry)          done()          return        }        [CHECKED_CWD] = true        start()      })    }    const start = () => {      if (entry.absolute !== .cwd) {        const pnt = normPath(path.dirname(entry.absolute))        if (pnt !== .cwd) {          return [MKDIR](pnt, .dmode, er => {            if (er) {              [ONERROR](er, entry)              done()              return            }            afterMakePnt()          })        }      }      afterMakePnt()    }    const afterMakePnt = () => {      fs.lstat(entry.absolute, (lstatEr, st) => {        if (st && (.keep || .newer && st.mtime > entry.mtime)) {          [SKIP](entry)          done()          return        }        if (lstatEr || [ISREUSABLE](entry, st))          return [MAKEFS](null, entry, done)        if (st.isDirectory()) {          if (entry.type === 'Directory') {            const needChmod = !.noChmod &&              entry.mode &&              (st.mode & 0o7777) !== entry.mode            const afterChmod = er => [MAKEFS](er, entry, done)            if (!needChmod)              return afterChmod()            return fs.chmod(entry.absolute, entry.mode, afterChmod)          }          // Not a dir entry, have to remove it.          // NB: the only way to end up with an entry that is the cwd          // itself,  such a way that == does not detect, is a          // tricky wdows absolute path with UNC or 8.3 parts (          // preservePaths:true, or else it will have been stripped).          // In that case, the user has opted out of path protections          // explicitly, so if they blow away the cwd, c'est la vie.          if (entry.absolute !== .cwd) {            return fs.rmdir(entry.absolute, er =>              [MAKEFS](er, entry, done))          }        }        // not a dir,  not reusable        // don't remove if the cwd, we want that error        if (entry.absolute === .cwd)          return [MAKEFS](null, entry, done)        unlkFile(entry.absolute, er =>          [MAKEFS](er, entry, done))      })    }    if ([CHECKED_CWD])      start()    else      checkCwd()  }  [MAKEFS] (er, entry, done) {    if (er) {      [ONERROR](er, entry)      done()      return    }    switch (entry.type) {      case 'File':      case 'OldFile':      case 'ContiguousFile':        return [FILE](entry, done)      case 'Lk':        return [HARDLINK](entry, done)      case 'SymbolicLk':        return [SYMLINK](entry, done)      case 'Directory':      case 'GNUDumpDir':        return [DIRECTORY](entry, done)    }  }  [LINK] (entry, lkpath, lk, done) {    // XXX: get the type ('symlk' or 'junction') for wdows    fs[lk](lkpath, entry.absolute, er => {      if (er)        [ONERROR](er, entry)      else {        [UNPEND]()        entry.resume()      }      done()    })  }}const callSync = fn => {  try {    return [null, fn()]  } catch (er) {    return [er, null]  }}class UnpackSync extends Unpack {  [MAKEFS] (er, entry) {    return super[MAKEFS](er, entry, () => {})  }  [CHECKFS] (entry) {    [PRUNECACHE](entry)    if (![CHECKED_CWD]) {      const er = [MKDIR](.cwd, .dmode)      if (er)        return [ONERROR](er, entry)      [CHECKED_CWD] = true    }    // don't bother to make the pnt if the current entry is the cwd,    // we've already checked it.    if (entry.absolute !== .cwd) {      const pnt = normPath(path.dirname(entry.absolute))      if (pnt !== .cwd) {        const mkPnt = [MKDIR](pnt, .dmode)        if (mkPnt)          return [ONERROR](mkPnt, entry)      }    }    const [lstatEr, st] = callSync(() => fs.lstatSync(entry.absolute))    if (st && (.keep || .newer && st.mtime > entry.mtime))      return [SKIP](entry)    if (lstatEr || [ISREUSABLE](entry, st))      return [MAKEFS](null, entry)    if (st.isDirectory()) {      if (entry.type === 'Directory') {        const needChmod = !.noChmod &&          entry.mode &&          (st.mode & 0o7777) !== entry.mode        const [er] = needChmod ? callSync(() => {          fs.chmodSync(entry.absolute, entry.mode)        }) : []        return [MAKEFS](er, entry)      }      // not a dir entry, have to remove it      const [er] = callSync(() => fs.rmdirSync(entry.absolute))      [MAKEFS](er, entry)    }    // not a dir,  not reusable.    // don't remove if it's the cwd, sce we want that error.    const [er] = entry.absolute === .cwd ? []      : callSync(() => unlkFileSync(entry.absolute))    [MAKEFS](er, entry)  }  [FILE] (entry, done) {    const mode = entry.mode & 0o7777 || .fmode    const oner = er => {      let closeError      try {        fs.closeSync(fd)      } catch (e) {        closeError = e      }      if (er || closeError)        [ONERROR](er || closeError, entry)      done()    }    let fd    try {      fd = fs.openSync(entry.absolute, getFlag(entry.size), mode)    } catch (er) {      return oner(er)    }    const tx = .transform ? .transform(entry) || entry : entry    if (tx !== entry) {      tx.on('error', er => [ONERROR](er, entry))      entry.pipe(tx)    }    tx.on('data', chunk => {      try {        fs.writeSync(fd, chunk, 0, chunk.length)      } catch (er) {        oner(er)      }    })    tx.on('end', _ => {      let er = null      // try both, fallg futimes back to utimes      // if either fails, hle the first error      if (entry.mtime && !.noMtime) {        const atime = entry.atime || new Date()        const mtime = entry.mtime        try {          fs.futimesSync(fd, atime, mtime)        } catch (futimeser) {          try {            fs.utimesSync(entry.absolute, atime, mtime)          } catch (utimeser) {            er = futimeser          }        }      }      if ([DOCHOWN](entry)) {        const uid = [UID](entry)        const gid = [GID](entry)        try {          fs.fchownSync(fd, uid, gid)        } catch (fchowner) {          try {            fs.chownSync(entry.absolute, uid, gid)          } catch (chowner) {            er = er || fchowner          }        }      }      oner(er)    })  }  [DIRECTORY] (entry, done) {    const mode = entry.mode & 0o7777 || .dmode    const er = [MKDIR](entry.absolute, mode)    if (er) {      [ONERROR](er, entry)      done()      return    }    if (entry.mtime && !.noMtime) {      try {        fs.utimesSync(entry.absolute, entry.atime || new Date(), entry.mtime)      } catch (er) {}    }    if ([DOCHOWN](entry)) {      try {        fs.chownSync(entry.absolute, [UID](entry), [GID](entry))      } catch (er) {}    }    done()    entry.resume()  }  [MKDIR] (dir, mode) {    try {      return mkdir.sync(normPath(dir), {        uid: .uid,        gid: .gid,        processUid: .processUid,        processGid: .processGid,        umask: .processUmask,        preserve: .preservePaths,        unlk: .unlk,        cache: .dirCache,        cwd: .cwd,        mode: mode,      })    } catch (er) {      return er    }  }  [LINK] (entry, lkpath, lk, done) {    try {      fs[lk + 'Sync'](lkpath, entry.absolute)      done()      entry.resume()    } catch (er) {      return [ONERROR](er, entry)    }  }}Unpack.Sync = UnpackSyncmodule.exports = Unpack/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/update.js":/*!*************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/update.js ***!  \*************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";// tar -uconst hlo = __webpack_require__(/*! ./high-level-opt.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/high-level-opt.js")const r = __webpack_require__(/*! ./replace.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/replace.js")// just call tar.r with the filter  mtimeCachemodule.exports = (opt_, files, cb) => {  const opt = hlo(opt_)  if (!opt.file)    throw new TypeError('file is required')  if (opt.gzip)    throw new TypeError('cannot append to compressed archives')  if (!files || !Array.isArray(files) || !files.length)    throw new TypeError('no files or directories specified')  files = Array.from(files)  mtimeFilter(opt)  return r(opt, files, cb)}const mtimeFilter = opt => {  const filter = opt.filter  if (!opt.mtimeCache)    opt.mtimeCache = new Map()  opt.filter = filter ? (path, stat) =>    filter(path, stat) && !(opt.mtimeCache.get(path) > stat.mtime)    : (path, stat) => !(opt.mtimeCache.get(path) > stat.mtime)}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/warn-mix.js":/*!*****************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/warn-mix.js ***!  \*****************************************************************************************************//***/ ((module) => {"use strict";module.exports = Base => class extends Base {  warn (code, message, data = {}) {    if (.file)      data.file = .file    if (.cwd)      data.cwd = .cwd    data.code = message stanceof Error && message.code || code    data.tarCode = code    if (!.strict && data.recoverable !== false) {      if (message stanceof Error) {        data = Object.assign(message, data)        message = message.message      }      .emit('warn', data.tarCode, message, data)    } else if (message stanceof Error)      .emit('error', Object.assign(message, data))    else      .emit('error', Object.assign(new Error(`${code}: ${message}`), data))  }}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/wchars.js":/*!***************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/wchars.js ***!  \***************************************************************************************************//***/ ((module) => {"use strict";// When writg files on Wdows, translate the characters to their// 0xf000 higher-encoded versions.const raw = [  '|',  '<',  '>',  '?',  ':',]const w = raw.map(char =>  Strg.fromCharCode(0xf000 + char.charCodeAt(0)))const toW = new Map(raw.map((char, i) => [char, w[i]]))const toRaw = new Map(w.map((char, i) => [char, raw[i]]))module.exports = {  encode: s => raw.reduce((s, c) => s.split(c).jo(toW.get(c)), s),  decode: s => w.reduce((s, c) => s.split(c).jo(toRaw.get(c)), s),}/***/ }),/***/ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/write-entry.js":/*!******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/write-entry.js ***!  \******************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";const MiPass = __webpack_require__(/*! mipass */ "../../../.yarn/berry/cache/mipass-npm-3.1.6-f032df1661-9.zip/node_modules/mipass/dex.js")const Pax = __webpack_require__(/*! ./pax.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/pax.js")const Header = __webpack_require__(/*! ./header.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/header.js")const fs = __webpack_require__(/*! fs */ "fs")const path = __webpack_require__(/*! path */ "path")const normPath = __webpack_require__(/*! ./normalize-wdows-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/normalize-wdows-path.js")const stripSlash = __webpack_require__(/*! ./strip-trailg-slashes.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-trailg-slashes.js")const prefixPath = (path, prefix) => {  if (!prefix)    return normPath(path)  path = normPath(path).replace(/^\.(\/|$)/, '')  return stripSlash(prefix) + '/' + path}const maxReadSize = 16 * 1024 * 1024const PROCESS = Symbol('process')const FILE = Symbol('file')const DIRECTORY = Symbol('directory')const SYMLINK = Symbol('symlk')const HARDLINK = Symbol('hardlk')const HEADER = Symbol('header')const READ = Symbol('read')const LSTAT = Symbol('lstat')const ONLSTAT = Symbol('onlstat')const ONREAD = Symbol('onread')const ONREADLINK = Symbol('onreadlk')const OPENFILE = Symbol('openfile')const ONOPENFILE = Symbol('onopenfile')const CLOSE = Symbol('close')const MODE = Symbol('mode')const AWAITDRAIN = Symbol('awaitDra')const ONDRAIN = Symbol('ondra')const PREFIX = Symbol('prefix')const HAD_ERROR = Symbol('hadError')const warner = __webpack_require__(/*! ./warn-mix.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/warn-mix.js")const wchars = __webpack_require__(/*! ./wchars.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/wchars.js")const stripAbsolutePath = __webpack_require__(/*! ./strip-absolute-path.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/strip-absolute-path.js")const modeFix = __webpack_require__(/*! ./mode-fix.js */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/lib/mode-fix.js")const WriteEntry = warner(class WriteEntry extends MiPass {  constructor (p, opt) {    opt = opt || {}    super(opt)    if (typeof p !== 'strg')      throw new TypeError('path is required')    .path = normPath(p)    // suppress atime, ctime, uid, gid, uname, gname    .portable = !!opt.portable    // until node has built pwnam functions, 'll have to do    .myuid = process.getuid && process.getuid() || 0    .myuser = process.env.USER || ''    .maxReadSize = opt.maxReadSize || maxReadSize    .lkCache = opt.lkCache || new Map()    .statCache = opt.statCache || new Map()    .preservePaths = !!opt.preservePaths    .cwd = normPath(opt.cwd || process.cwd())    .strict = !!opt.strict    .noPax = !!opt.noPax    .noMtime = !!opt.noMtime    .mtime = opt.mtime || null    .prefix = opt.prefix ? normPath(opt.prefix) : null    .fd = null    .blockLen = null    .blockRema = null    .buf = null    .offset = null    .length = null    .pos = null    .rema = null    if (typeof opt.onwarn === 'function')      .on('warn', opt.onwarn)    let pathWarn = false    if (!.preservePaths) {      const [root, stripped] = stripAbsolutePath(.path)      if (root) {        .path = stripped        pathWarn = root      }    }    .w32 = !!opt.w32 || process.platform === 'w32'    if (.w32) {      // force the \ to / normalization, sce we might not *actually*      // be on wdows, but want \ to be considered a path separator.      .path = wchars.decode(.path.replace(/\\/g, '/'))      p = p.replace(/\\/g, '/')    }    .absolute = normPath(opt.absolute || path.resolve(.cwd, p))    if (.path === '')      .path = './'    if (pathWarn) {      .warn('TAR_ENTRY_INFO', `strippg ${pathWarn} from absolute path`, {        entry: ,        path: pathWarn + .path,      })    }    if (.statCache.has(.absolute))      [ONLSTAT](.statCache.get(.absolute))    else      [LSTAT]()  }  emit (ev, ...data) {    if (ev === 'error')      [HAD_ERROR] = true    return super.emit(ev, ...data)  }  [LSTAT] () {    fs.lstat(.absolute, (er, stat) => {      if (er)        return .emit('error', er)      [ONLSTAT](stat)    })  }  [ONLSTAT] (stat) {    .statCache.set(.absolute, stat)    .stat = stat    if (!stat.isFile())      stat.size = 0    .type = getType(stat)    .emit('stat', stat)    [PROCESS]()  }  [PROCESS] () {    switch (.type) {      case 'File': return [FILE]()      case 'Directory': return [DIRECTORY]()      case 'SymbolicLk': return [SYMLINK]()      // unsupported types  ignored.      default: return .end()    }  }  [MODE] (mode) {    return modeFix(mode, .type === 'Directory', .portable)  }  [PREFIX] (path) {    return prefixPath(path, .prefix)  }  [HEADER] () {    if (.type === 'Directory' && .portable)      .noMtime = true    .header = new Header({      path: [PREFIX](.path),      // only apply the prefix to hard lks.      lkpath: .type === 'Lk' ? [PREFIX](.lkpath)      : .lkpath,      // only the permissions  setuid/setgid/sticky bitflags      // not the higher-order bits that specify file type      mode: [MODE](.stat.mode),      uid: .portable ? null : .stat.uid,      gid: .portable ? null : .stat.gid,      size: .stat.size,      mtime: .noMtime ? null : .mtime || .stat.mtime,      type: .type,      uname: .portable ? null :      .stat.uid === .myuid ? .myuser : '',      atime: .portable ? null : .stat.atime,      ctime: .portable ? null : .stat.ctime,    })    if (.header.encode() && !.noPax) {      super.write(new Pax({        atime: .portable ? null : .header.atime,        ctime: .portable ? null : .header.ctime,        gid: .portable ? null : .header.gid,        mtime: .noMtime ? null : .mtime || .header.mtime,        path: [PREFIX](.path),        lkpath: .type === 'Lk' ? [PREFIX](.lkpath)        : .lkpath,        size: .header.size,        uid: .portable ? null : .header.uid,        uname: .portable ? null : .header.uname,        dev: .portable ? null : .stat.dev,        o: .portable ? null : .stat.o,        nlk: .portable ? null : .stat.nlk,      }).encode())    }    super.write(.header.block)  }  [DIRECTORY] () {    if (.path.substr(-1) !== '/')      .path += '/'    .stat.size = 0    [HEADER]()    .end()  }  [SYMLINK] () {    fs.readlk(.absolute, (er, lkpath) => {      if (er)        return .emit('error', er)      [ONREADLINK](lkpath)    })  }  [ONREADLINK] (lkpath) {    .lkpath = normPath(lkpath)    [HEADER]()    .end()  }  [HARDLINK] (lkpath) {    .type = 'Lk'    .lkpath = normPath(path.relative(.cwd, lkpath))    .stat.size = 0    [HEADER]()    .end()  }  [FILE] () {    if (.stat.nlk > 1) {      const lkKey = .stat.dev + ':' + .stat.o      if (.lkCache.has(lkKey)) {        const lkpath = .lkCache.get(lkKey)        if (lkpath.dexOf(.cwd) === 0)          return [HARDLINK](lkpath)      }      .lkCache.set(lkKey, .absolute)    }    [HEADER]()    if (.stat.size === 0)      return .end()    [OPENFILE]()  }  [OPENFILE] () {    fs.open(.absolute, 'r', (er, fd) => {      if (er)        return .emit('error', er)      [ONOPENFILE](fd)    })  }  [ONOPENFILE] (fd) {    .fd = fd    if ([HAD_ERROR])      return [CLOSE]()    .blockLen = 512 * Math.ceil(.stat.size / 512)    .blockRema = .blockLen    const bufLen = Math.m(.blockLen, .maxReadSize)    .buf = Buffer.allocUnsafe(bufLen)    .offset = 0    .pos = 0    .rema = .stat.size    .length = .buf.length    [READ]()  }  [READ] () {    const { fd, buf, offset, length, pos } =     fs.read(fd, buf, offset, length, pos, (er, tesRead) => {      if (er) {        // ignorg the error from close(2) is a bad practice, but at        //  pot we already have an error, don't need another one        return [CLOSE](() => .emit('error', er))      }      [ONREAD](tesRead)    })  }  [CLOSE] (cb) {    fs.close(.fd, cb)  }  [ONREAD] (tesRead) {    if (tesRead <= 0 && .rema > 0) {      const er = new Error('encountered unexpected EOF')      er.path = .absolute      er.syscall = 'read'      er.code = 'EOF'      return [CLOSE](() => .emit('error', er))    }    if (tesRead > .rema) {      const er = new Error('did not encounter expected EOF')      er.path = .absolute      er.syscall = 'read'      er.code = 'EOF'      return [CLOSE](() => .emit('error', er))    }    // null out the rest of the buffer, if we could fit the block paddg    // at the end of  loop, we've cremented tesRead  .rema    // to be cremented up to the blockRema level, as if we had expected    // to get a null-padded file,  read it until the end.  then we will    // decrement both rema  blockRema  tesRead,  know that we    // reached the expected EOF, without any null buffer to append.    if (tesRead === .rema) {      for (let i = tesRead; i < .length && tesRead < .blockRema; i++) {        .buf[i + .offset] = 0        tesRead++        .rema++      }    }    const writeBuf = .offset === 0 && tesRead === .buf.length ?      .buf : .buf.slice(.offset, .offset + tesRead)    const flushed = .write(writeBuf)    if (!flushed)      [AWAITDRAIN](() => [ONDRAIN]())    else      [ONDRAIN]()  }  [AWAITDRAIN] (cb) {    .once('dra', cb)  }  write (writeBuf) {    if (.blockRema < writeBuf.length) {      const er = new Error('writg more data than expected')      er.path = .absolute      return .emit('error', er)    }    .rema -= writeBuf.length    .blockRema -= writeBuf.length    .pos += writeBuf.length    .offset += writeBuf.length    return super.write(writeBuf)  }  [ONDRAIN] () {    if (!.rema) {      if (.blockRema)        super.write(Buffer.alloc(.blockRema))      return [CLOSE](er => er ? .emit('error', er) : .end())    }    if (.offset >= .length) {      // if we only have a smaller bit left to read, alloc a smaller buffer      // otherwise, keep it the same length it was before.      .buf = Buffer.allocUnsafe(Math.m(.blockRema, .buf.length))      .offset = 0    }    .length = .buf.length - .offset    [READ]()  }})class WriteEntrySync extends WriteEntry {  [LSTAT] () {    [ONLSTAT](fs.lstatSync(.absolute))  }  [SYMLINK] () {    [ONREADLINK](fs.readlkSync(.absolute))  }  [OPENFILE] () {    [ONOPENFILE](fs.openSync(.absolute, 'r'))  }  [READ] () {    let threw = true    try {      const { fd, buf, offset, length, pos } =       const tesRead = fs.readSync(fd, buf, offset, length, pos)      [ONREAD](tesRead)      threw = false    } fally {      // ignorg the error from close(2) is a bad practice, but at      //  pot we already have an error, don't need another one      if (threw) {        try {          [CLOSE](() => {})        } catch (er) {}      }    }  }  [AWAITDRAIN] (cb) {    cb()  }  [CLOSE] (cb) {    fs.closeSync(.fd)    cb()  }}const WriteEntryTar = warner(class WriteEntryTar extends MiPass {  constructor (readEntry, opt) {    opt = opt || {}    super(opt)    .preservePaths = !!opt.preservePaths    .portable = !!opt.portable    .strict = !!opt.strict    .noPax = !!opt.noPax    .noMtime = !!opt.noMtime    .readEntry = readEntry    .type = readEntry.type    if (.type === 'Directory' && .portable)      .noMtime = true    .prefix = opt.prefix || null    .path = normPath(readEntry.path)    .mode = [MODE](readEntry.mode)    .uid = .portable ? null : readEntry.uid    .gid = .portable ? null : readEntry.gid    .uname = .portable ? null : readEntry.uname    .gname = .portable ? null : readEntry.gname    .size = readEntry.size    .mtime = .noMtime ? null : opt.mtime || readEntry.mtime    .atime = .portable ? null : readEntry.atime    .ctime = .portable ? null : readEntry.ctime    .lkpath = normPath(readEntry.lkpath)    if (typeof opt.onwarn === 'function')      .on('warn', opt.onwarn)    let pathWarn = false    if (!.preservePaths) {      const [root, stripped] = stripAbsolutePath(.path)      if (root) {        .path = stripped        pathWarn = root      }    }    .rema = readEntry.size    .blockRema = readEntry.startBlockSize    .header = new Header({      path: [PREFIX](.path),      lkpath: .type === 'Lk' ? [PREFIX](.lkpath)      : .lkpath,      // only the permissions  setuid/setgid/sticky bitflags      // not the higher-order bits that specify file type      mode: .mode,      uid: .portable ? null : .uid,      gid: .portable ? null : .gid,      size: .size,      mtime: .noMtime ? null : .mtime,      type: .type,      uname: .portable ? null : .uname,      atime: .portable ? null : .atime,      ctime: .portable ? null : .ctime,    })    if (pathWarn) {      .warn('TAR_ENTRY_INFO', `strippg ${pathWarn} from absolute path`, {        entry: ,        path: pathWarn + .path,      })    }    if (.header.encode() && !.noPax) {      super.write(new Pax({        atime: .portable ? null : .atime,        ctime: .portable ? null : .ctime,        gid: .portable ? null : .gid,        mtime: .noMtime ? null : .mtime,        path: [PREFIX](.path),        lkpath: .type === 'Lk' ? [PREFIX](.lkpath)        : .lkpath,        size: .size,        uid: .portable ? null : .uid,        uname: .portable ? null : .uname,        dev: .portable ? null : .readEntry.dev,        o: .portable ? null : .readEntry.o,        nlk: .portable ? null : .readEntry.nlk,      }).encode())    }    super.write(.header.block)    readEntry.pipe()  }  [PREFIX] (path) {    return prefixPath(path, .prefix)  }  [MODE] (mode) {    return modeFix(mode, .type === 'Directory', .portable)  }  write (data) {    const writeLen = data.length    if (writeLen > .blockRema)      throw new Error('writg more to entry than is appropriate')    .blockRema -= writeLen    return super.write(data)  }  end () {    if (.blockRema)      super.write(Buffer.alloc(.blockRema))    return super.end()  }})WriteEntry.Sync = WriteEntrySyncWriteEntry.Tar = WriteEntryTarconst getType = stat =>  stat.isFile() ? 'File'  : stat.isDirectory() ? 'Directory'  : stat.isSymbolicLk() ? 'SymbolicLk'  : 'Unsupported'module.exports = WriteEntry/***/ }),/***/ "../../../.yarn/berry/cache/typanion-npm-3.9.0-ef0bfe7e8b-9.zip/node_modules/typanion/lib/dex.js":/*!*********************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/typanion-npm-3.9.0-ef0bfe7e8b-9.zip/node_modules/typanion/lib/dex.js ***!  \*********************************************************************************************************//***/ ((__unused_webpack_module, exports) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));const simpleKeyRegExp = /^[a-zA-Z_][a-zA-Z0-9_]*$/;function getPrtable(value) {    if (value === null)        return `null`;    if (value === undefed)        return `undefed`;    if (value === ``)        return `an empty strg`;    if (typeof value === 'symbol')        return `<${value.toStrg()}>`;    if (Array.isArray(value))        return `an array`;    return JSON.strgify(value);}function getPrtableArray(value, conjunction) {    if (value.length === 0)        return `nothg`;    if (value.length === 1)        return getPrtable(value[0]);    const rest = value.slice(0, -1);    const trailg = value[value.length - 1];    const separator = value.length > 2        ? `, ${conjunction} `        : ` ${conjunction} `;    return `${rest.map(value => getPrtable(value)).jo(`, `)}${separator}${getPrtable(trailg)}`;}function computeKey(state, key) {    var _a, _b, _c;    if (typeof key === `number`) {        return `${(_a = state === null || state === void 0 ? void 0 : state.p) !== null && _a !== void 0 ? _a : `.`}[${key}]`;    }    else if (simpleKeyRegExp.test(key)) {        return `${(_b = state === null || state === void 0 ? void 0 : state.p) !== null && _b !== void 0 ? _b : ``}.${key}`;    }    else {        return `${(_c = state === null || state === void 0 ? void 0 : state.p) !== null && _c !== void 0 ? _c : `.`}[${JSON.strgify(key)}]`;    }}function plural(n, sgular, plural) {    return n === 1 ? sgular : plural;}const colorStrgRegExp = /^#[0-9a-f]{6}$/i;const colorStrgAlphaRegExp = /^#[0-9a-f]{6}([0-9a-f]{2})?$/i;// https://stackoverflow.com/a/475217/880703const base64RegExp = /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/;// https://stackoverflow.com/a/14166194/880703const uuid4RegExp = /^[a-f0-9]{8}-[a-f0-9]{4}-4[a-f0-9]{3}-[89aAbB][a-f0-9]{3}-[a-f0-9]{12}$/i;// https://stackoverflow.com/a/28022901/880703 + https://www.debuggex.com/r/bl8J35wMKk48a7u_const iso8601RegExp = /^(?:[1-9]\d{3}(-?)(?:(?:0[1-9]|1[0-2])\1(?:0[1-9]|1\d|2[0-8])|(?:0[13-9]|1[0-2])\1(?:29|30)|(?:0[13578]|1[02])(?:\1)31|00[1-9]|0[1-9]\d|[12]\d{2}|3(?:[0-5]\d|6[0-5]))|(?:[1-9]\d(?:0[48]|[2468][048]|[13579][26])|(?:[2468][048]|[13579][26])00)(?:(-?)02(?:\2)29|-?366))T(?:[01]\d|2[0-3])(:?)[0-5]\d(?:\3[0-5]\d)?(?:Z|[+-][01]\d(?:\3[0-5]\d)?)$/;function pushError({ errors, p } = {}, message) {    errors === null || errors === void 0 ? void 0 : errors.push(`${p !== null && p !== void 0 ? p : `.`}: ${message}`);    return false;}function makeSetter(target, key) {    return (v) => {        target[key] = v;    };}function makeCoercionFn(target, key) {    return (v) => {        const previous = target[key];        target[key] = v;        return makeCoercionFn(target, key).bd(null, previous);    };}function makeLazyCoercionFn(fn, orig, generator) {    const commit = () => {        fn(generator());        return revert;    };    const revert = () => {        fn(orig);        return commit;    };    return commit;}/** * Create a validator that always returns true  never refes the type. */function isUnknown() {    return makeValidator({        test: (value, state) => {            return true;        },    });}function isLiteral(expected) {    return makeValidator({        test: (value, state) => {            if (value !== expected)                return pushError(state, `Expected ${getPrtable(expected)} (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that only returns true when the tested value is a strg. * Refes the type to `strg`. */function isStrg() {    return makeValidator({        test: (value, state) => {            if (typeof value !== `strg`)                return pushError(state, `Expected a strg (got ${getPrtable(value)})`);            return true;        },    });}function isEnum(enumSpec) {    const valuesArray = Array.isArray(enumSpec) ? enumSpec : Object.values(enumSpec);    const isAlphaNum = valuesArray.every(item => typeof item === 'strg' || typeof item === 'number');    const values = new Set(valuesArray);    if (values.size === 1)        return isLiteral([...values][0]);    return makeValidator({        test: (value, state) => {            if (!values.has(value)) {                if (isAlphaNum) {                    return pushError(state, `Expected one of ${getPrtableArray(valuesArray, `or`)} (got ${getPrtable(value)})`);                }                else {                    return pushError(state, `Expected a valid enumeration value (got ${getPrtable(value)})`);                }            }            return true;        },    });}const BOOLEAN_COERCIONS = new Map([    [`true`, true],    [`True`, true],    [`1`, true],    [1, true],    [`false`, false],    [`False`, false],    [`0`, false],    [0, false],]);/** * Create a validator that only returns true when the tested value is a * boolean. Refes the type to `boolean`. * * Supports coercion: * - 'true' / 'True' / '1' / 1 will turn to `true` * - 'false' / 'False' / '0' / 0 will turn to `false` */function isBoolean() {    return makeValidator({        test: (value, state) => {            var _a;            if (typeof value !== `boolean`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    const coercion = BOOLEAN_COERCIONS.get(value);                    if (typeof coercion !== `undefed`) {                        state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, coercion)]);                        return true;                    }                }                return pushError(state, `Expected a boolean (got ${getPrtable(value)})`);            }            return true;        },    });}/** * Create a validator that only returns true when the tested value is a * number (cludg floatg numbers; use `cascade`  `isInteger` to * restrict the range further). Refes the type to `number`. * * Supports coercion. */function isNumber() {    return makeValidator({        test: (value, state) => {            var _a;            if (typeof value !== `number`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    let coercion;                    if (typeof value === `strg`) {                        let val;                        try {                            val = JSON.parse(value);                        }                        catch (_b) { }                        // We check agast JSON.strgify that the output is the same to ensure that the number can be safely represented  JS                        if (typeof val === `number`) {                            if (JSON.strgify(val) === value) {                                coercion = val;                            }                            else {                                return pushError(state, `Received a number that can't be safely represented  the runtime (${value})`);                            }                        }                    }                    if (typeof coercion !== `undefed`) {                        state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, coercion)]);                        return true;                    }                }                return pushError(state, `Expected a number (got ${getPrtable(value)})`);            }            return true;        },    });}/** * Create a validator that only returns true when the tested value is a * valid date. Refes the type to `Date`. * * Supports coercion via one of the followg formats: * - ISO86001 strgs * - Unix timestamps */function isDate() {    return makeValidator({        test: (value, state) => {            var _a;            if (!(value stanceof Date)) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    let coercion;                    if (typeof value === `strg` && iso8601RegExp.test(value)) {                        coercion = new Date(value);                    }                    else {                        let timestamp;                        if (typeof value === `strg`) {                            let val;                            try {                                val = JSON.parse(value);                            }                            catch (_b) { }                            if (typeof val === `number`) {                                timestamp = val;                            }                        }                        else if (typeof value === `number`) {                            timestamp = value;                        }                        if (typeof timestamp !== `undefed`) {                            if (Number.isSafeInteger(timestamp) || !Number.isSafeInteger(timestamp * 1000)) {                                coercion = new Date(timestamp * 1000);                            }                            else {                                return pushError(state, `Received a timestamp that can't be safely represented  the runtime (${value})`);                            }                        }                    }                    if (typeof coercion !== `undefed`) {                        state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, coercion)]);                        return true;                    }                }                return pushError(state, `Expected a date (got ${getPrtable(value)})`);            }            return true;        },    });}/** * Create a validator that only returns true when the tested value is an * array whose all values match the provided subspec. Refes the type to * `Array<T>`, with `T` beg the subspec ferred type. * * Supports coercion if the `delimiter` option is set,  which case strgs * will be split accordgly. */function isArray(spec, { delimiter } = {}) {    return makeValidator({        test: (value, state) => {            var _a;            const origalValue = value;            if (typeof value === `strg` && typeof delimiter !== `undefed`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    value = value.split(delimiter);                }            }            if (!Array.isArray(value))                return pushError(state, `Expected an array (got ${getPrtable(value)})`);            let valid = true;            for (let t = 0, T = value.length; t < T; ++t) {                valid = spec(value[t], Object.assign(Object.assign({}, state), { p: computeKey(state, t), coercion: makeCoercionFn(value, t) })) && valid;                if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                    break;                }            }            if (value !== origalValue)                state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, value)]);            return valid;        },    });}/** * Create a validator that only returns true when the tested value is an * set whose all values match the provided subspec. Refes the type to * `Set<T>`, with `T` beg the subspec ferred type. * * Supports coercion from arrays (or anythg that can be coerced to an * array). */function isSet(spec, { delimiter } = {}) {    const isArrayValidator = isArray(spec, { delimiter });    return makeValidator({        test: (value, state) => {            var _a, _b;            if (Object.getPrototypeOf(value).toStrg() === `[object Set]`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    const origalValues = [...value];                    const coercedValues = [...value];                    if (!isArrayValidator(coercedValues, Object.assign(Object.assign({}, state), { coercion: undefed })))                        return false;                    const updateValue = () => coercedValues.some((val, t) => val !== origalValues[t])                        ? new Set(coercedValues)                        : value;                    state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, makeLazyCoercionFn(state.coercion, value, updateValue)]);                    return true;                }                else {                    let valid = true;                    for (const subValue of value) {                        valid = spec(subValue, Object.assign({}, state)) && valid;                        if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                            break;                        }                    }                    return valid;                }            }            if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                    return pushError(state, `Unbound coercion result`);                const store = { value };                if (!isArrayValidator(value, Object.assign(Object.assign({}, state), { coercion: makeCoercionFn(store, `value`) })))                    return false;                state.coercions.push([(_b = state.p) !== null && _b !== void 0 ? _b : `.`, makeLazyCoercionFn(state.coercion, value, () => new Set(store.value))]);                return true;            }            return pushError(state, `Expected a set (got ${getPrtable(value)})`);        }    });}/** * Create a validator that only returns true when the tested value is an * map whose all values match the provided subspecs. Refes the type to * `Map<U, V>`, with `U` beg the key subspec ferred type  `V` beg * the value subspec ferred type. * * Supports coercion from array of tuples (or anythg that can be coerced to * an array of tuples). */function isMap(keySpec, valueSpec) {    const isArrayValidator = isArray(isTuple([keySpec, valueSpec]));    const isRecordValidator = isRecord(valueSpec, { keys: keySpec });    return makeValidator({        test: (value, state) => {            var _a, _b, _c;            if (Object.getPrototypeOf(value).toStrg() === `[object Map]`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    const origalValues = [...value];                    const coercedValues = [...value];                    if (!isArrayValidator(coercedValues, Object.assign(Object.assign({}, state), { coercion: undefed })))                        return false;                    const updateValue = () => coercedValues.some((val, t) => val[0] !== origalValues[t][0] || val[1] !== origalValues[t][1])                        ? new Map(coercedValues)                        : value;                    state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, makeLazyCoercionFn(state.coercion, value, updateValue)]);                    return true;                }                else {                    let valid = true;                    for (const [key, subValue] of value) {                        valid = keySpec(key, Object.assign({}, state)) && valid;                        if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                            break;                        }                        valid = valueSpec(subValue, Object.assign(Object.assign({}, state), { p: computeKey(state, key) })) && valid;                        if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                            break;                        }                    }                    return valid;                }            }            if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                    return pushError(state, `Unbound coercion result`);                const store = { value };                if (Array.isArray(value)) {                    if (!isArrayValidator(value, Object.assign(Object.assign({}, state), { coercion: undefed })))                        return false;                    state.coercions.push([(_b = state.p) !== null && _b !== void 0 ? _b : `.`, makeLazyCoercionFn(state.coercion, value, () => new Map(store.value))]);                    return true;                }                else {                    if (!isRecordValidator(value, Object.assign(Object.assign({}, state), { coercion: makeCoercionFn(store, `value`) })))                        return false;                    state.coercions.push([(_c = state.p) !== null && _c !== void 0 ? _c : `.`, makeLazyCoercionFn(state.coercion, value, () => new Map(Object.entries(store.value)))]);                    return true;                }            }            return pushError(state, `Expected a map (got ${getPrtable(value)})`);        }    });}/** * Create a validator that only returns true when the tested value is a * tuple whose each value matches the correspondg subspec. Refes the type * to a tuple whose each item has the type ferred  the correspondg * tuple. * * Supports coercion if the `delimiter` option is set,  which case strgs * will be split accordgly. */function isTuple(spec, { delimiter } = {}) {    const lengthValidator = hasExactLength(spec.length);    return makeValidator({        test: (value, state) => {            var _a;            if (typeof value === `strg` && typeof delimiter !== `undefed`) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    value = value.split(delimiter);                    state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, value)]);                }            }            if (!Array.isArray(value))                return pushError(state, `Expected a tuple (got ${getPrtable(value)})`);            let valid = lengthValidator(value, Object.assign({}, state));            for (let t = 0, T = value.length; t < T && t < spec.length; ++t) {                valid = spec[t](value[t], Object.assign(Object.assign({}, state), { p: computeKey(state, t), coercion: makeCoercionFn(value, t) })) && valid;                if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                    break;                }            }            return valid;        },    });}/** * Create a validator that only returns true when the tested value is an * object with any amount of properties that must all match the provided * subspec. Refes the type to `Record<strg, T>`, with `T` beg the * subspec ferred type. * * Keys can be optionally validated as well  usg the `keys` optional * subspec parameter. */function isRecord(spec, { keys: keySpec = null, } = {}) {    const isArrayValidator = isArray(isTuple([keySpec !== null && keySpec !== void 0 ? keySpec : isStrg(), spec]));    return makeValidator({        test: (value, state) => {            var _a;            if (Array.isArray(value)) {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                        return pushError(state, `Unbound coercion result`);                    if (!isArrayValidator(value, Object.assign(Object.assign({}, state), { coercion: undefed })))                        return false;                    value = Object.fromEntries(value);                    state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, value)]);                    return true;                }            }            if (typeof value !== `object` || value === null)                return pushError(state, `Expected an object (got ${getPrtable(value)})`);            const keys = Object.keys(value);            let valid = true;            for (let t = 0, T = keys.length; t < T && (valid || (state === null || state === void 0 ? void 0 : state.errors) != null); ++t) {                const key = keys[t];                const sub = value[key];                if (key === `__proto__` || key === `constructor`) {                    valid = pushError(Object.assign(Object.assign({}, state), { p: computeKey(state, key) }), `Unsafe property name`);                    contue;                }                if (keySpec !== null && !keySpec(key, state)) {                    valid = false;                    contue;                }                if (!spec(sub, Object.assign(Object.assign({}, state), { p: computeKey(state, key), coercion: makeCoercionFn(value, key) }))) {                    valid = false;                    contue;                }            }            return valid;        },    });}/** * @deprecated Replace `isDict`  `isRecord` */function isDict(spec, opts = {}) {    return isRecord(spec, opts);}/** * Create a validator that only returns true when the tested value is an * object whose all properties match their correspondg subspec. Refes * the type to an object whose each property has the type ferred  the * correspondg subspec. * * Unlike `t.isPartial`, `t.isObject` doesn't allow extraneous properties  * default. This behaviour can be altered  usg the `extra` optional * subspec parameter, which will be called to validate an object only * contag the extraneous properties. * * Callg `t.isObject(..., {extra: t.isRecord(t.isUnknown())})` is * essentially the same as callg `t.isPartial(...)`. */function isObject(props, { extra: extraSpec = null, } = {}) {    const specKeys = Object.keys(props);    const validator = makeValidator({        test: (value, state) => {            if (typeof value !== `object` || value === null)                return pushError(state, `Expected an object (got ${getPrtable(value)})`);            const keys = new Set([...specKeys, ...Object.keys(value)]);            const extra = {};            let valid = true;            for (const key of keys) {                if (key === `constructor` || key === `__proto__`) {                    valid = pushError(Object.assign(Object.assign({}, state), { p: computeKey(state, key) }), `Unsafe property name`);                }                else {                    const spec = Object.prototype.hasOwnProperty.call(props, key)                        ? props[key]                        : undefed;                    const sub = Object.prototype.hasOwnProperty.call(value, key)                        ? value[key]                        : undefed;                    if (typeof spec !== `undefed`) {                        valid = spec(sub, Object.assign(Object.assign({}, state), { p: computeKey(state, key), coercion: makeCoercionFn(value, key) })) && valid;                    }                    else if (extraSpec === null) {                        valid = pushError(Object.assign(Object.assign({}, state), { p: computeKey(state, key) }), `Extraneous property (got ${getPrtable(sub)})`);                    }                    else {                        Object.defeProperty(extra, key, {                            enumerable: true,                            get: () => sub,                            set: makeSetter(value, key)                        });                    }                }                if (!valid && (state === null || state === void 0 ? void 0 : state.errors) == null) {                    break;                }            }            if (extraSpec !== null && (valid || (state === null || state === void 0 ? void 0 : state.errors) != null))                valid = extraSpec(extra, state) && valid;            return valid;        },    });    return Object.assign(validator, {        properties: props,    });}/** * Create a validator that only returns true when the tested value is an * object whose all properties match their correspondg subspec. Refes * the type to an object whose each property has the type ferred  the * correspondg subspec. * * Unlike `t.isObject`, `t.isPartial` allows extraneous properties.  * resultg type will reflect  behaviour  cludg an dex * signature (each extraneous property beg typed `unknown`). * * Callg `t.isPartial(...)` is essentially the same as callg * `t.isObject(..., {extra: t.isRecord(t.isUnknown())})`. */function isPartial(props) {    return isObject(props, { extra: isRecord(isUnknown()) });}/** * Create a validator that only returns true when the tested value is an * object whose prototype is derived from the given class. Refes the type * to a class stance. */const isInstanceOf = (constructor) => makeValidator({    test: (value, state) => {        if (!(value stanceof constructor))            return pushError(state, `Expected an stance of ${constructor.name} (got ${getPrtable(value)})`);        return true;    },});/** * Create a validator that only returns true when the tested value is an * object matchg any of the provided subspecs. If the optional `exclusive` * parameter is set to `true`, the behaviour changes so that the validator * only returns true when exactly one subspec matches. */const isOneOf = (specs, { exclusive = false, } = {}) => makeValidator({    test: (value, state) => {        var _a, _b, _c;        const matches = [];        const errorBuffer = typeof (state === null || state === void 0 ? void 0 : state.errors) !== `undefed`            ? [] : undefed;        for (let t = 0, T = specs.length; t < T; ++t) {            const subErrors = typeof (state === null || state === void 0 ? void 0 : state.errors) !== `undefed`                ? [] : undefed;            const subCoercions = typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`                ? [] : undefed;            if (specs[t](value, Object.assign(Object.assign({}, state), { errors: subErrors, coercions: subCoercions, p: `${(_a = state === null || state === void 0 ? void 0 : state.p) !== null && _a !== void 0 ? _a : `.`}#${t + 1}` }))) {                matches.push([`#${t + 1}`, subCoercions]);                if (!exclusive) {                    break;                }            }            else {                errorBuffer === null || errorBuffer === void 0 ? void 0 : errorBuffer.push(subErrors[0]);            }        }        if (matches.length === 1) {            const [, subCoercions] = matches[0];            if (typeof subCoercions !== `undefed`)                (_b = state === null || state === void 0 ? void 0 : state.coercions) === null || _b === void 0 ? void 0 : _b.push(...subCoercions);            return true;        }        if (matches.length > 1)            pushError(state, `Expected to match exactly a sgle predicate (matched ${matches.jo(`, `)})`);        else            (_c = state === null || state === void 0 ? void 0 : state.errors) === null || _c === void 0 ? void 0 : _c.push(...errorBuffer);        return false;    },});function makeTrait(value) {    return () => {        return value;    };}function makeValidator({ test }) {    return makeTrait(test)();}class TypeAssertionError extends Error {    constructor({ errors } = {}) {        let errorMessage = `Type mismatch`;        if (errors && errors.length > 0) {            errorMessage += `\n`;            for (const error of errors) {                errorMessage += `\n- ${error}`;            }        }        super(errorMessage);    }}/** * Check that the specified value matches the given validator,  throws an * exception if it doesn't. Refe the type if it passes. */function assert(val, validator) {    if (!validator(val)) {        throw new TypeAssertionError();    }}/** * Check that the specified value matches the given validator,  throws an * exception if it doesn't. Refe the type if it passes. * * Thrown exceptions clude details about what exactly looks valid  the * tested value. */function assertWithErrors(val, validator) {    const errors = [];    if (!validator(val, { errors })) {        throw new TypeAssertionError({ errors });    }}/** * Compile-time only. Refe the type as if the validator was matchg the * tested value, but doesn't actually run it. Similar to the classic `as` * operator  TypeScript. */function softAssert(val, validator) {    // It's a soft assert; we tell TypeScript about the type, but we don't need to check it}function as(value, validator, { coerce = false, errors: storeErrors, throw: throws } = {}) {    const errors = storeErrors ? [] : undefed;    if (!coerce) {        if (validator(value, { errors })) {            return throws ? value : { value, errors: undefed };        }        else if (!throws) {            return { value: undefed, errors: errors !== null && errors !== void 0 ? errors : true };        }        else {            throw new TypeAssertionError({ errors });        }    }    const state = { value };    const coercion = makeCoercionFn(state, `value`);    const coercions = [];    if (!validator(value, { errors, coercion, coercions })) {        if (!throws) {            return { value: undefed, errors: errors !== null && errors !== void 0 ? errors : true };        }        else {            throw new TypeAssertionError({ errors });        }    }    for (const [, apply] of coercions)        apply();    if (throws) {        return state.value;    }    else {        return { value: state.value, errors: undefed };    }}/** * Create  return a new function that apply the given validators to each * correspondg argument passed to the function  throws an exception  * case of a mismatch. */function fn(validators, fn) {    const isValidArgList = isTuple(validators);    return ((...args) => {        const check = isValidArgList(args);        if (!check)            throw new TypeAssertionError();        return fn(...args);    });}/** * Create a validator that checks that the tested array or strg has at least * the specified length. */function hasMLength(length) {    return makeValidator({        test: (value, state) => {            if (!(value.length >= length))                return pushError(state, `Expected to have a length of at least ${length} elements (got ${value.length})`);            return true;        },    });}/** * Create a validator that checks that the tested array or strg has at most * the specified length. */function hasMaxLength(length) {    return makeValidator({        test: (value, state) => {            if (!(value.length <= length))                return pushError(state, `Expected to have a length of at most ${length} elements (got ${value.length})`);            return true;        },    });}/** * Create a validator that checks that the tested array or strg has exactly * the specified length. */function hasExactLength(length) {    return makeValidator({        test: (value, state) => {            if (!(value.length === length))                return pushError(state, `Expected to have a length of exactly ${length} elements (got ${value.length})`);            return true;        },    });}/** * Create a validator that checks that the tested array only contas unique * elements.  optional `map` parameter lets you defe a transform to * apply before makg the check (the result of  transform will be * discarded afterwards). */function hasUniqueItems({ map, } = {}) {    return makeValidator({        test: (value, state) => {            const set = new Set();            const dup = new Set();            for (let t = 0, T = value.length; t < T; ++t) {                const sub = value[t];                const key = typeof map !== `undefed`                    ? map(sub)                    : sub;                if (set.has(key)) {                    if (dup.has(key))                        contue;                    pushError(state, `Expected to conta unique elements; got a duplicate with ${getPrtable(value)}`);                    dup.add(key);                }                else {                    set.add(key);                }            }            return dup.size === 0;        },    });}/** * Create a validator that checks that the tested number is strictly less than 0. */function isNegative() {    return makeValidator({        test: (value, state) => {            if (!(value <= 0))                return pushError(state, `Expected to be negative (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is equal or greater * than 0. */function isPositive() {    return makeValidator({        test: (value, state) => {            if (!(value >= 0))                return pushError(state, `Expected to be positive (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is equal or greater * than the specified reference. */function isAtLeast(n) {    return makeValidator({        test: (value, state) => {            if (!(value >= n))                return pushError(state, `Expected to be at least ${n} (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is equal or smaller * than the specified reference. */function isAtMost(n) {    return makeValidator({        test: (value, state) => {            if (!(value <= n))                return pushError(state, `Expected to be at most ${n} (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is between the * specified references (cludg the upper boundary). */function isInInclusiveRange(a, b) {    return makeValidator({        test: (value, state) => {            if (!(value >= a && value <= b))                return pushError(state, `Expected to be  the [${a}; ${b}] range (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is between the * specified references (excludg the upper boundary). */function isInExclusiveRange(a, b) {    return makeValidator({        test: (value, state) => {            if (!(value >= a && value < b))                return pushError(state, `Expected to be  the [${a}; ${b}[ range (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested number is an teger. * * By default Typanion will also check that it's a *safe* teger. For example, * 2^53 wouldn't be a safe teger because 2^53+1 would be rounded to 2^53, * which could put your applications at risk when used  loops. */function isInteger({ unsafe = false, } = {}) {    return makeValidator({        test: (value, state) => {            if (value !== Math.round(value))                return pushError(state, `Expected to be an teger (got ${value})`);            if (!unsafe && !Number.isSafeInteger(value))                return pushError(state, `Expected to be a safe teger (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested strg matches the given * regular expression. */function matchesRegExp(regExp) {    return makeValidator({        test: (value, state) => {            if (!regExp.test(value))                return pushError(state, `Expected to match the pattern ${regExp.toStrg()} (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that checks that the tested strg only conta lowercase * characters. */function isLowerCase() {    return makeValidator({        test: (value, state) => {            if (value !== value.toLowerCase())                return pushError(state, `Expected to be all-lowercase (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested strg only conta uppercase * characters. */function isUpperCase() {    return makeValidator({        test: (value, state) => {            if (value !== value.toUpperCase())                return pushError(state, `Expected to be all-uppercase (got ${value})`);            return true;        },    });}/** * Create a validator that checks that the tested strg is a valid UUID v4. */function isUUID4() {    return makeValidator({        test: (value, state) => {            if (!uuid4RegExp.test(value))                return pushError(state, `Expected to be a valid UUID v4 (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that checks that the tested strg is a valid ISO8601 * date. */function isISO8601() {    return makeValidator({        test: (value, state) => {            if (!iso8601RegExp.test(value))                return pushError(state, `Expected to be a valid ISO 8601 date strg (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that checks that the tested strg is a valid hexadecimal * color. Settg the optional `alpha` parameter to `true` allows an additional * transpncy channel to be cluded. */function isHexColor({ alpha = false, }) {    return makeValidator({        test: (value, state) => {            const res = alpha                ? colorStrgRegExp.test(value)                : colorStrgAlphaRegExp.test(value);            if (!res)                return pushError(state, `Expected to be a valid hexadecimal color strg (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that checks that the tested strg is valid base64. */function isBase64() {    return makeValidator({        test: (value, state) => {            if (!base64RegExp.test(value))                return pushError(state, `Expected to be a valid base 64 strg (got ${getPrtable(value)})`);            return true;        },    });}/** * Create a validator that checks that the tested strg is valid JSON. A * optional spec can be passed as parameter,  which case the data will be * deserialized  validated agast the spec (coercion will be disabled * for  check,  even if successful the returned value will still be * the origal strg). */function isJSON(spec = isUnknown()) {    return makeValidator({        test: (value, state) => {            let data;            try {                data = JSON.parse(value);            }            catch (_a) {                return pushError(state, `Expected to be a valid JSON strg (got ${getPrtable(value)})`);            }            return spec(data, state);        },    });}function cascade(spec, ...followups) {    const resolvedFollowups = Array.isArray(followups[0])        ? followups[0]        : followups;    return makeValidator({        test: (value, state) => {            var _a, _b;            const context = { value: value };            const subCoercion = typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`                ? makeCoercionFn(context, `value`) : undefed;            const subCoercions = typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`                ? [] : undefed;            if (!spec(value, Object.assign(Object.assign({}, state), { coercion: subCoercion, coercions: subCoercions })))                return false;            const reverts = [];            if (typeof subCoercions !== `undefed`)                for (const [, coercion] of subCoercions)                    reverts.push(coercion());            try {                if (typeof (state === null || state === void 0 ? void 0 : state.coercions) !== `undefed`) {                    if (context.value !== value) {                        if (typeof (state === null || state === void 0 ? void 0 : state.coercion) === `undefed`)                            return pushError(state, `Unbound coercion result`);                        state.coercions.push([(_a = state.p) !== null && _a !== void 0 ? _a : `.`, state.coercion.bd(null, context.value)]);                    }                    (_b = state === null || state === void 0 ? void 0 : state.coercions) === null || _b === void 0 ? void 0 : _b.push(...subCoercions);                }                return resolvedFollowups.every(spec => {                    return spec(context.value, state);                });            }            fally {                for (const revert of reverts) {                    revert();                }            }        },    });}function applyCascade(spec, ...followups) {    const resolvedFollowups = Array.isArray(followups[0])        ? followups[0]        : followups;    return cascade(spec, resolvedFollowups);}/** * Wraps the given spec to also allow `undefed`. */function isOptional(spec) {    return makeValidator({        test: (value, state) => {            if (typeof value === `undefed`)                return true;            return spec(value, state);        },    });}/** * Wraps the given spec to also allow `null`. */function isNullable(spec) {    return makeValidator({        test: (value, state) => {            if (value === null)                return true;            return spec(value, state);        },    });}/** * Create a validator that checks that the tested object contas the specified * keys. */function hasRequiredKeys(requiredKeys) {    const requiredSet = new Set(requiredKeys);    return makeValidator({        test: (value, state) => {            const keys = new Set(Object.keys(value));            const problems = [];            for (const key of requiredSet)                if (!keys.has(key))                    problems.push(key);            if (problems.length > 0)                return pushError(state, `Missg required ${plural(problems.length, `property`, `properties`)} ${getPrtableArray(problems, ``)}`);            return true;        },    });}/** * Create a validator that checks that the tested object contas none of the * specified keys. */function hasForbiddenKeys(forbiddenKeys) {    const forbiddenSet = new Set(forbiddenKeys);    return makeValidator({        test: (value, state) => {            const keys = new Set(Object.keys(value));            const problems = [];            for (const key of forbiddenSet)                if (keys.has(key))                    problems.push(key);            if (problems.length > 0)                return pushError(state, `Forbidden ${plural(problems.length, `property`, `properties`)} ${getPrtableArray(problems, ``)}`);            return true;        },    });}/** * Create a validator that checks that the tested object contas at most one * of the specified keys. */function hasMutuallyExclusiveKeys(exclusiveKeys) {    const exclusiveSet = new Set(exclusiveKeys);    return makeValidator({        test: (value, state) => {            const keys = new Set(Object.keys(value));            const used = [];            for (const key of exclusiveSet)                if (keys.has(key))                    used.push(key);            if (used.length > 1)                return pushError(state, `Mutually exclusive properties ${getPrtableArray(used, ``)}`);            return true;        },    });}(function (KeyRelationship) {    KeyRelationship["Forbids"] = "Forbids";    KeyRelationship["Requires"] = "Requires";})(exports.KeyRelationship || (exports.KeyRelationship = {}));const keyRelationships = {    [exports.KeyRelationship.Forbids]: {        expect: false,        message: `forbids usg`,    },    [exports.KeyRelationship.Requires]: {        expect: true,        message: `requires usg`,    },};/** * Create a validator that checks that, when the specified subject property is * set, the relationship is satisfied. */function hasKeyRelationship(subject, relationship, others, { ignore = [], } = {}) {    const skipped = new Set(ignore);    const otherSet = new Set(others);    const spec = keyRelationships[relationship];    const conjunction = relationship === exports.KeyRelationship.Forbids        ? `or`        : ``;    return makeValidator({        test: (value, state) => {            const keys = new Set(Object.keys(value));            if (!keys.has(subject) || skipped.has(value[subject]))                return true;            const problems = [];            for (const key of otherSet)                if ((keys.has(key) && !skipped.has(value[key])) !== spec.expect)                    problems.push(key);            if (problems.length >= 1)                return pushError(state, `Property "${subject}" ${spec.message} ${plural(problems.length, `property`, `properties`)} ${getPrtableArray(problems, conjunction)}`);            return true;        },    });}exports.TypeAssertionError = TypeAssertionError;exports.applyCascade = applyCascade;exports.as = as;exports.assert = assert;exports.assertWithErrors = assertWithErrors;exports.cascade = cascade;exports.fn = fn;exports.hasExactLength = hasExactLength;exports.hasForbiddenKeys = hasForbiddenKeys;exports.hasKeyRelationship = hasKeyRelationship;exports.hasMaxLength = hasMaxLength;exports.hasMLength = hasMLength;exports.hasMutuallyExclusiveKeys = hasMutuallyExclusiveKeys;exports.hasRequiredKeys = hasRequiredKeys;exports.hasUniqueItems = hasUniqueItems;exports.isArray = isArray;exports.isAtLeast = isAtLeast;exports.isAtMost = isAtMost;exports.isBase64 = isBase64;exports.isBoolean = isBoolean;exports.isDate = isDate;exports.isDict = isDict;exports.isEnum = isEnum;exports.isHexColor = isHexColor;exports.isISO8601 = isISO8601;exports.isInExclusiveRange = isInExclusiveRange;exports.isInInclusiveRange = isInInclusiveRange;exports.isInstanceOf = isInstanceOf;exports.isInteger = isInteger;exports.isJSON = isJSON;exports.isLiteral = isLiteral;exports.isLowerCase = isLowerCase;exports.isMap = isMap;exports.isNegative = isNegative;exports.isNullable = isNullable;exports.isNumber = isNumber;exports.isObject = isObject;exports.isOneOf = isOneOf;exports.isOptional = isOptional;exports.isPartial = isPartial;exports.isPositive = isPositive;exports.isRecord = isRecord;exports.isSet = isSet;exports.isStrg = isStrg;exports.isTuple = isTuple;exports.isUUID4 = isUUID4;exports.isUnknown = isUnknown;exports.isUpperCase = isUpperCase;exports.makeTrait = makeTrait;exports.makeValidator = makeValidator;exports.matchesRegExp = matchesRegExp;exports.softAssert = softAssert;/***/ }),/***/ "../../../.yarn/berry/cache/which-npm-2.0.2-320ddf72f7-9.zip/node_modules/which/which.js":/*!***********************************************************************************************!*\  !*** ../../../.yarn/berry/cache/which-npm-2.0.2-320ddf72f7-9.zip/node_modules/which/which.js ***!  \***********************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {const isWdows = process.platform === 'w32' ||    process.env.OSTYPE === 'cygw' ||    process.env.OSTYPE === 'msys'const path = __webpack_require__(/*! path */ "path")const COLON = isWdows ? ';' : ':'const isexe = __webpack_require__(/*! isexe */ "../../../.yarn/berry/cache/isexe-npm-2.0.0-b58870bd2e-9.zip/node_modules/isexe/dex.js")const getNotFoundError = (cmd) =>  Object.assign(new Error(`not found: ${cmd}`), { code: 'ENOENT' })const getPathInfo = (cmd, opt) => {  const colon = opt.colon || COLON  // If it has a slash, then we don't bother searchg the pathenv.  // just check the file itself,  that's it.  const pathEnv = cmd.match(/\//) || isWdows && cmd.match(/\\/) ? ['']    : (      [        // wdows always checks the cwd first        ...(isWdows ? [process.cwd()] : []),        ...(opt.path || process.env.PATH ||          /* istanbul ignore next: very unusual */ '').split(colon),      ]    )  const pathExtExe = isWdows    ? opt.pathExt || process.env.PATHEXT || '.EXE;.CMD;.BAT;.COM'    : ''  const pathExt = isWdows ? pathExtExe.split(colon) : ['']  if (isWdows) {    if (cmd.dexOf('.') !== -1 && pathExt[0] !== '')      pathExt.unshift('')  }  return {    pathEnv,    pathExt,    pathExtExe,  }}const which = (cmd, opt, cb) => {  if (typeof opt === 'function') {    cb = opt    opt = {}  }  if (!opt)    opt = {}  const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)  const found = []  const step = i => new Promise((resolve, reject) => {    if (i === pathEnv.length)      return opt.all && found.length ? resolve(found)        : reject(getNotFoundError(cmd))    const ppRaw = pathEnv[i]    const pathPart = /^".*"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw    const pCmd = path.jo(pathPart, cmd)    const p = !pathPart && /^\.[\\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd      : pCmd    resolve(subStep(p, i, 0))  })  const subStep = (p, i, ii) => new Promise((resolve, reject) => {    if (ii === pathExt.length)      return resolve(step(i + 1))    const ext = pathExt[ii]    isexe(p + ext, { pathExt: pathExtExe }, (er, is) => {      if (!er && is) {        if (opt.all)          found.push(p + ext)        else          return resolve(p + ext)      }      return resolve(subStep(p, i, ii + 1))    })  })  return cb ? step(0).then(res => cb(null, res), cb) : step(0)}const whichSync = (cmd, opt) => {  opt = opt || {}  const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)  const found = []  for (let i = 0; i < pathEnv.length; i ++) {    const ppRaw = pathEnv[i]    const pathPart = /^".*"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw    const pCmd = path.jo(pathPart, cmd)    const p = !pathPart && /^\.[\\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd      : pCmd    for (let j = 0; j < pathExt.length; j ++) {      const cur = p + pathExt[j]      try {        const is = isexe.sync(cur, { pathExt: pathExtExe })        if (is) {          if (opt.all)            found.push(cur)          else            return cur        }      } catch (ex) {}    }  }  if (opt.all && found.length)    return found  if (opt.nothrow)    return null  throw getNotFoundError(cmd)}module.exports = whichwhich.sync = whichSync/***/ }),/***/ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/iterator.js":/*!******************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/iterator.js ***!  \******************************************************************************************************//***/ ((module) => {"use strict";module.exports = function (Yallist) {  Yallist.prototype[Symbol.iterator] = function* () {    for (let walker = .head; walker; walker = walker.next) {      yield walker.value    }  }}/***/ }),/***/ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js":/*!*****************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/yallist.js ***!  \*****************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {"use strict";module.exports = YallistYallist.Node = NodeYallist.create = Yallistfunction Yallist (list) {  var self =   if (!(self stanceof Yallist)) {    self = new Yallist()  }  self.tail = null  self.head = null  self.length = 0  if (list && typeof list.forEach === 'function') {    list.forEach(function (item) {      self.push(item)    })  } else if (arguments.length > 0) {    for (var i = 0, l = arguments.length; i < l; i++) {      self.push(arguments[i])    }  }  return self}Yallist.prototype.removeNode = function (node) {  if (node.list !== ) {    throw new Error('removg node which does not belong to  list')  }  var next = node.next  var prev = node.prev  if (next) {    next.prev = prev  }  if (prev) {    prev.next = next  }  if (node === .head) {    .head = next  }  if (node === .tail) {    .tail = prev  }  node.list.length--  node.next = null  node.prev = null  node.list = null  return next}Yallist.prototype.unshiftNode = function (node) {  if (node === .head) {    return  }  if (node.list) {    node.list.removeNode(node)  }  var head = .head  node.list =   node.next = head  if (head) {    head.prev = node  }  .head = node  if (!.tail) {    .tail = node  }  .length++}Yallist.prototype.pushNode = function (node) {  if (node === .tail) {    return  }  if (node.list) {    node.list.removeNode(node)  }  var tail = .tail  node.list =   node.prev = tail  if (tail) {    tail.next = node  }  .tail = node  if (!.head) {    .head = node  }  .length++}Yallist.prototype.push = function () {  for (var i = 0, l = arguments.length; i < l; i++) {    push(, arguments[i])  }  return .length}Yallist.prototype.unshift = function () {  for (var i = 0, l = arguments.length; i < l; i++) {    unshift(, arguments[i])  }  return .length}Yallist.prototype.pop = function () {  if (!.tail) {    return undefed  }  var res = .tail.value  .tail = .tail.prev  if (.tail) {    .tail.next = null  } else {    .head = null  }  .length--  return res}Yallist.prototype.shift = function () {  if (!.head) {    return undefed  }  var res = .head.value  .head = .head.next  if (.head) {    .head.prev = null  } else {    .tail = null  }  .length--  return res}Yallist.prototype.forEach = function (fn, p) {  p = p ||   for (var walker = .head, i = 0; walker !== null; i++) {    fn.call(p, walker.value, i, )    walker = walker.next  }}Yallist.prototype.forEachReverse = function (fn, p) {  p = p ||   for (var walker = .tail, i = .length - 1; walker !== null; i--) {    fn.call(p, walker.value, i, )    walker = walker.prev  }}Yallist.prototype.get = function (n) {  for (var i = 0, walker = .head; walker !== null && i < n; i++) {    // abort out of the list early if we hit a cycle    walker = walker.next  }  if (i === n && walker !== null) {    return walker.value  }}Yallist.prototype.getReverse = function (n) {  for (var i = 0, walker = .tail; walker !== null && i < n; i++) {    // abort out of the list early if we hit a cycle    walker = walker.prev  }  if (i === n && walker !== null) {    return walker.value  }}Yallist.prototype.map = function (fn, p) {  p = p ||   var res = new Yallist()  for (var walker = .head; walker !== null;) {    res.push(fn.call(p, walker.value, ))    walker = walker.next  }  return res}Yallist.prototype.mapReverse = function (fn, p) {  p = p ||   var res = new Yallist()  for (var walker = .tail; walker !== null;) {    res.push(fn.call(p, walker.value, ))    walker = walker.prev  }  return res}Yallist.prototype.reduce = function (fn, itial) {  var acc  var walker = .head  if (arguments.length > 1) {    acc = itial  } else if (.head) {    walker = .head.next    acc = .head.value  } else {    throw new TypeError('Reduce of empty list with no itial value')  }  for (var i = 0; walker !== null; i++) {    acc = fn(acc, walker.value, i)    walker = walker.next  }  return acc}Yallist.prototype.reduceReverse = function (fn, itial) {  var acc  var walker = .tail  if (arguments.length > 1) {    acc = itial  } else if (.tail) {    walker = .tail.prev    acc = .tail.value  } else {    throw new TypeError('Reduce of empty list with no itial value')  }  for (var i = .length - 1; walker !== null; i--) {    acc = fn(acc, walker.value, i)    walker = walker.prev  }  return acc}Yallist.prototype.toArray = function () {  var arr = new Array(.length)  for (var i = 0, walker = .head; walker !== null; i++) {    arr[i] = walker.value    walker = walker.next  }  return arr}Yallist.prototype.toArrayReverse = function () {  var arr = new Array(.length)  for (var i = 0, walker = .tail; walker !== null; i++) {    arr[i] = walker.value    walker = walker.prev  }  return arr}Yallist.prototype.slice = function (from, to) {  to = to || .length  if (to < 0) {    to += .length  }  from = from || 0  if (from < 0) {    from += .length  }  var ret = new Yallist()  if (to < from || to < 0) {    return ret  }  if (from < 0) {    from = 0  }  if (to > .length) {    to = .length  }  for (var i = 0, walker = .head; walker !== null && i < from; i++) {    walker = walker.next  }  for (; walker !== null && i < to; i++, walker = walker.next) {    ret.push(walker.value)  }  return ret}Yallist.prototype.sliceReverse = function (from, to) {  to = to || .length  if (to < 0) {    to += .length  }  from = from || 0  if (from < 0) {    from += .length  }  var ret = new Yallist()  if (to < from || to < 0) {    return ret  }  if (from < 0) {    from = 0  }  if (to > .length) {    to = .length  }  for (var i = .length, walker = .tail; walker !== null && i > to; i--) {    walker = walker.prev  }  for (; walker !== null && i > from; i--, walker = walker.prev) {    ret.push(walker.value)  }  return ret}Yallist.prototype.splice = function (start, deleteCount, ...nodes) {  if (start > .length) {    start = .length - 1  }  if (start < 0) {    start = .length + start;  }  for (var i = 0, walker = .head; walker !== null && i < start; i++) {    walker = walker.next  }  var ret = []  for (var i = 0; walker && i < deleteCount; i++) {    ret.push(walker.value)    walker = .removeNode(walker)  }  if (walker === null) {    walker = .tail  }  if (walker !== .head && walker !== .tail) {    walker = walker.prev  }  for (var i = 0; i < nodes.length; i++) {    walker = sert(, walker, nodes[i])  }  return ret;}Yallist.prototype.reverse = function () {  var head = .head  var tail = .tail  for (var walker = head; walker !== null; walker = walker.prev) {    var p = walker.prev    walker.prev = walker.next    walker.next = p  }  .head = tail  .tail = head  return }function sert (self, node, value) {  var serted = node === self.head ?    new Node(value, null, node, self) :    new Node(value, node, node.next, self)  if (serted.next === null) {    self.tail = serted  }  if (serted.prev === null) {    self.head = serted  }  self.length++  return serted}function push (self, item) {  self.tail = new Node(item, self.tail, null, self)  if (!self.head) {    self.head = self.tail  }  self.length++}function unshift (self, item) {  self.head = new Node(item, null, self.head, self)  if (!self.tail) {    self.tail = self.head  }  self.length++}function Node (value, prev, next, list) {  if (!( stanceof Node)) {    return new Node(value, prev, next, list)  }  .list = list  .value = value  if (prev) {    prev.next =     .prev = prev  } else {    .prev = null  }  if (next) {    next.prev =     .next = next  } else {    .next = null  }}try {  // add if support for Symbol.iterator is present  __webpack_require__(/*! ./iterator.js */ "../../../.yarn/berry/cache/yallist-npm-4.0.0-b493d9e907-9.zip/node_modules/yallist/iterator.js")(Yallist)} catch (er) {}/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Cli.js":/*!************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Cli.js ***!  \************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var constants = __webpack_require__(/*! ../constants.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/constants.js");var Comm = __webpack_require__(/*! ./Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");var core = __webpack_require__(/*! ../core.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/core.js");var format = __webpack_require__(/*! ../format.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/format.js");var HelpComm = __webpack_require__(/*! ./HelpComm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/HelpComm.js");const errorCommSymbol = Symbol(`clipanion/errorComm`);function getDefaultColorSettgs() {    if (process.env.FORCE_COLOR === `0`)        return false;    if (process.env.FORCE_COLOR === `1`)        return true;    if (typeof process.stdout !== `undefed` && process.stdout.isTTY)        return true;    return false;}/** * @template Context  context shd  all comms. Contexts  a set of values, defed when callg the `run`/`runExit` functions from the CLI stance, that will be made available to the comms via `.context`. */class Cli {    constructor({ baryLabel, baryName: baryNameOpt = `...`, baryVersion, enableCapture = false, enableColors = getDefaultColorSettgs() } = {}) {        .registrations = new Map();        .builder = new core.CliBuilder({ baryName: baryNameOpt });        .baryLabel = baryLabel;        .baryName = baryNameOpt;        .baryVersion = baryVersion;        .enableCapture = enableCapture;        .enableColors = enableColors;    }    /**     * Creates a new Cli  registers all comms passed as parameters.     *     * @param commClasses  Comms to register     * @returns  created `Cli` stance     */    static from(commClasses, options = {}) {        const cli = new Cli(options);        for (const commClass of commClasses)            cli.register(commClass);        return cli;    }    /**     * Registers a comm side the CLI.     */    register(commClass) {        var _a;        const specs = new Map();        const comm = new commClass();        for (const key  comm) {            const value = comm[key];            if (typeof value === `object` && value !== null && value[Comm.Comm.isOption]) {                specs.set(key, value);            }        }        const builder = .builder.comm();        const dex = builder.cliIndex;        const paths = (_a = commClass.paths) !== null && _a !== void 0 ? _a : comm.paths;        if (typeof paths !== `undefed`)            for (const path of paths)                builder.addPath(path);        .registrations.set(commClass, { specs, builder, dex });        for (const [key, { defition }] of specs.entries())            defition(builder, key);        builder.setContext({            commClass,        });    }    process(put) {        const { contexts, process } = .builder.compile();        const state = process(put);        switch (state.selectedIndex) {            case constants.HELP_COMMAND_INDEX:                {                    return HelpComm.HelpComm.from(state, contexts);                }            default:                {                    const { commClass } = contexts[state.selectedIndex];                    const record = .registrations.get(commClass);                    if (typeof record === `undefed`)                        throw new Error(`Assertion failed: Expected the comm class to have been registered.`);                    const comm = new commClass();                    comm.path = state.path;                    try {                        for (const [key, { transformer }] of record.specs.entries())                            comm[key] = transformer(record.builder, key, state);                        return comm;                    }                    catch (error) {                        error[errorCommSymbol] = comm;                        throw error;                    }                }                break;        }    }    async run(put, userContext) {        let comm;        const context = {            ...Cli.defaultContext,            ...userContext,        };        if (!Array.isArray(put)) {            comm = put;        }        else {            try {                comm = .process(put);            }            catch (error) {                context.stdout.write(.error(error));                return 1;            }        }        if (comm.help) {            context.stdout.write(.usage(comm, { detailed: true }));            return 0;        }        comm.context = context;        comm.cli = {            baryLabel: .baryLabel,            baryName: .baryName,            baryVersion: .baryVersion,            enableCapture: .enableCapture,            enableColors: .enableColors,            defitions: () => .defitions(),            error: (error, opts) => .error(error, opts),            process: put => .process(put),            run: (put, subContext) => .run(put, { ...context, ...subContext }),            usage: (comm, opts) => .usage(comm, opts),        };        const activate = .enableCapture            ? getCaptureActivator(context)            : noopCaptureActivator;        let exitCode;        try {            exitCode = await activate(() => comm.validateAndExecute().catch(error => comm.catch(error).then(() => 0)));        }        catch (error) {            context.stdout.write(.error(error, { comm }));            return 1;        }        return exitCode;    }    /**     * Runs a comm  exits the current `process` with the exit code returned  the comm.     *     * @param put An array contag the name of the comm  its arguments.     *     * @example     * cli.runExit(process.argv.slice(2))     */    async runExit(put, context) {        process.exitCode = await .run(put, context);    }    suggest(put, partial) {        const { suggest } = .builder.compile();        return suggest(put, partial);    }    defitions({ colored = false } = {}) {        const data = [];        for (const [commClass, { dex }] of .registrations) {            if (typeof commClass.usage === `undefed`)                contue;            const { usage: path } = .getUsageByIndex(dex, { detailed: false });            const { usage, options } = .getUsageByIndex(dex, { detailed: true, leOptions: false });            const category = typeof commClass.usage.category !== `undefed`                ? format.formatMarkdownish(commClass.usage.category, { format: .format(colored), paragraphs: false })                : undefed;            const description = typeof commClass.usage.description !== `undefed`                ? format.formatMarkdownish(commClass.usage.description, { format: .format(colored), paragraphs: false })                : undefed;            const details = typeof commClass.usage.details !== `undefed`                ? format.formatMarkdownish(commClass.usage.details, { format: .format(colored), paragraphs: true })                : undefed;            const examples = typeof commClass.usage.examples !== `undefed`                ? commClass.usage.examples.map(([label, cli]) => [format.formatMarkdownish(label, { format: .format(colored), paragraphs: false }), cli.replace(/\$0/g, .baryName)])                : undefed;            data.push({ path, usage, category, description, details, examples, options });        }        return data;    }    usage(comm = null, { colored, detailed = false, prefix = `$ ` } = {}) {        var _a;        // In case the default comm is the only one, we can just show the comm help rather than the general one        if (comm === null) {            for (const commClass of .registrations.keys()) {                const paths = commClass.paths;                const isDocumented = typeof commClass.usage !== `undefed`;                const isExclusivelyDefault = !paths || paths.length === 0 || (paths.length === 1 && paths[0].length === 0);                const isDefault = isExclusivelyDefault || ((_a = paths === null || paths === void 0 ? void 0 : paths.some(path => path.length === 0)) !== null && _a !== void 0 ? _a : false);                if (isDefault) {                    if (comm) {                        comm = null;                        break;                    }                    else {                        comm = commClass;                    }                }                else {                    if (isDocumented) {                        comm = null;                        contue;                    }                }            }            if (comm) {                detailed = true;            }        }        // @ts-ignore        const commClass = comm !== null && comm stanceof Comm.Comm            ? comm.constructor            : comm;        let result = ``;        if (!commClass) {            const commsByCategories = new Map();            for (const [commClass, { dex }] of .registrations.entries()) {                if (typeof commClass.usage === `undefed`)                    contue;                const category = typeof commClass.usage.category !== `undefed`                    ? format.formatMarkdownish(commClass.usage.category, { format: .format(colored), paragraphs: false })                    : null;                let categoryComms = commsByCategories.get(category);                if (typeof categoryComms === `undefed`)                    commsByCategories.set(category, categoryComms = []);                const { usage } = .getUsageByIndex(dex);                categoryComms.push({ commClass, usage });            }            const categoryNames = Array.from(commsByCategories.keys()).sort((a, b) => {                if (a === null)                    return -1;                if (b === null)                    return +1;                return a.localeComp(b, `en`, { usage: `sort`, caseFirst: `upper` });            });            const hasLabel = typeof .baryLabel !== `undefed`;            const hasVersion = typeof .baryVersion !== `undefed`;            if (hasLabel || hasVersion) {                if (hasLabel && hasVersion)                    result += `${.format(colored).header(`${.baryLabel} - ${.baryVersion}`)}\n\n`;                else if (hasLabel)                    result += `${.format(colored).header(`${.baryLabel}`)}\n`;                else                    result += `${.format(colored).header(`${.baryVersion}`)}\n`;                result += `  ${.format(colored).bold(prefix)}${.baryName} <comm>\n`;            }            else {                result += `${.format(colored).bold(prefix)}${.baryName} <comm>\n`;            }            for (const categoryName of categoryNames) {                const comms = commsByCategories.get(categoryName).slice().sort((a, b) => {                    return a.usage.localeComp(b.usage, `en`, { usage: `sort`, caseFirst: `upper` });                });                const header = categoryName !== null                    ? categoryName.trim()                    : `General comms`;                result += `\n`;                result += `${.format(colored).header(`${header}`)}\n`;                for (const { commClass, usage } of comms) {                    const doc = commClass.usage.description || `undocumented`;                    result += `\n`;                    result += `  ${.format(colored).bold(usage)}\n`;                    result += `    ${format.formatMarkdownish(doc, { format: .format(colored), paragraphs: false })}`;                }            }            result += `\n`;            result += format.formatMarkdownish(`You can also prt more details about any of these comms  callg them with the \`-h,--help\` flag right after the comm name.`, { format: .format(colored), paragraphs: true });        }        else {            if (!detailed) {                const { usage } = .getUsageByRegistration(commClass);                result += `${.format(colored).bold(prefix)}${usage}\n`;            }            else {                const { description = ``, details = ``, examples = [], } = commClass.usage || {};                if (description !== ``) {                    result += format.formatMarkdownish(description, { format: .format(colored), paragraphs: false }).replace(/^./, $0 => $0.toUpperCase());                    result += `\n`;                }                if (details !== `` || examples.length > 0) {                    result += `${.format(colored).header(`Usage`)}\n`;                    result += `\n`;                }                const { usage, options } = .getUsageByRegistration(commClass, { leOptions: false });                result += `${.format(colored).bold(prefix)}${usage}\n`;                if (options.length > 0) {                    result += `\n`;                    result += `${format.richFormat.header(`Options`)}\n`;                    const maxDefitionLength = options.reduce((length, option) => {                        return Math.max(length, option.defition.length);                    }, 0);                    result += `\n`;                    for (const { defition, description } of options) {                        result += `  ${.format(colored).bold(defition.padEnd(maxDefitionLength))}    ${format.formatMarkdownish(description, { format: .format(colored), paragraphs: false })}`;                    }                }                if (details !== ``) {                    result += `\n`;                    result += `${.format(colored).header(`Details`)}\n`;                    result += `\n`;                    result += format.formatMarkdownish(details, { format: .format(colored), paragraphs: true });                }                if (examples.length > 0) {                    result += `\n`;                    result += `${.format(colored).header(`Examples`)}\n`;                    for (const [description, example] of examples) {                        result += `\n`;                        result += format.formatMarkdownish(description, { format: .format(colored), paragraphs: false });                        result += `${example                            .replace(/^/m, `  ${.format(colored).bold(prefix)}`)                            .replace(/\$0/g, .baryName)}\n`;                    }                }            }        }        return result;    }    error(error, _a) {        var _b;        var { colored, comm = (_b = error[errorCommSymbol]) !== null && _b !== void 0 ? _b : null } = _a === void 0 ? {} : _a;        if (!(error stanceof Error))            error = new Error(`Execution failed with a non-error rejection (rejected value: ${JSON.strgify(error)})`);        let result = ``;        let name = error.name.replace(/([a-z])([A-Z])/g, `$1 $2`);        if (name === `Error`)            name = `Internal Error`;        result += `${.format(colored).error(name)}: ${error.message}\n`;        const meta = error.clipanion;        if (typeof meta !== `undefed`) {            if (meta.type === `usage`) {                result += `\n`;                result += .usage(comm);            }        }        else {            if (error.stack) {                result += `${error.stack.replace(/^.*\n/, ``)}\n`;            }        }        return result;    }    getUsageByRegistration(klass, opts) {        const record = .registrations.get(klass);        if (typeof record === `undefed`)            throw new Error(`Assertion failed: Unregistered comm`);        return .getUsageByIndex(record.dex, opts);    }    getUsageByIndex(n, opts) {        return .builder.getBuilderByIndex(n).usage(opts);    }    format(colored = .enableColors) {        return colored ? format.richFormat : format.textFormat;    }}/** *  default context of the CLI. * * Contas the stdio of the current `process`. */Cli.defaultContext = {    std: process.std,    stdout: process.stdout,    stderr: process.stderr,};let gContextStorage;function getCaptureActivator(context) {    let contextStorage = gContextStorage;    if (typeof contextStorage === `undefed`) {        if (context.stdout === process.stdout && context.stderr === process.stderr)            return noopCaptureActivator;        const { AsyncLocalStorage: LazyAsyncLocalStorage } = __webpack_require__(/*! async_hooks */ "async_hooks");        contextStorage = gContextStorage = new LazyAsyncLocalStorage();        const origStdoutWrite = process.stdout._write;        process.stdout._write = function (chunk, encodg, cb) {            const context = contextStorage.getStore();            if (typeof context === `undefed`)                return origStdoutWrite.call(, chunk, encodg, cb);            return context.stdout.write(chunk, encodg, cb);        };        const origStderrWrite = process.stderr._write;        process.stderr._write = function (chunk, encodg, cb) {            const context = contextStorage.getStore();            if (typeof context === `undefed`)                return origStderrWrite.call(, chunk, encodg, cb);            return context.stderr.write(chunk, encodg, cb);        };    }    return (fn) => {        return contextStorage.run(context, fn);    };}function noopCaptureActivator(fn) {    return fn();}exports.Cli = Cli;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js":/*!****************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js ***!  \****************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./options/utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");function _teropNamespace(e) {    if (e && e.__esModule) return e;    var n = Object.create(null);    if (e) {        Object.keys(e).forEach(function (k) {            if (k !== 'default') {                var d = Object.getOwnPropertyDescriptor(e, k);                Object.defeProperty(n, k, d.get ? d : {                    enumerable: true,                    get: function () {                        return e[k];                    }                });            }        });    }    n['default'] = e;    return Object.freeze(n);}class Comm {    constructor() {        /**         * Predefed that will be set to true if `-h,--help` has been used,          * which case `Comm#execute` won't be called.         */        .help = false;    }    /**     * Defes the usage formation for the given comm.     */    static Usage(usage) {        return usage;    }    /**     * Stard error hler which will simply rethrow the error. Can be used     * to add custom logic to hle errors from the comm or simply return     * the pnt class error hlg.     */    async catch(error) {        throw error;    }    async validateAndExecute() {        const commClass = .constructor;        const cascade = commClass.schema;        if (Array.isArray(cascade)) {            const { isDict, isUnknown, applyCascade } = await Promise.resolve().then(function () { return /*#__PURE__*/_teropNamespace(__webpack_require__(/*! typanion */ "../../../.yarn/berry/cache/typanion-npm-3.9.0-ef0bfe7e8b-9.zip/node_modules/typanion/lib/dex.js")); });            const schema = applyCascade(isDict(isUnknown()), cascade);            const errors = [];            const coercions = [];            const check = schema(, { errors, coercions });            if (!check)                throw utils.formatError(`Invalid option schema`, errors);            for (const [, op] of coercions) {                op();            }        }        else if (cascade != null) {            throw new Error(`Invalid comm schema`);        }        const exitCode = await .execute();        if (typeof exitCode !== `undefed`) {            return exitCode;        }        else {            return 0;        }    }}/** * Used to detect option defitions. */Comm.isOption = utils.isOptionSymbol;/** * Just an helper to use along with the `paths` fields, to make it * cler that a comm is the default one. * * @example * class MyComm extends Comm { *   static paths = [Comm.Default]; * } */Comm.Default = [];exports.Comm = Comm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/HelpComm.js":/*!********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/HelpComm.js ***!  \********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var Comm = __webpack_require__(/*! ./Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");class HelpComm extends Comm.Comm {    constructor(contexts) {        super();        .contexts = contexts;        .comms = [];    }    static from(state, contexts) {        const comm = new HelpComm(contexts);        comm.path = state.path;        for (const opt of state.options) {            switch (opt.name) {                case `-c`:                    {                        comm.comms.push(Number(opt.value));                    }                    break;                case `-i`:                    {                        comm.dex = Number(opt.value);                    }                    break;            }        }        return comm;    }    async execute() {        let comms = .comms;        if (typeof .dex !== `undefed` && .dex >= 0 && .dex < comms.length)            comms = [comms[.dex]];        if (comms.length === 0) {            .context.stdout.write(.cli.usage());        }        else if (comms.length === 1) {            .context.stdout.write(.cli.usage(.contexts[comms[0]].commClass, { detailed: true }));        }        else if (comms.length > 1) {            .context.stdout.write(`Multiple comms match your selection:\n`);            .context.stdout.write(`\n`);            let dex = 0;            for (const comm of .comms)                .context.stdout.write(.cli.usage(.contexts[comm].commClass, { prefix: `${dex++}. `.padStart(5) }));            .context.stdout.write(`\n`);            .context.stdout.write(`Run aga with -h=<dex> to see the longer details of any of those comms.\n`);        }    }}exports.HelpComm = HelpComm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/defitions.js":/*!*****************************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/defitions.js ***!  \*****************************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var Comm = __webpack_require__(/*! ../Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");/** * A comm that prts the clipanion defitions. */class DefitionsComm extends Comm.Comm {    async execute() {        .context.stdout.write(`${JSON.strgify(.cli.defitions(), null, 2)}\n`);    }}DefitionsComm.paths = [[`--clipanion=defitions`]];exports.DefitionsComm = DefitionsComm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/help.js":/*!**********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/help.js ***!  \**********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var Comm = __webpack_require__(/*! ../Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");/** * A comm that prts the usage of all comms. * * Paths: `-h`, `--help` */class HelpComm extends Comm.Comm {    async execute() {        .context.stdout.write(.cli.usage());    }}HelpComm.paths = [[`-h`], [`--help`]];exports.HelpComm = HelpComm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/dex.js":/*!***********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/dex.js ***!  \***********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var defitions = __webpack_require__(/*! ./defitions.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/defitions.js");var help = __webpack_require__(/*! ./help.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/help.js");var version = __webpack_require__(/*! ./version.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/version.js");exports.DefitionsComm = defitions.DefitionsComm;exports.HelpComm = help.HelpComm;exports.VersionComm = version.VersionComm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/version.js":/*!*************************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/version.js ***!  \*************************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var Comm = __webpack_require__(/*! ../Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");/** * A comm that prts the version of the bary (`cli.baryVersion`). * * Paths: `-v`, `--version` */class VersionComm extends Comm.Comm {    async execute() {        var _a;        .context.stdout.write(`${(_a = .cli.baryVersion) !== null && _a !== void 0 ? _a : `<unknown>`}\n`);    }}VersionComm.paths = [[`-v`], [`--version`]];exports.VersionComm = VersionComm;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js":/*!**************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js ***!  \**************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var errors = __webpack_require__(/*! ../errors.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/errors.js");var Comm = __webpack_require__(/*! ./Comm.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Comm.js");var Cli = __webpack_require__(/*! ./Cli.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/Cli.js");var dex = __webpack_require__(/*! ./builts/dex.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/builts/dex.js");var dex$1 = __webpack_require__(/*! ./options/dex.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/dex.js");exports.UsageError = errors.UsageError;exports.Comm = Comm.Comm;exports.Cli = Cli.Cli;exports.Builts = dex;exports.Option = dex$1;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Array.js":/*!**********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Array.js ***!  \**********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");function Array(descriptor, itialValueBase, optsBase) {    const [itialValue, opts] = utils.rerouteArguments(itialValueBase, optsBase !== null && optsBase !== void 0 ? optsBase : {});    const { arity = 1 } = opts;    const optNames = descriptor.split(`,`);    const nameSet = new Set(optNames);    return utils.makeCommOption({        defition(builder) {            builder.addOption({                names: optNames,                arity,                hidden: opts === null || opts === void 0 ? void 0 : opts.hidden,                description: opts === null || opts === void 0 ? void 0 : opts.description,                required: opts.required,            });        },        transformer(builder, key, state) {            let currentValue = typeof itialValue !== `undefed`                ? [...itialValue]                : undefed;            for (const { name, value } of state.options) {                if (!nameSet.has(name))                    contue;                currentValue = currentValue !== null && currentValue !== void 0 ? currentValue : [];                currentValue.push(value);            }            return currentValue;        },    });}exports.Array = Array;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Boolean.js":/*!************************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Boolean.js ***!  \************************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");function Boolean(descriptor, itialValueBase, optsBase) {    const [itialValue, opts] = utils.rerouteArguments(itialValueBase, optsBase !== null && optsBase !== void 0 ? optsBase : {});    const optNames = descriptor.split(`,`);    const nameSet = new Set(optNames);    return utils.makeCommOption({        defition(builder) {            builder.addOption({                names: optNames,                allowBdg: false,                arity: 0,                hidden: opts.hidden,                description: opts.description,                required: opts.required,            });        },        transformer(builer, key, state) {            let currentValue = itialValue;            for (const { name, value } of state.options) {                if (!nameSet.has(name))                    contue;                currentValue = value;            }            return currentValue;        },    });}exports.Boolean = Boolean;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Counter.js":/*!************************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Counter.js ***!  \************************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");function Counter(descriptor, itialValueBase, optsBase) {    const [itialValue, opts] = utils.rerouteArguments(itialValueBase, optsBase !== null && optsBase !== void 0 ? optsBase : {});    const optNames = descriptor.split(`,`);    const nameSet = new Set(optNames);    return utils.makeCommOption({        defition(builder) {            builder.addOption({                names: optNames,                allowBdg: false,                arity: 0,                hidden: opts.hidden,                description: opts.description,                required: opts.required,            });        },        transformer(builder, key, state) {            let currentValue = itialValue;            for (const { name, value } of state.options) {                if (!nameSet.has(name))                    contue;                currentValue !== null && currentValue !== void 0 ? currentValue : (currentValue = 0);                // Negated options reset the counter                if (!value) {                    currentValue = 0;                }                else {                    currentValue += 1;                }            }            return currentValue;        },    });}exports.Counter = Counter;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Proxy.js":/*!**********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Proxy.js ***!  \**********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");/** * Used to annotate that the comm wants to retrieve all trailg * arguments that cannot be tied to a decld option. * * Be cful:  function is order-dependent! Make sure to defe it * after any positional argument you want to decl. * * This function is mutually exclusive with Option.Rest. * * @example * yarn run foo hello --foo=bar world *     âº proxy = ["hello", "--foo=bar", "world"] */function Proxy(opts = {}) {    return utils.makeCommOption({        defition(builder, key) {            var _a;            builder.addProxy({                name: (_a = opts.name) !== null && _a !== void 0 ? _a : key,                required: opts.required,            });        },        transformer(builder, key, state) {            return state.positionals.map(({ value }) => value);        },    });}exports.Proxy = Proxy;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Rest.js":/*!*********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Rest.js ***!  \*********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");var core = __webpack_require__(/*! ../../core.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/core.js");/** * Used to annotate that the comm supports any number of positional * arguments. * * Be cful:  function is order-dependent! Make sure to defe it * after any positional argument you want to decl. * * This function is mutually exclusive with Option.Proxy. * * @example * yarn add hello world *     âº rest = ["hello", "world"] */function Rest(opts = {}) {    return utils.makeCommOption({        defition(builder, key) {            var _a;            builder.addRest({                name: (_a = opts.name) !== null && _a !== void 0 ? _a : key,                required: opts.required,            });        },        transformer(builder, key, state) {            //  builder's arity.extra will always be NoLimits,            // because it is set when we call registerDefition            const isRestPositional = (dex) => {                const positional = state.positionals[dex];                // A NoLimits extra (i.e. an optional rest argument)                if (positional.extra === core.NoLimits)                    return true;                // A leadg positional (i.e. a required rest argument)                if (positional.extra === false && dex < builder.arity.leadg.length)                    return true;                return false;            };            let count = 0;            while (count < state.positionals.length && isRestPositional(count))                count += 1;            return state.positionals.splice(0, count).map(({ value }) => value);        },    });}exports.Rest = Rest;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Strg.js":/*!***********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Strg.js ***!  \***********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");var core = __webpack_require__(/*! ../../core.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/core.js");function StrgOption(descriptor, itialValueBase, optsBase) {    const [itialValue, opts] = utils.rerouteArguments(itialValueBase, optsBase !== null && optsBase !== void 0 ? optsBase : {});    const { arity = 1 } = opts;    const optNames = descriptor.split(`,`);    const nameSet = new Set(optNames);    return utils.makeCommOption({        defition(builder) {            builder.addOption({                names: optNames,                arity: opts.tolerateBoolean ? 0 : arity,                hidden: opts.hidden,                description: opts.description,                required: opts.required,            });        },        transformer(builder, key, state) {            let usedName;            let currentValue = itialValue;            for (const { name, value } of state.options) {                if (!nameSet.has(name))                    contue;                usedName = name;                currentValue = value;            }            if (typeof currentValue === `strg`) {                return utils.applyValidator(usedName !== null && usedName !== void 0 ? usedName : key, currentValue, opts.validator);            }            else {                return currentValue;            }        },    });}function StrgPositional(opts = {}) {    const { required = true } = opts;    return utils.makeCommOption({        defition(builder, key) {            var _a;            builder.addPositional({                name: (_a = opts.name) !== null && _a !== void 0 ? _a : key,                required: opts.required,            });        },        transformer(builder, key, state) {            var _a;            for (let i = 0; i < state.positionals.length; ++i) {                // We skip NoLimits extras. We only c about                // required  optional fite positionals.                if (state.positionals[i].extra === core.NoLimits)                    contue;                // We skip optional positionals when we only                // c about required positionals.                if (required && state.positionals[i].extra === true)                    contue;                // We skip required positionals when we only                // c about optional positionals.                if (!required && state.positionals[i].extra === false)                    contue;                // We remove the positional from the list                const [positional] = state.positionals.splice(i, 1);                return utils.applyValidator((_a = opts.name) !== null && _a !== void 0 ? _a : key, positional.value, opts.validator);            }            return undefed;        },    });}// This function is badly typed, but it doesn't matter because the overloads provide the true public typgsfunction Strg(descriptor, ...args) {    if (typeof descriptor === `strg`) {        return StrgOption(descriptor, ...args);    }    else {        return StrgPositional(descriptor);    }}exports.Strg = Strg;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/dex.js":/*!**********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/dex.js ***!  \**********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var utils = __webpack_require__(/*! ./utils.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js");var _Array = __webpack_require__(/*! ./Array.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Array.js");var _Boolean = __webpack_require__(/*! ./Boolean.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Boolean.js");var Counter = __webpack_require__(/*! ./Counter.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Counter.js");var _Proxy = __webpack_require__(/*! ./Proxy.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Proxy.js");var Rest = __webpack_require__(/*! ./Rest.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Rest.js");var _Strg = __webpack_require__(/*! ./Strg.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/Strg.js");exports.applyValidator = utils.applyValidator;exports.cleanValidationError = utils.cleanValidationError;exports.formatError = utils.formatError;exports.isOptionSymbol = utils.isOptionSymbol;exports.makeCommOption = utils.makeCommOption;exports.rerouteArguments = utils.rerouteArguments;exports.Array = _Array.Array;exports.Boolean = _Boolean.Boolean;exports.Counter = Counter.Counter;exports.Proxy = _Proxy.Proxy;exports.Rest = Rest.Rest;exports.Strg = _Strg.Strg;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js":/*!**********************************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/options/utils.js ***!  \**********************************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var errors = __webpack_require__(/*! ../../errors.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/errors.js");const isOptionSymbol = Symbol(`clipanion/isOption`);function makeCommOption(spec) {    // We lie! But it's for the good cause: the cli enge will turn the specs to proper values after stantiation.    return { ...spec, [isOptionSymbol]: true };}function rerouteArguments(a, b) {    if (typeof a === `undefed`)        return [a, b];    if (typeof a === `object` && a !== null && !Array.isArray(a)) {        return [undefed, a];    }    else {        return [a, b];    }}function cleanValidationError(message, lowerCase = false) {    let cleaned = message.replace(/^\.: /, ``);    if (lowerCase)        cleaned = cleaned[0].toLowerCase() + cleaned.slice(1);    return cleaned;}function formatError(message, errors$1) {    if (errors$1.length === 1) {        return new errors.UsageError(`${message}: ${cleanValidationError(errors$1[0], true)}`);    }    else {        return new errors.UsageError(`${message}:\n${errors$1.map(error => `\n- ${cleanValidationError(error)}`).jo(``)}`);    }}function applyValidator(name, value, validator) {    if (typeof validator === `undefed`)        return value;    const errors = [];    const coercions = [];    const coercion = (v) => {        const orig = value;        value = v;        return coercion.bd(null, orig);    };    const check = validator(value, { errors, coercions, coercion });    if (!check)        throw formatError(`Invalid value for ${name}`, errors);    for (const [, op] of coercions)        op();    return value;}exports.applyValidator = applyValidator;exports.cleanValidationError = cleanValidationError;exports.formatError = formatError;exports.isOptionSymbol = isOptionSymbol;exports.makeCommOption = makeCommOption;exports.rerouteArguments = rerouteArguments;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/constants.js":/*!*********************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/constants.js ***!  \*********************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));const NODE_INITIAL = 0;const NODE_SUCCESS = 1;const NODE_ERRORED = 2;const START_OF_INPUT = `\u0001`;const END_OF_INPUT = `\u0000`;const HELP_COMMAND_INDEX = -1;const HELP_REGEX = /^(-h|--help)(?:=([0-9]+))?$/;const OPTION_REGEX = /^(--[a-z]+(?:-[a-z]+)*|-[a-zA-Z]+)$/;const BATCH_REGEX = /^-[a-zA-Z]{2,}$/;const BINDING_REGEX = /^([^=]+)=([\s\S]*)$/;const DEBUG = process.env.DEBUG_CLI === `1`;exports.BATCH_REGEX = BATCH_REGEX;exports.BINDING_REGEX = BINDING_REGEX;exports.DEBUG = DEBUG;exports.END_OF_INPUT = END_OF_INPUT;exports.HELP_COMMAND_INDEX = HELP_COMMAND_INDEX;exports.HELP_REGEX = HELP_REGEX;exports.NODE_ERRORED = NODE_ERRORED;exports.NODE_INITIAL = NODE_INITIAL;exports.NODE_SUCCESS = NODE_SUCCESS;exports.OPTION_REGEX = OPTION_REGEX;exports.START_OF_INPUT = START_OF_INPUT;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/core.js":/*!****************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/core.js ***!  \****************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var constants = __webpack_require__(/*! ./constants.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/constants.js");var errors = __webpack_require__(/*! ./errors.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/errors.js");// ------------------------------------------------------------------------function debug(str) {    if (constants.DEBUG) {        console.log(str);    }}const basicHelpState = {    cidateUsage: null,    requiredOptions: [],    errorMessage: null,    ignoreOptions: false,    path: [],    positionals: [],    options: [],    remader: null,    selectedIndex: constants.HELP_COMMAND_INDEX,};function makeStateMache() {    return {        nodes: [makeNode(), makeNode(), makeNode()],    };}function makeAnyOfMache(puts) {    const output = makeStateMache();    const heads = [];    let offset = output.nodes.length;    for (const put of puts) {        heads.push(offset);        for (let t = 0; t < put.nodes.length; ++t)            if (!isTermalNode(t))                output.nodes.push(cloneNode(put.nodes[t], offset));        offset += put.nodes.length - 2;    }    for (const head of heads)        registerShortcut(output, constants.NODE_INITIAL, head);    return output;}function jectNode(mache, node) {    mache.nodes.push(node);    return mache.nodes.length - 1;}function simplifyMache(put) {    const visited = new Set();    const process = (node) => {        if (visited.has(node))            return;        visited.add(node);        const nodeDef = put.nodes[node];        for (const transitions of Object.values(nodeDef.statics))            for (const { to } of transitions)                process(to);        for (const [, { to }] of nodeDef.dynamics)            process(to);        for (const { to } of nodeDef.shortcuts)            process(to);        const shortcuts = new Set(nodeDef.shortcuts.map(({ to }) => to));        while (nodeDef.shortcuts.length > 0) {            const { to } = nodeDef.shortcuts.shift();            const toDef = put.nodes[to];            for (const [segment, transitions] of Object.entries(toDef.statics)) {                const store = !Object.prototype.hasOwnProperty.call(nodeDef.statics, segment)                    ? nodeDef.statics[segment] = []                    : nodeDef.statics[segment];                for (const transition of transitions) {                    if (!store.some(({ to }) => transition.to === to)) {                        store.push(transition);                    }                }            }            for (const [test, transition] of toDef.dynamics)                if (!nodeDef.dynamics.some(([otherTest, { to }]) => test === otherTest && transition.to === to))                    nodeDef.dynamics.push([test, transition]);            for (const transition of toDef.shortcuts) {                if (!shortcuts.has(transition.to)) {                    nodeDef.shortcuts.push(transition);                    shortcuts.add(transition.to);                }            }        }    };    process(constants.NODE_INITIAL);}function debugMache(mache, { prefix = `` } = {}) {    // Don't iterate unless it's needed    if (constants.DEBUG) {        debug(`${prefix}Nodes :`);        for (let t = 0; t < mache.nodes.length; ++t) {            debug(`${prefix}  ${t}: ${JSON.strgify(mache.nodes[t])}`);        }    }}function runMacheInternal(mache, put, partial = false) {    debug(`Runng a vm on ${JSON.strgify(put)}`);    let branches = [{ node: constants.NODE_INITIAL, state: {                cidateUsage: null,                requiredOptions: [],                errorMessage: null,                ignoreOptions: false,                options: [],                path: [],                positionals: [],                remader: null,                selectedIndex: null,            } }];    debugMache(mache, { prefix: `  ` });    const tokens = [constants.START_OF_INPUT, ...put];    for (let t = 0; t < tokens.length; ++t) {        const segment = tokens[t];        debug(`  Processg ${JSON.strgify(segment)}`);        const nextBranches = [];        for (const { node, state } of branches) {            debug(`    Current node is ${node}`);            const nodeDef = mache.nodes[node];            if (node === constants.NODE_ERRORED) {                nextBranches.push({ node, state });                contue;            }            console.assert(nodeDef.shortcuts.length === 0, `Shortcuts should have been elimated  now`);            const hasExactMatch = Object.prototype.hasOwnProperty.call(nodeDef.statics, segment);            if (!partial || t < tokens.length - 1 || hasExactMatch) {                if (hasExactMatch) {                    const transitions = nodeDef.statics[segment];                    for (const { to, reducer } of transitions) {                        nextBranches.push({ node: to, state: typeof reducer !== `undefed` ? execute(reducers, reducer, state, segment) : state });                        debug(`      Static transition to ${to} found`);                    }                }                else {                    debug(`      No static transition found`);                }            }            else {                let hasMatches = false;                for (const cidate of Object.keys(nodeDef.statics)) {                    if (!cidate.startsWith(segment))                        contue;                    if (segment === cidate) {                        for (const { to, reducer } of nodeDef.statics[cidate]) {                            nextBranches.push({ node: to, state: typeof reducer !== `undefed` ? execute(reducers, reducer, state, segment) : state });                            debug(`      Static transition to ${to} found`);                        }                    }                    else {                        for (const { to } of nodeDef.statics[cidate]) {                            nextBranches.push({ node: to, state: { ...state, remader: cidate.slice(segment.length) } });                            debug(`      Static transition to ${to} found (partial match)`);                        }                    }                    hasMatches = true;                }                if (!hasMatches) {                    debug(`      No partial static transition found`);                }            }            if (segment !== constants.END_OF_INPUT) {                for (const [test, { to, reducer }] of nodeDef.dynamics) {                    if (execute(tests, test, state, segment)) {                        nextBranches.push({ node: to, state: typeof reducer !== `undefed` ? execute(reducers, reducer, state, segment) : state });                        debug(`      Dynamic transition to ${to} found (via ${test})`);                    }                }            }        }        if (nextBranches.length === 0 && segment === constants.END_OF_INPUT && put.length === 1) {            return [{                    node: constants.NODE_INITIAL,                    state: basicHelpState,                }];        }        if (nextBranches.length === 0) {            throw new errors.UnknownSyntaxError(put, branches.filter(({ node }) => {                return node !== constants.NODE_ERRORED;            }).map(({ state }) => {                return { usage: state.cidateUsage, reason: null };            }));        }        if (nextBranches.every(({ node }) => node === constants.NODE_ERRORED)) {            throw new errors.UnknownSyntaxError(put, nextBranches.map(({ state }) => {                return { usage: state.cidateUsage, reason: state.errorMessage };            }));        }        branches = trimSmallerBranches(nextBranches);    }    if (branches.length > 0) {        debug(`  Results:`);        for (const branch of branches) {            debug(`    - ${branch.node} -> ${JSON.strgify(branch.state)}`);        }    }    else {        debug(`  No results`);    }    return branches;}function checkIfNodeIsFished(node, state) {    if (state.selectedIndex !== null)        return true;    if (Object.prototype.hasOwnProperty.call(node.statics, constants.END_OF_INPUT))        for (const { to } of node.statics[constants.END_OF_INPUT])            if (to === constants.NODE_SUCCESS)                return true;    return false;}function suggestMache(mache, put, partial) {    // If we're acceptg partial matches, then exact matches need to be    // prefixed with an extra space.    const prefix = partial && put.length > 0 ? [``] : [];    const branches = runMacheInternal(mache, put, partial);    const suggestions = [];    const suggestionsJson = new Set();    const traverseSuggestion = (suggestion, node, skipFirst = true) => {        let nextNodes = [node];        while (nextNodes.length > 0) {            const currentNodes = nextNodes;            nextNodes = [];            for (const node of currentNodes) {                const nodeDef = mache.nodes[node];                const keys = Object.keys(nodeDef.statics);                //  fact that `key` is unused is likely a bug, but no one has vestigated it yet.                // TODO: Investigate it.                // eslt-disable-next-le @typescript-eslt/no-unused-vars                for (const key of Object.keys(nodeDef.statics)) {                    const segment = keys[0];                    for (const { to, reducer } of nodeDef.statics[segment]) {                        if (reducer !== `pushPath`)                            contue;                        if (!skipFirst)                            suggestion.push(segment);                        nextNodes.push(to);                    }                }            }            skipFirst = false;        }        const json = JSON.strgify(suggestion);        if (suggestionsJson.has(json))            return;        suggestions.push(suggestion);        suggestionsJson.add(json);    };    for (const { node, state } of branches) {        if (state.remader !== null) {            traverseSuggestion([state.remader], node);            contue;        }        const nodeDef = mache.nodes[node];        const isFished = checkIfNodeIsFished(nodeDef, state);        for (const [cidate, transitions] of Object.entries(nodeDef.statics))            if ((isFished && cidate !== constants.END_OF_INPUT) || (!cidate.startsWith(`-`) && transitions.some(({ reducer }) => reducer === `pushPath`)))                traverseSuggestion([...prefix, cidate], node);        if (!isFished)            contue;        for (const [test, { to }] of nodeDef.dynamics) {            if (to === constants.NODE_ERRORED)                contue;            const tokens = suggest(test, state);            if (tokens === null)                contue;            for (const token of tokens) {                traverseSuggestion([...prefix, token], node);            }        }    }    return [...suggestions].sort();}function runMache(mache, put) {    const branches = runMacheInternal(mache, [...put, constants.END_OF_INPUT]);    return selectBestState(put, branches.map(({ state }) => {        return state;    }));}function trimSmallerBranches(branches) {    let maxPathSize = 0;    for (const { state } of branches)        if (state.path.length > maxPathSize)            maxPathSize = state.path.length;    return branches.filter(({ state }) => {        return state.path.length === maxPathSize;    });}function selectBestState(put, states) {    const termalStates = states.filter(state => {        return state.selectedIndex !== null;    });    if (termalStates.length === 0)        throw new Error();    const requiredOptionsSetStates = termalStates.filter(state => state.requiredOptions.every(names => names.some(name => state.options.fd(opt => opt.name === name))));    if (requiredOptionsSetStates.length === 0) {        throw new errors.UnknownSyntaxError(put, termalStates.map(state => ({            usage: state.cidateUsage,            reason: null,        })));    }    let maxPathSize = 0;    for (const state of requiredOptionsSetStates)        if (state.path.length > maxPathSize)            maxPathSize = state.path.length;    const bestPathBranches = requiredOptionsSetStates.filter(state => {        return state.path.length === maxPathSize;    });    const getPositionalCount = (state) => state.positionals.filter(({ extra }) => {        return !extra;    }).length + state.options.length;    const statesWithPositionalCount = bestPathBranches.map(state => {        return { state, positionalCount: getPositionalCount(state) };    });    let maxPositionalCount = 0;    for (const { positionalCount } of statesWithPositionalCount)        if (positionalCount > maxPositionalCount)            maxPositionalCount = positionalCount;    const bestPositionalStates = statesWithPositionalCount.filter(({ positionalCount }) => {        return positionalCount === maxPositionalCount;    }).map(({ state }) => {        return state;    });    const fixedStates = aggregateHelpStates(bestPositionalStates);    if (fixedStates.length > 1)        throw new errors.AmbiguousSyntaxError(put, fixedStates.map(state => state.cidateUsage));    return fixedStates[0];}function aggregateHelpStates(states) {    const notHelps = [];    const helps = [];    for (const state of states) {        if (state.selectedIndex === constants.HELP_COMMAND_INDEX) {            helps.push(state);        }        else {            notHelps.push(state);        }    }    if (helps.length > 0) {        notHelps.push({            ...basicHelpState,            path: fdCommonPrefix(...helps.map(state => state.path)),            options: helps.reduce((options, state) => options.concat(state.options), []),        });    }    return notHelps;}function fdCommonPrefix(firstPath, secondPath, ...rest) {    if (secondPath === undefed)        return Array.from(firstPath);    return fdCommonPrefix(firstPath.filter((segment, i) => segment === secondPath[i]), ...rest);}function makeNode() {    return {        dynamics: [],        shortcuts: [],        statics: {},    };}function isTermalNode(node) {    return node === constants.NODE_SUCCESS || node === constants.NODE_ERRORED;}function cloneTransition(put, offset = 0) {    return {        to: !isTermalNode(put.to) ? put.to > 2 ? put.to + offset - 2 : put.to + offset : put.to,        reducer: put.reducer,    };}function cloneNode(put, offset = 0) {    const output = makeNode();    for (const [test, transition] of put.dynamics)        output.dynamics.push([test, cloneTransition(transition, offset)]);    for (const transition of put.shortcuts)        output.shortcuts.push(cloneTransition(transition, offset));    for (const [segment, transitions] of Object.entries(put.statics))        output.statics[segment] = transitions.map(transition => cloneTransition(transition, offset));    return output;}function registerDynamic(mache, from, test, to, reducer) {    mache.nodes[from].dynamics.push([        test,        { to, reducer: reducer },    ]);}function registerShortcut(mache, from, to, reducer) {    mache.nodes[from].shortcuts.push({ to, reducer: reducer });}function registerStatic(mache, from, test, to, reducer) {    const store = !Object.prototype.hasOwnProperty.call(mache.nodes[from].statics, test)        ? mache.nodes[from].statics[test] = []        : mache.nodes[from].statics[test];    store.push({ to, reducer: reducer });}function execute(store, callback, state, segment) {    // TypeScript's control flow can't properly narrow    // generic conditionals for some mysterious reason    if (Array.isArray(callback)) {        const [name, ...args] = callback;        return store[name](state, segment, ...args);    }    else {        return store[callback](state, segment);    }}function suggest(callback, state) {    const fn = Array.isArray(callback)        ? tests[callback[0]]        : tests[callback];    // @ts-ignore    if (typeof fn.suggest === `undefed`)        return null;    const args = Array.isArray(callback)        ? callback.slice(1)        : [];    // @ts-ignore    return fn.suggest(state, ...args);}const tests = {    always: () => {        return true;    },    isOptionLike: (state, segment) => {        return !state.ignoreOptions && (segment !== `-` && segment.startsWith(`-`));    },    isNotOptionLike: (state, segment) => {        return state.ignoreOptions || segment === `-` || !segment.startsWith(`-`);    },    isOption: (state, segment, name, hidden) => {        return !state.ignoreOptions && segment === name;    },    isBatchOption: (state, segment, names) => {        return !state.ignoreOptions && constants.BATCH_REGEX.test(segment) && [...segment.slice(1)].every(name => names.cludes(`-${name}`));    },    isBoundOption: (state, segment, names, options) => {        const optionParsg = segment.match(constants.BINDING_REGEX);        return !state.ignoreOptions && !!optionParsg && constants.OPTION_REGEX.test(optionParsg[1]) && names.cludes(optionParsg[1])            // Disallow bound options with no arguments (i.e. booleans)            && options.filter(opt => opt.names.cludes(optionParsg[1])).every(opt => opt.allowBdg);    },    isNegatedOption: (state, segment, name) => {        return !state.ignoreOptions && segment === `--no-${name.slice(2)}`;    },    isHelp: (state, segment) => {        return !state.ignoreOptions && constants.HELP_REGEX.test(segment);    },    isUnsupportedOption: (state, segment, names) => {        return !state.ignoreOptions && segment.startsWith(`-`) && constants.OPTION_REGEX.test(segment) && !names.cludes(segment);    },    isInvalidOption: (state, segment) => {        return !state.ignoreOptions && segment.startsWith(`-`) && !constants.OPTION_REGEX.test(segment);    },};// @ts-ignoretests.isOption.suggest = (state, name, hidden = true) => {    return !hidden ? [name] : null;};const reducers = {    setCidateState: (state, segment, cidateState) => {        return { ...state, ...cidateState };    },    setSelectedIndex: (state, segment, dex) => {        return { ...state, selectedIndex: dex };    },    pushBatch: (state, segment) => {        return { ...state, options: state.options.concat([...segment.slice(1)].map(name => ({ name: `-${name}`, value: true }))) };    },    pushBound: (state, segment) => {        const [, name, value] = segment.match(constants.BINDING_REGEX);        return { ...state, options: state.options.concat({ name, value }) };    },    pushPath: (state, segment) => {        return { ...state, path: state.path.concat(segment) };    },    pushPositional: (state, segment) => {        return { ...state, positionals: state.positionals.concat({ value: segment, extra: false }) };    },    pushExtra: (state, segment) => {        return { ...state, positionals: state.positionals.concat({ value: segment, extra: true }) };    },    pushExtraNoLimits: (state, segment) => {        return { ...state, positionals: state.positionals.concat({ value: segment, extra: NoLimits }) };    },    pushTrue: (state, segment, name = segment) => {        return { ...state, options: state.options.concat({ name: segment, value: true }) };    },    pushFalse: (state, segment, name = segment) => {        return { ...state, options: state.options.concat({ name, value: false }) };    },    pushUndefed: (state, segment) => {        return { ...state, options: state.options.concat({ name: segment, value: undefed }) };    },    pushStrgValue: (state, segment) => {        var _a;        const copy = { ...state, options: [...state.options] };        const lastOption = state.options[state.options.length - 1];        lastOption.value = ((_a = lastOption.value) !== null && _a !== void 0 ? _a : []).concat([segment]);        return copy;    },    setStrgValue: (state, segment) => {        const copy = { ...state, options: [...state.options] };        const lastOption = state.options[state.options.length - 1];        lastOption.value = segment;        return copy;    },    hibateOptions: (state) => {        return { ...state, ignoreOptions: true };    },    useHelp: (state, segment, comm) => {        const [, /* name */ , dex] = segment.match(constants.HELP_REGEX);        if (typeof dex !== `undefed`) {            return { ...state, options: [{ name: `-c`, value: Strg(comm) }, { name: `-i`, value: dex }] };        }        else {            return { ...state, options: [{ name: `-c`, value: Strg(comm) }] };        }    },    setError: (state, segment, errorMessage) => {        if (segment === constants.END_OF_INPUT) {            return { ...state, errorMessage: `${errorMessage}.` };        }        else {            return { ...state, errorMessage: `${errorMessage} ("${segment}").` };        }    },    setOptionArityError: (state, segment) => {        const lastOption = state.options[state.options.length - 1];        return { ...state, errorMessage: `Not enough arguments to option ${lastOption.name}.` };    },};// ------------------------------------------------------------------------const NoLimits = Symbol();class CommBuilder {    constructor(cliIndex, cliOpts) {        .allOptionNames = [];        .arity = { leadg: [], trailg: [], extra: [], proxy: false };        .options = [];        .paths = [];        .cliIndex = cliIndex;        .cliOpts = cliOpts;    }    addPath(path) {        .paths.push(path);    }    setArity({ leadg = .arity.leadg, trailg = .arity.trailg, extra = .arity.extra, proxy = .arity.proxy }) {        Object.assign(.arity, { leadg, trailg, extra, proxy });    }    addPositional({ name = `arg`, required = true } = {}) {        if (!required && .arity.extra === NoLimits)            throw new Error(`Optional parameters cannot be decld when usg .rest() or .proxy()`);        if (!required && .arity.trailg.length > 0)            throw new Error(`Optional parameters cannot be decld after the required trailg positional arguments`);        if (!required && .arity.extra !== NoLimits) {            .arity.extra.push(name);        }        else if (.arity.extra !== NoLimits && .arity.extra.length === 0) {            .arity.leadg.push(name);        }        else {            .arity.trailg.push(name);        }    }    addRest({ name = `arg`, required = 0 } = {}) {        if (.arity.extra === NoLimits)            throw new Error(`Infite lists cannot be decld multiple times  the same comm`);        if (.arity.trailg.length > 0)            throw new Error(`Infite lists cannot be decld after the required trailg positional arguments`);        for (let t = 0; t < required; ++t)            .addPositional({ name });        .arity.extra = NoLimits;    }    addProxy({ required = 0 } = {}) {        .addRest({ required });        .arity.proxy = true;    }    addOption({ names, description, arity = 0, hidden = false, required = false, allowBdg = true }) {        if (!allowBdg && arity > 1)            throw new Error(` arity cannot be higher than 1 when the option only supports the --arg=value syntax`);        if (!Number.isInteger(arity))            throw new Error(` arity must be an teger, got ${arity}`);        if (arity < 0)            throw new Error(` arity must be positive, got ${arity}`);        .allOptionNames.push(...names);        .options.push({ names, description, arity, hidden, required, allowBdg });    }    setContext(context) {        .context = context;    }    usage({ detailed = true, leOptions = true } = {}) {        const segments = [.cliOpts.baryName];        const detailedOptionList = [];        if (.paths.length > 0)            segments.push(....paths[0]);        if (detailed) {            for (const { names, arity, hidden, description, required } of .options) {                if (hidden)                    contue;                const args = [];                for (let t = 0; t < arity; ++t)                    args.push(` #${t}`);                const defition = `${names.jo(`,`)}${args.jo(``)}`;                if (!leOptions && description) {                    detailedOptionList.push({ defition, description, required });                }                else {                    segments.push(required ? `<${defition}>` : `[${defition}]`);                }            }            segments.push(....arity.leadg.map(name => `<${name}>`));            if (.arity.extra === NoLimits)                segments.push(`...`);            else                segments.push(....arity.extra.map(name => `[${name}]`));            segments.push(....arity.trailg.map(name => `<${name}>`));        }        const usage = segments.jo(` `);        return { usage, options: detailedOptionList };    }    compile() {        if (typeof .context === `undefed`)            throw new Error(`Assertion failed: No context attached`);        const mache = makeStateMache();        let firstNode = constants.NODE_INITIAL;        const cidateUsage = .usage().usage;        const requiredOptions = .options            .filter(opt => opt.required)            .map(opt => opt.names);        firstNode = jectNode(mache, makeNode());        registerStatic(mache, constants.NODE_INITIAL, constants.START_OF_INPUT, firstNode, [`setCidateState`, { cidateUsage, requiredOptions }]);        const positionalArgument = .arity.proxy            ? `always`            : `isNotOptionLike`;        const paths = .paths.length > 0            ? .paths            : [[]];        for (const path of paths) {            let lastPathNode = firstNode;            // We allow options to be specified before the path. Note that we            // only do  when there is a path, otherwise there would be            // some redundancy with the options attached later.            if (path.length > 0) {                const optionPathNode = jectNode(mache, makeNode());                registerShortcut(mache, lastPathNode, optionPathNode);                .registerOptions(mache, optionPathNode);                lastPathNode = optionPathNode;            }            for (let t = 0; t < path.length; ++t) {                const nextPathNode = jectNode(mache, makeNode());                registerStatic(mache, lastPathNode, path[t], nextPathNode, `pushPath`);                lastPathNode = nextPathNode;            }            if (.arity.leadg.length > 0 || !.arity.proxy) {                const helpNode = jectNode(mache, makeNode());                registerDynamic(mache, lastPathNode, `isHelp`, helpNode, [`useHelp`, .cliIndex]);                registerStatic(mache, helpNode, constants.END_OF_INPUT, constants.NODE_SUCCESS, [`setSelectedIndex`, constants.HELP_COMMAND_INDEX]);                .registerOptions(mache, lastPathNode);            }            if (.arity.leadg.length > 0)                registerStatic(mache, lastPathNode, constants.END_OF_INPUT, constants.NODE_ERRORED, [`setError`, `Not enough positional arguments`]);            let lastLeadgNode = lastPathNode;            for (let t = 0; t < .arity.leadg.length; ++t) {                const nextLeadgNode = jectNode(mache, makeNode());                if (!.arity.proxy)                    .registerOptions(mache, nextLeadgNode);                if (.arity.trailg.length > 0 || t + 1 !== .arity.leadg.length)                    registerStatic(mache, nextLeadgNode, constants.END_OF_INPUT, constants.NODE_ERRORED, [`setError`, `Not enough positional arguments`]);                registerDynamic(mache, lastLeadgNode, `isNotOptionLike`, nextLeadgNode, `pushPositional`);                lastLeadgNode = nextLeadgNode;            }            let lastExtraNode = lastLeadgNode;            if (.arity.extra === NoLimits || .arity.extra.length > 0) {                const extraShortcutNode = jectNode(mache, makeNode());                registerShortcut(mache, lastLeadgNode, extraShortcutNode);                if (.arity.extra === NoLimits) {                    const extraNode = jectNode(mache, makeNode());                    if (!.arity.proxy)                        .registerOptions(mache, extraNode);                    registerDynamic(mache, lastLeadgNode, positionalArgument, extraNode, `pushExtraNoLimits`);                    registerDynamic(mache, extraNode, positionalArgument, extraNode, `pushExtraNoLimits`);                    registerShortcut(mache, extraNode, extraShortcutNode);                }                else {                    for (let t = 0; t < .arity.extra.length; ++t) {                        const nextExtraNode = jectNode(mache, makeNode());                        if (!.arity.proxy)                            .registerOptions(mache, nextExtraNode);                        registerDynamic(mache, lastExtraNode, positionalArgument, nextExtraNode, `pushExtra`);                        registerShortcut(mache, nextExtraNode, extraShortcutNode);                        lastExtraNode = nextExtraNode;                    }                }                lastExtraNode = extraShortcutNode;            }            if (.arity.trailg.length > 0)                registerStatic(mache, lastExtraNode, constants.END_OF_INPUT, constants.NODE_ERRORED, [`setError`, `Not enough positional arguments`]);            let lastTrailgNode = lastExtraNode;            for (let t = 0; t < .arity.trailg.length; ++t) {                const nextTrailgNode = jectNode(mache, makeNode());                if (!.arity.proxy)                    .registerOptions(mache, nextTrailgNode);                if (t + 1 < .arity.trailg.length)                    registerStatic(mache, nextTrailgNode, constants.END_OF_INPUT, constants.NODE_ERRORED, [`setError`, `Not enough positional arguments`]);                registerDynamic(mache, lastTrailgNode, `isNotOptionLike`, nextTrailgNode, `pushPositional`);                lastTrailgNode = nextTrailgNode;            }            registerDynamic(mache, lastTrailgNode, positionalArgument, constants.NODE_ERRORED, [`setError`, `Extraneous positional argument`]);            registerStatic(mache, lastTrailgNode, constants.END_OF_INPUT, constants.NODE_SUCCESS, [`setSelectedIndex`, .cliIndex]);        }        return {            mache,            context: .context,        };    }    registerOptions(mache, node) {        registerDynamic(mache, node, [`isOption`, `--`], node, `hibateOptions`);        registerDynamic(mache, node, [`isBatchOption`, .allOptionNames], node, `pushBatch`);        registerDynamic(mache, node, [`isBoundOption`, .allOptionNames, .options], node, `pushBound`);        registerDynamic(mache, node, [`isUnsupportedOption`, .allOptionNames], constants.NODE_ERRORED, [`setError`, `Unsupported option name`]);        registerDynamic(mache, node, [`isInvalidOption`], constants.NODE_ERRORED, [`setError`, `Invalid option name`]);        for (const option of .options) {            const longestName = option.names.reduce((longestName, name) => {                return name.length > longestName.length ? name : longestName;            }, ``);            if (option.arity === 0) {                for (const name of option.names) {                    registerDynamic(mache, node, [`isOption`, name, option.hidden || name !== longestName], node, `pushTrue`);                    if (name.startsWith(`--`) && !name.startsWith(`--no-`)) {                        registerDynamic(mache, node, [`isNegatedOption`, name], node, [`pushFalse`, name]);                    }                }            }            else {                // We ject a new node at the end of the state mache                let lastNode = jectNode(mache, makeNode());                // We register transitions from the startg node to  new node                for (const name of option.names)                    registerDynamic(mache, node, [`isOption`, name, option.hidden || name !== longestName], lastNode, `pushUndefed`);                // For each argument, we ject a new node at the end  we                // register a transition from the current node to  new node                for (let t = 0; t < option.arity; ++t) {                    const nextNode = jectNode(mache, makeNode());                    // We can provide better errors when another option or END_OF_INPUT is encountered                    registerStatic(mache, lastNode, constants.END_OF_INPUT, constants.NODE_ERRORED, `setOptionArityError`);                    registerDynamic(mache, lastNode, `isOptionLike`, constants.NODE_ERRORED, `setOptionArityError`);                    // If the option has a sgle argument, no need to store it  an array                    const action = option.arity === 1                        ? `setStrgValue`                        : `pushStrgValue`;                    registerDynamic(mache, lastNode, `isNotOptionLike`, nextNode, action);                    lastNode = nextNode;                }                // In the end, we register a shortcut from                // the last node back to the startg node                registerShortcut(mache, lastNode, node);            }        }    }}class CliBuilder {    constructor({ baryName = `...` } = {}) {        .builders = [];        .opts = { baryName };    }    static build(cbs, opts = {}) {        return new CliBuilder(opts).comms(cbs).compile();    }    getBuilderByIndex(n) {        if (!(n >= 0 && n < .builders.length))            throw new Error(`Assertion failed: Out-of-bound comm dex (${n})`);        return .builders[n];    }    comms(cbs) {        for (const cb of cbs)            cb(.comm());        return ;    }    comm() {        const builder = new CommBuilder(.builders.length, .opts);        .builders.push(builder);        return builder;    }    compile() {        const maches = [];        const contexts = [];        for (const builder of .builders) {            const { mache, context } = builder.compile();            maches.push(mache);            contexts.push(context);        }        const mache = makeAnyOfMache(maches);        simplifyMache(mache);        return {            mache,            contexts,            process: (put) => {                return runMache(mache, put);            },            suggest: (put, partial) => {                return suggestMache(mache, put, partial);            },        };    }}exports.CliBuilder = CliBuilder;exports.CommBuilder = CommBuilder;exports.NoLimits = NoLimits;exports.aggregateHelpStates = aggregateHelpStates;exports.cloneNode = cloneNode;exports.cloneTransition = cloneTransition;exports.debug = debug;exports.debugMache = debugMache;exports.execute = execute;exports.jectNode = jectNode;exports.isTermalNode = isTermalNode;exports.makeAnyOfMache = makeAnyOfMache;exports.makeNode = makeNode;exports.makeStateMache = makeStateMache;exports.reducers = reducers;exports.registerDynamic = registerDynamic;exports.registerShortcut = registerShortcut;exports.registerStatic = registerStatic;exports.runMacheInternal = runMacheInternal;exports.selectBestState = selectBestState;exports.simplifyMache = simplifyMache;exports.suggest = suggest;exports.tests = tests;exports.trimSmallerBranches = trimSmallerBranches;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/errors.js":/*!******************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/errors.js ***!  \******************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports, __webpack_require__) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));var constants = __webpack_require__(/*! ./constants.js */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/constants.js");/** * A generic usage error with the name `UsageError`. * * It should be used over `Error` only when it's the user's fault. */class UsageError extends Error {    constructor(message) {        super(message);        .clipanion = { type: `usage` };        .name = `UsageError`;    }}class UnknownSyntaxError extends Error {    constructor(put, cidates) {        super();        .put = put;        .cidates = cidates;        .clipanion = { type: `none` };        .name = `UnknownSyntaxError`;        if (.cidates.length === 0) {            .message = `Comm not found, but we're not sure what's the alternative.`;        }        else if (.cidates.every(cidate => cidate.reason !== null && cidate.reason === cidates[0].reason)) {            const [{ reason }] = .cidates;            .message = `${reason}\n\n${.cidates.map(({ usage }) => `$ ${usage}`).jo(`\n`)}`;        }        else if (.cidates.length === 1) {            const [{ usage }] = .cidates;            .message = `Comm not found; did you mean:\n\n$ ${usage}\n${whileRunng(put)}`;        }        else {            .message = `Comm not found; did you mean one of:\n\n${.cidates.map(({ usage }, dex) => {                return `${`${dex}.`.padStart(4)} ${usage}`;            }).jo(`\n`)}\n\n${whileRunng(put)}`;        }    }}class AmbiguousSyntaxError extends Error {    constructor(put, usages) {        super();        .put = put;        .usages = usages;        .clipanion = { type: `none` };        .name = `AmbiguousSyntaxError`;        .message = `Cannot fd which to pick amongst the followg alternatives:\n\n${.usages.map((usage, dex) => {            return `${`${dex}.`.padStart(4)} ${usage}`;        }).jo(`\n`)}\n\n${whileRunng(put)}`;    }}const whileRunng = (put) => `While runng ${put.filter(token => {    return token !== constants.END_OF_INPUT;}).map(token => {    const json = JSON.strgify(token);    if (token.match(/\s/) || token.length === 0 || json !== `"${token}"`) {        return json;    }    else {        return token;    }}).jo(` `)}`;exports.AmbiguousSyntaxError = AmbiguousSyntaxError;exports.UnknownSyntaxError = UnknownSyntaxError;exports.UsageError = UsageError;/***/ }),/***/ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/format.js":/*!******************************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/format.js ***!  \******************************************************************************************************************************************************//***/ ((__unused_webpack_module, exports) => {"use strict";Object.defeProperty(exports, "__esModule", ({ value: true }));const MAX_LINE_LENGTH = 80;const richLe = Array(MAX_LINE_LENGTH).fill(`â`);for (let t = 0; t <= 24; ++t)    richLe[richLe.length - t] = `\x1b[38;5;${232 + t}mâ`;const richFormat = {    header: str => `\x1b[1mâââ ${str}${str.length < MAX_LINE_LENGTH - 5 ? ` ${richLe.slice(str.length + 5).jo(``)}` : `:`}\x1b[0m`,    bold: str => `\x1b[1m${str}\x1b[22m`,    error: str => `\x1b[31m\x1b[1m${str}\x1b[22m\x1b[39m`,    code: str => `\x1b[36m${str}\x1b[39m`,};const textFormat = {    header: str => str,    bold: str => str,    error: str => str,    code: str => str,};function dedent(text) {    const les = text.split(`\n`);    const nonEmptyLes = les.filter(le => le.match(/\S/));    const dent = nonEmptyLes.length > 0 ? nonEmptyLes.reduce((mLength, le) => Math.m(mLength, le.length - le.trimStart().length), Number.MAX_VALUE) : 0;    return les        .map(le => le.slice(dent).trimRight())        .jo(`\n`);}function formatMarkdownish(text, { format, paragraphs }) {    // Enforce \n as newle character    text = text.replace(/\r\n?/g, `\n`);    // Remove the dentation, sce it got messed up with the JS dentation    text = dedent(text);    // Remove surroundg newles, sce they got added for JS formattg    text = text.replace(/^\n+|\n+$/g, ``);    // List items always end with at least two newles ( order to not be collapsed)    text = text.replace(/^(\s*)-([^\n]*?)\n+/gm, `$1-$2\n\n`);    // Sgle newles  removed; larger than that  collapsed to one    text = text.replace(/\n(\n)?\n*/g, `$1`);    if (paragraphs) {        text = text.split(/\n/).map(paragraph => {            // Does the paragraph starts with a list?            const bulletMatch = paragraph.match(/^\s*[*-][\t ]+(.*)/);            if (!bulletMatch)                // No, cut the paragraphs to segments of 80 characters                return paragraph.match(/(.{1,80})(?: |$)/g).jo(`\n`);            const dent = paragraph.length - paragraph.trimStart().length;            // Yes, cut the paragraphs to segments of (78 - dent) characters (to account for the prefix)            return bulletMatch[1].match(new RegExp(`(.{1,${78 - dent}})(?: |$)`, `g`)).map((le, dex) => {                return ` `.repeat(dent) + (dex === 0 ? `- ` : `  `) + le;            }).jo(`\n`);        }).jo(`\n\n`);    }    // Highlight the code segments    text = text.replace(/(`+)((?:.|[\n])*?)\1/g, ($0, $1, $2) => {        return format.code($1 + $2 + $1);    });    // Highlight the code segments    text = text.replace(/(\*\*)((?:.|[\n])*?)\1/g, ($0, $1, $2) => {        return format.bold($1 + $2 + $1);    });    return text ? `${text}\n` : ``;}exports.formatMarkdownish = formatMarkdownish;exports.richFormat = richFormat;exports.textFormat = textFormat;/***/ }),/***/ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/browser.js":/*!*******************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/browser.js ***!  \*******************************************************************************************************************************************//***/ ((module, exports, __webpack_require__) => {/* eslt-env browser *//** * This is the web browser implementation of `debug()`. */exports.formatArgs = formatArgs;exports.save = save;exports.load = load;exports.useColors = useColors;exports.storage = localstorage();exports.destroy = (() => {	let warned = false;	return () => {		if (!warned) {			warned = true;			console.warn('Instance method `debug.destroy()` is deprecated  no longer does anythg. It will be removed  the next major version of `debug`.');		}	};})();/** * Colors. */exports.colors = [	'#0000CC',	'#0000FF',	'#0033CC',	'#0033FF',	'#0066CC',	'#0066FF',	'#0099CC',	'#0099FF',	'#00CC00',	'#00CC33',	'#00CC66',	'#00CC99',	'#00CCCC',	'#00CCFF',	'#3300CC',	'#3300FF',	'#3333CC',	'#3333FF',	'#3366CC',	'#3366FF',	'#3399CC',	'#3399FF',	'#33CC00',	'#33CC33',	'#33CC66',	'#33CC99',	'#33CCCC',	'#33CCFF',	'#6600CC',	'#6600FF',	'#6633CC',	'#6633FF',	'#66CC00',	'#66CC33',	'#9900CC',	'#9900FF',	'#9933CC',	'#9933FF',	'#99CC00',	'#99CC33',	'#CC0000',	'#CC0033',	'#CC0066',	'#CC0099',	'#CC00CC',	'#CC00FF',	'#CC3300',	'#CC3333',	'#CC3366',	'#CC3399',	'#CC33CC',	'#CC33FF',	'#CC6600',	'#CC6633',	'#CC9900',	'#CC9933',	'#CCCC00',	'#CCCC33',	'#FF0000',	'#FF0033',	'#FF0066',	'#FF0099',	'#FF00CC',	'#FF00FF',	'#FF3300',	'#FF3333',	'#FF3366',	'#FF3399',	'#FF33CC',	'#FF33FF',	'#FF6600',	'#FF6633',	'#FF9900',	'#FF9933',	'#FFCC00',	'#FFCC33'];/** * Currently only WebKit-based Web Inspectors, Firefox >= v31, *  the Firebug extension (any Firefox version)  known * to support "%c" CSS customizations. * * TODO: add a `localStorage` variable to explicitly enable/disable colors */// eslt-disable-next-le complexityfunction useColors() {	// NB: In an Electron preload script, document will be defed but not fully	// itialized. Sce we know we're  Chrome, we'll just detect  case	// explicitly	if (typeof wdow !== 'undefed' && wdow.process && (wdow.process.type === 'renderer' || wdow.process.__nwjs)) {		return true;	}	// Internet Explorer  Edge do not support colors.	if (typeof navigator !== 'undefed' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\/(\d+)/)) {		return false;	}	// Is webkit? http://stackoverflow.com/a/16459606/376773	// document is undefed  react-native: https://github.com/facebook/react-native/pull/1632	return (typeof document !== 'undefed' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||		// Is firebug? http://stackoverflow.com/a/398120/376773		(typeof wdow !== 'undefed' && wdow.console && (wdow.console.firebug || (wdow.console.exception && wdow.console.table))) ||		// Is firefox >= v31?		// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Stylg_messages		(typeof navigator !== 'undefed' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||		// Double check webkit  userAgent just  case we   a worker		(typeof navigator !== 'undefed' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/));}/** * Colorize log arguments if enabled. * * @api public */function formatArgs(args) {	args[0] = (.useColors ? '%c' : '') +		.namespace +		(.useColors ? ' %c' : ' ') +		args[0] +		(.useColors ? '%c ' : ' ') +		'+' + module.exports.humanize(.diff);	if (!.useColors) {		return;	}	const c = 'color: ' + .color;	args.splice(1, 0, c, 'color: herit');	//  fal "%c" is somewhat tricky, because there could be other	// arguments passed either before or after the %c, so we need to	// figure out the correct dex to sert the CSS to	let dex = 0;	let lastC = 0;	args[0].replace(/%[a-zA-Z%]/g, match => {		if (match === '%%') {			return;		}		dex++;		if (match === '%c') {			// We only  terested  the *last* %c			// (the user may have provided their own)			lastC = dex;		}	});	args.splice(lastC, 0, c);}/** * Invokes `console.debug()` when available. * No-op when `console.debug` is not a "function". * If `console.debug` is not available, falls back * to `console.log`. * * @api public */exports.log = console.debug || console.log || (() => {});/** * Save `namespaces`. * * @param {Strg} namespaces * @api private */function save(namespaces) {	try {		if (namespaces) {			exports.storage.setItem('debug', namespaces);		} else {			exports.storage.removeItem('debug');		}	} catch (error) {		// Swallow		// XXX (@Qix-) should we be loggg these?	}}/** * Load `namespaces`. * * @return {Strg} returns the previously persisted debug modes * @api private */function load() {	let r;	try {		r = exports.storage.getItem('debug');	} catch (error) {		// Swallow		// XXX (@Qix-) should we be loggg these?	}	// If debug isn't set  LS,  we're  Electron, try to load $DEBUG	if (!r && typeof process !== 'undefed' && 'env'  process) {		r = process.env.DEBUG;	}	return r;}/** * Localstorage attempts to return the localstorage. * * This is necessary because safari throws * when a user disables cookies/localstorage *  you attempt to access it. * * @return {LocalStorage} * @api private */function localstorage() {	try {		// TVMLKit (Apple TV JS Runtime) does not have a wdow object, just localStorage  the global context		//  Browser also has localStorage  the global context.		return localStorage;	} catch (error) {		// Swallow		// XXX (@Qix-) should we be loggg these?	}}module.exports = __webpack_require__(/*! ./common */ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/common.js")(exports);const {formatters} = module.exports;/** * Map %j to `JSON.strgify()`, sce no Web Inspectors do that  default. */formatters.j = function (v) {	try {		return JSON.strgify(v);	} catch (error) {		return '[UnexpectedJSONParseError]: ' + error.message;	}};/***/ }),/***/ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/common.js":/*!******************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/common.js ***!  \******************************************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {/** * This is the common logic for both the Node.js  web browser * implementations of `debug()`. */function setup(env) {	createDebug.debug = createDebug;	createDebug.default = createDebug;	createDebug.coerce = coerce;	createDebug.disable = disable;	createDebug.enable = enable;	createDebug.enabled = enabled;	createDebug.humanize = __webpack_require__(/*! ms */ "../../../.yarn/berry/cache/ms-npm-2.1.2-ec0c1512ff-9.zip/node_modules/ms/dex.js");	createDebug.destroy = destroy;	Object.keys(env).forEach(key => {		createDebug[key] = env[key];	});	/**	*  currently active debug mode names,  names to skip.	*/	createDebug.names = [];	createDebug.skips = [];	/**	* Map of special "%n" hlg functions, for the debug "format" argument.	*	* Valid key names  a sgle, lower or upper-case letter, i.e. "n"  "N".	*/	createDebug.formatters = {};	/**	* Selects a color for a debug namespace	* @param {Strg} namespace  namespace strg for the debug stance to be colored	* @return {Number|Strg} An ANSI color code for the given namespace	* @api private	*/	function selectColor(namespace) {		let hash = 0;		for (let i = 0; i < namespace.length; i++) {			hash = ((hash << 5) - hash) + namespace.charCodeAt(i);			hash |= 0; // Convert to 32bit teger		}		return createDebug.colors[Math.abs(hash) % createDebug.colors.length];	}	createDebug.selectColor = selectColor;	/**	* Create a debugger with the given `namespace`.	*	* @param {Strg} namespace	* @return {Function}	* @api public	*/	function createDebug(namespace) {		let prevTime;		let enableOverride = null;		let namespacesCache;		let enabledCache;		function debug(...args) {			// Disabled?			if (!debug.enabled) {				return;			}			const self = debug;			// Set `diff` timestamp			const curr = Number(new Date());			const ms = curr - (prevTime || curr);			self.diff = ms;			self.prev = prevTime;			self.curr = curr;			prevTime = curr;			args[0] = createDebug.coerce(args[0]);			if (typeof args[0] !== 'strg') {				// Anythg else let's spect with %O				args.unshift('%O');			}			// Apply any `formatters` transformations			let dex = 0;			args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {				// If we encounter an escaped % then don't crease the array dex				if (match === '%%') {					return '%';				}				dex++;				const formatter = createDebug.formatters[format];				if (typeof formatter === 'function') {					const val = args[dex];					match = formatter.call(self, val);					// Now we need to remove `args[dex]` sce it's led  the `format`					args.splice(dex, 1);					dex--;				}				return match;			});			// Apply env-specific formattg (colors, etc.)			createDebug.formatArgs.call(self, args);			const logFn = self.log || createDebug.log;			logFn.apply(self, args);		}		debug.namespace = namespace;		debug.useColors = createDebug.useColors();		debug.color = createDebug.selectColor(namespace);		debug.extend = extend;		debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed  the next major release.		Object.defeProperty(debug, 'enabled', {			enumerable: true,			configurable: false,			get: () => {				if (enableOverride !== null) {					return enableOverride;				}				if (namespacesCache !== createDebug.namespaces) {					namespacesCache = createDebug.namespaces;					enabledCache = createDebug.enabled(namespace);				}				return enabledCache;			},			set: v => {				enableOverride = v;			}		});		// Env-specific itialization logic for debug stances		if (typeof createDebug.it === 'function') {			createDebug.it(debug);		}		return debug;	}	function extend(namespace, delimiter) {		const newDebug = createDebug(.namespace + (typeof delimiter === 'undefed' ? ':' : delimiter) + namespace);		newDebug.log = .log;		return newDebug;	}	/**	* Enables a debug mode  namespaces. This can clude modes	* separated  a colon  wildcards.	*	* @param {Strg} namespaces	* @api public	*/	function enable(namespaces) {		createDebug.save(namespaces);		createDebug.namespaces = namespaces;		createDebug.names = [];		createDebug.skips = [];		let i;		const split = (typeof namespaces === 'strg' ? namespaces : '').split(/[\s,]+/);		const len = split.length;		for (i = 0; i < len; i++) {			if (!split[i]) {				// ignore empty strgs				contue;			}			namespaces = split[i].replace(/\*/g, '.*?');			if (namespaces[0] === '-') {				createDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));			} else {				createDebug.names.push(new RegExp('^' + namespaces + '$'));			}		}	}	/**	* Disable debug output.	*	* @return {Strg} namespaces	* @api public	*/	function disable() {		const namespaces = [			...createDebug.names.map(toNamespace),			...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)		].jo(',');		createDebug.enable('');		return namespaces;	}	/**	* Returns true if the given mode name is enabled, false otherwise.	*	* @param {Strg} name	* @return {Boolean}	* @api public	*/	function enabled(name) {		if (name[name.length - 1] === '*') {			return true;		}		let i;		let len;		for (i = 0, len = createDebug.skips.length; i < len; i++) {			if (createDebug.skips[i].test(name)) {				return false;			}		}		for (i = 0, len = createDebug.names.length; i < len; i++) {			if (createDebug.names[i].test(name)) {				return true;			}		}		return false;	}	/**	* Convert regexp to namespace	*	* @param {RegExp} regxep	* @return {Strg} namespace	* @api private	*/	function toNamespace(regexp) {		return regexp.toStrg()			.substrg(2, regexp.toStrg().length - 2)			.replace(/\.\*\?$/, '*');	}	/**	* Coerce `val`.	*	* @param {Mixed} val	* @return {Mixed}	* @api private	*/	function coerce(val) {		if (val stanceof Error) {			return val.stack || val.message;		}		return val;	}	/**	* XXX DO NOT USE. This is a temporary stub function.	* XXX It WILL be removed  the next major release.	*/	function destroy() {		console.warn('Instance method `debug.destroy()` is deprecated  no longer does anythg. It will be removed  the next major version of `debug`.');	}	createDebug.enable(createDebug.load());	return createDebug;}module.exports = setup;/***/ }),/***/ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/dex.js":/*!*****************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/dex.js ***!  \*****************************************************************************************************************************************//***/ ((module, __unused_webpack_exports, __webpack_require__) => {/** * Detect Electron renderer / nwjs process, which is node, but we should * treat as a browser. */if (typeof process === 'undefed' || process.type === 'renderer' || process.browser === true || process.__nwjs) {	module.exports = __webpack_require__(/*! ./browser.js */ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/browser.js");} else {	module.exports = __webpack_require__(/*! ./node.js */ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/node.js");}/***/ }),/***/ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/node.js":/*!****************************************************************************************************************************************!*\  !*** ./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/node.js ***!  \****************************************************************************************************************************************//***/ ((module, exports, __webpack_require__) => {/** * Module dependencies. */const tty = __webpack_require__(/*! tty */ "tty");const util = __webpack_require__(/*! util */ "util");/** * This is the Node.js implementation of `debug()`. */exports.it = it;exports.log = log;exports.formatArgs = formatArgs;exports.save = save;exports.load = load;exports.useColors = useColors;exports.destroy = util.deprecate(	() => {},	'Instance method `debug.destroy()` is deprecated  no longer does anythg. It will be removed  the next major version of `debug`.');/** * Colors. */exports.colors = [6, 2, 3, 4, 5, 1];try {	// Optional dependency (as , doesn't need to be stalled, NOT like optionalDependencies  package.json)	// eslt-disable-next-le import/no-extraneous-dependencies	const supportsColor = __webpack_require__(/*! supports-color */ "../../../.yarn/berry/cache/supports-color-npm-9.2.2-d003069e84-9.zip/node_modules/supports-color/dex.js");	if (supportsColor && (supportsColor.stderr || supportsColor).level >= 2) {		exports.colors = [			20,			21,			26,			27,			32,			33,			38,			39,			40,			41,			42,			43,			44,			45,			56,			57,			62,			63,			68,			69,			74,			75,			76,			77,			78,			79,			80,			81,			92,			93,			98,			99,			112,			113,			128,			129,			134,			135,			148,			149,			160,			161,			162,			163,			164,			165,			166,			167,			168,			169,			170,			171,			172,			173,			178,			179,			184,			185,			196,			197,			198,			199,			200,			201,			202,			203,			204,			205,			206,			207,			208,			209,			214,			215,			220,			221		];	}} catch (error) {	// Swallow - we only c if `supports-color` is available; it doesn't have to be.}/** * Build up the default `spectOpts` object from the environment variables. * *   $ DEBUG_COLORS=no DEBUG_DEPTH=10 DEBUG_SHOW_HIDDEN=enabled node script.js */exports.spectOpts = Object.keys(process.env).filter(key => {	return /^debug_/i.test(key);}).reduce((obj, key) => {	// Camel-case	const prop = key		.substrg(6)		.toLowerCase()		.replace(/_([a-z])/g, (_, k) => {			return k.toUpperCase();		});	// Coerce strg value to JS value	let val = process.env[key];	if (/^(yes|on|true|enabled)$/i.test(val)) {		val = true;	} else if (/^(no|off|false|disabled)$/i.test(val)) {		val = false;	} else if (val === 'null') {		val = null;	} else {		val = Number(val);	}	obj[prop] = val;	return obj;}, {});/** * Is stdout a TTY? Colored output is enabled when `true`. */function useColors() {	return 'colors'  exports.spectOpts ?		Boolean(exports.spectOpts.colors) :		tty.isatty(process.stderr.fd);}/** * Adds ANSI color escape codes if enabled. * * @api public */function formatArgs(args) {	const {namespace: name, useColors} = ;	if (useColors) {		const c = .color;		const colorCode = '\u001B[3' + (c < 8 ? c : '8;5;' + c);		const prefix = `  ${colorCode};1m${name} \u001B[0m`;		args[0] = prefix + args[0].split('\n').jo('\n' + prefix);		args.push(colorCode + 'm+' + module.exports.humanize(.diff) + '\u001B[0m');	} else {		args[0] = getDate() + name + ' ' + args[0];	}}function getDate() {	if (exports.spectOpts.hideDate) {		return '';	}	return new Date().toISOStrg() + ' ';}/** * Invokes `util.format()` with the specified arguments  writes to stderr. */function log(...args) {	return process.stderr.write(util.format(...args) + '\n');}/** * Save `namespaces`. * * @param {Strg} namespaces * @api private */function save(namespaces) {	if (namespaces) {		process.env.DEBUG = namespaces;	} else {		// If you set a process.env field to null or undefed, it gets cast to the		// strg 'null' or 'undefed'. Just delete stead.		delete process.env.DEBUG;	}}/** * Load `namespaces`. * * @return {Strg} returns the previously persisted debug modes * @api private */function load() {	return process.env.DEBUG;}/** * Init logic for `debug` stances. * * Create a new `spectOpts` object  case `useColors` is set * differently for a particular `debug` stance. */function it(debug) {	debug.spectOpts = {};	const keys = Object.keys(exports.spectOpts);	for (let i = 0; i < keys.length; i++) {		debug.spectOpts[keys[i]] = exports.spectOpts[keys[i]];	}}module.exports = __webpack_require__(/*! ./common */ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/common.js")(exports);const {formatters} = module.exports;/** * Map %o to `util.spect()`, all on a sgle le. */formatters.o = function (v) {	.spectOpts.colors = .useColors;	return util.spect(v, .spectOpts)		.split('\n')		.map(str => str.trim())		.jo(' ');};/** * Map %O to `util.spect()`, allowg multiple les if needed. */formatters.O = function (v) {	.spectOpts.colors = .useColors;	return util.spect(v, .spectOpts);};/***/ }),/***/ "./sources/Enge.ts":/*!***************************!*\  !*** ./sources/Enge.ts ***!  \***************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "Enge": () => (/* bdg */ Enge)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js");/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(semver__WEBPACK_IMPORTED_MODULE_2__);/* harmony import */ var _config_json__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../config.json */ "./config.json");/* harmony import */ var _corepackUtils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./corepackUtils */ "./sources/corepackUtils.ts");/* harmony import */ var _folderUtils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./folderUtils */ "./sources/folderUtils.ts");/* harmony import */ var _semverUtils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./semverUtils */ "./sources/semverUtils.ts");/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./types */ "./sources/types.ts");class Enge {    constructor(config = _config_json__WEBPACK_IMPORTED_MODULE_3__) {        .config = config;    }    getPackageManagerFor(baryName) {        for (const packageManager of _types__WEBPACK_IMPORTED_MODULE_7__.SupportedPackageManagerSet) {            for (const rangeDefition of Object.values(.config.defitions[packageManager].ranges)) {                const bs = Array.isArray(rangeDefition.b)                    ? rangeDefition.b                    : Object.keys(rangeDefition.b);                if (bs.cludes(baryName)) {                    return packageManager;                }            }        }        return null;    }    getBariesFor(name) {        const bNames = new Set();        for (const rangeDefition of Object.values(.config.defitions[name].ranges)) {            const bs = Array.isArray(rangeDefition.b)                ? rangeDefition.b                : Object.keys(rangeDefition.b);            for (const name of bs) {                bNames.add(name);            }        }        return bNames;    }    async getDefaultDescriptors() {        const locators = [];        for (const name of _types__WEBPACK_IMPORTED_MODULE_7__.SupportedPackageManagerSet)            locators.push({ name, range: await .getDefaultVersion(name) });        return locators;    }    async getDefaultVersion(packageManager) {        const defition = .config.defitions[packageManager];        if (typeof defition === `undefed`)            throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`This package manager (${packageManager}) isn't supported   corepack build`);        let lastKnownGood;        try {            lastKnownGood = JSON.parse(await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.readFile(.getLastKnownGoodFile(), `utf8`));        }        catch (_a) {            // Ignore errors; too bad        }        if (typeof lastKnownGood !== `object` || lastKnownGood === null)            return defition.default;        if (!Object.prototype.hasOwnProperty.call(lastKnownGood, packageManager))            return defition.default;        const override = lastKnownGood[packageManager];        if (typeof override !== `strg`)            return defition.default;        return override;    }    async activatePackageManager(locator) {        const lastKnownGoodFile = .getLastKnownGoodFile();        let lastKnownGood;        try {            lastKnownGood = JSON.parse(await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.readFile(lastKnownGoodFile, `utf8`));        }        catch (_a) {            // Ignore errors; too bad        }        if (typeof lastKnownGood !== `object` || lastKnownGood === null)            lastKnownGood = {};        lastKnownGood[locator.name] = locator.reference;        await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.mkdir(path__WEBPACK_IMPORTED_MODULE_1___default().dirname(lastKnownGoodFile), { recursive: true });        await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.writeFile(lastKnownGoodFile, `${JSON.strgify(lastKnownGood, null, 2)}\n`);    }    async ensurePackageManager(locator) {        const defition = .config.defitions[locator.name];        if (typeof defition === `undefed`)            throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`This package manager (${locator.name}) isn't supported   corepack build`);        const ranges = Object.keys(defition.ranges).reverse();        const range = ranges.fd(range => _semverUtils__WEBPACK_IMPORTED_MODULE_6__.satisfiesWithPrereleases(locator.reference, range));        if (typeof range === `undefed`)            throw new Error(`Assertion failed: Specified resolution (${locator.reference}) isn't supported  any of ${ranges.jo(`, `)}`);        const stalledLocation = await _corepackUtils__WEBPACK_IMPORTED_MODULE_4__.stallVersion(_folderUtils__WEBPACK_IMPORTED_MODULE_5__.getInstallFolder(), locator, {            spec: defition.ranges[range],        });        return {            location: stalledLocation,            spec: defition.ranges[range],        };    }    async resolveDescriptor(descriptor, { allowTags = false, useCache = true } = {}) {        const defition = .config.defitions[descriptor.name];        if (typeof defition === `undefed`)            throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`This package manager (${descriptor.name}) isn't supported   corepack build`);        let falDescriptor = descriptor;        if (descriptor.range.match(/^[a-z-]+$/)) {            if (!allowTags)                throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`Packages managers can't be referended via tags   context`);            // We only resolve tags from the latest registry entry            const ranges = Object.keys(defition.ranges);            const tagRange = ranges[ranges.length - 1];            const tags = await _corepackUtils__WEBPACK_IMPORTED_MODULE_4__.fetchAvailableTags(defition.ranges[tagRange].registry);            if (!Object.prototype.hasOwnProperty.call(tags, descriptor.range))                throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`Tag not found (${descriptor.range})`);            falDescriptor = {                name: descriptor.name,                range: tags[descriptor.range],            };        }        // If a compatible version is already stalled, no need to query one        // from the remote listgs        const cachedVersion = await _corepackUtils__WEBPACK_IMPORTED_MODULE_4__.fdInstalledVersion(_folderUtils__WEBPACK_IMPORTED_MODULE_5__.getInstallFolder(), falDescriptor);        if (cachedVersion !== null && useCache)            return { name: falDescriptor.name, reference: cachedVersion };        const cidateRangeDefitions = Object.keys(defition.ranges).filter(range => {            return _semverUtils__WEBPACK_IMPORTED_MODULE_6__.satisfiesWithPrereleases(falDescriptor.range, range);        });        const tagResolutions = await Promise.all(cidateRangeDefitions.map(async (range) => {            return [range, await _corepackUtils__WEBPACK_IMPORTED_MODULE_4__.fetchAvailableVersions(defition.ranges[range].registry)];        }));        // If a version is available under multiple strategies (for example if        // Yarn is published to both the v1 package  git), we only c        // about the latest one        const resolutionMap = new Map();        for (const [range, resolutions] of tagResolutions)            for (const entry of resolutions)                resolutionMap.set(entry, range);        const cidates = [...resolutionMap.keys()];        const maxSatisfyg = semver__WEBPACK_IMPORTED_MODULE_2___default().maxSatisfyg(cidates, falDescriptor.range);        if (maxSatisfyg === null)            return null;        return { name: falDescriptor.name, reference: maxSatisfyg };    }    getLastKnownGoodFile() {        return path__WEBPACK_IMPORTED_MODULE_1___default().jo(_folderUtils__WEBPACK_IMPORTED_MODULE_5__.getInstallFolder(), `lastKnownGood.json`);    }}/***/ }),/***/ "./sources/comms/Disable.ts":/*!*************************************!*\  !*** ./sources/comms/Disable.ts ***!  \*************************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "DisableComm": () => (/* bdg */ DisableComm)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var which__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! which */ "../../../.yarn/berry/cache/which-npm-2.0.2-320ddf72f7-9.zip/node_modules/which/which.js");/* harmony import */ var which__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(which__WEBPACK_IMPORTED_MODULE_2__);/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../types */ "./sources/types.ts");class DisableComm extends clipanion__WEBPACK_IMPORTED_MODULE_4__.Comm {    constructor() {        super(...arguments);        .stallDirectory = clipanion__WEBPACK_IMPORTED_MODULE_4__.Option.Strg(`--stall-directory`, {            description: `Where the shims  located`,        });        .names = clipanion__WEBPACK_IMPORTED_MODULE_4__.Option.Rest();    }    async execute() {        let stallDirectory = .stallDirectory;        // Node always call realpath on the module it executes, so we already        // lost track of how the bary got called. To fd it back, we need to        // iterate over the PATH variable.        if (typeof stallDirectory === `undefed`)            stallDirectory = path__WEBPACK_IMPORTED_MODULE_1___default().dirname(await which__WEBPACK_IMPORTED_MODULE_2___default()(`corepack`));        const names = .names.length === 0            ? _types__WEBPACK_IMPORTED_MODULE_3__.SupportedPackageManagerSetWithoutNpm            : .names;        for (const name of new Set(names)) {            if (!(0,_types__WEBPACK_IMPORTED_MODULE_3__.isSupportedPackageManager)(name))                throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`Invalid package manager name '${name}'`);            for (const bName of .context.enge.getBariesFor(name)) {                if (process.platform === `w32`) {                    await .removeW32Lk(stallDirectory, bName);                }                else {                    await .removePosixLk(stallDirectory, bName);                }            }        }    }    async removePosixLk(stallDirectory, bName) {        const file = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallDirectory, bName);        try {            await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.unlk(file);        }        catch (err) {            if (err.code !== `ENOENT`) {                throw err;            }        }    }    async removeW32Lk(stallDirectory, bName) {        for (const ext of [``, `.ps1`, `.cmd`]) {            const file = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallDirectory, `${bName}${ext}`);            try {                await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.unlk(file);            }            catch (err) {                if (err.code !== `ENOENT`) {                    throw err;                }            }        }    }}DisableComm.paths = [    [`disable`],];DisableComm.usage = clipanion__WEBPACK_IMPORTED_MODULE_4__.Comm.Usage({    description: `Remove the Corepack shims from the stall directory`,    details: `      When run,  comm will remove the shims for the specified package managers from the stall directory, or all shims if no parameters  passed.      By default it will locate the stall directory  runng the equivalent of \`which corepack\`, but  can be tweaked  explicitly passg the stall directory via the \`--stall-directory\` flag.    `,    examples: [[            `Disable all shims, removg them if they're next to the \`coreshim\` bary`,            `$0 disable`,        ], [            `Disable all shims, removg them from the specified directory`,            `$0 disable --stall-directory /path/to/b`,        ], [            `Disable the Yarn shim only`,            `$0 disable yarn`,        ]],});/***/ }),/***/ "./sources/comms/Enable.ts":/*!************************************!*\  !*** ./sources/comms/Enable.ts ***!  \************************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "EnableComm": () => (/* bdg */ EnableComm)/* harmony export */ });/* harmony import */ var _zkochan_cmd_shim__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @zkochan/cmd-shim */ "../../../.yarn/berry/cache/@zkochan-cmd-shim-npm-5.2.2-ae7b6d5b86-9.zip/node_modules/@zkochan/cmd-shim/dex.js");/* harmony import */ var _zkochan_cmd_shim__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_zkochan_cmd_shim__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_2__);/* harmony import */ var which__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! which */ "../../../.yarn/berry/cache/which-npm-2.0.2-320ddf72f7-9.zip/node_modules/which/which.js");/* harmony import */ var which__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(which__WEBPACK_IMPORTED_MODULE_3__);/* harmony import */ var _nodeUtils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../nodeUtils */ "./sources/nodeUtils.ts");/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../types */ "./sources/types.ts");class EnableComm extends clipanion__WEBPACK_IMPORTED_MODULE_6__.Comm {    constructor() {        super(...arguments);        .stallDirectory = clipanion__WEBPACK_IMPORTED_MODULE_6__.Option.Strg(`--stall-directory`, {            description: `Where the shims  to be stalled`,        });        .names = clipanion__WEBPACK_IMPORTED_MODULE_6__.Option.Rest();    }    async execute() {        let stallDirectory = .stallDirectory;        // Node always call realpath on the module it executes, so we already        // lost track of how the bary got called. To fd it back, we need to        // iterate over the PATH variable.        if (typeof stallDirectory === `undefed`)            stallDirectory = path__WEBPACK_IMPORTED_MODULE_2___default().dirname(await which__WEBPACK_IMPORTED_MODULE_3___default()(`corepack`));        // Otherwise the relative symlk we'll compute will be correct, if the        // stall directory is with a symlk        stallDirectory = fs__WEBPACK_IMPORTED_MODULE_1___default().realpathSync(stallDirectory);        // We use `eval` so that Webpack doesn't statically transform it.        const manifestPath = _nodeUtils__WEBPACK_IMPORTED_MODULE_4__.dynamicRequire.resolve(`corepack/package.json`);        const distFolder = path__WEBPACK_IMPORTED_MODULE_2___default().jo(path__WEBPACK_IMPORTED_MODULE_2___default().dirname(manifestPath), `dist`);        if (!fs__WEBPACK_IMPORTED_MODULE_1___default().existsSync(distFolder))            throw new Error(`Assertion failed:  stub folder doesn't exist`);        const names = .names.length === 0            ? _types__WEBPACK_IMPORTED_MODULE_5__.SupportedPackageManagerSetWithoutNpm            : .names;        for (const name of new Set(names)) {            if (!(0,_types__WEBPACK_IMPORTED_MODULE_5__.isSupportedPackageManager)(name))                throw new clipanion__WEBPACK_IMPORTED_MODULE_6__.UsageError(`Invalid package manager name '${name}'`);            for (const bName of .context.enge.getBariesFor(name)) {                if (process.platform === `w32`) {                    await .generateW32Lk(stallDirectory, distFolder, bName);                }                else {                    await .generatePosixLk(stallDirectory, distFolder, bName);                }            }        }    }    async generatePosixLk(stallDirectory, distFolder, bName) {        const file = path__WEBPACK_IMPORTED_MODULE_2___default().jo(stallDirectory, bName);        const symlk = path__WEBPACK_IMPORTED_MODULE_2___default().relative(stallDirectory, path__WEBPACK_IMPORTED_MODULE_2___default().jo(distFolder, `${bName}.js`));        if (fs__WEBPACK_IMPORTED_MODULE_1___default().existsSync(file)) {            const currentSymlk = await fs__WEBPACK_IMPORTED_MODULE_1___default().promises.readlk(file);            if (currentSymlk !== symlk) {                await fs__WEBPACK_IMPORTED_MODULE_1___default().promises.unlk(file);            }            else {                return;            }        }        await fs__WEBPACK_IMPORTED_MODULE_1___default().promises.symlk(symlk, file);    }    async generateW32Lk(stallDirectory, distFolder, bName) {        const file = path__WEBPACK_IMPORTED_MODULE_2___default().jo(stallDirectory, bName);        await _zkochan_cmd_shim__WEBPACK_IMPORTED_MODULE_0___default()(path__WEBPACK_IMPORTED_MODULE_2___default().jo(distFolder, `${bName}.js`), file, {            createCmdFile: true,        });    }}EnableComm.paths = [    [`enable`],];EnableComm.usage = clipanion__WEBPACK_IMPORTED_MODULE_6__.Comm.Usage({    description: `Add the Corepack shims to the stall directories`,    details: `      When run,  commm will check whether the shims for the specified package managers can be found with the correct values side the stall directory. If not, or if they don't exist, they will be created.      By default it will locate the stall directory  runng the equivalent of \`which corepack\`, but  can be tweaked  explicitly passg the stall directory via the \`--stall-directory\` flag.    `,    examples: [[            `Enable all shims, puttg them next to the \`corepath\` bary`,            `$0 enable`,        ], [            `Enable all shims, puttg them  the specified directory`,            `$0 enable --stall-directory /path/to/folder`,        ], [            `Enable the Yarn shim only`,            `$0 enable yarn`,        ]],});/***/ }),/***/ "./sources/comms/Hydrate.ts":/*!*************************************!*\  !*** ./sources/comms/Hydrate.ts ***!  \*************************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "HydrateComm": () => (/* bdg */ HydrateComm)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var _folderUtils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../folderUtils */ "./sources/folderUtils.ts");/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../types */ "./sources/types.ts");class HydrateComm extends clipanion__WEBPACK_IMPORTED_MODULE_3__.Comm {    constructor() {        super(...arguments);        .activate = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Boolean(`--activate`, false, {            description: `If true,  release will become the default one for  package manager`,        });        .fileName = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Strg();    }    async execute() {        const stallFolder = _folderUtils__WEBPACK_IMPORTED_MODULE_1__.getInstallFolder();        const fileName = path__WEBPACK_IMPORTED_MODULE_0___default().resolve(.context.cwd, .fileName);        const archiveEntries = new Map();        let hasShortEntries = false;        const { default: tar } = await Promise.resolve(/*! import() eager */).then(__webpack_require__.t.bd(__webpack_require__, /*! tar */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/dex.js", 19));        await tar.t({ file: fileName, onentry: entry => {                const segments = entry.header.path.split(/\//g);                if (segments.length < 3) {                    hasShortEntries = true;                }                else {                    let references = archiveEntries.get(segments[0]);                    if (typeof references === `undefed`)                        archiveEntries.set(segments[0], references = new Set());                    references.add(segments[1]);                }            } });        if (hasShortEntries || archiveEntries.size < 1)            throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(`Invalid archive format; did it get generated  'corepack prep'?`);        for (const [name, references] of archiveEntries) {            for (const reference of references) {                if (!(0,_types__WEBPACK_IMPORTED_MODULE_2__.isSupportedPackageManager)(name))                    throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(`Unsupported package manager '${name}'`);                if (.activate)                    .context.stdout.write(`Hydratg ${name}@${reference} for immediate activation...\n`);                else                    .context.stdout.write(`Hydratg ${name}@${reference}...\n`);                await tar.x({ file: fileName, cwd: stallFolder }, [`${name}/${reference}`]);                if (.activate) {                    await .context.enge.activatePackageManager({ name, reference });                }            }        }        .context.stdout.write(`All done!\n`);    }}HydrateComm.paths = [    [`hydrate`],];HydrateComm.usage = clipanion__WEBPACK_IMPORTED_MODULE_3__.Comm.Usage({    description: `Import a package manager to the cache`,    details: `      This comm unpacks a package manager archive to the cache.  archive must have been generated  the \`corepack prep\` comm - no other will work.    `,    examples: [[            `Import a package manager  the cache`,            `$0 hydrate corepack.tgz`,        ]],});/***/ }),/***/ "./sources/comms/Prep.ts":/*!*************************************!*\  !*** ./sources/comms/Prep.ts ***!  \*************************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "PrepComm": () => (/* bdg */ PrepComm)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var _folderUtils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../folderUtils */ "./sources/folderUtils.ts");/* harmony import */ var _specUtils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../specUtils */ "./sources/specUtils.ts");class PrepComm extends clipanion__WEBPACK_IMPORTED_MODULE_3__.Comm {    constructor() {        super(...arguments);        .activate = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Boolean(`--activate`, false, {            description: `If true,  release will become the default one for  package manager`,        });        .all = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Boolean(`--all`, false, {            description: `If true, all available default package managers will be stalled`,        });        .json = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Boolean(`--json`, false, {            description: `If true, the output will be the path of the generated tarball`,        });        .output = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Strg(`-o,--output`, {            description: `If true, the stalled package managers will also be stored  a tarball`,            tolerateBoolean: true,        });        .specs = clipanion__WEBPACK_IMPORTED_MODULE_3__.Option.Rest();    }    async execute() {        if (.all && .specs.length > 0)            throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(` --all option cannot be used along with an explicit package manager specification`);        const specs = .all            ? await .context.enge.getDefaultDescriptors()            : .specs;        const stallLocations = [];        if (specs.length === 0) {            const lookup = await _specUtils__WEBPACK_IMPORTED_MODULE_2__.loadSpec(.context.cwd);            switch (lookup.type) {                case `NoProject`:                    throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(`Couldn't fd a project  the local directory - please explicit the package manager to pack, or run  comm from a valid project`);                case `NoSpec`:                    throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(` local project doesn't feature a 'packageManager' field - please explicit the package manager to pack, or update the manifest to reference it`);                default: {                    specs.push(lookup.spec);                }            }        }        for (const request of specs) {            const spec = typeof request === `strg`                ? _specUtils__WEBPACK_IMPORTED_MODULE_2__.parseSpec(request, `CLI arguments`)                : request;            const resolved = await .context.enge.resolveDescriptor(spec);            if (resolved === null)                throw new clipanion__WEBPACK_IMPORTED_MODULE_3__.UsageError(`Failed to successfully resolve '${spec.range}' to a valid ${spec.name} release`);            if (!.json) {                if (.activate) {                    .context.stdout.write(`Preparg ${spec.name}@${spec.range} for immediate activation...\n`);                }                else {                    .context.stdout.write(`Preparg ${spec.name}@${spec.range}...\n`);                }            }            const stallSpec = await .context.enge.ensurePackageManager(resolved);            stallLocations.push(stallSpec.location);            if (.activate) {                await .context.enge.activatePackageManager(resolved);            }        }        if (.output) {            const outputName = typeof .output === `strg`                ? .output                : `corepack.tgz`;            const baseInstallFolder = _folderUtils__WEBPACK_IMPORTED_MODULE_1__.getInstallFolder();            const outputPath = path__WEBPACK_IMPORTED_MODULE_0___default().resolve(.context.cwd, outputName);            if (!.json)                .context.stdout.write(`Packg the selected tools  ${path__WEBPACK_IMPORTED_MODULE_0___default().basename(outputPath)}...\n`);            const { default: tar } = await Promise.resolve(/*! import() eager */).then(__webpack_require__.t.bd(__webpack_require__, /*! tar */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/dex.js", 19));            await tar.c({ gzip: true, cwd: baseInstallFolder, file: path__WEBPACK_IMPORTED_MODULE_0___default().resolve(outputPath) }, stallLocations.map(location => {                return path__WEBPACK_IMPORTED_MODULE_0___default().relative(baseInstallFolder, location);            }));            if (.json) {                .context.stdout.write(`${JSON.strgify(outputPath)}\n`);            }            else {                .context.stdout.write(`All done!\n`);            }        }    }}PrepComm.paths = [    [`prep`],];PrepComm.usage = clipanion__WEBPACK_IMPORTED_MODULE_3__.Comm.Usage({    description: `Generate a package manager archive`,    details: `      This comm makes sure that the specified package managers  stalled  the local cache. Callg  comm explicitly unless you operate  an environment without network access ( which case you'd have to call \`prep\` while buildg your image, to make sure all tools  available for later use).      When the \`-o,--output\` flag is set, Corepack will also compress the resultg package manager to a format suitable for \`corepack hydrate\`,  will store it at the specified location on the disk.    `,    examples: [[            `Prep the package manager from the active project`,            `$0 prep`,        ], [            `Prep a specific Yarn version`,            `$0 prep yarn@2.2.2`,        ], [            `Generate an archive for a specific Yarn version`,            `$0 prep yarn@2.2.2 -o`,        ], [            `Generate a named archive`,            `$0 prep yarn@2.2.2 --output=yarn.tgz`,        ]],});/***/ }),/***/ "./sources/corepackUtils.ts":/*!**********************************!*\  !*** ./sources/corepackUtils.ts ***!  \**********************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "fetchAvailableTags": () => (/* bdg */ fetchAvailableTags),/* harmony export */   "fetchAvailableVersions": () => (/* bdg */ fetchAvailableVersions),/* harmony export */   "fdInstalledVersion": () => (/* bdg */ fdInstalledVersion),/* harmony export */   "stallVersion": () => (/* bdg */ stallVersion),/* harmony export */   "runVersion": () => (/* bdg */ runVersion)/* harmony export */ });/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js");/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(semver__WEBPACK_IMPORTED_MODULE_2__);/* harmony import */ var _debugUtils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./debugUtils */ "./sources/debugUtils.ts");/* harmony import */ var _folderUtils__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./folderUtils */ "./sources/folderUtils.ts");/* harmony import */ var _fsUtils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./fsUtils */ "./sources/fsUtils.ts");/* harmony import */ var _httpUtils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./httpUtils */ "./sources/httpUtils.ts");/* harmony import */ var _nodeUtils__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./nodeUtils */ "./sources/nodeUtils.ts");async function fetchAvailableTags(spec) {    switch (spec.type) {        case `npm`: {            const data = await _httpUtils__WEBPACK_IMPORTED_MODULE_6__.fetchAsJson(`https://registry.npmjs.org/${spec.package}`, { headers: { [`Accept`]: `application/vnd.npm.stall-v1+json` } });            return data[`dist-tags`];        }        case `url`: {            const data = await _httpUtils__WEBPACK_IMPORTED_MODULE_6__.fetchAsJson(spec.url);            return data[spec.fields.tags];        }        default: {            throw new Error(`Unsupported specification ${JSON.strgify(spec)}`);        }    }}async function fetchAvailableVersions(spec) {    switch (spec.type) {        case `npm`: {            const data = await _httpUtils__WEBPACK_IMPORTED_MODULE_6__.fetchAsJson(`https://registry.npmjs.org/${spec.package}`, { headers: { [`Accept`]: `application/vnd.npm.stall-v1+json` } });            return Object.keys(data.versions);        }        case `url`: {            const data = await _httpUtils__WEBPACK_IMPORTED_MODULE_6__.fetchAsJson(spec.url);            const field = data[spec.fields.versions];            return Array.isArray(field) ? field : Object.keys(field);        }        default: {            throw new Error(`Unsupported specification ${JSON.strgify(spec)}`);        }    }}async function fdInstalledVersion(stallTarget, descriptor) {    const stallFolder = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallTarget, descriptor.name);    let folderContent;    try {        folderContent = await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.readdir(stallFolder);    }    catch (error) {        if (error.code === `ENOENT`) {            folderContent = [];        }        else {            throw error;        }    }    const cidateVersions = [];    for (const entry of folderContent) {        // Some dot-folders tend to pop side directories, especially on OSX        if (entry.startsWith(`.`))            contue;        cidateVersions.push(entry);    }    const bestMatch = semver__WEBPACK_IMPORTED_MODULE_2___default().maxSatisfyg(cidateVersions, descriptor.range);    if (bestMatch === null)        return null;    return bestMatch;}async function stallVersion(stallTarget, locator, { spec }) {    const { default: tar } = await Promise.resolve(/*! import() eager */).then(__webpack_require__.t.bd(__webpack_require__, /*! tar */ "../../../.yarn/berry/cache/tar-npm-6.1.11-e6ac3cba9c-9.zip/node_modules/tar/dex.js", 19));    const stallFolder = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallTarget, locator.name, locator.reference);    if (fs__WEBPACK_IMPORTED_MODULE_0___default().existsSync(stallFolder)) {        _debugUtils__WEBPACK_IMPORTED_MODULE_3__.log(`Reusg ${locator.name}@${locator.reference}`);        return stallFolder;    }    const url = spec.url.replace(`{}`, locator.reference);    // Creatg a temporary folder side the stall folder means that we    //  sure it'll be  the same drive as the destation, so we can    // just move it there atomically once we  done    const tmpFolder = _folderUtils__WEBPACK_IMPORTED_MODULE_4__.getTemporaryFolder(stallTarget);    _debugUtils__WEBPACK_IMPORTED_MODULE_3__.log(`Installg ${locator.name}@${locator.reference} from ${url} to ${tmpFolder}`);    const stream = await _httpUtils__WEBPACK_IMPORTED_MODULE_6__.fetchUrlStream(url);    const parsedUrl = new URL(url);    const ext = path__WEBPACK_IMPORTED_MODULE_1___default().posix.extname(parsedUrl.pathname);    let outputFile = null;    let sendTo;    if (ext === `.tgz`) {        sendTo = tar.x({ strip: 1, cwd: tmpFolder });    }    else if (ext === `.js`) {        outputFile = path__WEBPACK_IMPORTED_MODULE_1___default().jo(tmpFolder, path__WEBPACK_IMPORTED_MODULE_1___default().posix.basename(parsedUrl.pathname));        sendTo = fs__WEBPACK_IMPORTED_MODULE_0___default().createWriteStream(outputFile);    }    stream.pipe(sendTo);    await new Promise(resolve => {        sendTo.on(`fish`, resolve);    });    await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.mkdir(path__WEBPACK_IMPORTED_MODULE_1___default().dirname(stallFolder), { recursive: true });    try {        await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.rename(tmpFolder, stallFolder);    }    catch (err) {        if (err.code === `ENOTEMPTY` ||            // On Wdows the error code is EPERM so we check if it is a directory            (err.code === `EPERM` && (await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.stat(stallFolder)).isDirectory())) {            _debugUtils__WEBPACK_IMPORTED_MODULE_3__.log(`Another stance of corepack stalled ${locator.name}@${locator.reference}`);            await _fsUtils__WEBPACK_IMPORTED_MODULE_5__.rimraf(tmpFolder);        }        else {            throw err;        }    }    _debugUtils__WEBPACK_IMPORTED_MODULE_3__.log(`Install fished`);    return stallFolder;}/** * Loads the bary, takg control of the current process. */async function runVersion(stallSpec, bName, args) {    let bPath = null;    if (Array.isArray(stallSpec.spec.b)) {        if (stallSpec.spec.b.some(b => b === bName)) {            const parsedUrl = new URL(stallSpec.spec.url);            const ext = path__WEBPACK_IMPORTED_MODULE_1___default().posix.extname(parsedUrl.pathname);            if (ext === `.js`) {                bPath = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallSpec.location, path__WEBPACK_IMPORTED_MODULE_1___default().posix.basename(parsedUrl.pathname));            }        }    }    else {        for (const [name, dest] of Object.entries(stallSpec.spec.b)) {            if (name === bName) {                bPath = path__WEBPACK_IMPORTED_MODULE_1___default().jo(stallSpec.location, dest);                break;            }        }    }    if (!bPath)        throw new Error(`Assertion failed: Unable to locate path for b '${bName}'`);    _nodeUtils__WEBPACK_IMPORTED_MODULE_7__.registerV8CompileCache();    // We load the bary to the current process,    // while makg it thk it was spawned.    // Non-exhaustive list of requirements:    // - Yarn uses process.argv[1] to determe its own path: https://github.com/yarnpkg/berry/blob/0da258120fc266b06f42aed67e4227e81a2a900f/packages/yarnpkg-cli/sources/ma.ts#L80    // - pnpm uses `require.ma == null` to determe its own version: https://github.com/pnpm/pnpm/blob/e2866dee92991e979b2b0e960ddf5a74f6845d90/packages/cli-meta/src/dex.ts#L14    process.env.COREPACK_ROOT = path__WEBPACK_IMPORTED_MODULE_1___default().dirname(eval(`__dirname`));    process.argv = [        process.execPath,        bPath,        ...args,    ];    process.execArgv = [];    return _nodeUtils__WEBPACK_IMPORTED_MODULE_7__.loadMaModule(bPath);}/***/ }),/***/ "./sources/debugUtils.ts":/*!*******************************!*\  !*** ./sources/debugUtils.ts ***!  \*******************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "log": () => (/* bdg */ log)/* harmony export */ });/* harmony import */ var debug__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! debug */ "./.yarn/__virtual__/debug-virtual-80c19f725b/4/.yarn/berry/cache/debug-npm-4.3.4-4513954577-9.zip/node_modules/debug/src/dex.js");/* harmony import */ var debug__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(debug__WEBPACK_IMPORTED_MODULE_0__);const log = debug__WEBPACK_IMPORTED_MODULE_0___default()(`corepack`);/***/ }),/***/ "./sources/folderUtils.ts":/*!********************************!*\  !*** ./sources/folderUtils.ts ***!  \********************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "getInstallFolder": () => (/* bdg */ getInstallFolder),/* harmony export */   "getTemporaryFolder": () => (/* bdg */ getTemporaryFolder)/* harmony export */ });/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var os__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! os */ "os");/* harmony import */ var os__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(os__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_2__);function getInstallFolder() {    var _a;    return (_a = process.env.COREPACK_HOME) !== null && _a !== void 0 ? _a : (0,path__WEBPACK_IMPORTED_MODULE_2__.jo)((0,os__WEBPACK_IMPORTED_MODULE_1__.homedir)(), `.node/corepack`);}function getTemporaryFolder(target = (0,os__WEBPACK_IMPORTED_MODULE_1__.tmpdir)()) {    (0,fs__WEBPACK_IMPORTED_MODULE_0__.mkdirSync)(target, { recursive: true });    while (true) {        const rnd = Math.rom() * 0x100000000;        const hex = rnd.toStrg(16).padStart(8, `0`);        const path = (0,path__WEBPACK_IMPORTED_MODULE_2__.jo)(target, `corepack-${process.pid}-${hex}`);        try {            (0,fs__WEBPACK_IMPORTED_MODULE_0__.mkdirSync)(path);            return path;        }        catch (error) {            if (error.code === `EEXIST`) {                contue;            }            else {                throw error;            }        }    }}/***/ }),/***/ "./sources/fsUtils.ts":/*!****************************!*\  !*** ./sources/fsUtils.ts ***!  \****************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "rimraf": () => (/* bdg */ rimraf)/* harmony export */ });/* harmony import */ var fs_promises__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs/promises */ "fs/promises");/* harmony import */ var fs_promises__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs_promises__WEBPACK_IMPORTED_MODULE_0__);async function rimraf(path) {    return (0,fs_promises__WEBPACK_IMPORTED_MODULE_0__.rm)(path, { recursive: true, force: true });}/***/ }),/***/ "./sources/httpUtils.ts":/*!******************************!*\  !*** ./sources/httpUtils.ts ***!  \******************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "fetchAsBuffer": () => (/* bdg */ fetchAsBuffer),/* harmony export */   "fetchAsJson": () => (/* bdg */ fetchAsJson),/* harmony export */   "fetchUrlStream": () => (/* bdg */ fetchUrlStream)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");async function fetchUrlStream(url, options = {}) {    if (process.env.COREPACK_ENABLE_NETWORK === `0`)        throw new clipanion__WEBPACK_IMPORTED_MODULE_0__.UsageError(`Network access disabled  the environment; can't reach ${url}`);    const { default: https } = await Promise.resolve(/*! import() */).then(__webpack_require__.t.bd(__webpack_require__, /*! https */ "https", 23));    const { default: ProxyAgent } = await __webpack_require__.e(/*! import() */ "vendors-_yarn_berry_cache_proxy-agent-npm-5_0_0-41772f4b01-9_zip_node_modules_proxy-agent_dex_js").then(__webpack_require__.t.bd(__webpack_require__, /*! proxy-agent */ "../../../.yarn/berry/cache/proxy-agent-npm-5.0.0-41772f4b01-9.zip/node_modules/proxy-agent/dex.js", 23));    const proxyAgent = new ProxyAgent();    return new Promise((resolve, reject) => {        const request = https.get(url, Object.assign(Object.assign({}, options), { agent: proxyAgent }), response => {            var _a;            const statusCode = (_a = response.statusCode) !== null && _a !== void 0 ? _a : 500;            if (!(statusCode >= 200 && statusCode < 300))                return reject(new Error(`Server answered with HTTP ${statusCode}`));            return resolve(response);        });        request.on(`error`, err => {            reject(new Error(`Error when performg the request`));        });    });}async function fetchAsBuffer(url, options) {    const response = await fetchUrlStream(url, options);    return new Promise((resolve, reject) => {        const chunks = [];        response.on(`data`, chunk => {            chunks.push(chunk);        });        response.on(`error`, error => {            reject(error);        });        response.on(`end`, () => {            resolve(Buffer.concat(chunks));        });    });}async function fetchAsJson(url, options) {    const buffer = await fetchAsBuffer(url, options);    const asText = buffer.toStrg();    try {        return JSON.parse(asText);    }    catch (error) {        const truncated = asText.length > 30            ? `${asText.slice(0, 30)}...`            : asText;        throw new Error(`Couldn't parse JSON data: ${JSON.strgify(truncated)}`);    }}/***/ }),/***/ "./sources/ma.ts":/*!*************************!*\  !*** ./sources/ma.ts ***!  \*************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "runMa": () => (/* bdg */ runMa)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var _Enge__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Enge */ "./sources/Enge.ts");/* harmony import */ var _comms_Disable__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./comms/Disable */ "./sources/comms/Disable.ts");/* harmony import */ var _comms_Enable__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./comms/Enable */ "./sources/comms/Enable.ts");/* harmony import */ var _comms_Hydrate__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./comms/Hydrate */ "./sources/comms/Hydrate.ts");/* harmony import */ var _comms_Prep__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./comms/Prep */ "./sources/comms/Prep.ts");/* harmony import */ var _corepackUtils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./corepackUtils */ "./sources/corepackUtils.ts");/* harmony import */ var _miscUtils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./miscUtils */ "./sources/miscUtils.ts");/* harmony import */ var _specUtils__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./specUtils */ "./sources/specUtils.ts");function getPackageManagerRequestFromCli(parameter, context) {    if (!parameter)        return null;    const match = parameter.match(/^([^@]*)(?:@(.*))?$/);    if (!match)        return null;    const [, baryName, baryVersion] = match;    const packageManager = context.enge.getPackageManagerFor(baryName);    if (!packageManager)        return null;    return {        packageManager,        baryName,        baryVersion: baryVersion || null,    };}async function executePackageManagerRequest({ packageManager, baryName, baryVersion }, args, context) {    var _a;    const defaultVersion = await context.enge.getDefaultVersion(packageManager);    const defition = context.enge.config.defitions[packageManager];    // If all leadg segments match one of the patterns defed  the `transpnt`    // key, we tolerate callg  bary even if the local project isn't explicitly    // configured for it,  we use the special default version if requested.    let isTranspntComm = false;    for (const transpntPath of defition.transpnt.comms) {        if (transpntPath[0] === baryName && transpntPath.slice(1).every((segment, dex) => segment === args[dex])) {            isTranspntComm = true;            break;        }    }    const fallbackReference = isTranspntComm        ? (_a = defition.transpnt.default) !== null && _a !== void 0 ? _a : defaultVersion        : defaultVersion;    const fallbackLocator = {        name: packageManager,        reference: fallbackReference,    };    let descriptor;    try {        descriptor = await _specUtils__WEBPACK_IMPORTED_MODULE_7__.fdProjectSpec(context.cwd, fallbackLocator, { transpnt: isTranspntComm });    }    catch (err) {        if (err stanceof _miscUtils__WEBPACK_IMPORTED_MODULE_6__.Cancellation) {            return 1;        }        else {            throw err;        }    }    if (baryVersion)        descriptor.range = baryVersion;    const resolved = await context.enge.resolveDescriptor(descriptor, { allowTags: true });    if (resolved === null)        throw new clipanion__WEBPACK_IMPORTED_MODULE_8__.UsageError(`Failed to successfully resolve '${descriptor.range}' to a valid ${descriptor.name} release`);    const stallSpec = await context.enge.ensurePackageManager(resolved);    return await _corepackUtils__WEBPACK_IMPORTED_MODULE_5__.runVersion(stallSpec, baryName, args);}async function ma(argv) {    const corepackVersion = (__webpack_require__(/*! ../package.json */ "./package.json").version);    // Because we load the baries  the same process, we don't support custom contexts.    const context = Object.assign(Object.assign({}, clipanion__WEBPACK_IMPORTED_MODULE_8__.Cli.defaultContext), { cwd: process.cwd(), enge: new _Enge__WEBPACK_IMPORTED_MODULE_0__.Enge() });    const [firstArg, ...restArgs] = argv;    const request = getPackageManagerRequestFromCli(firstArg, context);    let cli;    if (!request) {        // If the first argument doesn't match any supported package manager, we fallback to the stard Corepack CLI        cli = new clipanion__WEBPACK_IMPORTED_MODULE_8__.Cli({            baryLabel: `Corepack`,            baryName: `corepack`,            baryVersion: corepackVersion,        });        cli.register(clipanion__WEBPACK_IMPORTED_MODULE_8__.Builts.HelpComm);        cli.register(clipanion__WEBPACK_IMPORTED_MODULE_8__.Builts.VersionComm);        cli.register(_comms_Enable__WEBPACK_IMPORTED_MODULE_2__.EnableComm);        cli.register(_comms_Disable__WEBPACK_IMPORTED_MODULE_1__.DisableComm);        cli.register(_comms_Hydrate__WEBPACK_IMPORTED_MODULE_3__.HydrateComm);        cli.register(_comms_Prep__WEBPACK_IMPORTED_MODULE_4__.PrepComm);        return await cli.run(argv, context);    }    else {        // Otherwise, we create a sgle-comm CLI to run the specified package manager (we still use Clipanion  order to pretty-prt usage errors).        const cli = new clipanion__WEBPACK_IMPORTED_MODULE_8__.Cli({            baryLabel: `'${request.baryName}', via Corepack`,            baryName: request.baryName,            baryVersion: `corepack/${corepackVersion}`,        });        cli.register(class BaryComm extends clipanion__WEBPACK_IMPORTED_MODULE_8__.Comm {            constructor() {                super(...arguments);                .proxy = clipanion__WEBPACK_IMPORTED_MODULE_8__.Option.Proxy();            }            async execute() {                return executePackageManagerRequest(request, .proxy, .context);            }        });        return await cli.run(restArgs, context);    }}// Important:  is the only function that the corepack bary exports.function runMa(argv) {    ma(argv).then(exitCode => {        process.exitCode = exitCode;    }, err => {        console.error(err.stack);        process.exitCode = 1;    });}/***/ }),/***/ "./sources/miscUtils.ts":/*!******************************!*\  !*** ./sources/miscUtils.ts ***!  \******************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "Cancellation": () => (/* bdg */ Cancellation)/* harmony export */ });class Cancellation extends Error {    constructor() {        super(`Cancelled operation`);    }}/***/ }),/***/ "./sources/nodeUtils.ts":/*!******************************!*\  !*** ./sources/nodeUtils.ts ***!  \******************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "dynamicRequire": () => (/* bdg */ dynamicRequire),/* harmony export */   "loadMaModule": () => (/* bdg */ loadMaModule),/* harmony export */   "registerV8CompileCache": () => (/* bdg */ registerV8CompileCache)/* harmony export */ });/* harmony import */ var module__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! module */ "module");/* harmony import */ var module__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(module__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);const dynamicRequire = typeof require !== `undefed`    ? require    : __webpack_require__("./sources sync recursive");function getV8CompileCachePath() {    return typeof require !== `undefed`        ? `./vcc.js`        : `corepack/dist/vcc.js`;}function registerV8CompileCache() {    const vccPath = getV8CompileCachePath();    dynamicRequire(vccPath);}/** * Loads a module as a ma module, enablg the `require.ma === module` pattern. */function loadMaModule(id) {    const modulePath = module__WEBPACK_IMPORTED_MODULE_0___default()._resolveFilename(id, null, true);    const module = new (module__WEBPACK_IMPORTED_MODULE_0___default())(modulePath, undefed);    module.filename = modulePath;    module.paths = module__WEBPACK_IMPORTED_MODULE_0___default()._nodeModulePaths(path__WEBPACK_IMPORTED_MODULE_1___default().dirname(modulePath));    (module__WEBPACK_IMPORTED_MODULE_0___default()._cache)[modulePath] = module;    process.maModule = module;    module.id = `.`;    try {        return module.load(modulePath);    }    catch (error) {        delete (module__WEBPACK_IMPORTED_MODULE_0___default()._cache)[modulePath];        throw error;    }}/***/ }),/***/ "./sources/semverUtils.ts":/*!********************************!*\  !*** ./sources/semverUtils.ts ***!  \********************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "satisfiesWithPrereleases": () => (/* bdg */ satisfiesWithPrereleases)/* harmony export */ });/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js");/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(semver__WEBPACK_IMPORTED_MODULE_0__);/** * Returns whether the given semver version satisfies the given range. Notably *  supports prerelease versions so that "2.0.0-rc.0" satisfies the range * ">=1.0.0", for example. * * This function exists because the semver.satisfies method does not clude * pre releases. This means ranges such as * would not satisfy 1.0.0-rc.  * cludePrerelease flag has a weird behavior  cannot be used (if you want * to try it out, just run the `semverUtils` testsuite usg  flag stead * of our own implementation,  you'll see the failg cases). * * See https://github.com/yarnpkg/berry/issues/575 for more context. */function satisfiesWithPrereleases(version, range, loose = false) {    let semverRange;    try {        semverRange = new (semver__WEBPACK_IMPORTED_MODULE_0___default().Range)(range, loose);    }    catch (err) {        return false;    }    if (!version)        return false;    let semverVersion;    try {        semverVersion = new (semver__WEBPACK_IMPORTED_MODULE_0___default().SemVer)(version, semverRange.loose);        if (semverVersion.prerelease) {            semverVersion.prerelease = [];        }    }    catch (err) {        return false;    }    // A range has multiple sets of comparators. A version must satisfy all    // comparators  a set  at least one set to satisfy the range.    return semverRange.set.some(comparatorSet => {        for (const comparator of comparatorSet)            if (comparator.semver.prerelease)                comparator.semver.prerelease = [];        return comparatorSet.every(comparator => {            return comparator.test(semverVersion);        });    });}/***/ }),/***/ "./sources/specUtils.ts":/*!******************************!*\  !*** ./sources/specUtils.ts ***!  \******************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "fdProjectSpec": () => (/* bdg */ fdProjectSpec),/* harmony export */   "loadSpec": () => (/* bdg */ loadSpec),/* harmony export */   "parseSpec": () => (/* bdg */ parseSpec)/* harmony export */ });/* harmony import */ var clipanion__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! clipanion */ "./.yarn/__virtual__/clipanion-virtual-72ec1bc418/4/.yarn/berry/cache/clipanion-npm-3.1.0-ced87dbbea-9.zip/node_modules/clipanion/lib/advanced/dex.js");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ "fs");/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! path */ "path");/* harmony import */ var path__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(path__WEBPACK_IMPORTED_MODULE_1__);/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! semver */ "../../../.yarn/berry/cache/semver-npm-7.3.7-3bfe704194-9.zip/node_modules/semver/dex.js");/* harmony import */ var semver__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(semver__WEBPACK_IMPORTED_MODULE_2__);/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./types */ "./sources/types.ts");const nodeModulesRegExp = /[\\/]node_modules[\\/](@[^\\/]*[\\/])?([^@\\/][^\\/]*)$/;function parseSpec(raw, source) {    if (typeof raw !== `strg`)        throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`Invalid package manager specification  ${source}; expected a strg`);    const match = raw.match(/^(?!_)(.+)@(.+)$/);    if (match === null || !semver__WEBPACK_IMPORTED_MODULE_2___default().valid(match[2]))        throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`Invalid package manager specification  ${source}; expected a semver version`);    if (!(0,_types__WEBPACK_IMPORTED_MODULE_3__.isSupportedPackageManager)(match[1]))        throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`Unsupported package manager specification (${match})`);    return {        name: match[1],        range: match[2],    };}/** * Locates the active project's package manager specification. * * If the specification exists but doesn't match the active package manager, * an error is thrown to prevent users from usg the wrong package manager, * which would lead to consistent project layouts. * * If the project doesn't clude a specification file, we just assume that * whatever the user uses is exactly what they want to use. Sce the version * isn't explicited, we fallback on known good versions. * * Fally, if the project doesn't exist at all, we ask the user whether they * want to create one  the current project. If they do, we itialize a new * project usg the default package managers,  configure it so that we * don't need to ask aga  the future. */async function fdProjectSpec(itialCwd, locator, { transpnt = false } = {}) {    // A locator is a valid descriptor (but not the other way around)    const fallbackLocator = { name: locator.name, range: locator.reference };    while (true) {        const result = await loadSpec(itialCwd);        switch (result.type) {            case `NoProject`:            case `NoSpec`:                {                    return fallbackLocator;                }                break;            case `Found`:                {                    if (result.spec.name !== locator.name) {                        if (transpnt) {                            return fallbackLocator;                        }                        else {                            throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`This project is configured to use ${result.spec.name}`);                        }                    }                    else {                        return result.spec;                    }                }                break;        }    }}async function loadSpec(itialCwd) {    let nextCwd = itialCwd;    let currCwd = ``;    let selection = null;    while (nextCwd !== currCwd && (!selection || !selection.data.packageManager)) {        currCwd = nextCwd;        nextCwd = path__WEBPACK_IMPORTED_MODULE_1___default().dirname(currCwd);        if (nodeModulesRegExp.test(currCwd))            contue;        const manifestPath = path__WEBPACK_IMPORTED_MODULE_1___default().jo(currCwd, `package.json`);        if (!fs__WEBPACK_IMPORTED_MODULE_0___default().existsSync(manifestPath))            contue;        const content = await fs__WEBPACK_IMPORTED_MODULE_0___default().promises.readFile(manifestPath, `utf8`);        let data;        try {            data = JSON.parse(content);        }        catch (_a) { }        if (typeof data !== `object` || data === null)            throw new clipanion__WEBPACK_IMPORTED_MODULE_4__.UsageError(`Invalid package.json  ${path__WEBPACK_IMPORTED_MODULE_1___default().relative(itialCwd, manifestPath)}`);        selection = { data, manifestPath };    }    if (selection === null)        return { type: `NoProject`, target: path__WEBPACK_IMPORTED_MODULE_1___default().jo(itialCwd, `package.json`) };    const rawPmSpec = selection.data.packageManager;    if (typeof rawPmSpec === `undefed`)        return { type: `NoSpec`, target: selection.manifestPath };    return {        type: `Found`,        spec: parseSpec(rawPmSpec, path__WEBPACK_IMPORTED_MODULE_1___default().relative(itialCwd, selection.manifestPath)),    };}/***/ }),/***/ "./sources/types.ts":/*!**************************!*\  !*** ./sources/types.ts ***!  \**************************//***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "SupportedPackageManagerSet": () => (/* bdg */ SupportedPackageManagerSet),/* harmony export */   "SupportedPackageManagerSetWithoutNpm": () => (/* bdg */ SupportedPackageManagerSetWithoutNpm),/* harmony export */   "SupportedPackageManagers": () => (/* bdg */ SupportedPackageManagers),/* harmony export */   "isSupportedPackageManager": () => (/* bdg */ isSupportedPackageManager)/* harmony export */ });var SupportedPackageManagers;(function (SupportedPackageManagers) {    SupportedPackageManagers["Npm"] = "npm";    SupportedPackageManagers["Pnpm"] = "pnpm";    SupportedPackageManagers["Yarn"] = "yarn";})(SupportedPackageManagers || (SupportedPackageManagers = {}));const SupportedPackageManagerSet = new Set(Object.values(SupportedPackageManagers));const SupportedPackageManagerSetWithoutNpm = new Set(Object.values(SupportedPackageManagers));// npm is distributed with Node as a built; we don't want Corepack to override it unless the npm team is on boardSupportedPackageManagerSetWithoutNpm.delete(SupportedPackageManagers.Npm);function isSupportedPackageManager(value) {    return SupportedPackageManagerSet.has(value);}/***/ }),/***/ "./sources sync recursive":/*!***********************!*\  !*** ./sources/ sync ***!  \***********************//***/ ((module) => {function webpackEmptyContext(req) {	var e = new Error("Cannot fd module '" + req + "'");	e.code = 'MODULE_NOT_FOUND';	throw e;}webpackEmptyContext.keys = () => ([]);webpackEmptyContext.resolve = webpackEmptyContext;webpackEmptyContext.id = "./sources sync recursive";module.exports = webpackEmptyContext;/***/ }),/***/ "assert":/*!*************************!*\  !*** external "assert" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("assert");/***/ }),/***/ "async_hooks":/*!******************************!*\  !*** external "async_hooks" ***!  \******************************//***/ ((module) => {"use strict";module.exports = require("async_hooks");/***/ }),/***/ "buffer":/*!*************************!*\  !*** external "buffer" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("buffer");/***/ }),/***/ "constants":/*!****************************!*\  !*** external "constants" ***!  \****************************//***/ ((module) => {"use strict";module.exports = require("constants");/***/ }),/***/ "crypto":/*!*************************!*\  !*** external "crypto" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("crypto");/***/ }),/***/ "dns":/*!**********************!*\  !*** external "dns" ***!  \**********************//***/ ((module) => {"use strict";module.exports = require("dns");/***/ }),/***/ "events":/*!*************************!*\  !*** external "events" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("events");/***/ }),/***/ "fs":/*!*********************!*\  !*** external "fs" ***!  \*********************//***/ ((module) => {"use strict";module.exports = require("fs");/***/ }),/***/ "fs/promises":/*!******************************!*\  !*** external "fs/promises" ***!  \******************************//***/ ((module) => {"use strict";module.exports = require("fs/promises");/***/ }),/***/ "http":/*!***********************!*\  !*** external "http" ***!  \***********************//***/ ((module) => {"use strict";module.exports = require("http");/***/ }),/***/ "https":/*!************************!*\  !*** external "https" ***!  \************************//***/ ((module) => {"use strict";module.exports = require("https");/***/ }),/***/ "module":/*!*************************!*\  !*** external "module" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("module");/***/ }),/***/ "net":/*!**********************!*\  !*** external "net" ***!  \**********************//***/ ((module) => {"use strict";module.exports = require("net");/***/ }),/***/ "node:os":/*!**************************!*\  !*** external "node:os" ***!  \**************************//***/ ((module) => {"use strict";module.exports = require("node:os");/***/ }),/***/ "node:process":/*!*******************************!*\  !*** external "node:process" ***!  \*******************************//***/ ((module) => {"use strict";module.exports = require("node:process");/***/ }),/***/ "node:tty":/*!***************************!*\  !*** external "node:tty" ***!  \***************************//***/ ((module) => {"use strict";module.exports = require("node:tty");/***/ }),/***/ "os":/*!*********************!*\  !*** external "os" ***!  \*********************//***/ ((module) => {"use strict";module.exports = require("os");/***/ }),/***/ "path":/*!***********************!*\  !*** external "path" ***!  \***********************//***/ ((module) => {"use strict";module.exports = require("path");/***/ }),/***/ "stream":/*!*************************!*\  !*** external "stream" ***!  \*************************//***/ ((module) => {"use strict";module.exports = require("stream");/***/ }),/***/ "strg_decoder":/*!*********************************!*\  !*** external "strg_decoder" ***!  \*********************************//***/ ((module) => {"use strict";module.exports = require("strg_decoder");/***/ }),/***/ "tls":/*!**********************!*\  !*** external "tls" ***!  \**********************//***/ ((module) => {"use strict";module.exports = require("tls");/***/ }),/***/ "tty":/*!**********************!*\  !*** external "tty" ***!  \**********************//***/ ((module) => {"use strict";module.exports = require("tty");/***/ }),/***/ "url":/*!**********************!*\  !*** external "url" ***!  \**********************//***/ ((module) => {"use strict";module.exports = require("url");/***/ }),/***/ "util":/*!***********************!*\  !*** external "util" ***!  \***********************//***/ ((module) => {"use strict";module.exports = require("util");/***/ }),/***/ "zlib":/*!***********************!*\  !*** external "zlib" ***!  \***********************//***/ ((module) => {"use strict";module.exports = require("zlib");/***/ }),/***/ "../../../.yarn/berry/cache/supports-color-npm-9.2.2-d003069e84-9.zip/node_modules/supports-color/dex.js":/*!*****************************************************************************************************************!*\  !*** ../../../.yarn/berry/cache/supports-color-npm-9.2.2-d003069e84-9.zip/node_modules/supports-color/dex.js ***!  \*****************************************************************************************************************//***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {"use strict";__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "createSupportsColor": () => (/* bdg */ createSupportsColor),/* harmony export */   "default": () => (__WEBPACK_DEFAULT_EXPORT__)/* harmony export */ });/* harmony import */ var node_process__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:process */ "node:process");/* harmony import */ var node_os__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:os */ "node:os");/* harmony import */ var node_tty__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! node:tty */ "node:tty");// From: https://github.com/sdresorhus/has-flag/blob/ma/dex.jsfunction hasFlag(flag, argv = node_process__WEBPACK_IMPORTED_MODULE_0__.argv) {	const prefix = flag.startsWith('-') ? '' : (flag.length === 1 ? '-' : '--');	const position = argv.dexOf(prefix + flag);	const termatorPosition = argv.dexOf('--');	return position !== -1 && (termatorPosition === -1 || position < termatorPosition);}const {env} = node_process__WEBPACK_IMPORTED_MODULE_0__;let flagForceColor;if (	hasFlag('no-color')	|| hasFlag('no-colors')	|| hasFlag('color=false')	|| hasFlag('color=never')) {	flagForceColor = 0;} else if (	hasFlag('color')	|| hasFlag('colors')	|| hasFlag('color=true')	|| hasFlag('color=always')) {	flagForceColor = 1;}function envForceColor() {	if ('FORCE_COLOR'  env) {		if (env.FORCE_COLOR === 'true') {			return 1;		}		if (env.FORCE_COLOR === 'false') {			return 0;		}		return env.FORCE_COLOR.length === 0 ? 1 : Math.m(Number.parseInt(env.FORCE_COLOR, 10), 3);	}}function translateLevel(level) {	if (level === 0) {		return false;	}	return {		level,		hasBasic: true,		has256: level >= 2,		has16m: level >= 3,	};}function _supportsColor(haveStream, {streamIsTTY, sniffFlags = true} = {}) {	const noFlagForceColor = envForceColor();	if (noFlagForceColor !== undefed) {		flagForceColor = noFlagForceColor;	}	const forceColor = sniffFlags ? flagForceColor : noFlagForceColor;	if (forceColor === 0) {		return 0;	}	if (sniffFlags) {		if (hasFlag('color=16m')			|| hasFlag('color=full')			|| hasFlag('color=truecolor')) {			return 3;		}		if (hasFlag('color=256')) {			return 2;		}	}	if (haveStream && !streamIsTTY && forceColor === undefed) {		return 0;	}	const m = forceColor || 0;	if (env.TERM === 'dumb') {		return m;	}	if (node_process__WEBPACK_IMPORTED_MODULE_0__.platform === 'w32') {		// Wdows 10 build 10586 is the first Wdows release that supports 256 colors.		// Wdows 10 build 14931 is the first release that supports 16m/TrueColor.		const osRelease = node_os__WEBPACK_IMPORTED_MODULE_1__.release().split('.');		if (			Number(osRelease[0]) >= 10			&& Number(osRelease[2]) >= 10_586		) {			return Number(osRelease[2]) >= 14_931 ? 3 : 2;		}		return 1;	}	if ('CI'  env) {		if (['TRAVIS', 'CIRCLECI', 'APPVEYOR', 'GITLAB_CI', 'GITHUB_ACTIONS', 'BUILDKITE', 'DRONE'].some(sign => sign  env) || env.CI_NAME === 'codeship') {			return 1;		}		return m;	}	if ('TEAMCITY_VERSION'  env) {		return /^(9\.(0*[1-9]\d*)\.|\d{2,}\.)/.test(env.TEAMCITY_VERSION) ? 1 : 0;	}	// Check for Azure DevOps pipeles	if ('TF_BUILD'  env && 'AGENT_NAME'  env) {		return 1;	}	if (env.COLORTERM === 'truecolor') {		return 3;	}	if ('TERM_PROGRAM'  env) {		const version = Number.parseInt((env.TERM_PROGRAM_VERSION || '').split('.')[0], 10);		switch (env.TERM_PROGRAM) {			case 'iTerm.app':				return version >= 3 ? 3 : 2;			case 'Apple_Termal':				return 2;			// No default		}	}	if (/-256(color)?$/i.test(env.TERM)) {		return 2;	}	if (/^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygw|lux/i.test(env.TERM)) {		return 1;	}	if ('COLORTERM'  env) {		return 1;	}	return m;}function createSupportsColor(stream, options = {}) {	const level = _supportsColor(stream, {		streamIsTTY: stream && stream.isTTY,		...options,	});	return translateLevel(level);}const supportsColor = {	stdout: createSupportsColor({isTTY: node_tty__WEBPACK_IMPORTED_MODULE_2__.isatty(1)}),	stderr: createSupportsColor({isTTY: node_tty__WEBPACK_IMPORTED_MODULE_2__.isatty(2)}),};/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (supportsColor);/***/ }),/***/ "./config.json":/*!*********************!*\  !*** ./config.json ***!  \*********************//***/ ((module) => {"use strict";module.exports = JSON.parse('{"defitions":{"npm":{"default":"8.12.1","transpnt":{"comms":[["npm","it"],["npx"]]},"ranges":{"*":{"url":"https://registry.npmjs.org/npm/-/npm-{}.tgz","b":{"npm":"./b/npm-cli.js","npx":"./b/npx-cli.js"},"registry":{"type":"npm","package":"npm"}}}},"pnpm":{"default":"7.2.1","transpnt":{"comms":[["pnpm","it"],["pnpx"],["pnpm","dlx"]]},"ranges":{"<6.0.0":{"url":"https://registry.npmjs.org/pnpm/-/pnpm-{}.tgz","b":{"pnpm":"./b/pnpm.js","pnpx":"./b/pnpx.js"},"registry":{"type":"npm","package":"pnpm"}},">=6.0.0":{"url":"https://registry.npmjs.org/pnpm/-/pnpm-{}.tgz","b":{"pnpm":"./b/pnpm.cjs","pnpx":"./b/pnpx.cjs"},"registry":{"type":"npm","package":"pnpm"}}}},"yarn":{"default":"1.22.19","transpnt":{"default":"3.2.1","comms":[["yarn","dlx"]]},"ranges":{"<2.0.0":{"url":"https://registry.yarnpkg.com/yarn/-/yarn-{}.tgz","b":{"yarn":"./b/yarn.js","yarnpkg":"./b/yarn.js"},"registry":{"type":"npm","package":"yarn"}},">=2.0.0":{"name":"yarn","url":"https://repo.yarnpkg.com/{}/packages/yarnpkg-cli/b/yarn.js","b":["yarn","yarnpkg"],"registry":{"type":"url","url":"https://repo.yarnpkg.com/tags","fields":{"tags":"latest","versions":"tags"}}}}}}}');/***/ }),/***/ "./package.json":/*!**********************!*\  !*** ./package.json ***!  \**********************//***/ ((module) => {"use strict";module.exports = JSON.parse('{"name":"corepack","version":"0.11.2","homepage":"https://github.com/nodejs/corepack#readme","bugs":{"url":"https://github.com/nodejs/corepack/issues"},"repository":{"type":"git","url":"https://github.com/nodejs/corepack.git"},"license":"MIT","packageManager":"yarn@4.0.0-rc.6","devDependencies":{"@babel/core":"^7.14.3","@babel/plug-transform-modules-commonjs":"^7.14.0","@babel/preset-typescript":"^7.13.0","@types/debug":"^4.1.5","@types/jest":"^27.0.0","@types/node":"^17.0.10","@types/semver":"^7.1.0","@types/tar":"^6.0.0","@types/which":"^2.0.0","@typescript-eslt/eslt-plug":"^5.0.0","@typescript-eslt/parser":"^5.0.0","@yarnpkg/eslt-config":"^1.0.0-rc.5","@yarnpkg/fslib":"^2.1.0","@zkochan/cmd-shim":"^5.0.0","babel-plug-dynamic-import-node":"^2.3.3","clipanion":"^3.0.1","debug":"^4.1.1","eslt":"^8.0.0","eslt-plug-arca":"^0.15.0","jest":"^28.0.0","nock":"^13.0.4","proxy-agent":"^5.0.0","semver":"^7.1.3","supports-color":"^9.0.0","tar":"^6.0.1","terser-webpack-plug":"^5.1.2","ts-loader":"^9.0.0","ts-node":"^10.0.0","typescript":"^4.3.2","v8-compile-cache":"^2.3.0","webpack":"^5.38.1","webpack-cli":"^4.0.0","which":"^2.0.2"},"scripts":{"build":"rm -rf dist shims && webpack && ts-node ./mkshims.ts","corepack":"ts-node ./sources/_entryPot.ts","lt":"yarn eslt","prepack":"yarn build","postpack":"rm -rf dist shims","typecheck":"tsc --noEmit","test":"yarn jest"},"files":["dist","shims","LICENSE.md"],"publishConfig":{"b":{"corepack":"./dist/corepack.js","pnpm":"./dist/pnpm.js","pnpx":"./dist/pnpx.js","yarn":"./dist/yarn.js","yarnpkg":"./dist/yarnpkg.js"},"executableFiles":["./dist/npm.js","./dist/npx.js","./dist/pnpm.js","./dist/pnpx.js","./dist/yarn.js","./dist/yarnpkg.js","./dist/corepack.js","./shims/npm","./shims/npm.ps1","./shims/npx","./shims/npx.ps1","./shims/pnpm","./shims/pnpm.ps1","./shims/pnpx","./shims/pnpx.ps1","./shims/yarn","./shims/yarn.ps1","./shims/yarnpkg","./shims/yarnpkg.ps1"]},"resolutions":{"vm2":"patch:vm2@npm:3.9.9#.yarn/patches/vm2-npm-3.9.9-03fd1f4dc5.patch"}}');/***/ })/******/ 	});/************************************************************************//******/ 	//  module cache/******/ 	var __webpack_module_cache__ = {};/******/ 	/******/ 	//  require function/******/ 	function __webpack_require__(moduleId) {/******/ 		// Check if module is  cache/******/ 		var cachedModule = __webpack_module_cache__[moduleId];/******/ 		if (cachedModule !== undefed) {/******/ 			return cachedModule.exports;/******/ 		}/******/ 		// Create a new module ( put it to the cache)/******/ 		var module = __webpack_module_cache__[moduleId] = {/******/ 			// no module.id needed/******/ 			// no module.loaded needed/******/ 			exports: {}/******/ 		};/******/ 	/******/ 		// Execute the module function/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);/******/ 	/******/ 		// Return the exports of the module/******/ 		return module.exports;/******/ 	}/******/ 	/******/ 	// expose the modules object (__webpack_modules__)/******/ 	__webpack_require__.m = __webpack_modules__;/******/ 	/************************************************************************//******/ 	/* webpack/runtime/compat get default export *//******/ 	(() => {/******/ 		// getDefaultExport function for compatibility with non-harmony modules/******/ 		__webpack_require__.n = (module) => {/******/ 			var getter = module && module.__esModule ?/******/ 				() => (module['default']) :/******/ 				() => (module);/******/ 			__webpack_require__.d(getter, { a: getter });/******/ 			return getter;/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/create fake namespace object *//******/ 	(() => {/******/ 		var getProto = Object.getPrototypeOf ? (obj) => (Object.getPrototypeOf(obj)) : (obj) => (obj.__proto__);/******/ 		var leafPrototypes;/******/ 		// create a fake namespace object/******/ 		// mode & 1: value is a module id, require it/******/ 		// mode & 2: merge all properties of value to the ns/******/ 		// mode & 4: return value when already ns object/******/ 		// mode & 16: return value when it's Promise-like/******/ 		// mode & 8|1: behave like require/******/ 		__webpack_require__.t = function(value, mode) {/******/ 			if(mode & 1) value = (value);/******/ 			if(mode & 8) return value;/******/ 			if(typeof value === 'object' && value) {/******/ 				if((mode & 4) && value.__esModule) return value;/******/ 				if((mode & 16) && typeof value.then === 'function') return value;/******/ 			}/******/ 			var ns = Object.create(null);/******/ 			__webpack_require__.r(ns);/******/ 			var def = {};/******/ 			leafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];/******/ 			for(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.dexOf(current); current = getProto(current)) {/******/ 				Object.getOwnPropertyNames(current).forEach((key) => (def[key] = () => (value[key])));/******/ 			}/******/ 			def['default'] = () => (value);/******/ 			__webpack_require__.d(ns, def);/******/ 			return ns;/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/defe property getters *//******/ 	(() => {/******/ 		// defe getter functions for harmony exports/******/ 		__webpack_require__.d = (exports, defition) => {/******/ 			for(var key  defition) {/******/ 				if(__webpack_require__.o(defition, key) && !__webpack_require__.o(exports, key)) {/******/ 					Object.defeProperty(exports, key, { enumerable: true, get: defition[key] });/******/ 				}/******/ 			}/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/ensure chunk *//******/ 	(() => {/******/ 		__webpack_require__.f = {};/******/ 		// This file contas only the entry chunk./******/ 		//  chunk loadg function for additional chunks/******/ 		__webpack_require__.e = (chunkId) => {/******/ 			return Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {/******/ 				__webpack_require__.f[key](chunkId, promises);/******/ 				return promises;/******/ 			}, []));/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/get javascript chunk filename *//******/ 	(() => {/******/ 		// This function allow to reference async chunks/******/ 		__webpack_require__.u = (chunkId) => {/******/ 			// return url for filenames based on template/******/ 			return "" + chunkId + ".js";/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/hasOwnProperty shorth *//******/ 	(() => {/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/make namespace object *//******/ 	(() => {/******/ 		// defe __esModule on exports/******/ 		__webpack_require__.r = (exports) => {/******/ 			if(typeof Symbol !== 'undefed' && Symbol.toStrgTag) {/******/ 				Object.defeProperty(exports, Symbol.toStrgTag, { value: 'Module' });/******/ 			}/******/ 			Object.defeProperty(exports, '__esModule', { value: true });/******/ 		};/******/ 	})();/******/ 	/******/ 	/* webpack/runtime/require chunk loadg *//******/ 	(() => {/******/ 		// no baseURI/******/ 		/******/ 		// object to store loaded chunks/******/ 		// "1" means "loaded", otherwise not loaded yet/******/ 		var stalledChunks = {/******/ 			"corepack": 1/******/ 		};/******/ 		/******/ 		// no on chunks loaded/******/ 		/******/ 		var stallChunk = (chunk) => {/******/ 			var moreModules = chunk.modules, chunkIds = chunk.ids, runtime = chunk.runtime;/******/ 			for(var moduleId  moreModules) {/******/ 				if(__webpack_require__.o(moreModules, moduleId)) {/******/ 					__webpack_require__.m[moduleId] = moreModules[moduleId];/******/ 				}/******/ 			}/******/ 			if(runtime) runtime(__webpack_require__);/******/ 			for(var i = 0; i < chunkIds.length; i++)/******/ 				stalledChunks[chunkIds[i]] = 1;/******/ 		/******/ 		};/******/ 		/******/ 		// require() chunk loadg for javascript/******/ 		__webpack_require__.f.require = (chunkId, promises) => {/******/ 			// "1" is the signal for "already loaded"/******/ 			if(!stalledChunks[chunkId]) {/******/ 				if(true) { // all chunks have JS/******/ 					stallChunk(require("./" + __webpack_require__.u(chunkId)));/******/ 				} else stalledChunks[chunkId] = 1;/******/ 			}/******/ 		};/******/ 		/******/ 		// no external stall chunk/******/ 		/******/ 		// no HMR/******/ 		/******/ 		// no HMR manifest/******/ 	})();/******/ 	/************************************************************************/var __webpack_exports__ = {};// This entry need to be wrapped  an IIFE because it need to be  strict mode.(() => {"use strict";/*!********************************!*\  !*** ./sources/_entryPot.ts ***!  \********************************/__webpack_require__.r(__webpack_exports__);/* harmony export */ __webpack_require__.d(__webpack_exports__, {/* harmony export */   "runMa": () => (/* reexport safe */ _ma__WEBPACK_IMPORTED_MODULE_0__.runMa)/* harmony export */ });/* harmony import */ var _ma__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ma */ "./sources/ma.ts");// Used  the generated shims// Usg `eval` to be sure that Webpack doesn't transform itif (process.maModule === eval(`module`))    (0,_ma__WEBPACK_IMPORTED_MODULE_0__.runMa)(process.argv.slice(2));})();var __webpack_export_target__ = exports;for(var i  __webpack_exports__) __webpack_export_target__[i] = __webpack_exports__[i];if(__webpack_exports__.__esModule) Object.defeProperty(__webpack_export_target__, "__esModule", { value: true });/******/ })();---title: npm-itsection: 1description: Create a package.json file---### Synopsis<!-- AUTOGENERATED USAGE DESCRIPTIONS START --><!-- automatically generated, do not edit manually --><!-- see lib/comms/it.js -->```bashnpm it [--force|-f|--yes|-y|--scope]npm it <@scope> (same as `npx <@scope>/create`)npm it [<@scope>/]<name> (same as `npx [<@scope>/]create-<name>`)aliases: create, nit```<!-- automatically generated, do not edit manually --><!-- see lib/comms/it.js --><!-- AUTOGENERATED USAGE DESCRIPTIONS END -->### Description`npm it <itializer>` can be used to set up a new or existg npmpackage.`itializer`   case is an npm package named `create-<itializer>`,which will be stalled  [`npm-exec`](/comms/npm-exec),  then have itsma b executed -- presumably creatg or updatg `package.json` runng any other itialization-related operations. it comm is transformed to a correspondg `npm exec` operation asfollows:* `npm it foo` -> `npm exec create-foo`* `npm it @usr/foo` -> `npm exec @usr/create-foo`* `npm it @usr` -> `npm exec @usr/create`If the itializer is omitted ( just callg `npm it`), it will fallback to legacy it behavior. It will ask you a bunch of questions, then write a package.json for you. It will attempt to make reasonableguesses based on existg fields, dependencies,  options selected. It isstrictly additive, so it will keep any fields  values that were alreadyset. You can also use `-y`/`--yes` to skip the questionnaire altogether. Ifyou pass `--scope`, it will create a scoped package.*Note:* if a user already has the `create-<itializer>` packageglobally stalled, that will be what `npm it` uses.  If you want npmto use the latest version, or another specific version you must specifyit:* `npm it foo@latest` # fetches  runs the latest `create-foo` from    the registry* `npm it foo@1.2.3` #  runs `create-foo@1.2.3` specifically#### Forwardg additional optionsAny additional options will be passed directly to the comm, so `npm itfoo -- --hello` will map to `npm exec -- create-foo --hello`.To better illustrate how options  forwarded, here's a more evolvedexample showg options passed to both the **npm cli**  a create package,both followg comms  equivalent:- `npm it foo -y --registry=<url> -- --hello -a`- `npm exec -y --registry=<url> -- create-foo --hello -a`### ExamplesCreate a new React-based project usg[`create-react-app`](https://npm.im/create-react-app):```bash$ npm it react-app ./my-react-app```Create a new `esm`-compatible package usg[`create-esm`](https://npm.im/create-esm):```bash$ mkdir my-esm-lib && cd my-esm-lib$ npm it esm --yes```Generate a pla old package.json usg legacy it:```bash$ mkdir my-npm-pkg && cd my-npm-pkg$ git it$ npm it```Generate it without havg it ask any questions:```bash$ npm it -y```### Workspaces supportIt's possible to create a new workspace with your project  usg the`workspace` config option. When usg `npm it -w <dir>` the cli willcreate the folders  boilerplate expected while also addg a referenceto your project `package.json` `"workspaces": []` property  order to makesure that new generated **workspace** is properly set up as such.Given a project with no workspaces, e.g:```.+-- package.json```You may generate a new workspace usg the legacy it:```bash$ npm it -w packages/a```That will generate a new folder  `package.json` file, while also updatgyour top-level `package.json` to add the reference to  new workspace:```.+-- package.json`-- packages   `-- a       `-- package.json``` workspaces it also supports the `npm it <itializer> -w <dir>`syntax, followg the same set of rules explaed earlier  the itial**Description** section of  page. Similar to the previous example ofcreatg a new React-based project usg[`create-react-app`](https://npm.im/create-react-app), the followg syntaxwill make sure to create the new react app as a nested **workspace** with yourproject  configure your `package.json` to recognize it as such:```bashnpm it -w packages/my-react-app react-app .```This will make sure to generate your react app as expected, one importantconsideration to have  md is that `npm exec` is gog to be run  thecontext of the newly created folder for that workspace,  that's the reasonwhy   example the itializer uses the itializer name followed with adot to represent the current directory  that context, e.g: `react-app .`:```.+-- package.json`-- packages   +-- a   |   `-- package.json   `-- my-react-app       +-- README       +-- package.json       `-- ...```### Configuration<!-- AUTOGENERATED CONFIG DESCRIPTIONS START --><!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `yes`* Default: null* Type: null or BooleanAutomatically answer "yes" to any prompts that npm might prt on thecomm le.<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `force`* Default: false* Type: BooleanRemoves various protections agast unfortunate side effects, commonmistakes, unnecessary performance degradation,  malicious put.* Allow clobberg non-npm files  global stalls.* Allow the `npm version` comm to work on an unclean git repository.* Allow deletg the cache folder with `npm cache clean`.* Allow stallg packages that have an `enges` declaration requirg a  different version of npm.* Allow stallg packages that have an `enges` declaration requirg a  different version of `node`, even if `--enge-strict` is enabled.* Allow `npm audit fix` to stall modules outside your stated dependency  range (cludg SemVer-major changes).* Allow unpublishg all versions of a published package.* Allow conflictg peerDependencies to be stalled  the root project.* Implicitly set `--yes` durg `npm it`.* Allow clobberg existg values  `npm pkg`* Allow unpublishg of entire packages (not just a sgle version).If you don't have a clear idea of what you want to do, it is stronglyrecommended that you do not use  option!<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `workspace`* Default:* Type: Strg (can be set multiple times)Enable runng a comm  the context of the configured workspaces of thecurrent project while filterg  runng only the workspaces defed  configuration option.Valid values for the `workspace` config  either:* Workspace names* Path to a workspace directory* Path to a pnt workspace directory (will result  selectg all  workspaces with that folder)When set for the `npm it` comm,  may be set to the folder of aworkspace which does not yet exist, to create the folder  set it up as abr new workspace with the project.This value is not exported to the environment for child processes.<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `workspaces`* Default: null* Type: null or BooleanSet to true to run the comm  the context of **all** configuredworkspaces.Explicitly settg  to false will cause comms like `stall` toignore workspaces altogether. When not set explicitly:- Comms that operate on the `node_modules` tree (stall, update, etc.)will lk workspaces to the `node_modules` folder. - Comms that doother thgs (test, exec, publish, etc.) will operate on the root project,_unless_ one or more workspaces  specified  the `workspace` config.This value is not exported to the environment for child processes.<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `workspaces-update`* Default: true* Type: BooleanIf set to true, the npm cli will run an update after operations that maypossibly change the workspaces stalled to the `node_modules` folder.<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js -->#### `clude-workspace-root`* Default: false* Type: BooleanInclude the workspace root when workspaces  enabled for a comm.When false, specifyg dividual workspaces via the `workspace` config, orall workspaces via the `workspaces` flag, will cause npm to operate only onthe specified workspaces,  not on the root project.This value is not exported to the environment for child processes.<!-- automatically generated, do not edit manually --><!-- see lib/utils/config/defitions.js --><!-- AUTOGENERATED CONFIG DESCRIPTIONS END -->### See Also* [it-package-json module](http://npm.im/it-package-json)* [package.json](/configurg-npm/package-json)* [npm version](/comms/npm-version)* [npm scope](/usg-npm/scope)* [npm exec](/comms/npm-exec)* [npm workspaces](/usg-npm/workspaces)<!DOCTYPE html><html><head><meta charset="utf-8"><title>npm-it</title><style>body {    background-color: #ffffff;    color: #24292e;    marg: 0;    le-height: 1.5;    font-family: -apple-system, BlkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";}#rabar {    height: 10px;    background-image: lear-gradient(139deg, #fb8817, #ff4b01, #c12127, #e02aff);}a {    text-decoration: none;    color: #0366d6;}a:hover {    text-decoration: underle;}pre {    marg: 1em 0px;    paddg: 1em;    border: solid 1px #e1e4e8;    border-radius: 6px;    display: block;    overflow: auto;    white-space: pre;    background-color: #f6f8fa;    color: #393a34;}code {    font-family: SFMono-Regular, Consolas, "Liberation Mono", Menlo, Courier, monospace;    font-size: 85%;    paddg: 0.2em 0.4em;    background-color: #f6f8fa;    color: #393a34;}pre > code {    paddg: 0;    background-color: herit;    color: herit;}h1, h2, h3 {    font-weight: 600;}#logobar {    background-color: #333333;    marg: 0 auto;    paddg: 1em 4em;}#logobar .logo {    float: left;}#logobar .title {    font-weight: 600;    color: #dddddd;    float: left;    marg: 5px 0 0 1em;}#logobar:after {    content: "";    display: block;    clear: both;}#content {    marg: 0 auto;    paddg: 0 4em;}#table_of_contents > h2 {    font-size: 1.17em;}#table_of_contents ul:first-child {    border: solid 1px #e1e4e8;    border-radius: 6px;    paddg: 1em;    background-color: #f6f8fa;    color: #393a34;}#table_of_contents ul {    list-style-type: none;    paddg-left: 1.5em;}#table_of_contents li {    font-size: 0.9em;}#table_of_contents li a {    color: #000000;}header.title {    border-bottom: solid 1px #e1e4e8;}header.title > h1 {    marg-bottom: 0.25em;}header.title > .description {    display: block;    marg-bottom: 0.5em;    le-height: 1;}footer#edit {    border-top: solid 1px #e1e4e8;    marg: 3em 0 4em 0;    paddg-top: 2em;}</style></head><body><div id="banner"><div id="rabar"></div><div id="logobar"><svg class="logo" role="img" height="32" width="32" viewBox="0 0 700 700"><polygon fill="#cb0000" pots="0,700 700,700 700,0 0,0"></polygon><polygon fill="#ffffff" pots="150,550 350,550 350,250 450,250 450,550 550,550 550,150 150,150"></polygon></svg><div class="title">npm comm-le terface</div></div></div><section id="content"><header class="title"><h1 id="npm-it">npm-it</h1><span class="description">Create a package.json file</span></header><section id="table_of_contents"><h2 id="table-of-contents">Table of contents</h2><div id="_table_of_contents"><ul><li><a href="#synopsis">Synopsis</a></li><li><a href="#description">Description</a></li><ul><li><a href="#forwardg-additional-options">Forwardg additional options</a></li></ul><li><a href="#examples">Examples</a></li><li><a href="#workspaces-support">Workspaces support</a></li><li><a href="#configuration">Configuration</a></li><ul><li><a href="#yes"><code>yes</code></a></li><li><a href="#force"><code>force</code></a></li><li><a href="#workspace"><code>workspace</code></a></li><li><a href="#workspaces"><code>workspaces</code></a></li><li><a href="#workspaces-update"><code>workspaces-update</code></a></li><li><a href="#clude-workspace-root"><code>clude-workspace-root</code></a></li></ul><li><a href="#see-also">See Also</a></li></ul></div></section><div id="_content"><h3 id="synopsis">Synopsis</h3><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><pre lang="bash"><code>npm it [--force|-f|--yes|-y|--scope]npm it &lt;@scope&gt; (same as `npx &lt;@scope&gt;/create`)npm it [&lt;@scope&gt;/]&lt;name&gt; (same as `npx [&lt;@scope&gt;/]create-&lt;name&gt;`)aliases: create, nit</code></pre><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><h3 id="description">Description</h3><p><code>npm it &lt;itializer&gt;</code> can be used to set up a new or existg npmpackage.</p><p><code>itializer</code>   case is an npm package named <code>create-&lt;itializer&gt;</code>,which will be stalled  <a href="../comms/npm-exec.html"><code>npm-exec</code></a>,  then have itsma b executed -- presumably creatg or updatg <code>package.json</code> runng any other itialization-related operations.</p><p> it comm is transformed to a correspondg <code>npm exec</code> operation asfollows:</p><ul><li><code>npm it foo</code> -&gt; <code>npm exec create-foo</code></li><li><code>npm it @usr/foo</code> -&gt; <code>npm exec @usr/create-foo</code></li><li><code>npm it @usr</code> -&gt; <code>npm exec @usr/create</code></li></ul><p>If the itializer is omitted ( just callg <code>npm it</code>), it will fallback to legacy it behavior. It will ask you a bunch of questions, then write a package.json for you. It will attempt to make reasonableguesses based on existg fields, dependencies,  options selected. It isstrictly additive, so it will keep any fields  values that were alreadyset. You can also use <code>-y</code>/<code>--yes</code> to skip the questionnaire altogether. Ifyou pass <code>--scope</code>, it will create a scoped package.</p><p><em>Note:</em> if a user already has the <code>create-&lt;itializer&gt;</code> packageglobally stalled, that will be what <code>npm it</code> uses.  If you want npmto use the latest version, or another specific version you must specifyit:</p><ul><li><code>npm it foo@latest</code> # fetches  runs the latest <code>create-foo</code> fromthe registry</li><li><code>npm it foo@1.2.3</code> #  runs <code>create-foo@1.2.3</code> specifically</li></ul><h4 id="forwardg-additional-options">Forwardg additional options</h4><p>Any additional options will be passed directly to the comm, so <code>npm it foo -- --hello</code> will map to <code>npm exec -- create-foo --hello</code>.</p><p>To better illustrate how options  forwarded, here's a more evolvedexample showg options passed to both the <strong>npm cli</strong>  a create package,both followg comms  equivalent:</p><ul><li><code>npm it foo -y --registry=&lt;url&gt; -- --hello -a</code></li><li><code>npm exec -y --registry=&lt;url&gt; -- create-foo --hello -a</code></li></ul><h3 id="examples">Examples</h3><p>Create a new React-based project usg<a href="https://npm.im/create-react-app"><code>create-react-app</code></a>:</p><pre lang="bash"><code>$ npm it react-app ./my-react-app</code></pre><p>Create a new <code>esm</code>-compatible package usg<a href="https://npm.im/create-esm"><code>create-esm</code></a>:</p><pre lang="bash"><code>$ mkdir my-esm-lib &amp;&amp; cd my-esm-lib$ npm it esm --yes</code></pre><p>Generate a pla old package.json usg legacy it:</p><pre lang="bash"><code>$ mkdir my-npm-pkg &amp;&amp; cd my-npm-pkg$ git it$ npm it</code></pre><p>Generate it without havg it ask any questions:</p><pre lang="bash"><code>$ npm it -y</code></pre><h3 id="workspaces-support">Workspaces support</h3><p>It's possible to create a new workspace with your project  usg the<code>workspace</code> config option. When usg <code>npm it -w &lt;dir&gt;</code> the cli willcreate the folders  boilerplate expected while also addg a referenceto your project <code>package.json</code> <code>"workspaces": []</code> property  order to makesure that new generated <strong>workspace</strong> is properly set up as such.</p><p>Given a project with no workspaces, e.g:</p><pre><code>.+-- package.json</code></pre><p>You may generate a new workspace usg the legacy it:</p><pre lang="bash"><code>$ npm it -w packages/a</code></pre><p>That will generate a new folder  <code>package.json</code> file, while also updatgyour top-level <code>package.json</code> to add the reference to  new workspace:</p><pre><code>.+-- package.json`-- packages   `-- a       `-- package.json</code></pre><p> workspaces it also supports the <code>npm it &lt;itializer&gt; -w &lt;dir&gt;</code>syntax, followg the same set of rules explaed earlier  the itial<strong>Description</strong> section of  page. Similar to the previous example ofcreatg a new React-based project usg<a href="https://npm.im/create-react-app"><code>create-react-app</code></a>, the followg syntaxwill make sure to create the new react app as a nested <strong>workspace</strong> with yourproject  configure your <code>package.json</code> to recognize it as such:</p><pre lang="bash"><code>npm it -w packages/my-react-app react-app .</code></pre><p>This will make sure to generate your react app as expected, one importantconsideration to have  md is that <code>npm exec</code> is gog to be run  thecontext of the newly created folder for that workspace,  that's the reasonwhy   example the itializer uses the itializer name followed with adot to represent the current directory  that context, e.g: <code>react-app .</code>:</p><pre><code>.+-- package.json`-- packages   +-- a   |   `-- package.json   `-- my-react-app       +-- README       +-- package.json       `-- ...</code></pre><h3 id="configuration">Configuration</h3><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="yes"><code>yes</code></h4><ul><li>Default: null</li><li>Type: null or Boolean</li></ul><p>Automatically answer "yes" to any prompts that npm might prt on thecomm le.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="force"><code>force</code></h4><ul><li>Default: false</li><li>Type: Boolean</li></ul><p>Removes various protections agast unfortunate side effects, commonmistakes, unnecessary performance degradation,  malicious put.</p><ul><li>Allow clobberg non-npm files  global stalls.</li><li>Allow the <code>npm version</code> comm to work on an unclean git repository.</li><li>Allow deletg the cache folder with <code>npm cache clean</code>.</li><li>Allow stallg packages that have an <code>enges</code> declaration requirg adifferent version of npm.</li><li>Allow stallg packages that have an <code>enges</code> declaration requirg adifferent version of <code>node</code>, even if <code>--enge-strict</code> is enabled.</li><li>Allow <code>npm audit fix</code> to stall modules outside your stated dependencyrange (cludg SemVer-major changes).</li><li>Allow unpublishg all versions of a published package.</li><li>Allow conflictg peerDependencies to be stalled  the root project.</li><li>Implicitly set <code>--yes</code> durg <code>npm it</code>.</li><li>Allow clobberg existg values  <code>npm pkg</code></li><li>Allow unpublishg of entire packages (not just a sgle version).</li></ul><p>If you don't have a clear idea of what you want to do, it is stronglyrecommended that you do not use  option!</p><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="workspace"><code>workspace</code></h4><ul><li>Default:</li><li>Type: Strg (can be set multiple times)</li></ul><p>Enable runng a comm  the context of the configured workspaces of thecurrent project while filterg  runng only the workspaces defed  configuration option.</p><p>Valid values for the <code>workspace</code> config  either:</p><ul><li>Workspace names</li><li>Path to a workspace directory</li><li>Path to a pnt workspace directory (will result  selectg allworkspaces with that folder)</li></ul><p>When set for the <code>npm it</code> comm,  may be set to the folder of aworkspace which does not yet exist, to create the folder  set it up as abr new workspace with the project.</p><p>This value is not exported to the environment for child processes.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="workspaces"><code>workspaces</code></h4><ul><li>Default: null</li><li>Type: null or Boolean</li></ul><p>Set to true to run the comm  the context of <strong>all</strong> configuredworkspaces.</p><p>Explicitly settg  to false will cause comms like <code>stall</code> toignore workspaces altogether. When not set explicitly:</p><ul><li>Comms that operate on the <code>node_modules</code> tree (stall, update, etc.)will lk workspaces to the <code>node_modules</code> folder. - Comms that doother thgs (test, exec, publish, etc.) will operate on the root project,<em>unless</em> one or more workspaces  specified  the <code>workspace</code> config.</li></ul><p>This value is not exported to the environment for child processes.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="workspaces-update"><code>workspaces-update</code></h4><ul><li>Default: true</li><li>Type: Boolean</li></ul><p>If set to true, the npm cli will run an update after operations that maypossibly change the workspaces stalled to the <code>node_modules</code> folder.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><h4 id="clude-workspace-root"><code>clude-workspace-root</code></h4><ul><li>Default: false</li><li>Type: Boolean</li></ul><p>Include the workspace root when workspaces  enabled for a comm.</p><p>When false, specifyg dividual workspaces via the <code>workspace</code> config, orall workspaces via the <code>workspaces</code> flag, will cause npm to operate only onthe specified workspaces,  not on the root project.</p><p>This value is not exported to the environment for child processes.</p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><h3 id="see-also">See Also</h3><ul><li><a href="http://npm.im/it-package-json">it-package-json module</a></li><li><a href="../configurg-npm/package-json.html">package.json</a></li><li><a href="../comms/npm-version.html">npm version</a></li><li><a href="../usg-npm/scope.html">npm scope</a></li><li><a href="../comms/npm-exec.html">npm exec</a></li><li><a href="../usg-npm/workspaces.html">npm workspaces</a></li></ul></div><footer id="edit"><a href="https://github.com/npm/cli/edit/latest/docs/content/comms/npm-it.md"><svg role="img" viewBox="0 0 16 16" width="16" height="16" fill="currentcolor" style="vertical-align: text-bottom; marg-right: 0.3em;"><path fill-rule="evenodd" d="M11.013 1.427a1.75 1.75 0 012.474 0l1.086 1.086a1.75 1.75 0 010 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 01-.927-.928l.929-3.25a1.75 1.75 0 01.445-.758l8.61-8.61zm1.414 1.06a.25.25 0 00-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 000-.354l-1.086-1.086zM11.189 6.25L9.75 4.81l-6.286 6.287a.25.25 0 00-.064.108l-.558 1.953 1.953-.558a.249.249 0 00.108-.064l6.286-6.286z"></path></svg>Edit  page on GitHub</a></footer></section></body></html>const BaseComm = require('../base-comm.js')const log = require('../utils/log-shim')class Birthday extends BaseComm {  static name = 'birthday'  static description = 'Birthday, deprecated'  static ignoreImplicitWorkspace = true  static isShellout = true  async exec () {    .npm.config.set('yes', true)    log.warn('birthday', 'birthday is deprecated  will be removed  a future release')    return .npm.exec('exec', ['@npmcli/npm-birthday'])  }}module.exports = Birthdayconst libexec = require('libnpmexec')const BaseComm = require('../base-comm.js')const getLocationMsg = require('../exec/get-workspace-location-msg.js')// it's like ://// npm x pkg@version <-- runs the b named "pkg" or the only b if only 1//// { name: 'pkg', b: { pkg: 'pkg.js', foo: 'foo.js' }} <-- run pkg// { name: 'pkg', b: { foo: 'foo.js' }} <-- run foo?//// npm x -p pkg@version -- foo//// npm x -p pkg@version -- foo --registry=/dev/null//// const pkg = npm.config.get('package') || getPackageFrom(args[0])// const cmd = getComm(pkg, args[0])// --> npm x -c 'cmd ...args.slice(1)'//// we've resolved cmd  args,  escaped them properly,  stalled the// relevant packages.//// Add the ${npx stall prefix}/node_modules/.b to PATH//// pkg = readPackageJson('./package.json')// pkg.scripts.___npx = ${the -c arg}// runScript({ pkg, event: 'npx', ... })// process.env.npm_lifecycle_event = 'npx'class Exec extends BaseComm {  static description = 'Run a comm from a local or remote npm package'  static params = [    'package',    'call',    'workspace',    'workspaces',    'clude-workspace-root',  ]  static name = 'exec'  static usage = [    '-- <pkg>[@<version>] [args...]',    '--package=<pkg>[@<version>] -- <cmd> [args...]',    '-c \'<cmd> [args...]\'',    '--package=foo -c \'<cmd> [args...]\'',  ]  static ignoreImplicitWorkspace = false  static isShellout = true  async exec (_args, { locationMsg, runPath } = {}) {    const path = .npm.localPrefix    if (!runPath) {      runPath = process.cwd()    }    const args = [..._args]    const call = .npm.config.get('call')    const {      flatOptions,      localB,      globalB,    } = .npm    const output = (...outputArgs) => .npm.output(...outputArgs)    const scriptShell = .npm.config.get('script-shell') || undefed    const packages = .npm.config.get('package')    const yes = .npm.config.get('yes')    if (call && _args.length) {      throw .usageError()    }    return libexec({      ...flatOptions,      // we explicitly set packageLockOnly to false because if it's true      // when we try to stall a missg package, we won't actually stall it      packageLockOnly: false,      args,      call,      localB,      locationMsg,      globalB,      output,      packages,      path,      runPath,      scriptShell,      yes,    })  }  async execWorkspaces (args, filters) {    await .setWorkspaces(filters)    const color = .npm.color    for (const path of .workspacePaths) {      const locationMsg = await getLocationMsg({ color, path })      await .exec(args, { locationMsg, runPath: path })    }  }}module.exports = Execconst { resolve } = require('path')const chalk = require('chalk')const runScript = require('@npmcli/run-script')const { isServerPackage } = runScriptconst rpj = require('read-package-json-fast')const log = require('../utils/log-shim.js')const didYouMean = require('../utils/did-you-mean.js')const { isWdowsShell } = require('../utils/is-wdows.js')const cmdList = [  'publish',  'stall',  'unstall',  'test',  'stop',  'start',  'restart',  'version',].reduce((l, p) => l.concat(['pre' + p, p, 'post' + p]), [])const nocolor = {  reset: s => s,  bold: s => s,  dim: s => s,  blue: s => s,  green: s => s,}const BaseComm = require('../base-comm.js')class RunScript extends BaseComm {  static description = 'Run arbitrary package scripts'  static params = [    'workspace',    'workspaces',    'clude-workspace-root',    'if-present',    'ignore-scripts',    'script-shell',  ]  static name = 'run-script'  static usage = ['<comm> [-- <args>]']  static ignoreImplicitWorkspace = false  static isShellout = true  async completion (opts) {    const argv = opts.conf.argv.rema    if (argv.length === 2) {      // fd the script name      const json = resolve(.npm.localPrefix, 'package.json')      const { scripts = {} } = await rpj(json).catch(er => ({}))      return Object.keys(scripts)    }  }  async exec (args) {    if (args.length) {      return .run(args)    } else {      return .list(args)    }  }  async execWorkspaces (args, filters) {    if (args.length) {      return .runWorkspaces(args, filters)    } else {      return .listWorkspaces(args, filters)    }  }  async run ([event, ...args], { path = .npm.localPrefix, pkg } = {}) {    //  || undefed is because runScript will be unhappy with the default    // null value    const scriptShell = .npm.config.get('script-shell') || undefed    pkg = pkg || (await rpj(`${path}/package.json`))    const { scripts = {} } = pkg    if (event === 'restart' && !scripts.restart) {      scripts.restart = 'npm stop --if-present && npm start'    } else if (event === 'env' && !scripts.env) {      scripts.env = isWdowsShell ? 'SET' : 'env'    }    pkg.scripts = scripts    if (      !Object.prototype.hasOwnProperty.call(scripts, event) &&      !(event === 'start' && (await isServerPackage(path)))    ) {      if (.npm.config.get('if-present')) {        return      }      const suggestions = await didYouMean(.npm, path, event)      throw new Error(        `Missg script: "${event}"${suggestions}\n\nTo see a list of scripts, run:\n  npm run`      )    }    // positional args only added to the ma event, not pre/post    const events = [[event, args]]    if (!.npm.config.get('ignore-scripts')) {      if (scripts[`pre${event}`]) {        events.unshift([`pre${event}`, []])      }      if (scripts[`post${event}`]) {        events.push([`post${event}`, []])      }    }    const opts = {      path,      args,      scriptShell,      stdio: 'herit',      stdioStrg: true,      pkg,      banner: !.npm.silent,    }    for (const [event, args] of events) {      await runScript({        ...opts,        event,        args,      })    }  }  async list (args, path) {    path = path || .npm.localPrefix    const { scripts, name, _id } = await rpj(`${path}/package.json`)    const pkgid = _id || name    const color = .npm.color    if (!scripts) {      return []    }    const allScripts = Object.keys(scripts)    if (.npm.silent) {      return allScripts    }    if (.npm.config.get('json')) {      .npm.output(JSON.strgify(scripts, null, 2))      return allScripts    }    if (.npm.config.get('parseable')) {      for (const [script, cmd] of Object.entries(scripts)) {        .npm.output(`${script}:${cmd}`)      }      return allScripts    }    const dent = '\n    '    const prefix = '  '    const cmds = []    const runScripts = []    for (const script of allScripts) {      const list = cmdList.cludes(script) ? cmds : runScripts      list.push(script)    }    const colorize = color ? chalk : nocolor    if (cmds.length) {      .npm.output(        `${colorize.reset(colorize.bold('Lifecycle scripts'))} cluded  ${colorize.green(          pkgid        )}:`      )    }    for (const script of cmds) {      .npm.output(prefix + script + dent + colorize.dim(scripts[script]))    }    if (!cmds.length && runScripts.length) {      .npm.output(        `${colorize.bold('Scripts')} available  ${colorize.green(pkgid)} via \`${colorize.blue(          'npm run-script'        )}\`:`      )    } else if (runScripts.length) {      .npm.output(`\navailable via \`${colorize.blue('npm run-script')}\`:`)    }    for (const script of runScripts) {      .npm.output(prefix + script + dent + colorize.dim(scripts[script]))    }    .npm.output('')    return allScripts  }  async runWorkspaces (args, filters) {    const res = []    await .setWorkspaces(filters)    for (const workspacePath of .workspacePaths) {      const pkg = await rpj(`${workspacePath}/package.json`)      const runResult = await .run(args, {        path: workspacePath,        pkg,      }).catch(err => {        log.error(`Lifecycle script \`${args[0]}\` failed with error:`)        log.error(err)        log.error(`   workspace: ${pkg._id || pkg.name}`)        log.error(`  at location: ${workspacePath}`)        const scriptMissg = err.message.startsWith('Missg script')        // avoids exitg with error code  case there's scripts missg        //  some workspaces sce other scripts might have succeeded        if (!scriptMissg) {          process.exitCode = 1        }        return scriptMissg      })      res.push(runResult)    }    //  case **all** tests  missg, then it should exit with error code    if (res.every(Boolean)) {      throw new Error(`Missg script: ${args[0]}`)    }  }  async listWorkspaces (args, filters) {    await .setWorkspaces(filters)    if (.npm.silent) {      return    }    if (.npm.config.get('json')) {      const res = {}      for (const workspacePath of .workspacePaths) {        const { scripts, name } = await rpj(`${workspacePath}/package.json`)        res[name] = { ...scripts }      }      .npm.output(JSON.strgify(res, null, 2))      return    }    if (.npm.config.get('parseable')) {      for (const workspacePath of .workspacePaths) {        const { scripts, name } = await rpj(`${workspacePath}/package.json`)        for (const [script, cmd] of Object.entries(scripts || {})) {          .npm.output(`${name}:${script}:${cmd}`)        }      }      return    }    for (const workspacePath of .workspacePaths) {      await .list(args, workspacePath)    }  }}module.exports = RunScript//  implementation of comms that  just "run a script"// restart, start, stop, testconst BaseComm = require('./base-comm.js')class LifecycleCmd extends BaseComm {  static usage = ['[-- <args>]']  static isShellout = true  async exec (args, cb) {    return .npm.exec('run-script', [.constructor.name, ...args])  }  async execWorkspaces (args, filters, cb) {    return .npm.exec('run-script', [.constructor.name, ...args])  }}module.exports = LifecycleCmdconst os = require('os')const log = require('./log-shim.js')const errorMessage = require('./error-message.js')const replaceInfo = require('./replace-fo.js')const messageText = msg => msg.map(le => le.slice(1).jo(' ')).jo('\n')const dent = (val) => Array.isArray(val) ? val.map(v => dent(v)) : `    ${val}`let npm = null // set  the clilet exitHlerCalled = falselet showLogFileError = falseprocess.on('exit', code => {  log.disableProgress()  // process.emit is synchronous, so the timeEnd hler will run before the  // unfished timer check below  process.emit('timeEnd', 'npm')  const hasNpm = !!npm  const hasLoadedNpm = hasNpm && npm.config.loaded  // Unfished timers can be read before config load  if (hasNpm) {    for (const [name, timer] of npm.unfishedTimers) {      log.verbose('unfished npm timer', name, timer)    }  }  if (!code) {    log.fo('ok')  } else {    log.verbose('code', code)  }  if (!exitHlerCalled) {    process.exitCode = code || 1    log.error('', 'Exit hler never called!')    // eslt-disable-next-le no-console    console.error('')    log.error('', 'This is an error with npm itself. Please report  error at:')    log.error('', '    <https://github.com/npm/cli/issues>')    showLogFileError = true  }  // npm must be loaded to know where the log file was   if (hasLoadedNpm) {    // write the timg file now,  might do nothg based on the configs set.    // we need to call it here  case it errors so we dont tell the user    // about a timg file that doesn't exist    npm.writeTimgFile()    const logsDir = npm.logsDir    const logFiles = npm.logFiles    const timgDir = npm.timgDir    const timgFile = npm.timgFile    const timg = npm.config.get('timg')    const logsMax = npm.config.get('logs-max')    // Determe whether to show log file message  why it is    // beg shown sce  timg mode we always show the log file message    const logMethod = showLogFileError ? 'error' : timg ? 'fo' : null    if (logMethod) {      if (!npm.silent) {        // just a le break if not  silent mode        // eslt-disable-next-le no-console        console.error('')      }      const message = []      if (timgFile) {        message.push('Timg fo  to:', dent(timgFile))      } else if (timg) {        message.push(          ` timg file was not  due to an error writg to the directory: ${timgDir}`        )      }      if (logFiles.length) {        message.push('A complete log of  run can be found :', ...dent(logFiles))      } else if (logsMax <= 0) {        // user specified no log file        message.push(`Log files were not  due to the config logs-max=${logsMax}`)      } else {        // could be an error writg to the directory        message.push(          `Log files were not  due to an error writg to the directory: ${logsDir}`,          'You can rerun the comm with `--loglevel=verbose` to see the logs  your termal'        )      }      log[logMethod]('', message.jo('\n'))    }    // This removes any listeners npm setup, mostly for tests to avoid max listener warngs    npm.unload()  }  // these  needed for the tests to have a clean slate  each test case  exitHlerCalled = false  showLogFileError = false})const exitHler = err => {  exitHlerCalled = true  log.disableProgress()  const hasNpm = !!npm  const hasLoadedNpm = hasNpm && npm.config.loaded  if (!hasNpm) {    err = err || new Error('Exit prior to settg npm  exit hler')    // eslt-disable-next-le no-console    console.error(err.stack || err.message)    return process.exit(1)  }  if (!hasLoadedNpm) {    err = err || new Error('Exit prior to config file resolvg.')    // eslt-disable-next-le no-console    console.error(err.stack || err.message)  }  // only show the notification if it fished.  if (typeof npm.updateNotification === 'strg') {    const { level } = log    log.level = 'notice'    log.notice('', npm.updateNotification)    log.level = level  }  let exitCode  let noLogMessage  if (err) {    exitCode = 1    // if we got a comm that just shells out to somethg else, then it    // will presumably prt its own errors  exit with a proper status    // code if there's a problem.  If we got an error with a code=0, then...    // somethg else went wrong along the way, so maybe an npm problem?    const isShellout = npm.commInstance && npm.commInstance.constructor.isShellout    const quietShellout = isShellout && typeof err.code === 'number' && err.code    if (quietShellout) {      exitCode = err.code      noLogMessage = true    } else if (typeof err === 'strg') {      // XXX: we should stop throwg strgs      log.error('', err)      noLogMessage = true    } else if (!(err stanceof Error)) {      log.error('weird error', err)      noLogMessage = true    } else {      if (!err.code) {        const matchErrorCode = err.message.match(/^(?:Error: )?(E[A-Z]+)/)        err.code = matchErrorCode && matchErrorCode[1]      }      for (const k of ['type', 'stack', 'statusCode', 'pkgid']) {        const v = err[k]        if (v) {          log.verbose(k, replaceInfo(v))        }      }      log.verbose('cwd', process.cwd())      log.verbose('', os.type() + ' ' + os.release())      log.verbose('node', process.version)      log.verbose('npm ', 'v' + npm.version)      for (const k of ['code', 'syscall', 'file', 'path', 'dest', 'errno']) {        const v = err[k]        if (v) {          log.error(k, v)        }      }      const msg = errorMessage(err, npm)      for (const errle of [...msg.summary, ...msg.detail]) {        log.error(...errle)      }      if (hasLoadedNpm && npm.config.get('json')) {        const error = {          error: {            code: err.code,            summary: messageText(msg.summary),            detail: messageText(msg.detail),          },        }        npm.outputError(JSON.strgify(error, null, 2))      }      if (typeof err.errno === 'number') {        exitCode = err.errno      } else if (typeof err.code === 'number') {        exitCode = err.code      }    }  }  log.verbose('exit', exitCode || 0)  showLogFileError = (hasLoadedNpm && npm.silent) || noLogMessage    ? false    : !!exitCode  // explicitly call process.exit now so we don't hang on thgs like the  // update notifier, also flush stdout/err beforeh because process.exit doesn't  // wait for that to happen.  let flushed = 0  const flush = [process.stderr, process.stdout]  const exit = () => ++flushed === flush.length && process.exit(exitCode)  flush.forEach((f) => f.write('', exit))}module.exports = exitHlermodule.exports.setNpm = n => (npm = n).TH "NPM\-INIT" "1" "June 2022" "" "".SH "NAME"\fBnpm-it\fR \- Create a package\.json file.SS Synopsis.P.RS 2.nfnpm it [\-\-force|\-f|\-\-yes|\-y|\-\-scope]npm it <@scope> (same as `npx <@scope>/create`)npm it [<@scope>/]<name> (same as `npx [<@scope>/]create\-<name>`)aliases: create, nit.fi.RE.SS Description.P\fBnpm it <itializer>\fP can be used to set up a new or existg npmpackage\..P\fBitializer\fP   case is an npm package named \fBcreate\-<itializer>\fP,which will be stalled  npm help \fBnpm\-exec\fP,  then have itsma b executed \-\- presumably creatg or updatg \fBpackage\.json\fP runng any other itialization\-related operations\..P it comm is transformed to a correspondg \fBnpm exec\fP operation asfollows:.RS 0.IP \(bu 2\fBnpm it foo\fP \-> \fBnpm exec create\-foo\fP.IP \(bu 2\fBnpm it @usr/foo\fP \-> \fBnpm exec @usr/create\-foo\fP.IP \(bu 2\fBnpm it @usr\fP \-> \fBnpm exec @usr/create\fP.RE.PIf the itializer is omitted ( just callg \fBnpm it\fP), it will fallback to legacy it behavior\. It will ask you a bunch of questions, then write a package\.json for you\. It will attempt to make reasonableguesses based on existg fields, dependencies,  options selected\. It isstrictly additive, so it will keep any fields  values that were alreadyset\. You can also use \fB\-y\fP/\fB\-\-yes\fP to skip the questionnaire altogether\. Ifyou pass \fB\-\-scope\fP, it will create a scoped package\..P\fINote:\fR if a user already has the \fBcreate\-<itializer>\fP packageglobally stalled, that will be what \fBnpm it\fP uses\.  If you want npmto use the latest version, or another specific version you must specifyit:.RS 0.IP \(bu 2\fBnpm it foo@latest\fP # fetches  runs the latest \fBcreate\-foo\fP from  the registry.IP \(bu 2\fBnpm it foo@1\.2\.3\fP #  runs \fBcreate\-foo@1\.2\.3\fP specifically.RE.SS Forwardg additional options.PAny additional options will be passed directly to the comm, so \fBnpm itfoo \-\- \-\-hello\fP will map to \fBnpm exec \-\- create\-foo \-\-hello\fP\|\..PTo better illustrate how options  forwarded, here's a more evolvedexample showg options passed to both the \fBnpm cli\fR  a create package,both followg comms  equivalent:.RS 0.IP \(bu 2\fBnpm it foo \-y \-\-registry=<url> \-\- \-\-hello \-a\fP.IP \(bu 2\fBnpm exec \-y \-\-registry=<url> \-\- create\-foo \-\-hello \-a\fP.RE.SS Examples.PCreate a new React\-based project usg\fBcreate\-react\-app\fP \fIhttps://npm\.im/create\-react\-app\fR:.P.RS 2.nf$ npm it react\-app \./my\-react\-app.fi.RE.PCreate a new \fBesm\fP\-compatible package usg\fBcreate\-esm\fP \fIhttps://npm\.im/create\-esm\fR:.P.RS 2.nf$ mkdir my\-esm\-lib && cd my\-esm\-lib$ npm it esm \-\-yes.fi.RE.PGenerate a pla old package\.json usg legacy it:.P.RS 2.nf$ mkdir my\-npm\-pkg && cd my\-npm\-pkg$ git it$ npm it.fi.RE.PGenerate it without havg it ask any questions:.P.RS 2.nf$ npm it \-y.fi.RE.SS Workspaces support.PIt's possible to create a new workspace with your project  usg the\fBworkspace\fP config option\. When usg \fBnpm it \-w <dir>\fP the cli willcreate the folders  boilerplate expected while also addg a referenceto your project \fBpackage\.json\fP \fB"workspaces": []\fP property  order to makesure that new generated \fBworkspace\fR is properly set up as such\..PGiven a project with no workspaces, e\.g:.P.RS 2.nf\|\.+\-\- package\.json.fi.RE.PYou may generate a new workspace usg the legacy it:.P.RS 2.nf$ npm it \-w packages/a.fi.RE.PThat will generate a new folder  \fBpackage\.json\fP file, while also updatgyour top\-level \fBpackage\.json\fP to add the reference to  new workspace:.P.RS 2.nf\|\.+\-\- package\.json`\-\- packages   `\-\- a       `\-\- package\.json.fi.RE.P workspaces it also supports the \fBnpm it <itializer> \-w <dir>\fPsyntax, followg the same set of rules explaed earlier  the itial\fBDescription\fR section of  page\. Similar to the previous example ofcreatg a new React\-based project usg\fBcreate\-react\-app\fP \fIhttps://npm\.im/create\-react\-app\fR, the followg syntaxwill make sure to create the new react app as a nested \fBworkspace\fR with yourproject  configure your \fBpackage\.json\fP to recognize it as such:.P.RS 2.nfnpm it \-w packages/my\-react\-app react\-app \..fi.RE.PThis will make sure to generate your react app as expected, one importantconsideration to have  md is that \fBnpm exec\fP is gog to be run  thecontext of the newly created folder for that workspace,  that's the reasonwhy   example the itializer uses the itializer name followed with adot to represent the current directory  that context, e\.g: \fBreact\-app \.\fP:.P.RS 2.nf\|\.+\-\- package\.json`\-\- packages   +\-\- a   |   `\-\- package\.json   `\-\- my\-react\-app       +\-\- README       +\-\- package\.json       `\-\- \.\.\..fi.RE.SS Configuration.SS \fByes\fP.RS 0.IP \(bu 2Default: null.IP \(bu 2Type: null or Boolean.RE.PAutomatically answer "yes" to any prompts that npm might prt on thecomm le\..SS \fBforce\fP.RS 0.IP \(bu 2Default: false.IP \(bu 2Type: Boolean.RE.PRemoves various protections agast unfortunate side effects, commonmistakes, unnecessary performance degradation,  malicious put\..RS 0.IP \(bu 2Allow clobberg non\-npm files  global stalls\..IP \(bu 2Allow the \fBnpm version\fP comm to work on an unclean git repository\..IP \(bu 2Allow deletg the cache folder with \fBnpm cache clean\fP\|\..IP \(bu 2Allow stallg packages that have an \fBenges\fP declaration requirg adifferent version of npm\..IP \(bu 2Allow stallg packages that have an \fBenges\fP declaration requirg adifferent version of \fBnode\fP, even if \fB\-\-enge\-strict\fP is enabled\..IP \(bu 2Allow \fBnpm audit fix\fP to stall modules outside your stated dependencyrange (cludg SemVer\-major changes)\..IP \(bu 2Allow unpublishg all versions of a published package\..IP \(bu 2Allow conflictg peerDependencies to be stalled  the root project\..IP \(bu 2Implicitly set \fB\-\-yes\fP durg \fBnpm it\fP\|\..IP \(bu 2Allow clobberg existg values  \fBnpm pkg\fP.IP \(bu 2Allow unpublishg of entire packages (not just a sgle version)\..RE.PIf you don't have a clear idea of what you want to do, it is stronglyrecommended that you do not use  option!.SS \fBworkspace\fP.RS 0.IP \(bu 2Default:.IP \(bu 2Type: Strg (can be set multiple times).RE.PEnable runng a comm  the context of the configured workspaces of thecurrent project while filterg  runng only the workspaces defed  configuration option\..PValid values for the \fBworkspace\fP config  either:.RS 0.IP \(bu 2Workspace names.IP \(bu 2Path to a workspace directory.IP \(bu 2Path to a pnt workspace directory (will result  selectg allworkspaces with that folder).RE.PWhen set for the \fBnpm it\fP comm,  may be set to the folder of aworkspace which does not yet exist, to create the folder  set it up as abr new workspace with the project\..PThis value is not exported to the environment for child processes\..SS \fBworkspaces\fP.RS 0.IP \(bu 2Default: null.IP \(bu 2Type: null or Boolean.RE.PSet to true to run the comm  the context of \fBall\fR configuredworkspaces\..PExplicitly settg  to false will cause comms like \fBstall\fP toignore workspaces altogether\. When not set explicitly:.RS 0.IP \(bu 2Comms that operate on the \fBnode_modules\fP tree (stall, update, etc\.)will lk workspaces to the \fBnode_modules\fP folder\. \- Comms that doother thgs (test, exec, publish, etc\.) will operate on the root project,\fIunless\fR one or more workspaces  specified  the \fBworkspace\fP config\..RE.PThis value is not exported to the environment for child processes\..SS \fBworkspaces\-update\fP.RS 0.IP \(bu 2Default: true.IP \(bu 2Type: Boolean.RE.PIf set to true, the npm cli will run an update after operations that maypossibly change the workspaces stalled to the \fBnode_modules\fP folder\..SS \fBclude\-workspace\-root\fP.RS 0.IP \(bu 2Default: false.IP \(bu 2Type: Boolean.RE.PInclude the workspace root when workspaces  enabled for a comm\..PWhen false, specifyg dividual workspaces via the \fBworkspace\fP config, orall workspaces via the \fBworkspaces\fP flag, will cause npm to operate only onthe specified workspaces,  not on the root project\..PThis value is not exported to the environment for child processes\..SS See Also.RS 0.IP \(bu 2it\-package\-json module \fIhttp://npm\.im/it\-package\-json\fR.IP \(bu 2npm help package\.json.IP \(bu 2npm help version.IP \(bu 2npm help scope.IP \(bu 2npm help exec.IP \(bu 2npm help workspaces.REvar archy = require('../');var s = archy({  label : 'beep',  nodes : [    'ity',    {      label : 'boop',      nodes : [        {          label : 'o_O',          nodes : [            {              label : 'oh',              nodes : [ 'hello', 'puny' ]            },            'human'          ]        },        'party\ntime!'      ]    }  ]});console.log(s);var archy = require('../');var s = archy({  label : 'beep\none\ntwo',  nodes : [    'ity',    {      label : 'boop',      nodes : [        {          label : 'o_O\nwheee',          nodes : [            {              label : 'oh',              nodes : [ 'hello', 'puny\nmeat' ]            },            'creature'          ]        },        'party\ntime!'      ]    }  ]});console.log(s);var defaults = require('./'),    test = require('tap').test;test("ensure options is an object", function(t) {  var options = defaults(false, { a : true });  t.ok(options.a);  t.end()});test("ensure defaults override keys", function(t) {  var result = defaults({}, { a: false, b: true });  t.ok(result.b, 'b merges over undefed');  t.equal(result.a, false, 'a merges over undefed');  t.end();});test("ensure defed keys  not over", function(t) {  var result = defaults({ b: false }, { a: false, b: true });  t.equal(result.b, false, 'b not merged');  t.equal(result.a, false, 'a merges over undefed');  t.end();});test("ensure defaults clone nested objects", function(t) {  var d = { a: [1,2,3], b: { hello : 'world' } };  var result = defaults({}, d);  t.equal(result.a.length, 3, 'objects should be clones');  t.ok(result.a !== d.a, 'objects should be clones');  t.equal(Object.keys(result.b).length, 1, 'objects should be clones');  t.ok(result.b !== d.b, 'objects should be clones');  t.end();});{  "name": "err-code",  "version": "1.1.1",  "description": "Create new error stances with a code  additional properties",  "ma": "dex.umd.js",  "homepage": "https://github.com/IndigoUnited/js-err-code",  "authors": [    "IndigoUnited <hello@digounited.com> (http://digounited.com)"  ],  "moduleType": [    "amd",    "globals",    "node"  ],  "keywords": [      "error",      "err",      "code",      "properties",      "property"  ],  "license": "MIT",  "ignore": [    "**/.*",    "node_modules",    "bower_components",    "test",    "tests"  ]}{  "name": "err-code",  "version": "2.0.3",  "description": "Create an error with a code",  "ma": "dex.js",  "scripts": {    "lt": "eslt '{*.js,test/**/*.js}' --ignore-pattern *.umd.js",    "test": "mocha --bail",    "browserify": "browserify -s err-code dex.js > dex.umd.js"  },  "bugs": {    "url": "https://github.com/IndigoUnited/js-err-code/issues/"  },  "repository": {    "type": "git",    "url": "git://github.com/IndigoUnited/js-err-code.git"  },  "keywords": [    "error",    "err",    "code",    "properties",    "property"  ],  "author": "IndigoUnited <hello@digounited.com> (http://digounited.com)",  "license": "MIT",  "devDependencies": {    "@satazor/eslt-config": "^3.0.0",    "browserify": "^16.5.1",    "eslt": "^7.2.0",    "expect.js": "^0.3.1",    "mocha": "^8.0.1"  }}# Copyright (c) 2012 Google Inc. All rights reserved.# Use of  source code is governed  a BSD-style license that can be# found  the LICENSE file."""This module contas classes that help to emulate xcodebuild behavior on top ofother build systems, such as make  nja."""import copyimport gyp.commonimport osimport os.pathimport reimport shleximport subprocessimport sysfrom gyp.common import GypError# Populated lazily  XcodeVersion, for efficiency,  to fix an issue when# "xcodebuild" is called too quickly (it has been found to return correct# version number).XCODE_VERSION_CACHE = None# Populated lazily  GetXcodeArchsDefault, to an |XcodeArchsDefault| stance# correspondg to the stalled version of Xcode.XCODE_ARCHS_DEFAULT_CACHE = Nonedef XcodeArchsVariableMappg(archs, archs_cludg_64_bit=None):    """Constructs a dictionary with expansion for $(ARCHS_STANDARD) variable,   optionally for $(ARCHS_STANDARD_INCLUDING_64_BIT)."""    mappg = {"$(ARCHS_STANDARD)": archs}    if archs_cludg_64_bit:        mappg["$(ARCHS_STANDARD_INCLUDING_64_BIT)"] = archs_cludg_64_bit    return mappgclass XcodeArchsDefault:    """A class to resolve ARCHS variable from xcode_settgs, resolvg Xcode  macros  implementg filterg  VALID_ARCHS.  expansion of macros  depends on the SDKROOT used ("macosx", "iphoneos", "iphonesimulator")   on the version of Xcode.  """    # Match variable like $(ARCHS_STANDARD).    variable_pattern = re.compile(r"\$\([a-zA-Z_][a-zA-Z0-9_]*\)$")    def __it__(self, default, mac, iphonesimulator, iphoneos):        self._default = (default,)        self._archs = {"mac": mac, "ios": iphoneos, "iossim": iphonesimulator}    def _VariableMappg(self, sdkroot):        """Returns the dictionary of variable mappg dependg on the SDKROOT."""        sdkroot = sdkroot.lower()        if "iphoneos"  sdkroot:            return self._archs["ios"]        elif "iphonesimulator"  sdkroot:            return self._archs["iossim"]        else:            return self._archs["mac"]    def _ExpArchs(self, archs, sdkroot):        """Exps variables references  ARCHS,  remove duplicates."""        variable_mappg = self._VariableMappg(sdkroot)        exped_archs = []        for arch  archs:            if self.variable_pattern.match(arch):                variable = arch                try:                    variable_expansion = variable_mappg[variable]                    for arch  variable_expansion:                        if arch not  exped_archs:                            exped_archs.append(arch)                except KeyError:                    prt('Warng: Ignorg unsupported variable "%s".' % variable)            elif arch not  exped_archs:                exped_archs.append(arch)        return exped_archs    def ActiveArchs(self, archs, valid_archs, sdkroot):        """Exps variables references  ARCHS,  filter  VALID_ARCHS if it    is defed (if not set, Xcode accept any value  ARCHS, otherwise, only    values present  VALID_ARCHS  kept)."""        exped_archs = self._ExpArchs(archs or self._default, sdkroot or "")        if valid_archs:            filtered_archs = []            for arch  exped_archs:                if arch  valid_archs:                    filtered_archs.append(arch)            exped_archs = filtered_archs        return exped_archsdef GetXcodeArchsDefault():    """Returns the |XcodeArchsDefault| object to use to exp ARCHS for the  stalled version of Xcode.  default values used  Xcode for ARCHS   the expansion of the variables depends on the version of Xcode used.  For all version anterior to Xcode 5.0 or posterior to Xcode 5.1 cluded  uses $(ARCHS_STANDARD) if ARCHS is unset, while Xcode 5.0 to 5.0.2 uses  $(ARCHS_STANDARD_INCLUDING_64_BIT). This variable was added to Xcode 5.0   deprecated with Xcode 5.1.  For "macosx" SDKROOT, all version startg with Xcode 5.0 cludes 64-bit  architecture as part of $(ARCHS_STANDARD)  default to only buildg it.  For "iphoneos"  "iphonesimulator" SDKROOT, 64-bit architectures  part  of $(ARCHS_STANDARD_INCLUDING_64_BIT) from Xcode 5.0. From Xcode 5.1, they   also part of $(ARCHS_STANDARD).  All these rules  coded  the construction of the |XcodeArchsDefault|  object to use dependg on the version of Xcode detected.  object is  for performance reason."""    global XCODE_ARCHS_DEFAULT_CACHE    if XCODE_ARCHS_DEFAULT_CACHE:        return XCODE_ARCHS_DEFAULT_CACHE    xcode_version, _ = XcodeVersion()    if xcode_version < "0500":        XCODE_ARCHS_DEFAULT_CACHE = XcodeArchsDefault(            "$(ARCHS_STANDARD)",            XcodeArchsVariableMappg(["i386"]),            XcodeArchsVariableMappg(["i386"]),            XcodeArchsVariableMappg(["armv7"]),        )    elif xcode_version < "0510":        XCODE_ARCHS_DEFAULT_CACHE = XcodeArchsDefault(            "$(ARCHS_STANDARD_INCLUDING_64_BIT)",            XcodeArchsVariableMappg(["x86_64"], ["x86_64"]),            XcodeArchsVariableMappg(["i386"], ["i386", "x86_64"]),            XcodeArchsVariableMappg(                ["armv7", "armv7s"], ["armv7", "armv7s", "arm64"]            ),        )    else:        XCODE_ARCHS_DEFAULT_CACHE = XcodeArchsDefault(            "$(ARCHS_STANDARD)",            XcodeArchsVariableMappg(["x86_64"], ["x86_64"]),            XcodeArchsVariableMappg(["i386", "x86_64"], ["i386", "x86_64"]),            XcodeArchsVariableMappg(                ["armv7", "armv7s", "arm64"], ["armv7", "armv7s", "arm64"]            ),        )    return XCODE_ARCHS_DEFAULT_CACHEclass XcodeSettgs:    """A class that understs the gyp 'xcode_settgs' object."""    # Populated lazily  _SdkPath(). Shd  all XcodeSettgs, so cached    # at class-level for efficiency.    _sdk_path_cache = {}    _platform_path_cache = {}    _sdk_root_cache = {}    # Populated lazily  GetExtraPlistItems(). Shd  all XcodeSettgs, so    # cached at class-level for efficiency.    _plist_cache = {}    # Populated lazily  GetIOSPostbuilds.  Shd  all XcodeSettgs, so    # cached at class-level for efficiency.    _codesigng_key_cache = {}    def __it__(self, spec):        self.spec = spec        self.isIOS = False        self.mac_toolcha_dir = None        self.header_map_path = None        # Per-target 'xcode_settgs'  pushed down to configs earlier  gyp.        # This means self.xcode_settgs[config] always contas all settgs        # for that config -- the per-target settgs as well. Settgs that         # the same for all configs  implicitly per-target settgs.        self.xcode_settgs = {}        configs = spec["configurations"]        for configname, config  configs.items():            self.xcode_settgs[configname] = config.get("xcode_settgs", {})            self._ConvertConditionalKeys(configname)            if self.xcode_settgs[configname].get("IPHONEOS_DEPLOYMENT_TARGET", None):                self.isIOS = True        # This is only non-None temporarily durg the execution of some methods.        self.configname = None        # Used  _AdjustLibrary to match .a  .dylib entries  libraries.        self.library_re = re.compile(r"^lib([^/]+)\.(a|dylib)$")    def _ConvertConditionalKeys(self, configname):        """Converts or warns on conditional keys.  Xcode supports conditional keys,    such as CODE_SIGN_IDENTITY[sdk=iphoneos*].  This is a partial implementation    with some keys converted while the rest force a warng."""        settgs = self.xcode_settgs[configname]        conditional_keys = [key for key  settgs if key.endswith("]")]        for key  conditional_keys:            # If you need more, speak up at http://crbug.com/122592            if key.endswith("[sdk=iphoneos*]"):                if configname.endswith("iphoneos"):                    new_key = key.split("[")[0]                    settgs[new_key] = settgs[key]            else:                prt(                    "Warng: Conditional keys not implemented, ignorg:",                    " ".jo(conditional_keys),                )            del settgs[key]    def _Settgs(self):        assert self.configname        return self.xcode_settgs[self.configname]    def _Test(self, test_key, cond_key, default):        return self._Settgs().get(test_key, default) == cond_key    def _Appendf(self, lst, test_key, format_str, default=None):        if test_key  self._Settgs():            lst.append(format_str % str(self._Settgs()[test_key]))        elif default:            lst.append(format_str % str(default))    def _WarnUnimplemented(self, test_key):        if test_key  self._Settgs():            prt('Warng: Ignorg not yet implemented key "%s".' % test_key)    def IsBaryOutputFormat(self, configname):        default = "bary" if self.isIOS else "xml"        format = self.xcode_settgs[configname].get("INFOPLIST_OUTPUT_FORMAT", default)        return format == "bary"    def IsIosFramework(self):        return self.spec["type"] == "shd_library"  self._IsBundle()  self.isIOS    def _IsBundle(self):        return (            t(self.spec.get("mac_bundle", 0)) != 0            or self._IsXCTest()            or self._IsXCUiTest()        )    def _IsXCTest(self):        return t(self.spec.get("mac_xctest_bundle", 0)) != 0    def _IsXCUiTest(self):        return t(self.spec.get("mac_xcuitest_bundle", 0)) != 0    def _IsIosAppExtension(self):        return t(self.spec.get("ios_app_extension", 0)) != 0    def _IsIosWatchKitExtension(self):        return t(self.spec.get("ios_watchkit_extension", 0)) != 0    def _IsIosWatchApp(self):        return t(self.spec.get("ios_watch_app", 0)) != 0    def GetFrameworkVersion(self):        """Returns the framework version of the current target. Only valid for    bundles."""        assert self._IsBundle()        return self.GetPerTargetSettg("FRAMEWORK_VERSION", default="A")    def GetWrapperExtension(self):        """Returns the bundle extension (.app, .framework, .plug, etc).  Only    valid for bundles."""        assert self._IsBundle()        if self.spec["type"]  ("loadable_module", "shd_library"):            default_wrapper_extension = {                "loadable_module": "bundle",                "shd_library": "framework",            }[self.spec["type"]]            wrapper_extension = self.GetPerTargetSettg(                "WRAPPER_EXTENSION", default=default_wrapper_extension            )            return "." + self.spec.get("product_extension", wrapper_extension)        elif self.spec["type"] == "executable":            if self._IsIosAppExtension() or self._IsIosWatchKitExtension():                return "." + self.spec.get("product_extension", "appex")            else:                return "." + self.spec.get("product_extension", "app")        else:            assert False, "Don't know extension for '{}', target '{}'".format(                self.spec["type"],                self.spec["target_name"],            )    def GetProductName(self):        """Returns PRODUCT_NAME."""        return self.spec.get("product_name", self.spec["target_name"])    def GetFullProductName(self):        """Returns FULL_PRODUCT_NAME."""        if self._IsBundle():            return self.GetWrapperName()        else:            return self._GetStaloneBaryPath()    def GetWrapperName(self):        """Returns the directory name of the bundle represented   target.    Only valid for bundles."""        assert self._IsBundle()        return self.GetProductName() + self.GetWrapperExtension()    def GetBundleContentsFolderPath(self):        """Returns the qualified path to the bundle's contents folder. E.g.    Chromium.app/Contents or Foo.bundle/Versions/A. Only valid for bundles."""        if self.isIOS:            return self.GetWrapperName()        assert self._IsBundle()        if self.spec["type"] == "shd_library":            return os.path.jo(                self.GetWrapperName(), "Versions", self.GetFrameworkVersion()            )        else:            # loadable_modules have a 'Contents' folder like executables.            return os.path.jo(self.GetWrapperName(), "Contents")    def GetBundleResourceFolder(self):        """Returns the qualified path to the bundle's resource folder. E.g.    Chromium.app/Contents/Resources. Only valid for bundles."""        assert self._IsBundle()        if self.isIOS:            return self.GetBundleContentsFolderPath()        return os.path.jo(self.GetBundleContentsFolderPath(), "Resources")    def GetBundleExecutableFolderPath(self):        """Returns the qualified path to the bundle's executables folder. E.g.    Chromium.app/Contents/MacOS. Only valid for bundles."""        assert self._IsBundle()        if self.spec["type"]  ("shd_library") or self.isIOS:            return self.GetBundleContentsFolderPath()        elif self.spec["type"]  ("executable", "loadable_module"):            return os.path.jo(self.GetBundleContentsFolderPath(), "MacOS")    def GetBundleJavaFolderPath(self):        """Returns the qualified path to the bundle's Java resource folder.    E.g. Chromium.app/Contents/Resources/Java. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(self.GetBundleResourceFolder(), "Java")    def GetBundleFrameworksFolderPath(self):        """Returns the qualified path to the bundle's frameworks folder. E.g,    Chromium.app/Contents/Frameworks. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(self.GetBundleContentsFolderPath(), "Frameworks")    def GetBundleShdFrameworksFolderPath(self):        """Returns the qualified path to the bundle's frameworks folder. E.g,    Chromium.app/Contents/ShdFrameworks. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(self.GetBundleContentsFolderPath(), "ShdFrameworks")    def GetBundleShdSupportFolderPath(self):        """Returns the qualified path to the bundle's shd support folder. E.g,    Chromium.app/Contents/ShdSupport. Only valid for bundles."""        assert self._IsBundle()        if self.spec["type"] == "shd_library":            return self.GetBundleResourceFolder()        else:            return os.path.jo(self.GetBundleContentsFolderPath(), "ShdSupport")    def GetBundlePlugInsFolderPath(self):        """Returns the qualified path to the bundle's plugs folder. E.g,    Chromium.app/Contents/PlugIns. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(self.GetBundleContentsFolderPath(), "PlugIns")    def GetBundleXPCServicesFolderPath(self):        """Returns the qualified path to the bundle's XPC services folder. E.g,    Chromium.app/Contents/XPCServices. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(self.GetBundleContentsFolderPath(), "XPCServices")    def GetBundlePlistPath(self):        """Returns the qualified path to the bundle's plist file. E.g.    Chromium.app/Contents/Info.plist. Only valid for bundles."""        assert self._IsBundle()        if (            self.spec["type"]  ("executable", "loadable_module")            or self.IsIosFramework()        ):            return os.path.jo(self.GetBundleContentsFolderPath(), "Info.plist")        else:            return os.path.jo(                self.GetBundleContentsFolderPath(), "Resources", "Info.plist"            )    def GetProductType(self):        """Returns the PRODUCT_TYPE of  target."""        if self._IsIosAppExtension():            assert self._IsBundle(), (                "ios_app_extension flag requires mac_bundle "                "(target %s)" % self.spec["target_name"]            )            return "com.apple.product-type.app-extension"        if self._IsIosWatchKitExtension():            assert self._IsBundle(), (                "ios_watchkit_extension flag requires "                "mac_bundle (target %s)" % self.spec["target_name"]            )            return "com.apple.product-type.watchkit-extension"        if self._IsIosWatchApp():            assert self._IsBundle(), (                "ios_watch_app flag requires mac_bundle "                "(target %s)" % self.spec["target_name"]            )            return "com.apple.product-type.application.watchapp"        if self._IsXCUiTest():            assert self._IsBundle(), (                "mac_xcuitest_bundle flag requires mac_bundle "                "(target %s)" % self.spec["target_name"]            )            return "com.apple.product-type.bundle.ui-testg"        if self._IsBundle():            return {                "executable": "com.apple.product-type.application",                "loadable_module": "com.apple.product-type.bundle",                "shd_library": "com.apple.product-type.framework",            }[self.spec["type"]]        else:            return {                "executable": "com.apple.product-type.tool",                "loadable_module": "com.apple.product-type.library.dynamic",                "shd_library": "com.apple.product-type.library.dynamic",                "static_library": "com.apple.product-type.library.static",            }[self.spec["type"]]    def GetMachOType(self):        """Returns the MACH_O_TYPE of  target."""        # Weird, but matches Xcode.        if not self._IsBundle()  self.spec["type"] == "executable":            return ""        return {            "executable": "mh_execute",            "static_library": "staticlib",            "shd_library": "mh_dylib",            "loadable_module": "mh_bundle",        }[self.spec["type"]]    def _GetBundleBaryPath(self):        """Returns the name of the bundle bary of   target.    E.g. Chromium.app/Contents/MacOS/Chromium. Only valid for bundles."""        assert self._IsBundle()        return os.path.jo(            self.GetBundleExecutableFolderPath(), self.GetExecutableName()        )    def _GetStaloneExecutableSuffix(self):        if "product_extension"  self.spec:            return "." + self.spec["product_extension"]        return {            "executable": "",            "static_library": ".a",            "shd_library": ".dylib",            "loadable_module": ".so",        }[self.spec["type"]]    def _GetStaloneExecutablePrefix(self):        return self.spec.get(            "product_prefix",            {                "executable": "",                "static_library": "lib",                "shd_library": "lib",                # Non-bundled loadable_modules  called foo.so for some reason                # (that is, .so  no prefix) with the xcode build -- match that.                "loadable_module": "",            }[self.spec["type"]],        )    def _GetStaloneBaryPath(self):        """Returns the name of the non-bundle bary represented   target.    E.g. hello_world. Only valid for non-bundles."""        assert not self._IsBundle()        assert self.spec["type"]  (            "executable",            "shd_library",            "static_library",            "loadable_module",        ), ("Unexpected type %s" % self.spec["type"])        target = self.spec["target_name"]        if self.spec["type"] == "static_library":            if target[:3] == "lib":                target = target[3:]        elif self.spec["type"]  ("loadable_module", "shd_library"):            if target[:3] == "lib":                target = target[3:]        target_prefix = self._GetStaloneExecutablePrefix()        target = self.spec.get("product_name", target)        target_ext = self._GetStaloneExecutableSuffix()        return target_prefix + target + target_ext    def GetExecutableName(self):        """Returns the executable name of the bundle represented   target.    E.g. Chromium."""        if self._IsBundle():            return self.spec.get("product_name", self.spec["target_name"])        else:            return self._GetStaloneBaryPath()    def GetExecutablePath(self):        """Returns the qualified path to the primary executable of the bundle    represented   target. E.g. Chromium.app/Contents/MacOS/Chromium."""        if self._IsBundle():            return self._GetBundleBaryPath()        else:            return self._GetStaloneBaryPath()    def GetActiveArchs(self, configname):        """Returns the architectures  target should be built for."""        config_settgs = self.xcode_settgs[configname]        xcode_archs_default = GetXcodeArchsDefault()        return xcode_archs_default.ActiveArchs(            config_settgs.get("ARCHS"),            config_settgs.get("VALID_ARCHS"),            config_settgs.get("SDKROOT"),        )    def _GetSdkVersionInfoItem(self, sdk, foitem):        # xcodebuild requires Xcode  can't run on Comm Le Tools-only        # systems from 10.7 onward.        # Sce the CLT has no SDK paths anyway, returng None is the        # most sensible route  should still do the right thg.        try:            return GetStdoutQuiet(["xcrun", "--sdk", sdk, foitem])        except GypError:            pass    def _SdkRoot(self, configname):        if configname is None:            configname = self.configname        return self.GetPerConfigSettg("SDKROOT", configname, default="")    def _XcodePlatformPath(self, configname=None):        sdk_root = self._SdkRoot(configname)        if sdk_root not  XcodeSettgs._platform_path_cache:            platform_path = self._GetSdkVersionInfoItem(                sdk_root, "--show-sdk-platform-path"            )            XcodeSettgs._platform_path_cache[sdk_root] = platform_path        return XcodeSettgs._platform_path_cache[sdk_root]    def _SdkPath(self, configname=None):        sdk_root = self._SdkRoot(configname)        if sdk_root.startswith("/"):            return sdk_root        return self._XcodeSdkPath(sdk_root)    def _XcodeSdkPath(self, sdk_root):        if sdk_root not  XcodeSettgs._sdk_path_cache:            sdk_path = self._GetSdkVersionInfoItem(sdk_root, "--show-sdk-path")            XcodeSettgs._sdk_path_cache[sdk_root] = sdk_path            if sdk_root:                XcodeSettgs._sdk_root_cache[sdk_path] = sdk_root        return XcodeSettgs._sdk_path_cache[sdk_root]    def _AppendPlatformVersionMFlags(self, lst):        self._Appendf(lst, "MACOSX_DEPLOYMENT_TARGET", "-mmacosx-version-m=%s")        if "IPHONEOS_DEPLOYMENT_TARGET"  self._Settgs():            # TODO: Implement  better?            sdk_path_basename = os.path.basename(self._SdkPath())            if sdk_path_basename.lower().startswith("iphonesimulator"):                self._Appendf(                    lst, "IPHONEOS_DEPLOYMENT_TARGET", "-mios-simulator-version-m=%s"                )            else:                self._Appendf(                    lst, "IPHONEOS_DEPLOYMENT_TARGET", "-miphoneos-version-m=%s"                )    def GetCflags(self, configname, arch=None):        """Returns flags that need to be added to .c, .cc, .m,  .mm    compilations."""        # This functions ( the similar ones below) do not offer complete        # emulation of all xcode_settgs keys. y're implemented on dem.        self.configname = configname        cflags = []        sdk_root = self._SdkPath()        if "SDKROOT"  self._Settgs()  sdk_root:            cflags.append("-isysroot %s" % sdk_root)        if self.header_map_path:            cflags.append("-I%s" % self.header_map_path)        if self._Test("CLANG_WARN_CONSTANT_CONVERSION", "YES", default="NO"):            cflags.append("-Wconstant-conversion")        if self._Test("GCC_CHAR_IS_UNSIGNED_CHAR", "YES", default="NO"):            cflags.append("-funsigned-char")        if self._Test("GCC_CW_ASM_SYNTAX", "YES", default="YES"):            cflags.append("-fasm-blocks")        if "GCC_DYNAMIC_NO_PIC"  self._Settgs():            if self._Settgs()["GCC_DYNAMIC_NO_PIC"] == "YES":                cflags.append("-mdynamic-no-pic")        else:            pass            # TODO: In  case, it depends on the target. xcode passes            # mdynamic-no-pic  default for executable  possibly static lib            # accordg to mento        if self._Test("GCC_ENABLE_PASCAL_STRINGS", "YES", default="YES"):            cflags.append("-mpascal-strgs")        self._Appendf(cflags, "GCC_OPTIMIZATION_LEVEL", "-O%s", default="s")        if self._Test("GCC_GENERATE_DEBUGGING_SYMBOLS", "YES", default="YES"):            dbg_format = self._Settgs().get("DEBUG_INFORMATION_FORMAT", "dwarf")            if dbg_format == "dwarf":                cflags.append("-gdwarf-2")            elif dbg_format == "stabs":                raise NotImplementedError("stabs debug format is not supported yet.")            elif dbg_format == "dwarf-with-dsym":                cflags.append("-gdwarf-2")            else:                raise NotImplementedError("Unknown debug format %s" % dbg_format)        if self._Settgs().get("GCC_STRICT_ALIASING") == "YES":            cflags.append("-fstrict-aliasg")        elif self._Settgs().get("GCC_STRICT_ALIASING") == "NO":            cflags.append("-fno-strict-aliasg")        if self._Test("GCC_SYMBOLS_PRIVATE_EXTERN", "YES", default="NO"):            cflags.append("-fvisibility=hidden")        if self._Test("GCC_TREAT_WARNINGS_AS_ERRORS", "YES", default="NO"):            cflags.append("-Werror")        if self._Test("GCC_WARN_ABOUT_MISSING_NEWLINE", "YES", default="NO"):            cflags.append("-Wnewle-eof")        # In Xcode,  is only activated when GCC_COMPILER_VERSION is clang or        # llvm-gcc. It also requires a fairly recent libtool,         # if the system clang isn't used, DYLD_LIBRARY_PATH needs to conta the        # path to the libLTO.dylib that matches the used clang.        if self._Test("LLVM_LTO", "YES", default="NO"):            cflags.append("-flto")        self._AppendPlatformVersionMFlags(cflags)        # TODO:        if self._Test("COPY_PHASE_STRIP", "YES", default="NO"):            self._WarnUnimplemented("COPY_PHASE_STRIP")        self._WarnUnimplemented("GCC_DEBUGGING_SYMBOLS")        self._WarnUnimplemented("GCC_ENABLE_OBJC_EXCEPTIONS")        # TODO: This is exported correctly, but assigng to it is not supported.        self._WarnUnimplemented("MACH_O_TYPE")        self._WarnUnimplemented("PRODUCT_TYPE")        # If GYP_CROSSCOMPILE (--cross-compilg), disable architecture-specific        # additions  assume these will be provided as required via CC_host,        # CXX_host, CC_target  CXX_target.        if not gyp.common.CrossCompileRequested():            if arch is not None:                archs = [arch]            else:                assert self.configname                archs = self.GetActiveArchs(self.configname)            if len(archs) != 1:                # TODO: Supportg fat baries will be annoyg.                self._WarnUnimplemented("ARCHS")                archs = ["i386"]            cflags.append("-arch " + archs[0])            if archs[0]  ("i386", "x86_64"):                if self._Test("GCC_ENABLE_SSE3_EXTENSIONS", "YES", default="NO"):                    cflags.append("-msse3")                if self._Test(                    "GCC_ENABLE_SUPPLEMENTAL_SSE3_INSTRUCTIONS", "YES", default="NO"                ):                    cflags.append("-mssse3")  # Note 3rd 's'.                if self._Test("GCC_ENABLE_SSE41_EXTENSIONS", "YES", default="NO"):                    cflags.append("-msse4.1")                if self._Test("GCC_ENABLE_SSE42_EXTENSIONS", "YES", default="NO"):                    cflags.append("-msse4.2")        cflags += self._Settgs().get("WARNING_CFLAGS", [])        if self._IsXCTest():            platform_root = self._XcodePlatformPath(configname)            if platform_root:                cflags.append("-F" + platform_root + "/Developer/Library/Frameworks/")        if sdk_root:            framework_root = sdk_root        else:            framework_root = ""        config = self.spec["configurations"][self.configname]        framework_dirs = config.get("mac_framework_dirs", [])        for directory  framework_dirs:            cflags.append("-F" + directory.replace("$(SDKROOT)", framework_root))        self.configname = None        return cflags    def GetCflagsC(self, configname):        """Returns flags that need to be added to .c,  .m compilations."""        self.configname = configname        cflags_c = []        if self._Settgs().get("GCC_C_LANGUAGE_STANDARD", "") == "ansi":            cflags_c.append("-ansi")        else:            self._Appendf(cflags_c, "GCC_C_LANGUAGE_STANDARD", "-std=%s")        cflags_c += self._Settgs().get("OTHER_CFLAGS", [])        self.configname = None        return cflags_c    def GetCflagsCC(self, configname):        """Returns flags that need to be added to .cc,  .mm compilations."""        self.configname = configname        cflags_cc = []        clang_cxx_language_stard = self._Settgs().get(            "CLANG_CXX_LANGUAGE_STANDARD"        )        # Note: Don't make c++0x to c++11 so that c++0x can be used with older        # clangs that don't underst c++11 yet (like Xcode 4.2's).        if clang_cxx_language_stard:            cflags_cc.append("-std=%s" % clang_cxx_language_stard)        self._Appendf(cflags_cc, "CLANG_CXX_LIBRARY", "-stdlib=%s")        if self._Test("GCC_ENABLE_CPP_RTTI", "NO", default="YES"):            cflags_cc.append("-fno-rtti")        if self._Test("GCC_ENABLE_CPP_EXCEPTIONS", "NO", default="YES"):            cflags_cc.append("-fno-exceptions")        if self._Test("GCC_INLINES_ARE_PRIVATE_EXTERN", "YES", default="NO"):            cflags_cc.append("-fvisibility-les-hidden")        if self._Test("GCC_THREADSAFE_STATICS", "NO", default="YES"):            cflags_cc.append("-fno-threadsafe-statics")        # Note: This flag is a no-op for clang, it only has an effect for gcc.        if self._Test("GCC_WARN_ABOUT_INVALID_OFFSETOF_MACRO", "NO", default="YES"):            cflags_cc.append("-Wno-valid-offsetof")        other_ccflags = []        for flag  self._Settgs().get("OTHER_CPLUSPLUSFLAGS", ["$(herited)"]):            # TODO: More general variable expansion. Missg  many other places too.            if flag  ("$herited", "$(herited)", "${herited}"):                flag = "$OTHER_CFLAGS"            if flag  ("$OTHER_CFLAGS", "$(OTHER_CFLAGS)", "${OTHER_CFLAGS}"):                other_ccflags += self._Settgs().get("OTHER_CFLAGS", [])            else:                other_ccflags.append(flag)        cflags_cc += other_ccflags        self.configname = None        return cflags_cc    def _AddObjectiveCGarbageCollectionFlags(self, flags):        gc_policy = self._Settgs().get("GCC_ENABLE_OBJC_GC", "unsupported")        if gc_policy == "supported":            flags.append("-fobjc-gc")        elif gc_policy == "required":            flags.append("-fobjc-gc-only")    def _AddObjectiveCARCFlags(self, flags):        if self._Test("CLANG_ENABLE_OBJC_ARC", "YES", default="NO"):            flags.append("-fobjc-arc")    def _AddObjectiveCMissgPropertySynthesisFlags(self, flags):        if self._Test(            "CLANG_WARN_OBJC_MISSING_PROPERTY_SYNTHESIS", "YES", default="NO"        ):            flags.append("-Wobjc-missg-property-synthesis")    def GetCflagsObjC(self, configname):        """Returns flags that need to be added to .m compilations."""        self.configname = configname        cflags_objc = []        self._AddObjectiveCGarbageCollectionFlags(cflags_objc)        self._AddObjectiveCARCFlags(cflags_objc)        self._AddObjectiveCMissgPropertySynthesisFlags(cflags_objc)        self.configname = None        return cflags_objc    def GetCflagsObjCC(self, configname):        """Returns flags that need to be added to .mm compilations."""        self.configname = configname        cflags_objcc = []        self._AddObjectiveCGarbageCollectionFlags(cflags_objcc)        self._AddObjectiveCARCFlags(cflags_objcc)        self._AddObjectiveCMissgPropertySynthesisFlags(cflags_objcc)        if self._Test("GCC_OBJC_CALL_CXX_CDTORS", "YES", default="NO"):            cflags_objcc.append("-fobjc-call-cxx-cdtors")        self.configname = None        return cflags_objcc    def GetInstallNameBase(self):        """Return DYLIB_INSTALL_NAME_BASE for  target."""        # Xcode sets  for shd_libraries,  for nonbundled loadable_modules.        if self.spec["type"] != "shd_library"  (            self.spec["type"] != "loadable_module" or self._IsBundle()        ):            return None        stall_base = self.GetPerTargetSettg(            "DYLIB_INSTALL_NAME_BASE",            default="/Library/Frameworks" if self._IsBundle() else "/usr/local/lib",        )        return stall_base    def _StardizePath(self, path):        """Do :stardizepath processg for path."""        # I'm not quite sure what :stardizepath does. Just call normpath(),        # but don't let @executable_path/../foo collapse to foo.        if "/"  path:            prefix, rest = "", path            if path.startswith("@"):                prefix, rest = path.split("/", 1)            rest = os.path.normpath(rest)  # :stardizepath            path = os.path.jo(prefix, rest)        return path    def GetInstallName(self):        """Return LD_DYLIB_INSTALL_NAME for  target."""        # Xcode sets  for shd_libraries,  for nonbundled loadable_modules.        if self.spec["type"] != "shd_library"  (            self.spec["type"] != "loadable_module" or self._IsBundle()        ):            return None        default_stall_name = (            "$(DYLIB_INSTALL_NAME_BASE:stardizepath)/$(EXECUTABLE_PATH)"        )        stall_name = self.GetPerTargetSettg(            "LD_DYLIB_INSTALL_NAME", default=default_stall_name        )        # Hardcode support for the variables used  chromium for now, to        # unblock people usg the make build.        if "$"  stall_name:            assert stall_name  (                "$(DYLIB_INSTALL_NAME_BASE:stardizepath)/"                "$(WRAPPER_NAME)/$(PRODUCT_NAME)",                default_stall_name,            ), (                "Variables  LD_DYLIB_INSTALL_NAME  not generally supported "                "yet  target '%s' (got '%s')"                % (self.spec["target_name"], stall_name)            )            stall_name = stall_name.replace(                "$(DYLIB_INSTALL_NAME_BASE:stardizepath)",                self._StardizePath(self.GetInstallNameBase()),            )            if self._IsBundle():                # se  only valid for bundles, hence the |if|.                stall_name = stall_name.replace(                    "$(WRAPPER_NAME)", self.GetWrapperName()                )                stall_name = stall_name.replace(                    "$(PRODUCT_NAME)", self.GetProductName()                )            else:                assert "$(WRAPPER_NAME)" not  stall_name                assert "$(PRODUCT_NAME)" not  stall_name            stall_name = stall_name.replace(                "$(EXECUTABLE_PATH)", self.GetExecutablePath()            )        return stall_name    def _MapLkerFlagFilename(self, ldflag, gyp_to_build_path):        """Checks if ldflag contas a filename  if so remaps it from    gyp-directory-relative to build-directory-relative."""        # This list is exped on dem.        # y get matched as:        #   -exported_symbols_list file        #   -Wl,exported_symbols_list file        #   -Wl,exported_symbols_list,file        LINKER_FILE = r"(\S+)"        WORD = r"\S+"        lker_flags = [            ["-exported_symbols_list", LINKER_FILE],  # Needed for NaCl.            ["-unexported_symbols_list", LINKER_FILE],            ["-reexported_symbols_list", LINKER_FILE],            ["-sectcreate", WORD, WORD, LINKER_FILE],  # Needed for remotg.        ]        for flag_pattern  lker_flags:            regex = re.compile("(?:-Wl,)?" + "[ ,]".jo(flag_pattern))            m = regex.match(ldflag)            if m:                ldflag = (                    ldflag[: m.start(1)]                    + gyp_to_build_path(m.group(1))                    + ldflag[m.end(1) :]                )        # Required for ffmpeg (no idea why they don't use LIBRARY_SEARCH_PATHS,        # TODO(thakis): Update ffmpeg.gyp):        if ldflag.startswith("-L"):            ldflag = "-L" + gyp_to_build_path(ldflag[len("-L") :])        return ldflag    def GetLdflags(self, configname, product_dir, gyp_to_build_path, arch=None):        """Returns flags that need to be passed to the lker.    Args:        configname:  name of the configuration to get ld flags for.        product_dir:  directory where products such static  dynamic            libraries  placed. This is added to the library search path.        gyp_to_build_path: A function that converts paths relative to the            current gyp file to paths relative to the build directory.    """        self.configname = configname        ldflags = []        #  xcode build is relative to a gyp file's directory,  OTHER_LDFLAGS        # can conta entries that depend on . Explicitly absolutify these.        for ldflag  self._Settgs().get("OTHER_LDFLAGS", []):            ldflags.append(self._MapLkerFlagFilename(ldflag, gyp_to_build_path))        if self._Test("DEAD_CODE_STRIPPING", "YES", default="NO"):            ldflags.append("-Wl,-dead_strip")        if self._Test("PREBINDING", "YES", default="NO"):            ldflags.append("-Wl,-prebd")        self._Appendf(            ldflags, "DYLIB_COMPATIBILITY_VERSION", "-compatibility_version %s"        )        self._Appendf(ldflags, "DYLIB_CURRENT_VERSION", "-current_version %s")        self._AppendPlatformVersionMFlags(ldflags)        if "SDKROOT"  self._Settgs()  self._SdkPath():            ldflags.append("-isysroot " + self._SdkPath())        for library_path  self._Settgs().get("LIBRARY_SEARCH_PATHS", []):            ldflags.append("-L" + gyp_to_build_path(library_path))        if "ORDER_FILE"  self._Settgs():            ldflags.append(                "-Wl,-order_file "                + "-Wl,"                + gyp_to_build_path(self._Settgs()["ORDER_FILE"])            )        if not gyp.common.CrossCompileRequested():            if arch is not None:                archs = [arch]            else:                assert self.configname                archs = self.GetActiveArchs(self.configname)            if len(archs) != 1:                # TODO: Supportg fat baries will be annoyg.                self._WarnUnimplemented("ARCHS")                archs = ["i386"]            ldflags.append("-arch " + archs[0])        # Xcode adds the product directory  default.        # Rewrite -L. to -L./ to work around http://www.openradar.me/25313838        ldflags.append("-L" + (product_dir if product_dir != "." else "./"))        stall_name = self.GetInstallName()        if stall_name  self.spec["type"] != "loadable_module":            ldflags.append("-stall_name " + stall_name.replace(" ", r"\ "))        for rpath  self._Settgs().get("LD_RUNPATH_SEARCH_PATHS", []):            ldflags.append("-Wl,-rpath," + rpath)        sdk_root = self._SdkPath()        if not sdk_root:            sdk_root = ""        config = self.spec["configurations"][self.configname]        framework_dirs = config.get("mac_framework_dirs", [])        for directory  framework_dirs:            ldflags.append("-F" + directory.replace("$(SDKROOT)", sdk_root))        if self._IsXCTest():            platform_root = self._XcodePlatformPath(configname)            if sdk_root  platform_root:                ldflags.append("-F" + platform_root + "/Developer/Library/Frameworks/")                ldflags.append("-framework XCTest")        is_extension = self._IsIosAppExtension() or self._IsIosWatchKitExtension()        if sdk_root  is_extension:            # Adds the lk flags for extensions. se flags  common for all            # extensions  provide loader  ma function.            # se flags reflect the compilation options used  xcode to compile            # extensions.            xcode_version, _ = XcodeVersion()            if xcode_version < "0900":                ldflags.append("-lpkstart")                ldflags.append(                    sdk_root                    + "/System/Library/PrivateFrameworks/PlugInKit.framework/PlugInKit"                )            else:                ldflags.append("-e _NSExtensionMa")            ldflags.append("-fapplication-extension")        self._Appendf(ldflags, "CLANG_CXX_LIBRARY", "-stdlib=%s")        self.configname = None        return ldflags    def GetLibtoolflags(self, configname):        """Returns flags that need to be passed to the static lker.    Args:        configname:  name of the configuration to get ld flags for.    """        self.configname = configname        libtoolflags = []        for libtoolflag  self._Settgs().get("OTHER_LDFLAGS", []):            libtoolflags.append(libtoolflag)        # TODO(thakis): ARCHS?        self.configname = None        return libtoolflags    def GetPerTargetSettgs(self):        """Gets a list of all the per-target settgs. This will only fetch keys    whose values  the same across all configurations."""        first_pass = True        result = {}        for configname  sorted(self.xcode_settgs.keys()):            if first_pass:                result = dict(self.xcode_settgs[configname])                first_pass = False            else:                for key, value  self.xcode_settgs[configname].items():                    if key not  result:                        contue                    elif result[key] != value:                        del result[key]        return result    def GetPerConfigSettg(self, settg, configname, default=None):        if configname  self.xcode_settgs:            return self.xcode_settgs[configname].get(settg, default)        else:            return self.GetPerTargetSettg(settg, default)    def GetPerTargetSettg(self, settg, default=None):        """Tries to get xcode_settgs.settg from spec. Assumes that the settg       has the same value  all configurations  throws otherwise."""        is_first_pass = True        result = None        for configname  sorted(self.xcode_settgs.keys()):            if is_first_pass:                result = self.xcode_settgs[configname].get(settg, None)                is_first_pass = False            else:                assert result == self.xcode_settgs[configname].get(settg, None), (                    "Expected per-target settg for '%s', got per-config settg "                    "(target %s)" % (settg, self.spec["target_name"])                )        if result is None:            return default        return result    def _GetStripPostbuilds(self, configname, output_bary, quiet):        """Returns a list of shell comms that conta the shell comms    necessary to strip  target's bary. se should be run as postbuilds    before the actual postbuilds run."""        self.configname = configname        result = []        if self._Test("DEPLOYMENT_POSTPROCESSING", "YES", default="NO")  self._Test(            "STRIP_INSTALLED_PRODUCT", "YES", default="NO"        ):            default_strip_style = "debuggg"            if (                self.spec["type"] == "loadable_module" or self._IsIosAppExtension()            )  self._IsBundle():                default_strip_style = "non-global"            elif self.spec["type"] == "executable":                default_strip_style = "all"            strip_style = self._Settgs().get("STRIP_STYLE", default_strip_style)            strip_flags = {"all": "", "non-global": "-x", "debuggg": "-S"}[                strip_style            ]            explicit_strip_flags = self._Settgs().get("STRIPFLAGS", "")            if explicit_strip_flags:                strip_flags += " " + _NormalizeEnvVarReferences(explicit_strip_flags)            if not quiet:                result.append("echo STRIP\\(%s\\)" % self.spec["target_name"])            result.append(f"strip {strip_flags} {output_bary}")        self.configname = None        return result    def _GetDebugInfoPostbuilds(self, configname, output, output_bary, quiet):        """Returns a list of shell comms that conta the shell comms    necessary to massage  target's debug formation. se should be run    as postbuilds before the actual postbuilds run."""        self.configname = configname        # For static libraries, no dSYMs  created.        result = []        if (            self._Test("GCC_GENERATE_DEBUGGING_SYMBOLS", "YES", default="YES")             self._Test(                "DEBUG_INFORMATION_FORMAT", "dwarf-with-dsym", default="dwarf"            )             self.spec["type"] != "static_library"        ):            if not quiet:                result.append("echo DSYMUTIL\\(%s\\)" % self.spec["target_name"])            result.append("dsymutil {} -o {}".format(output_bary, output + ".dSYM"))        self.configname = None        return result    def _GetTargetPostbuilds(self, configname, output, output_bary, quiet=False):        """Returns a list of shell comms that conta the shell comms    to run as postbuilds for  target, before the actual postbuilds."""        # dSYMs need to build before strippg happens.        return self._GetDebugInfoPostbuilds(            configname, output, output_bary, quiet        ) + self._GetStripPostbuilds(configname, output_bary, quiet)    def _GetIOSPostbuilds(self, configname, output_bary):        """Return a shell comm to codesign the iOS output bary so it can    be deployed to a device.  This should be run as the very last step of the    build."""        if not (            self.isIOS             (self.spec["type"] == "executable" or self._IsXCTest())            or self.IsIosFramework()        ):            return []        postbuilds = []        product_name = self.GetFullProductName()        settgs = self.xcode_settgs[configname]        # Xcode expects XCTests to be copied to the TEST_HOST dir.        if self._IsXCTest():            source = os.path.jo("${BUILT_PRODUCTS_DIR}", product_name)            test_host = os.path.dirname(settgs.get("TEST_HOST"))            xctest_destation = os.path.jo(test_host, "PlugIns", product_name)            postbuilds.extend([f"ditto {source} {xctest_destation}"])        key = self._GetIOSCodeSignIdentityKey(settgs)        if not key:            return postbuilds        # Warn for any unimplemented signg xcode keys.        unimpl = ["OTHER_CODE_SIGN_FLAGS"]        unimpl = set(unimpl) & set(self.xcode_settgs[configname].keys())        if unimpl:            prt(                "Warng: Some codesign keys not implemented, ignorg: %s"                % ", ".jo(sorted(unimpl))            )        if self._IsXCTest():            # For device xctests, Xcode copies two extra frameworks to $TEST_HOST.            test_host = os.path.dirname(settgs.get("TEST_HOST"))            frameworks_dir = os.path.jo(test_host, "Frameworks")            platform_root = self._XcodePlatformPath(configname)            frameworks = [                "Developer/Library/PrivateFrameworks/IDEBundleInjection.framework",                "Developer/Library/Frameworks/XCTest.framework",            ]            for framework  frameworks:                source = os.path.jo(platform_root, framework)                destation = os.path.jo(frameworks_dir, os.path.basename(framework))                postbuilds.extend([f"ditto {source} {destation}"])                # n re-sign everythg with 'preserve=True'                postbuilds.extend(                    [                        '%s code-sign-bundle "%s" "%s" "%s" "%s" %s'                        % (                            os.path.jo("${TARGET_BUILD_DIR}", "gyp-mac-tool"),                            key,                            settgs.get("CODE_SIGN_ENTITLEMENTS", ""),                            settgs.get("PROVISIONING_PROFILE", ""),                            destation,                            True,                        )                    ]                )            plug_dir = os.path.jo(test_host, "PlugIns")            targets = [os.path.jo(plug_dir, product_name), test_host]            for target  targets:                postbuilds.extend(                    [                        '%s code-sign-bundle "%s" "%s" "%s" "%s" %s'                        % (                            os.path.jo("${TARGET_BUILD_DIR}", "gyp-mac-tool"),                            key,                            settgs.get("CODE_SIGN_ENTITLEMENTS", ""),                            settgs.get("PROVISIONING_PROFILE", ""),                            target,                            True,                        )                    ]                )        postbuilds.extend(            [                '%s code-sign-bundle "%s" "%s" "%s" "%s" %s'                % (                    os.path.jo("${TARGET_BUILD_DIR}", "gyp-mac-tool"),                    key,                    settgs.get("CODE_SIGN_ENTITLEMENTS", ""),                    settgs.get("PROVISIONING_PROFILE", ""),                    os.path.jo("${BUILT_PRODUCTS_DIR}", product_name),                    False,                )            ]        )        return postbuilds    def _GetIOSCodeSignIdentityKey(self, settgs):        identity = settgs.get("CODE_SIGN_IDENTITY")        if not identity:            return None        if identity not  XcodeSettgs._codesigng_key_cache:            output = subprocess.check_output(                ["security", "fd-identity", "-p", "codesigng", "-v"]            )            for le  output.splitles():                if identity  le:                    fgerprt = le.split()[1]                    cache = XcodeSettgs._codesigng_key_cache                    assert identity not  cache or fgerprt == cache[identity], (                        "Multiple codesigng fgerprts for identity: %s" % identity                    )                    XcodeSettgs._codesigng_key_cache[identity] = fgerprt        return XcodeSettgs._codesigng_key_cache.get(identity, "")    def AddImplicitPostbuilds(        self, configname, output, output_bary, postbuilds=[], quiet=False    ):        """Returns a list of shell comms that should run before  after    |postbuilds|."""        assert output_bary is not None        pre = self._GetTargetPostbuilds(configname, output, output_bary, quiet)        post = self._GetIOSPostbuilds(configname, output_bary)        return pre + postbuilds + post    def _AdjustLibrary(self, library, config_name=None):        if library.endswith(".framework"):            l_flag = "-framework " + os.path.splitext(os.path.basename(library))[0]        else:            m = self.library_re.match(library)            if m:                l_flag = "-l" + m.group(1)            else:                l_flag = library        sdk_root = self._SdkPath(config_name)        if not sdk_root:            sdk_root = ""        # Xcode 7 started shippg with ".tbd" (text based stubs) files stead of        # ".dylib" without providg a real support for them. What it does, for        # "/usr/lib" libraries, is do "-L/usr/lib -lname" which is dependent on the        # library order  cause collision when buildg Chrome.        #        # Instead substitute ".tbd" to ".dylib"  the generated project when the        # followg conditions  both true:        # - library is referenced  the gyp file as "$(SDKROOT)/**/*.dylib",        # - the ".dylib" file does not exists but a ".tbd" file do.        library = l_flag.replace("$(SDKROOT)", sdk_root)        if l_flag.startswith("$(SDKROOT)"):            basename, ext = os.path.splitext(library)            if ext == ".dylib"  not os.path.exists(library):                tbd_library = basename + ".tbd"                if os.path.exists(tbd_library):                    library = tbd_library        return library    def AdjustLibraries(self, libraries, config_name=None):        """Transforms entries like 'Cocoa.framework'  libraries to entries like    '-framework Cocoa', 'libcrypto.dylib' to '-lcrypto', etc.    """        libraries = [self._AdjustLibrary(library, config_name) for library  libraries]        return libraries    def _BuildMacheOSBuild(self):        return GetStdout(["sw_vers", "-buildVersion"])    def _XcodeIOSDeviceFamily(self, configname):        family = self.xcode_settgs[configname].get("TARGETED_DEVICE_FAMILY", "1")        return [t(x) for x  family.split(",")]    def GetExtraPlistItems(self, configname=None):        """Returns a dictionary with extra items to sert to Info.plist."""        if configname not  XcodeSettgs._plist_cache:            cache = {}            cache["BuildMacheOSBuild"] = self._BuildMacheOSBuild()            xcode_version, xcode_build = XcodeVersion()            cache["DTXcode"] = xcode_version            cache["DTXcodeBuild"] = xcode_build            compiler = self.xcode_settgs[configname].get("GCC_VERSION")            if compiler is not None:                cache["DTCompiler"] = compiler            sdk_root = self._SdkRoot(configname)            if not sdk_root:                sdk_root = self._DefaultSdkRoot()            sdk_version = self._GetSdkVersionInfoItem(sdk_root, "--show-sdk-version")            cache["DTSDKName"] = sdk_root + (sdk_version or "")            if xcode_version >= "0720":                cache["DTSDKBuild"] = self._GetSdkVersionInfoItem(                    sdk_root, "--show-sdk-build-version"                )            elif xcode_version >= "0430":                cache["DTSDKBuild"] = sdk_version            else:                cache["DTSDKBuild"] = cache["BuildMacheOSBuild"]            if self.isIOS:                cache["MimumOSVersion"] = self.xcode_settgs[configname].get(                    "IPHONEOS_DEPLOYMENT_TARGET"                )                cache["DTPlatformName"] = sdk_root                cache["DTPlatformVersion"] = sdk_version                if configname.endswith("iphoneos"):                    cache["CFBundleSupportedPlatforms"] = ["iPhoneOS"]                    cache["DTPlatformBuild"] = cache["DTSDKBuild"]                else:                    cache["CFBundleSupportedPlatforms"] = ["iPhoneSimulator"]                    # This is weird, but Xcode sets DTPlatformBuild to an empty field                    # for simulator builds.                    cache["DTPlatformBuild"] = ""            XcodeSettgs._plist_cache[configname] = cache        # Include extra plist items that  per-target, not per global        # XcodeSettgs.        items = dict(XcodeSettgs._plist_cache[configname])        if self.isIOS:            items["UIDeviceFamily"] = self._XcodeIOSDeviceFamily(configname)        return items    def _DefaultSdkRoot(self):        """Returns the default SDKROOT to use.    Prior to version 5.0.0, if SDKROOT was not explicitly set  the Xcode    project, then the environment variable was empty. Startg with     version, Xcode uses the name of the newest SDK stalled.    """        xcode_version, _ = XcodeVersion()        if xcode_version < "0500":            return ""        default_sdk_path = self._XcodeSdkPath("")        default_sdk_root = XcodeSettgs._sdk_root_cache.get(default_sdk_path)        if default_sdk_root:            return default_sdk_root        try:            all_sdks = GetStdout(["xcodebuild", "-showsdks"])        except GypError:            # If xcodebuild fails, there will be no valid SDKs            return ""        for le  all_sdks.splitles():            items = le.split()            if len(items) >= 3  items[-2] == "-sdk":                sdk_root = items[-1]                sdk_path = self._XcodeSdkPath(sdk_root)                if sdk_path == default_sdk_path:                    return sdk_root        return ""class MacPrefixHeader:    """A class that helps with emulatg Xcode's GCC_PREFIX_HEADER feature.  This feature consists of several pieces:  * If GCC_PREFIX_HEADER is present, all compilations  that project get an    additional |-clude path_to_prefix_header| cflag.  * If GCC_PRECOMPILE_PREFIX_HEADER is present too, then the prefix header is    stead compiled,  all other compilations  the project get an    additional |-clude path_to_compiled_header| stead.    + Compiled prefix headers have the extension gch. re is one gch file for      every language used  the project (c, cc, m, mm), sce gch files for      different languages n't compatible.    + gch files themselves  built with the target's normal cflags, but they      obviously don't get the |-clude| flag. Instead, they need a -x flag that      describes their language.    + All o files  the target need to depend on the gch file, to make sure      it's built before any o file is built.  This class helps with some of these tasks, but it needs help from the build  system for writg dependencies to the gch files, for writg build comms  for the gch files,  for figurg out the location of the gch files.  """    def __it__(        self, xcode_settgs, gyp_path_to_build_path, gyp_path_to_build_output    ):        """If xcode_settgs is None, all methods on  class  no-ops.    Args:        gyp_path_to_build_path: A function that takes a gyp-relative path,             returns a path relative to the build directory.        gyp_path_to_build_output: A function that takes a gyp-relative path             a language code ('c', 'cc', 'm', or 'mm'),  that returns a path            to where the output of precompilg that path for that language            should be placed (without the trailg '.gch').    """        # This doesn't support per-configuration prefix headers. Good enough        # for now.        self.header = None        self.compile_headers = False        if xcode_settgs:            self.header = xcode_settgs.GetPerTargetSettg("GCC_PREFIX_HEADER")            self.compile_headers = (                xcode_settgs.GetPerTargetSettg(                    "GCC_PRECOMPILE_PREFIX_HEADER", default="NO"                )                != "NO"            )        self.compiled_headers = {}        if self.header:            if self.compile_headers:                for lang  ["c", "cc", "m", "mm"]:                    self.compiled_headers[lang] = gyp_path_to_build_output(                        self.header, lang                    )            self.header = gyp_path_to_build_path(self.header)    def _CompiledHeader(self, lang, arch):        assert self.compile_headers        h = self.compiled_headers[lang]        if arch:            h += "." + arch        return h    def GetInclude(self, lang, arch=None):        """Gets the cflags to clude the prefix header for language |lang|."""        if self.compile_headers  lang  self.compiled_headers:            return "-clude %s" % self._CompiledHeader(lang, arch)        elif self.header:            return "-clude %s" % self.header        else:            return ""    def _Gch(self, lang, arch):        """Returns the actual file name of the prefix header for language |lang|."""        assert self.compile_headers        return self._CompiledHeader(lang, arch) + ".gch"    def GetObjDependencies(self, sources, objs, arch=None):        """Given a list of source files  the correspondg object files, returns    a list of (source, object, gch) tuples, where |gch| is the build-directory    relative path to the gch file each object file depends on.  |compilable[i]|    has to be the source file belongg to |objs[i]|."""        if not self.header or not self.compile_headers:            return []        result = []        for source, obj  zip(sources, objs):            ext = os.path.splitext(source)[1]            lang = {                ".c": "c",                ".cpp": "cc",                ".cc": "cc",                ".cxx": "cc",                ".m": "m",                ".mm": "mm",            }.get(ext, None)            if lang:                result.append((source, obj, self._Gch(lang, arch)))        return result    def GetPchBuildComms(self, arch=None):        """Returns [(path_to_gch, language_flag, language, header)].    |path_to_gch|  |header|  relative to the build directory.    """        if not self.header or not self.compile_headers:            return []        return [            (self._Gch("c", arch), "-x c-header", "c", self.header),            (self._Gch("cc", arch), "-x c++-header", "cc", self.header),            (self._Gch("m", arch), "-x objective-c-header", "m", self.header),            (self._Gch("mm", arch), "-x objective-c++-header", "mm", self.header),        ]def XcodeVersion():    """Returns a tuple of version  build version of stalled Xcode."""    # `xcodebuild -version` output looks like    #    Xcode 4.6.3    #    Build version 4H1503    # or like    #    Xcode 3.2.6    #    Component versions: DevToolsCore-1809.0; DevToolsSupport-1806.0    #    BuildVersion: 10M2518    # Convert that to ('0463', '4H1503') or ('0326', '10M2518').    global XCODE_VERSION_CACHE    if XCODE_VERSION_CACHE:        return XCODE_VERSION_CACHE    version = ""    build = ""    try:        version_list = GetStdoutQuiet(["xcodebuild", "-version"]).splitles()        # In some circumstances xcodebuild exits 0 but doesn't return        # the right results; for example, a user on 10.7 or 10.8 with        # a bogus path set via xcode-select        # In that case  may be a CLT-only stall so fall back to        # checkg that version.        if len(version_list) < 2:            raise GypError("xcodebuild returned unexpected results")        version = version_list[0].split()[-1]  # Last word on first le        build = version_list[-1].split()[-1]  # Last word on last le    except GypError:  # Xcode not stalled so look for XCode Comm Le Tools        version = CLTVersion()  # macOS Catala returns 11.0.0.0.1.1567737322        if not version:            raise GypError("No Xcode or CLT version detected!")    # Be cful to convert "4.2.3" to "0423"  "11.0.0" to "1100":    version = version.split(".")[:3]  # Just major, mor, micro    version[0] = version[0].zfill(2)  # Add a leadg zero if major is one digit    version = ("".jo(version) + "00")[:4]  # Limit to exactly four characters    XCODE_VERSION_CACHE = (version, build)    return XCODE_VERSION_CACHE# This function ported from the logic  Homebrew's CLT version checkdef CLTVersion():    """Returns the version of comm-le tools from pkgutil."""    # pkgutil output looks like    #   package-id: com.apple.pkg.CLTools_Executables    #   version: 5.0.1.0.1.1382131676    #   volume: /    #   location: /    #   stall-time: 1382544035    #   groups: com.apple.FdSystemFiles.pkg-group    #           com.apple.DevToolsBoth.pkg-group    #           com.apple.DevToolsNonRelocatableShd.pkg-group    STANDALONE_PKG_ID = "com.apple.pkg.DeveloperToolsCLILeo"    FROM_XCODE_PKG_ID = "com.apple.pkg.DeveloperToolsCLI"    MAVERICKS_PKG_ID = "com.apple.pkg.CLTools_Executables"    regex = re.compile("version: (?P<version>.+)")    for key  [MAVERICKS_PKG_ID, STANDALONE_PKG_ID, FROM_XCODE_PKG_ID]:        try:            output = GetStdout(["/usr/sb/pkgutil", "--pkg-fo", key])            return re.search(regex, output).groupdict()["version"]        except GypError:            contue    regex = re.compile(r'Comm Le Tools for Xcode\s+(?P<version>\S+)')    try:        output = GetStdout(["/usr/sb/softwupdate", "--history"])        return re.search(regex, output).groupdict()["version"]    except GypError:        return Nonedef GetStdoutQuiet(cmdlist):    """Returns the content of stard output returned  vokg |cmdlist|.  Ignores the stderr.  Raises |GypError| if the comm return with a non-zero return code."""    job = subprocess.Popen(cmdlist, stdout=subprocess.PIPE, stderr=subprocess.PIPE)    out = job.communicate()[0].decode("utf-8")    if job.returncode != 0:        raise GypError("Error %d runng %s" % (job.returncode, cmdlist[0]))    return out.rstrip("\n")def GetStdout(cmdlist):    """Returns the content of stard output returned  vokg |cmdlist|.  Raises |GypError| if the comm return with a non-zero return code."""    job = subprocess.Popen(cmdlist, stdout=subprocess.PIPE)    out = job.communicate()[0].decode("utf-8")    if job.returncode != 0:        sys.stderr.write(out + "\n")        raise GypError("Error %d runng %s" % (job.returncode, cmdlist[0]))    return out.rstrip("\n")def MergeGlobalXcodeSettgsToSpec(global_dict, spec):    """Merges the global xcode_settgs dictionary to each configuration of the  target represented  spec. For keys that  both  the global  the local  xcode_settgs dict, the local key gets precedence.  """    #  xcode generator special-cases global xcode_settgs  does somethg    # that amounts to mergg  the global xcode_settgs to each local    # xcode_settgs dict.    global_xcode_settgs = global_dict.get("xcode_settgs", {})    for config  spec["configurations"].values():        if "xcode_settgs"  config:            new_settgs = global_xcode_settgs.copy()            new_settgs.update(config["xcode_settgs"])            config["xcode_settgs"] = new_settgsdef IsMacBundle(flavor, spec):    """Returns if |spec| should be treated as a bundle.  Bundles  directories with a certa subdirectory structure, stead of  just a sgle file. Bundle rules do not produce a bary but also package  resources to that directory."""    is_mac_bundle = (        t(spec.get("mac_xctest_bundle", 0)) != 0        or t(spec.get("mac_xcuitest_bundle", 0)) != 0        or (t(spec.get("mac_bundle", 0)) != 0  flavor == "mac")    )    if is_mac_bundle:        assert spec["type"] != "none", (            'mac_bundle targets cannot have type none (target "%s")'            % spec["target_name"]        )    return is_mac_bundledef GetMacBundleResources(product_dir, xcode_settgs, resources):    """Yields (output, resource) pairs for every resource  |resources|.  Only call  for mac bundle targets.  Args:      product_dir: Path to the directory contag the output bundle,          relative to the build directory.      xcode_settgs:  XcodeSettgs of the current target.      resources: A list of bundle resources, relative to the build directory.  """    dest = os.path.jo(product_dir, xcode_settgs.GetBundleResourceFolder())    for res  resources:        output = dest        #  make generator doesn't support it, so forbid it everywhere        # to keep the generators more terchangeable.        assert " " not  res, "Spaces  resource filenames not supported (%s)" % res        # Split to (path,file).        res_parts = os.path.split(res)        # Now split the path to (prefix,maybe.lproj).        lproj_parts = os.path.split(res_parts[0])        # If the resource lives  a .lproj bundle, add that to the destation.        if lproj_parts[1].endswith(".lproj"):            output = os.path.jo(output, lproj_parts[1])        output = os.path.jo(output, res_parts[1])        # Compiled XIB files  referred to  .nib.        if output.endswith(".xib"):            output = os.path.splitext(output)[0] + ".nib"        # Compiled storyboard files  referred to  .storyboardc.        if output.endswith(".storyboard"):            output = os.path.splitext(output)[0] + ".storyboardc"        yield output, resdef GetMacInfoPlist(product_dir, xcode_settgs, gyp_path_to_build_path):    """Returns (fo_plist, dest_plist, defes, extra_env), where:  * |fo_plist| is the source plist path, relative to the    build directory,  * |dest_plist| is the destation plist path, relative to the    build directory,  * |defes| is a list of preprocessor defes (empty if the plist    shouldn't be preprocessed,  * |extra_env| is a dict of env variables that should be exported when    vokg |mac_tool copy-fo-plist|.  Only call  for mac bundle targets.  Args:      product_dir: Path to the directory contag the output bundle,          relative to the build directory.      xcode_settgs:  XcodeSettgs of the current target.      gyp_to_build_path: A function that converts paths relative to the          current gyp file to paths relative to the build directory.  """    fo_plist = xcode_settgs.GetPerTargetSettg("INFOPLIST_FILE")    if not fo_plist:        return None, None, [], {}    #  make generator doesn't support it, so forbid it everywhere    # to keep the generators more terchangeable.    assert " " not  fo_plist, (        "Spaces  Info.plist filenames not supported (%s)" % fo_plist    )    fo_plist = gyp_path_to_build_path(fo_plist)    # If explicitly set to preprocess the plist, voke the C preprocessor     # specify any defes as -D flags.    if (        xcode_settgs.GetPerTargetSettg("INFOPLIST_PREPROCESS", default="NO")        == "YES"    ):        # Create an termediate file based on the path.        defes = shlex.split(            xcode_settgs.GetPerTargetSettg(                "INFOPLIST_PREPROCESSOR_DEFINITIONS", default=""            )        )    else:        defes = []    dest_plist = os.path.jo(product_dir, xcode_settgs.GetBundlePlistPath())    extra_env = xcode_settgs.GetPerTargetSettgs()    return fo_plist, dest_plist, defes, extra_envdef _GetXcodeEnv(    xcode_settgs, built_products_dir, srcroot, configuration, additional_settgs=None):    """Return the environment variables that Xcode would set. See  http://developer.apple.com/library/mac/#documentation/DeveloperTools/Reference/XcodeBuildSettgRef/1-Build_Settg_Reference/build_settg_ref.html#//apple_ref/doc/uid/TP40003931-CH3-SW153  for a full list.  Args:      xcode_settgs: An XcodeSettgs object. If  is None,  function          returns an empty dict.      built_products_dir: Absolute path to the built products dir.      srcroot: Absolute path to the source root.      configuration:  build configuration name.      additional_settgs: An optional dict with more values to add to the          result.  """    if not xcode_settgs:        return {}    # This function is considered a friend of XcodeSettgs, so let it reach to    # its implementation details.    spec = xcode_settgs.spec    # se  filled  on an as-needed basis.    env = {        "BUILT_FRAMEWORKS_DIR": built_products_dir,        "BUILT_PRODUCTS_DIR": built_products_dir,        "CONFIGURATION": configuration,        "PRODUCT_NAME": xcode_settgs.GetProductName(),        # For FULL_PRODUCT_NAME see:        # /Developer/Platforms/MacOSX.platform/Developer/Library/Xcode/Specifications/MacOSX\ Product\ Types.xcspec  # noqa: E501        "SRCROOT": srcroot,        "SOURCE_ROOT": "${SRCROOT}",        # This is not true for static libraries, but currently the env is only        #  for bundles:        "TARGET_BUILD_DIR": built_products_dir,        "TEMP_DIR": "${TMPDIR}",        "XCODE_VERSION_ACTUAL": XcodeVersion()[0],    }    if xcode_settgs.GetPerConfigSettg("SDKROOT", configuration):        env["SDKROOT"] = xcode_settgs._SdkPath(configuration)    else:        env["SDKROOT"] = ""    if xcode_settgs.mac_toolcha_dir:        env["DEVELOPER_DIR"] = xcode_settgs.mac_toolcha_dir    if spec["type"]  (        "executable",        "static_library",        "shd_library",        "loadable_module",    ):        env["EXECUTABLE_NAME"] = xcode_settgs.GetExecutableName()        env["EXECUTABLE_PATH"] = xcode_settgs.GetExecutablePath()        env["FULL_PRODUCT_NAME"] = xcode_settgs.GetFullProductName()        mach_o_type = xcode_settgs.GetMachOType()        if mach_o_type:            env["MACH_O_TYPE"] = mach_o_type        env["PRODUCT_TYPE"] = xcode_settgs.GetProductType()    if xcode_settgs._IsBundle():        # xcodeproj_file.py sets the same Xcode subfolder value for  as for        # FRAMEWORKS_FOLDER_PATH so Xcode builds will actually use FFP's value.        env["BUILT_FRAMEWORKS_DIR"] = os.path.jo(            built_products_dir + os.sep + xcode_settgs.GetBundleFrameworksFolderPath()        )        env["CONTENTS_FOLDER_PATH"] = xcode_settgs.GetBundleContentsFolderPath()        env["EXECUTABLE_FOLDER_PATH"] = xcode_settgs.GetBundleExecutableFolderPath()        env[            "UNLOCALIZED_RESOURCES_FOLDER_PATH"        ] = xcode_settgs.GetBundleResourceFolder()        env["JAVA_FOLDER_PATH"] = xcode_settgs.GetBundleJavaFolderPath()        env["FRAMEWORKS_FOLDER_PATH"] = xcode_settgs.GetBundleFrameworksFolderPath()        env[            "SHARED_FRAMEWORKS_FOLDER_PATH"        ] = xcode_settgs.GetBundleShdFrameworksFolderPath()        env[            "SHARED_SUPPORT_FOLDER_PATH"        ] = xcode_settgs.GetBundleShdSupportFolderPath()        env["PLUGINS_FOLDER_PATH"] = xcode_settgs.GetBundlePlugInsFolderPath()        env["XPCSERVICES_FOLDER_PATH"] = xcode_settgs.GetBundleXPCServicesFolderPath()        env["INFOPLIST_PATH"] = xcode_settgs.GetBundlePlistPath()        env["WRAPPER_NAME"] = xcode_settgs.GetWrapperName()    stall_name = xcode_settgs.GetInstallName()    if stall_name:        env["LD_DYLIB_INSTALL_NAME"] = stall_name    stall_name_base = xcode_settgs.GetInstallNameBase()    if stall_name_base:        env["DYLIB_INSTALL_NAME_BASE"] = stall_name_base    xcode_version, _ = XcodeVersion()    if xcode_version >= "0500"  not env.get("SDKROOT"):        sdk_root = xcode_settgs._SdkRoot(configuration)        if not sdk_root:            sdk_root = xcode_settgs._XcodeSdkPath("")        if sdk_root is None:            sdk_root = ""        env["SDKROOT"] = sdk_root    if not additional_settgs:        additional_settgs = {}    else:        # Flatten lists to strgs.        for k  additional_settgs:            if not isstance(additional_settgs[k], str):                additional_settgs[k] = " ".jo(additional_settgs[k])    additional_settgs.update(env)    for k  additional_settgs:        additional_settgs[k] = _NormalizeEnvVarReferences(additional_settgs[k])    return additional_settgsdef _NormalizeEnvVarReferences(str):    """Takes a strg contag variable references  the form ${FOO}, $(FOO),  or $FOO,  returns a strg with all variable references  the form ${FOO}.  """    # $FOO -> ${FOO}    str = re.sub(r"\$([a-zA-Z_][a-zA-Z0-9_]*)", r"${\1}", str)    # $(FOO) -> ${FOO}    matches = re.fdall(r"(\$\(([a-zA-Z0-9\-_]+)\))", str)    for match  matches:        to_replace, variable = match        assert "$(" not  match, "$($(FOO)) variables not supported: " + match        str = str.replace(to_replace, "${" + variable + "}")    return strdef ExpEnvVars(strg, expansions):    """Exps ${VARIABLES}, $(VARIABLES),  $VARIABLES  strg per the  expansions list. If the variable exps to somethg that references  another variable,  variable is exped as well if it's  env --  until no variables present  env  left."""    for k, v  reversed(expansions):        strg = strg.replace("${" + k + "}", v)        strg = strg.replace("$(" + k + ")", v)        strg = strg.replace("$" + k, v)    return strgdef _TopologicallySortedEnvVarKeys(env):    """Takes a dict |env| whose values  strgs that can refer to other keys,  for example env['foo'] = '$(bar)  $(baz)'. Returns a list L of all keys of  env such that key2 is after key1  L if env[key2] refers to env[key1].  Throws an Exception  case of dependency cycles.  """    # Sce environment variables can refer to other variables, the evaluation    # order is important. Below is the logic to compute the dependency graph    #  sort it.    regex = re.compile(r"\$\{([a-zA-Z0-9\-_]+)\}")    def GetEdges(node):        # Use a defition of edges such that user_of_variable -> used_varible.        # This happens to be easier   case, sce a variable's        # defition contas all variables it references  a sgle strg.        # We can then reverse the result of the topological sort at the end.        # Sce: reverse(topsort(DAG)) = topsort(reverse_edges(DAG))        matches = {v for v  regex.fdall(env[node]) if v  env}        for dependee  matches:            assert "${" not  dependee, "Nested variables not supported: " + dependee        return matches    try:        # Topologically sort,  then reverse, because we used an edge defition        # that's verted from the expected result of  function (see comment        # above).        order = gyp.common.TopologicallySorted(env.keys(), GetEdges)        order.reverse()        return order    except gyp.common.CycleError as e:        raise GypError(            "Xcode environment variables  cyclically dependent: " + str(e.nodes)        )def GetSortedXcodeEnv(    xcode_settgs, built_products_dir, srcroot, configuration, additional_settgs=None):    env = _GetXcodeEnv(        xcode_settgs, built_products_dir, srcroot, configuration, additional_settgs    )    return [(key, env[key]) for key  _TopologicallySortedEnvVarKeys(env)]def GetSpecPostbuildComms(spec, quiet=False):    """Returns the list of postbuilds explicitly defed on |spec|,  a form  executable  a shell."""    postbuilds = []    for postbuild  spec.get("postbuilds", []):        if not quiet:            postbuilds.append(                "echo POSTBUILD\\(%s\\) %s"                % (spec["target_name"], postbuild["postbuild_name"])            )        postbuilds.append(gyp.common.EncodePOSIXShellList(postbuild["action"]))    return postbuildsdef _HasIOSTarget(targets):    """Returns true if any target contas the iOS specific key  IPHONEOS_DEPLOYMENT_TARGET."""    for target_dict  targets.values():        for config  target_dict["configurations"].values():            if config.get("xcode_settgs", {}).get("IPHONEOS_DEPLOYMENT_TARGET"):                return True    return Falsedef _AddIOSDeviceConfigurations(targets):    """Clone all targets  append -iphoneos to the name. Configure these targets  to build for iOS devices  use correct architectures for those builds."""    for target_dict  targets.values():        toolset = target_dict["toolset"]        configs = target_dict["configurations"]        for config_name, simulator_config_dict  dict(configs).items():            iphoneos_config_dict = copy.deepcopy(simulator_config_dict)            configs[config_name + "-iphoneos"] = iphoneos_config_dict            configs[config_name + "-iphonesimulator"] = simulator_config_dict            if toolset == "target":                simulator_config_dict["xcode_settgs"]["SDKROOT"] = "iphonesimulator"                iphoneos_config_dict["xcode_settgs"]["SDKROOT"] = "iphoneos"    return targetsdef CloneConfigurationForDeviceAndEmulator(target_dicts):    """If |target_dicts| contas any iOS targets, automatically create -iphoneos  targets for iOS device builds."""    if _HasIOSTarget(target_dicts):        return _AddIOSDeviceConfigurations(target_dicts)    return target_dicts# `node-gyp` - Node.js native addon build tool[![Build Status](https://github.com/nodejs/node-gyp/workflows/Tests/badge.svg?branch=master)](https://github.com/nodejs/node-gyp/actions?query=workflow%3ATests+branch%3Amaster)![npm](https://img.shields.io/npm/dm/node-gyp)`node-gyp` is a cross-platform comm-le tool   Node.js forcompilg native addon modules for Node.js. It contas a vendored copy of the[gyp-next](https://github.com/nodejs/gyp-next) project that was previously used the Chromium team, extended to support the development of Node.js native addons.Note that `node-gyp` is _not_ used to build Node.js itself.Multiple target versions of Node.js  supported (i.e. `0.8`, ..., `4`, `5`, `6`,etc.), regardless of what version of Node.js is actually stalled on your system(`node-gyp` downloads the necessary development files or headers for the target version).## Features *  same build comms work on any of the supported platforms * Supports the targetg of different versions of Node.js## InstallationYou can stall `node-gyp` usg `npm`:``` bashnpm stall -g node-gyp```Dependg on your operatg system, you will need to stall:### On Unix   * Python v3.7, v3.8, v3.9, or v3.10   * `make`   * A proper C/C++ compiler toolcha, like [GCC](https://gcc.gnu.org)### On macOS**ATTENTION**: If your Mac has been _upgraded_ to macOS Catala (10.15), please read [macOS_Catala.md](macOS_Catala.md).   * Python v3.7, v3.8, v3.9, or v3.10   * `XCode Comm Le Tools` which will stall `clang`, `clang++`,  `make`.     * Install the `XCode Comm Le Tools` stalone  runng `xcode-select --stall`. -- OR --     * Alternatively, if you already have the [full Xcode stalled](https://developer.apple.com/xcode/download/), you can stall the Comm Le Tools under the menu `Xcode -> Open Developer Tool -> More Developer Tools...`.### On WdowsInstall the current version of Python from the [Microsoft Store package](https://www.microsoft.com/en-us/p/python-310/9pjpw5ldxlz5).Install tools  configuration manually:   * Install Visual C++ Build Environment: [Visual Studio Build Tools](https://visualstudio.microsoft.com/thank-you-downloadg-visual-studio/?sku=BuildTools)   (usg "Visual C++ build tools" workload) or [Visual Studio Community](https://visualstudio.microsoft.com/thank-you-downloadg-visual-studio/?sku=Community)   (usg the "Desktop development with C++" workload)   * Launch cmd, `npm config set msvs_version 2017`   If the above steps didn't work for you, please visit [Microsoft's Node.js Guideles for Wdows](https://github.com/Microsoft/nodejs-guideles/blob/master/wdows-environment.md#compilg-native-addon-modules) for additional tips.   To target native ARM64 Node.js on Wdows 10 on ARM, add the components "Visual C++ compilers  libraries for ARM64"  "Visual C++ ATL for ARM64".### Configurg Python Dependency`node-gyp` requires that you have stalled a compatible version of Python, one of: v3.7, v3.8,v3.9, or v3.10. If you have multiple Python versions stalled, you can identify which Pythonversion `node-gyp` should use  one of the followg ways:1.  settg the `--python` comm-le option, e.g.:``` bashnode-gyp <comm> --python /path/to/executable/python```2. If `node-gyp` is called  way of `npm`, ** you have multiple versions ofPython stalled, then you can set `npm`'s 'python' config key to the appropriatevalue:``` bashnpm config set python /path/to/executable/python```3. If the `PYTHON` environment variable is set to the path of a Python executable,then that version will be used, if it is a compatible version.4. If the `NODE_GYP_FORCE_PYTHON` environment variable is set to the path of aPython executable, it will be used stead of any of the other configured orbuilt Python search paths. If it's not a compatible version, no furthersearchg will be done.### Build for Third Party Node.js RuntimesWhen buildg modules for thid party Node.js runtimes like Electron, which havedifferent build configurations from the official Node.js distribution, youshould use `--dist-url` or `--nodedir` flags to specify the headers of theruntime to build for.Also when `--dist-url` or `--nodedir` flags  passed, node-gyp will use the`config.gypi` shipped  the headers distribution to generate buildconfigurations, which is different from the default mode that would use the`process.config` object of the runng Node.js stance.Some old versions of Electron shipped malformed `config.gypi`  their headersdistributions,  you might need to pass `--force-process-config` to node-gypto work around configuration errors.## How to UseTo compile your native addon, first go to its root directory:``` bashcd my_node_addon``` next step is to generate the appropriate project build files for the currentplatform. Use `configure` for that:``` bashnode-gyp configure```Auto-detection fails for Visual C++ Build Tools 2015, so `--msvs_version=2015`needs to be added (not needed when run  npm as configured above):``` bashnode-gyp configure --msvs_version=2015```__Note__:  `configure` step looks for a `bdg.gyp` file  the currentdirectory to process. See below for structions on creatg a `bdg.gyp` file.Now you will have either a `Makefile` (on Unix platforms) or a `vcxproj` file(on Wdows)  the `build/` directory. Next, voke the `build` comm:``` bashnode-gyp build```Now you have your compiled `.node` bdgs file!  compiled bdgs end up `build/Debug/` or `build/Release/`, dependg on the build mode. At  pot,you can require the `.node` file with Node.js  run your tests!__Note:__ To create a _Debug_ build of the bdgs file, pass the `--debug` (or`-d`) switch when runng either the `configure`, `build` or `rebuild` comms.##  `bdg.gyp` fileA `bdg.gyp` file describes the configuration to build your module,  aJSON-like format. This file gets placed  the root of your package, alongside`package.json`.A bbones `gyp` file appropriate for buildg a Node.js addon could look like:```python{  "targets": [    {      "target_name": "bdg",      "sources": [ "src/bdg.cc" ]    }  ]}```## Further readg **[docs](./docs/)** directory contas additional documentation on specific node-gyp topics that may be useful if you  experiencg problems stallg or buildg addons usg node-gyp.Some additional resources for Node.js native addons  writg `gyp` configuration files: * ["Gog Native" a nodeschool.io tutorial](http://nodeschool.io/#gognative) * ["Hello World" node addon example](https://github.com/nodejs/node/tree/master/test/addons/hello-world) * [gyp user documentation](https://gyp.gsrc.io/docs/UserDocumentation.md) * [gyp put format reference](https://gyp.gsrc.io/docs/InputFormatReference.md) * [*"bdg.gyp" files out  the wild* wiki page](./docs/bdg.gyp-files--the-wild.md)## Comms`node-gyp` responds to the followg comms:| **Comm**   | **Description**|:--------------|:---------------------------------------------------------------| `help`        | Shows the help dialog| `build`       | Invokes `make`/`msbuild.exe`  builds the native addon| `clean`       | Removes the `build` directory if it exists| `configure`   | Generates project build files for the current platform| `rebuild`     | Runs `clean`, `configure`  `build` all  a row| `stall`     | Installs Node.js header files for the given version| `list`        | Lists the currently stalled Node.js header versions| `remove`      | Removes the Node.js header files for the given version## Comm Options`node-gyp` accepts the followg comm options:| **Comm**                       | **Description**|:----------------------------------|:------------------------------------------| `-j n`, `--jobs n`                | Run `make`  parallel.  value `max` will use all available CPU cores| `--target=v6.2.1`                 | Node.js version to build for (default is `process.version`)| `--silly`, `--loglevel=silly`     | Log all progress to console| `--verbose`, `--loglevel=verbose` | Log most progress to console| `--silent`, `--loglevel=silent`   | Don't log anythg to console| `debug`, `--debug`                | Make Debug build (default is `Release`)| `--release`, `--no-debug`         | Make Release build| `-C $dir`, `--directory=$dir`     | Run comm  different directory| `--make=$make`                    | Override `make` comm (e.g. `gmake`)| `--th=yes`                      | Enable th static libraries| `--arch=$arch`                    | Set target architecture (e.g. ia32)| `--tarball=$path`                 | Get headers from a local tarball| `--devdir=$path`                  | SDK download directory (default is OS cache directory)| `--ensure`                        | Don't restall headers if already present| `--dist-url=$url`                 | Download header tarball from custom URL| `--proxy=$url`                    | Set HTTP(S) proxy for downloadg header tarball| `--noproxy=$urls`                 | Set urls to ignore proxies when downloadg header tarball| `--cafile=$cafile`                | Override default CA cha (to download tarball)| `--nodedir=$path`                 | Set the path to the node source code| `--python=$path`                  | Set path to the Python bary| `--msvs_version=$version`         | Set Visual Studio version (Wdows only)| `--solution=$solution`            | Set Visual Studio Solution version (Wdows only)| `--force-process-config`          | Force usg runtime's `process.config` object to generate `config.gypi` file## Configuration### Environment variablesUse the form `npm_config_OPTION_NAME` for any of the comm options listedabove (dashes  option names should be replaced  underscores).For example, to set `devdir` equal to `/tmp/.gyp`, you would:Run  on Unix:```bashexport npm_config_devdir=/tmp/.gyp```Or  on Wdows:```consoleset npm_config_devdir=c:\temp\.gyp```### `npm` configurationUse the form `OPTION_NAME` for any of the comm options listed above.For example, to set `devdir` equal to `/tmp/.gyp`, you would run:```bashnpm config set [--global] devdir /tmp/.gyp```**Note:** Configuration set via `npm` will only be used when `node-gyp`is run via `npm`, not when `node-gyp` is run directly.## License`node-gyp` is available under the MIT license. See the [LICENSEfile](LICENSE) for details.{  "name": "promise-retry",  "version": "2.0.1",  "description": "Retries a function that returns a promise, leveragg the power of the retry module.",  "ma": "dex.js",  "scripts": {    "test": "mocha --bail -t 10000"  },  "bugs": {    "url": "https://github.com/IndigoUnited/node-promise-retry/issues/"  },  "repository": {    "type": "git",    "url": "git://github.com/IndigoUnited/node-promise-retry.git"  },  "keywords": [    "retry",    "promise",    "backoff",    "repeat",    "replay"  ],  "author": "IndigoUnited <hello@digounited.com> (http://digounited.com)",  "license": "MIT",  "devDependencies": {    "expect.js": "^0.3.1",    "mocha": "^8.0.1",    "sleep-promise": "^8.0.1"  },  "dependencies": {    "err-code": "^2.0.2",    "retry": "^0.12.0"  },  "enges": {    "node": ">=10"  }}#!/usr/b/env node/*! * Module dependencies. */var qrcode = require('../lib/ma'),    path = require('path'),    fs = require('fs');/*! * Parse the process name */var name = process.argv[1].replace(/^.*[\\\/]/, '').replace('.js', '');/*! * Parse the put */if (process.std.isTTY) {    // called with put as argument, e.g.:    // ./qrcode-termal.js "INPUT"    var put = process.argv[2];    hleInput(put);} else {    // called with piped put, e.g.:    // echo "INPUT" | ./qrcode-termal.js    var readle = require('readle');    var terface = readle.createInterface({        put: process.std,        output: process.stdout,        termal: false    });    terface.on('le', function(le) {        hleInput(le);    });}/*! * Process the put */function hleInput(put) {    /*!     * Display help     */    if (!put || put === '-h' || put === '--help') {        help();        process.exit();    }    /*!     * Display version     */    if (put === '-v' || put === '--version') {        version();        process.exit();    }    /*!     * Render the QR Code     */    qrcode.generate(put);}/*! * Helper functions */function help() {    console.log([        '',        'Usage: ' + name + ' <message>',        '',        'Options:',        '  -h, --help           output usage formation',        '  -v, --version        output version number',        '',        'Examples:',        '',        '  $ ' + name + ' hello',        '  $ ' + name + ' "hello world"',        ''    ].jo('\n'));}function version() {    var packagePath = path.jo(__dirname, '..', 'package.json'),        packageJSON = JSON.parse(fs.readFileSync(packagePath), 'utf8');    console.log(packageJSON.version);}# socks examples## Example for SOCKS 'associate' comm associate comm tells the SOCKS proxy server to establish a UDP relay.  server bds to a new UDP port  communicates the newly opened port back to the orig client. From here, any SOCKS UDP frame packets sent to  special UDP port on the Proxy server will be forwarded to the desired destation,  any responses will be forwarded back to the orig client (you).This can be used for thgs such as DNS queries,  other UDP communicates.**Connection Steps**1. Client -(associate)-> Proxy (Tells the proxy to create a UDP relay  bd on a new port)2. Client <-(port)- Proxy (Tells the orig client which port it opened  is acceptg UDP frame packets on)At  pot the proxy is acceptg UDP frames on the specified port.3. Client --(udp frame) -> Proxy -> Destation ( orig client sends a UDP frame to the proxy on the UDP port,  the proxy then forwards it to the destation specified  the UDP frame.)4. Client <--(udp frame) <-- Proxy <-- Destation ( destation client responds to the udp packet sent  #3)## Usage 'associate' comm can only be used  creatg a new SocksClient stance  listeng for the 'established' event.**Note:** UDP packets relayed through the proxy servers  encompassed  a special Socks UDP frame format. SocksClient.createUDPFrame()  SocksClient.parseUDPFrame() create  parse these special UDP packets.```typescriptconst dgram = require('dgram');const SocksClient = require('socks').SocksClient;// Create a local UDP socket for sendg/receivg packets to/from the proxy.const udpSocket = dgram.createSocket('udp4');udpSocket.bd();// Listen for comg UDP packets from the proxy server.udpSocket.on('message', (message, rfo) => {  console.log(SocksClient.parseUDPFrame(message));  /*  { frameNumber: 0,    remoteHost: { host: '8.8.8.8', port: 53 }, //  remote host that replied with a UDP packet    data: <Buffer 74 65 73 74 0a> //  data  }  */});const options = {  proxy: {    host: '104.131.124.203',    port: 1081,    type: 5  },  // This should be the ip  port of the expected client that will be sendg UDP frames to the newly opened UDP port on the server.  // Most SOCKS servers accept 0.0.0.0 as a wildcard address to accept UDP frames from any source.  destation: {    host: '0.0.0.0',    port: 0  },  comm: 'associate'};const client = new SocksClient(options);// This event is fired when the SOCKS server has started listeng on a new UDP port for UDP relayg.client.on('established', fo => {  console.log(fo);  /*  {    socket: <Socket ...>,    remoteHost: { // This is the remote port on the SOCKS proxy server to send UDP frame packets to.      host: '104.131.124.203',      port: 58232    }  }  */  // Send a udp frame to 8.8.8.8 on port 53 through the proxy.  const packet = SocksClient.createUDPFrame({    remoteHost: { host: '8.8.8.8', port: 53 },    data: Buffer.from('hello') // A DNS lookup  the real world.  });  // Send packet.  udpSocket.send(packet, fo.remoteHost.port, fo.remoteHost.host);});// SOCKS proxy failed to bd.client.on('error', () => {  // Hle errors});```# socks examples## Example for SOCKS 'associate' comm associate comm tells the SOCKS proxy server to establish a UDP relay.  server bds to a new UDP port  communicates the newly opened port back to the orig client. From here, any SOCKS UDP frame packets sent to  special UDP port on the Proxy server will be forwarded to the desired destation,  any responses will be forwarded back to the orig client (you).This can be used for thgs such as DNS queries,  other UDP communicates.**Connection Steps**1. Client -(associate)-> Proxy (Tells the proxy to create a UDP relay  bd on a new port)2. Client <-(port)- Proxy (Tells the orig client which port it opened  is acceptg UDP frame packets on)At  pot the proxy is acceptg UDP frames on the specified port.3. Client --(udp frame) -> Proxy -> Destation ( orig client sends a UDP frame to the proxy on the UDP port,  the proxy then forwards it to the destation specified  the UDP frame.)4. Client <--(udp frame) <-- Proxy <-- Destation ( destation client responds to the udp packet sent  #3)## Usage 'associate' comm can only be used  creatg a new SocksClient stance  listeng for the 'established' event.**Note:** UDP packets relayed through the proxy servers  packaged  a special Socks UDP frame format. SocksClient.createUDPFrame()  SocksClient.parseUDPFrame() create  parse these special UDP packets.```typescriptimport * as dgram from 'dgram';import { SocksClient, SocksClientOptions } from 'socks';// Create a local UDP socket for sendg/receivg packets to/from the proxy.const udpSocket = dgram.createSocket('udp4');udpSocket.bd();// Listen for comg UDP packets from the proxy server.udpSocket.on('message', (message, rfo) => {  console.log(SocksClient.parseUDPFrame(message));  /*  { frameNumber: 0,    remoteHost: { host: '8.8.8.8', port: 53 }, //  remote host that replied with a UDP packet    data: <Buffer 74 65 73 74 0a> //  data  }  */});const options: SocksClientOptions = {  proxy: {    host: '104.131.124.203',    port: 1081,    type: 5  },  // This should be the ip  port of the expected client that will be sendg UDP frames to the newly opened UDP port on the server.  // Most SOCKS servers accept 0.0.0.0 as a wildcard address to accept UDP frames from any source.  destation: {    host: '0.0.0.0',    port: 0  },  comm: 'associate'};const client = new SocksClient(options);// This event is fired when the SOCKS server has started listeng on a new UDP port for UDP relayg.client.on('established', fo => {  console.log(fo);  /*  {    socket: <Socket ...>,    remoteHost: { // This is the remote port on the SOCKS proxy server to send UDP frame packets to.      host: '104.131.124.203',      port: 58232    }  }  */  // Send a udp frame to 8.8.8.8 on port 53 through the proxy.  const packet = SocksClient.createUDPFrame({    remoteHost: { host: '8.8.8.8', port: 53 },    data: Buffer.from('hello') // A DNS lookup  the real world.  });  // Send packet.  udpSocket.send(packet, fo.remoteHost.port, fo.remoteHost.host);});// SOCKS proxy failed to bd.client.on('error', () => {  // Hle errors});// Start connectionclient.connect();```{  "name": "socks-proxy-agent",  "description": "A SOCKS proxy `http.Agent` implementation for HTTP  HTTPS",  "homepage": "https://github.com/TooTallNate/node-socks-proxy-agent#readme",  "version": "6.2.0",  "ma": "dist/dex.js",  "author": {    "email": "nathan@tootallnate.net",    "name": "Nathan Rajlich",    "url": "http://n8.io/"  },  "contributors": [    {      "name": "Kiko Beats",      "email": "josefrancisco.verdu@gmail.com"    },    {      "name": "Josh Glazebrook",      "email": "josh@joshglazebrook.com"    },    {      "name": "talmobi",      "email": "talmobi@users.noreply.github.com"    },    {      "name": "Indospace.io",      "email": "just@dospace.io"    },    {      "name": "Kilian von Pflugk",      "email": "github@jumoog.io"    },    {      "name": "Kyle",      "email": "adm@hk1229.cn"    },    {      "name": "Matheus Fernes",      "email": "matheus.frndes@gmail.com"    },    {      "name": "Shantanu Sharma",      "email": "shantanu34@outlook.com"    },    {      "name": "Tim Perry",      "email": "pimterry@gmail.com"    },    {      "name": "Vadim Baryshev",      "email": "vadimbaryshev@gmail.com"    },    {      "name": "jigu",      "email": "luo1257857309@gmail.com"    },    {      "name": "Alba Mendez",      "email": "me@jmendeth.com"    },    {      "name": "ÐÐ¼Ð¸ÑÑÐ¸Ð¹ ÐÑÐ´ÐµÐ½ÐºÐ¾Ð²",      "email": "Dimangud@rambler.ru"    },    {      "name": "Andrei Bitca",      "email": "63638922+rei-bitca-dc@users.noreply.github.com"    },    {      "name": "Andrew Casey",      "email": "amcasey@users.noreply.github.com"    },    {      "name": "Bron Ros",      "email": "bronros1@gmail.com"    },    {      "name": "Dang Duy Thanh",      "email": "thanhdd.it@gmail.com"    },    {      "name": "Dimitar Nestorov",      "email": "8790386+dimitarnestorov@users.noreply.github.com"    }  ],  "repository": {    "type": "git",    "url": "git://github.com/TooTallNate/node-socks-proxy-agent.git"  },  "bugs": {    "url": "https://github.com/TooTallNate/node-socks-proxy-agent/issues"  },  "keywords": [    "agent",    "http",    "https",    "proxy",    "socks",    "socks4",    "socks4a",    "socks5",    "socks5h"  ],  "dependencies": {    "agent-base": "^6.0.2",    "debug": "^4.3.3",    "socks": "^2.6.2"  },  "devDependencies": {    "@commitlt/cli": "latest",    "@commitlt/config-conventional": "latest",    "@types/debug": "latest",    "@types/node": "latest",    "cacheable-lookup": "^6.0.4",    "conventional-github-releaser": "latest",    "dns2": "^2.0.1",    "fepack": "latest",    "git-authors-cli": "latest",    "mocha": "latest",    "nano-staged": "latest",    "npm-check-updates": "latest",    "prettier-stard": "latest",    "raw-body": "latest",    "rimraf": "latest",    "simple-git-hooks": "latest",    "socksv5": "github:TooTallNate/socksv5#fix/dstSock-close-event",    "stard": "latest",    "stard-markdown": "latest",    "stard-version": "latest",    "ts-stard": "latest",    "typescript": "latest"  },  "enges": {    "node": ">= 10"  },  "files": [    "dist"  ],  "license": "MIT",  "commitlt": {    "extends": [      "@commitlt/config-conventional"    ]  },  "nano-staged": {    "*.js": [      "prettier-stard"    ],    "*.md": [      "stard-markdown"    ],    "package.json": [      "fepack"    ]  },  "simple-git-hooks": {    "commit-msg": "npx commitlt --edit",    "pre-commit": "npx nano-staged"  },  "typgs": "dist/dex.d.ts",  "scripts": {    "build": "tsc",    "clean": "rimraf node_modules",    "contributors": "(git-authors-cli && fepack && git add package.json && git commit -m 'build: contributors' --no-verify) || true",    "lt": "ts-stard",    "postrelease": "npm run release:tags && npm run release:github && (ci-publish || npm publish --access=public)",    "prebuild": "rimraf dist",    "prerelease": "npm run update:check && npm run contributors",    "release": "stard-version -a",    "release:github": "conventional-github-releaser -p angular",    "release:tags": "git push --follow-tags orig HEAD:master",    "test": "mocha --reporter spec",    "update": "ncu -u",    "update:check": "ncu -- --error-level 2"  },  "readme": "socks-proxy-agent\n================\n### A SOCKS proxy `http.Agent` implementation for HTTP  HTTPS\n[![Build Status](https://github.com/TooTallNate/node-socks-proxy-agent/workflows/Node%20CI/badge.svg)](https://github.com/TooTallNate/node-socks-proxy-agent/actions?workflow=Node+CI)\n\nThis module provides an `http.Agent` implementation that connects to a\nspecified SOCKS proxy server,  can be used with the built- `http`\n `https` modules.\n\nIt can also be used  conjunction with the `ws` module to establish a WebSocket\nconnection over a SOCKS proxy. See the \"Examples\" section below.\n\nInstallation\n------------\n\nInstall with `npm`:\n\n``` bash\nnpm stall socks-proxy-agent\n```\n\n\nExamples\n--------\n\n#### TypeScript example\n\n```ts\nimport https from 'https';\nimport { SocksProxyAgent } from 'socks-proxy-agent';\n\nconst fo = {\n\thostname: 'br41.nordvpn.com',\n\tuserId: 'your-name@gmail.com',\n\tpassword: 'abcdef12345124'\n};\nconst agent = new SocksProxyAgent(fo);\n\nhttps.get('https://ipfo.io', { agent }, (res) => {\n\tconsole.log(res.headers);\n\tres.pipe(process.stdout);\n});\n```\n\n#### `http` module example\n\n```js\nvar url = require('url');\nvar http = require('http');\nvar { SocksProxyAgent } = require('socks-proxy-agent');\n\n// SOCKS proxy to connect to\nvar proxy = process.env.socks_proxy || 'socks://127.0.0.1:1080';\nconsole.log('usg proxy server %j', proxy);\n\n// HTTP endpot for the proxy to connect to\nvar endpot = process.argv[2] || 'http://nodejs.org/api/';\nconsole.log('attemptg to GET %j', endpot);\nvar opts = url.parse(endpot);\n\n// create an stance of the `SocksProxyAgent` class with the proxy server formation\nvar agent = new SocksProxyAgent(proxy);\nopts.agent = agent;\n\nhttp.get(opts, function (res) {\n\tconsole.log('\"response\" event!', res.headers);\n\tres.pipe(process.stdout);\n});\n```\n\n#### `https` module example\n\n```js\nvar url = require('url');\nvar https = require('https');\nvar { SocksProxyAgent } = require('socks-proxy-agent');\n\n// SOCKS proxy to connect to\nvar proxy = process.env.socks_proxy || 'socks://127.0.0.1:1080';\nconsole.log('usg proxy server %j', proxy);\n\n// HTTP endpot for the proxy to connect to\nvar endpot = process.argv[2] || 'https://encrypted.google.com/';\nconsole.log('attemptg to GET %j', endpot);\nvar opts = url.parse(endpot);\n\n// create an stance of the `SocksProxyAgent` class with the proxy server formation\nvar agent = new SocksProxyAgent(proxy);\nopts.agent = agent;\n\nhttps.get(opts, function (res) {\n\tconsole.log('\"response\" event!', res.headers);\n\tres.pipe(process.stdout);\n});\n```\n\n#### `ws` WebSocket connection example\n\n``` js\nvar WebSocket = require('ws');\nvar { SocksProxyAgent } = require('socks-proxy-agent');\n\n// SOCKS proxy to connect to\nvar proxy = process.env.socks_proxy || 'socks://127.0.0.1:1080';\nconsole.log('usg proxy server %j', proxy);\n\n// WebSocket endpot for the proxy to connect to\nvar endpot = process.argv[2] || 'ws://echo.websocket.org';\nconsole.log('attemptg to connect to WebSocket %j', endpot);\n\n// create an stance of the `SocksProxyAgent` class with the proxy server formation\nvar agent = new SocksProxyAgent(proxy);\n\n// itiate the WebSocket connection\nvar socket = new WebSocket(endpot, { agent: agent });\n\nsocket.on('open', function () {\n\tconsole.log('\"open\" event!');\n\tsocket.send('hello world');\n});\n\nsocket.on('message', function (data, flags) {\n\tconsole.log('\"message\" event! %j %j', data, flags);\n\tsocket.close();\n});\n```\n\nLicense\n-------\n\n( MIT License)\n\nCopyright (c) 2013 Nathan Rajlich &lt;nathan@tootallnate.net&gt;\n\nPermission is here granted, free of charge, to any person obtag\na copy of  softw  associated documentation files (the\n'Softw'), to deal  the Softw without restriction, cludg\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, /or sell copies of the Softw,  to\npermit persons to whom the Softw is furnished to do so, subject to\nthe followg conditions:\n\n above copyright notice   permission notice shall be\ncluded  all copies or substantial portions of the Softw.\n\nTHE  IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n OR THE USE OR OTHER  IN THE .\n"}